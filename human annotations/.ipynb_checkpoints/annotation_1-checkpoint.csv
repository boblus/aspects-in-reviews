review,question,yes,no,explanation
* The authors have included ablation tests to demonstrate the robustness of their approach.,Does the review address Result?,FALSE,TRUE,This sentence focuses on describing ablation tests rather than discussing results or findings.
3) The authors compared the robustness of the NVIB-regularized model with that of a regular transformer and found the former more robust to noisy input.,Does the review address Comparison?,TRUE,FALSE,The review directly compares the NVIB-regularized model with a regular transformer.
Proposes a novel approach by combining ideas from active learning and human-AI collaboration.,Does the review address Methodology?,TRUE,FALSE,The review describes the methodological approach of combining active learning and human-AI collaboration.
"Buf if that's the case, then there's a controllable parameter that implicitly controls an entropy constraint and it's no longer clear to me that low-entropy is emerging.",Does the review address Methodology?,TRUE,FALSE,The review discusses technical aspects of the methodology regarding parameter control and entropy constraints.
Provide additional feedback with the aim to improve the paper.,Does the review address Result?,FALSE,TRUE,"This is a meta-comment about providing feedback, not about results."
3) The authors compared the robustness of the NVIB-regularized model with that of a regular transformer and found the former more robust to noisy input.,Does the review address Result?,TRUE,FALSE,The review reports findings about model robustness to noisy input.
"To pick just one recent example [1], the results reported (such as F1) appear to be way higher than anything in Table 2 (and that is also true for the baselines reported in [1]).",Does the review address Result?,TRUE,FALSE,The review discusses specific performance metrics (F1) and compares reported results.
This combined with the baseline I proposed above could lead to a general-purpose pattern-based classifier.,Does the review address Comparison?,TRUE,FALSE,The review discusses a potential baseline comparison and its implications.
I am also somewhat confused by the second set of experiments.,Does the review address Experiment?,TRUE,FALSE,"The review directly references experiments, specifically the second set."
Comprehensive empirical analysis on multiple datasets and CIR tasks demonstrates the effectiveness over baselines.,Does the review address Analysis?,TRUE,FALSE,The review explicitly mentions empirical analysis across multiple datasets.
* The approach is straightforward and seems to improve over the pattern-verbalizer approach.,Does the review address Result?,TRUE,FALSE,"The review mentions improvement over an existing approach, indicating results."
1) The specific design choices made in adapting the original NVIB to self-attention could benefit from more justification and discussion.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review calls for more detailed discussion and justification of design choices.
Among the biggest issues I consider the following:   * Weak baselines: Given the chosen dataset contains much more information than the textual content I would want to see the results of this work compared to the state of the art reported in the literature that looks at the same dataset.,Does the review address Data/Task?,TRUE,FALSE,The review discusses the dataset's information content and its relationship to the task.
"In addition, the proposed approach could include more labels, e.g., from Wikipedia, which may or may not contain the labels of the downstream tasks, and create a larger dataset.",Does the review address Data/Task?,TRUE,FALSE,The review suggests modifications to the dataset and labeling approach.
* The randomized and mismatched ablations are not very well designed.,Does the review address Ablation?,TRUE,FALSE,The review directly critiques the design of ablation studies.
3) The ablation study in table 5 seemed more like good baselines which is good to have as it shows GBT is more effective when applied to only hard examples.,Does the review address Ablation?,TRUE,FALSE,The review discusses an ablation study and its implications.
Thus the model may require more steps to adapt.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological aspects of model adaptation.
I would expect however to compare these results with the other methods on the same set of samples.,Does the review address Result?,FALSE,TRUE,This is a suggestion about future comparisons rather than discussing current results.
"Given the closeness with this proposed work of using paraphrases (both negative and positive), some of baselines are necessary for comparison with GBT, especially counterfactual data-augmentation techniques as GBT uses (negative paraphrases in DA i.e., IBH0) Feng et.al., A Survey of Data Augmentation Approaches for NLP  Li  et.al., Data Augmentation Approaches in Natural Language Processing: A Survey 2) Some other, even more simpler baselines could be lower learning rate and training for more number of epochs.",Does the review address Comparison?,TRUE,FALSE,The review suggests necessary baseline comparisons and discusses related techniques.
The proposed method shows consistent performance improvement on the three benchmark datasets for referring expression comprehension.,Does the review address Presentation?,FALSE,TRUE,This discusses performance results rather than presentation aspects of the paper.
Claim verification is an important topic with practical significance.,Does the review address Significance?,TRUE,FALSE,The review directly addresses the significance and importance of the research topic.
The approach could inspire more work on human-machine collaboration for efficient system evaluation.,Does the review address Evaluation?,TRUE,FALSE,The review discusses potential implications for evaluation methodology.
A human study on how well the verification process leveraging only the top-1 search result is required.,Does the review address Result?,FALSE,TRUE,This is a suggestion for future work rather than discussing current results.
After reading the paper a few times I am a bit confused about how the experimental setup supports the claims & conclusions.,Does the review address Experiment?,TRUE,FALSE,The review directly questions the experimental setup and its relationship to conclusions.
2) The authors presented interesting results from intrinsic evaluation of the attention distributions of such a model pretrained on Wikitext-2 and from evaluating the quality of the representation in linguistic probing and text classification.,Does the review address Evaluation?,TRUE,FALSE,The review describes specific evaluation approaches and their results.
Comprehensive empirical analysis on multiple datasets and CIR tasks demonstrates the effectiveness over baselines.,Does the review address Data/Task?,TRUE,FALSE,The review mentions multiple datasets and specific tasks (CIR) used in the study.
Please provide a justification for this.,Does the review address Result?,FALSE,TRUE,This is a request for justification rather than discussing results.
"A lot of emphasis in the paper has been on generating explanations; however, only 30 examples have been evaluated which may not provide enough evidence to support the claims of the paper.",Does the review address Evaluation?,TRUE,FALSE,"The review critiques the evaluation methodology, specifically the sample size."
1) There are potentially numerous baselines as data augmentation for hard examples has several work.,Does the review address Comparison?,TRUE,FALSE,The review discusses potential baseline comparisons in the context of data augmentation.
"It is understandable that the authors were able to only evaluate 1,000 samples to reduce the cost.",Does the review address Evaluation?,TRUE,FALSE,The review comments on the evaluation scope and its limitations.
1) The specific design choices made in adapting the original NVIB to self-attention could benefit from more justification and discussion.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological design choices and requests more justification.
"As reported in the ProgramFC paper, it achieves 60.63 on HoVER 3-hop (as compared to 54.80 of FOLK) and similarly for the FEVEROUS dataset.",Does the review address Result?,TRUE,FALSE,The review discusses specific numerical results and performance comparisons.
I would expect however to compare these results with the other methods on the same set of samples.,Does the review address Methodology?,TRUE,FALSE,The review suggests methodological improvements regarding comparison approach.
5) The text in line 293-295 makes the above point a little bit more unclear.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out clarity issues in the paper's explanation.
* The results are neither surprising nor exciting.,Does the review address Result?,TRUE,FALSE,The review provides an assessment of the results' significance.
"To pick just one recent example [1], the results reported (such as F1) appear to be way higher than anything in Table 2 (and that is also true for the baselines reported in [1]).",Does the review address Comparison?,TRUE,FALSE,The review compares reported results with those in a specific table.
The authors use the same setting found during hyper-parameter tuning.,Does the review address Methodology?,TRUE,FALSE,The review describes a methodological choice regarding parameter settings.
"For Chain-of-Thought and Self-Ask baselines, do you provide the retrieved knowledge to verify the sub-claims as done with FOLK?",Does the review address Comparison?,TRUE,FALSE,The review asks about comparison methodology between different approaches.
Discrepancies in the presented results of ProgramFC approach.,Does the review address Methodology?,FALSE,TRUE,This is about results rather than methodology.
I don’t see a justification for doing this.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review directly addresses the lack of justification.
I think the paper does an interesting analysis and makes an interesting point about the problem being studied.,Does the review address Analysis?,TRUE,FALSE,The review directly comments on the analysis conducted in the paper.
The experiments show that it leads to some performance improvements.,Does the review address Experiment?,TRUE,FALSE,The review discusses experimental results and their outcomes.
A better ablation study could be giving just positive paraphrases (IBH1) and just negative paraphrases (IBH0) 4) Some of the important technical details are unclear.,Does the review address Ablation?,TRUE,FALSE,The review suggests specific improvements to the ablation study design.
The proposed method shows consistent performance improvement on the three benchmark datasets for referring expression comprehension.,Does the review address Data/Task?,TRUE,FALSE,The review mentions specific benchmark datasets and the task type.
Proposes a novel approach by combining ideas from active learning and human-AI collaboration.,Does the review address Novelty?,TRUE,FALSE,The review explicitly describes the novelty of combining different approaches.
Comprehensive empirical analysis on multiple datasets and CIR tasks demonstrates the effectiveness over baselines.,Does the review address Comparison?,TRUE,FALSE,The review mentions comparison with baselines and effectiveness evaluation.
"Is the approach well motivated, including being well-placed in the literature?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review directly questions the motivation and justification of the approach.
Please provide a justification for this.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review requests justification for a claim or approach.
* Conducting an ablation study is a strong aspect of the experimental work as it offers more nuanced insights into what components of the architecture contribute how much  to the overall performance.,Does the review address Presentation?,FALSE,TRUE,The review discusses the value of ablation studies rather than presentation aspects.
"* I believe the authors should have included one more baseline, i.e., the model trained on the 20NG dataset.",Does the review address Comparison?,TRUE,FALSE,The review suggests an additional baseline for comparison.
The weaknesses are minor compared to the contributions.,Does the review address Contribution?,TRUE,FALSE,The review evaluates the significance of the paper's contributions relative to its weaknesses.
* The approach is straightforward and seems to improve over the pattern-verbalizer approach.,Does the review address Methodology?,TRUE,FALSE,The review comments on the methodological approach and its improvements.
2) The authors presented interesting results from intrinsic evaluation of the attention distributions of such a model pretrained on Wikitext-2 and from evaluating the quality of the representation in linguistic probing and text classification.,Does the review address Result?,TRUE,FALSE,The review discusses specific evaluation results and findings.
Analyzing the relation between correct claim verification decision and the correct generated explanation can be added in the analysis section.,Does the review address Analysis?,TRUE,FALSE,The review suggests additional analysis to be included.
Addresses the important challenge of designing labor-efficient evaluation methods for conversational systems.,Does the review address Evaluation?,TRUE,FALSE,The review discusses evaluation methodology for conversational systems.
I am a bit confused by how the experimental setup supports the claims and their consequences.,Does the review address Experiment?,TRUE,FALSE,The review questions the relationship between experiments and claims.
"* There are no statistical significance tests (and terms such as ""outperform"" should therefore not be used)      [1] Donabauer ""Exploring Fake News Detection with Heterogeneous Social Media Context Graphs"".",Does the review address Presentation?,TRUE,FALSE,The review critiques the presentation of results without proper statistical support.
Analyzing the relation between correct claim verification decision and the correct generated explanation can be added in the analysis section.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests adding more detailed discussion and analysis.
* Conducting an ablation study is a strong aspect of the experimental work as it offers more nuanced insights into what components of the architecture contribute how much  to the overall performance.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological aspects of the experimental work.
"However, the ablated versions have a more difficult task to solve.",Does the review address Data/Task?,TRUE,FALSE,The review comments on the nature of the task in ablated versions.
"Given the closeness with this proposed work of using paraphrases (both negative and positive), some of baselines are necessary for comparison with GBT, especially counterfactual data-augmentation techniques as GBT uses (negative paraphrases in DA i.e., IBH0) Feng et.al., A Survey of Data Augmentation Approaches for NLP  Li  et.al., Data Augmentation Approaches in Natural Language Processing: A Survey 2) Some other, even more simpler baselines could be lower learning rate and training for more number of epochs.",Does the review address Data/Task?,TRUE,FALSE,The review discusses data augmentation approaches and task-specific techniques.
"In no, then verifying each sub-claim (decomposed by existing methods) leveraging the retrieved knowledge should be a fair baseline in comparison to the proposed approach that uses the retrieved knowledge.",Does the review address Comparison?,TRUE,FALSE,The review suggests a specific baseline comparison methodology.
* The results with InstructGPT (text-davinci-003) cannot be compared with the other results.,Does the review address Comparison?,TRUE,FALSE,The review points out incompatibility in result comparisons.
What is needed is a comparison against what the current state of the art is as reported in the literature (ideally reproduced to conduct significance tests where appropriate).,Does the review address Result?,FALSE,TRUE,This is suggesting methodology for future comparisons rather than discussing current results.
"A lot of emphasis in the paper has been on generating explanations; however, only 30 examples have been evaluated which may not provide enough evidence to support the claims of the paper.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the level of detail and evidence in explanations.
* The work is conducted on a well-known benchmark dataset and is therefore easily contextualisable with other work in the field.,Does the review address Data/Task?,TRUE,FALSE,The review comments on the choice and characteristics of the dataset.
"As reported in the ProgramFC paper, it achieves 60.63 on HoVER 3-hop (as compared to 54.80 of FOLK) and similarly for the FEVEROUS dataset.",Does the review address Data/Task?,TRUE,FALSE,"The review mentions specific datasets (HoVER, FEVEROUS) used in the study."
Addresses the important challenge of designing labor-efficient evaluation methods for conversational systems.,Does the review address Methodology?,TRUE,FALSE,The review discusses the methodological approach to evaluation.
* There are many missing details (and no supplementary material such as code) making it impossible to replicate the work.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out insufficient detail and documentation.
"- Although SGEPG is model-agnostic, this paper conduct experiments using a specific model, VLTVG, to validate the proposed method.",Does the review address Methodology?,TRUE,FALSE,The review discusses methodological choices regarding model selection.
3 make it unclear whether the temperature parameter is implicitly controlling entropy.,Does the review address Result?,FALSE,TRUE,This discusses methodology and parameter effects rather than results.
Reducing human annotation effort would have significant practical impact.,Does the review address Significance?,TRUE,FALSE,The review directly addresses the practical significance of the work.
"Instead, directly instructing the LLMs with a prompt as simple as “Generate questions verifying the sub-claims of the above claim” does very well in directly generating sub-questions that can be used for verifying the claims.",Does the review address Methodology?,TRUE,FALSE,The review describes a specific methodological approach using prompts.
"For example, which datasets and how was the paraphraser trained to generate candidate sentences for selecting IBH0 and IBH1.",Does the review address Data/Task?,TRUE,FALSE,The review asks about specific dataset and training details.
The additional experiments using the other VLM would be helpful to emphasize the effectiveness of the scene graph-enhanced pseudo-labeling approach.,Does the review address Experiment?,TRUE,FALSE,The review suggests additional experimental validations.
* Conducting an ablation study is a strong aspect of the experimental work as it offers more nuanced insights into what components of the architecture contribute how much  to the overall performance.,Does the review address Result?,TRUE,FALSE,The review discusses how ablation results provide insights into performance.
"The claim is that agents that try to solve a prediction task subject to a communication bottleneck will exchange low entropy messages, even if these messages are not explicitly encouraged to have low entropy.",Does the review address Data/Task?,TRUE,FALSE,The review describes the specific prediction task and its constraints.
I would be interested to see how the ablated versions would perform if the authors tuned the hyper-parameters on 20NG for each of these settings.,Does the review address Result?,FALSE,TRUE,This suggests future experiments rather than discussing current results.
The problem is timely and the solution is novel.,Does the review address Novelty?,TRUE,FALSE,The review directly comments on the novelty of the solution.
I would be interested to see how the ablated versions would perform if the authors tuned the hyper-parameters on 20NG for each of these settings.,Does the review address Methodology?,TRUE,FALSE,The review suggests methodological improvements regarding hyperparameter tuning.
"The authors fine-tune an MLM using patterns, which can be seen as instructions, and synthetic data.",Does the review address Data/Task?,TRUE,FALSE,The review describes the data type (synthetic) and task approach (pattern-based fine-tuning).
I would expect however to compare these results with the other methods on the same set of samples.,Does the review address Comparison?,TRUE,FALSE,The review suggests a specific comparison methodology.
"In effect, the model has learned to use these patterns and is therefore able to use this knowledge for classification.",Does the review address Methodology?,TRUE,FALSE,The review explains how the methodological approach works.
"On the other hand, InstructGPT [1] was much better than GPT-3 and the main reason was that it was trained to follow instructions (prompts).",Does the review address Methodology?,TRUE,FALSE,The review discusses training methodology differences between models.
"This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.",Does the review address Result?,TRUE,FALSE,The review discusses the evaluation of results' correctness and rigor.
"In line 268-277, more details would be needed as to how and where the 50K examples were selected from.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests more detailed explanation about data selection.
The negative and positive paraphrase augmentation seems like a good mix of balanced data augmentation (though we don’t know how much just adding IBH1 and just adding IBH0 independently contribute to improvement).,Does the review address Data/Task?,TRUE,FALSE,The review discusses specific data augmentation approaches.
"If yes, then how would you justify the better performance of your approach since both these approaches also result in accurate questions for verifying the subclaims.",Does the review address Comparison?,TRUE,FALSE,The review asks for justification of comparative performance.
The experiments show that it leads to some performance improvements.,Does the review address Result?,TRUE,FALSE,The review directly states experimental results.
"2) The propose technique seems like a good choice for the PI task and some of the analyses (Figure 2 for boosting interval and ratio, table 5 for why to use GBT for hard examples) highlight interesting takeaways about GBT.",Does the review address Data/Task?,TRUE,FALSE,The review discusses the technique's appropriateness for a specific task.
The discussion seems to suggest that setting higher temperature in GS creates pressure for lower-entropy messages.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review interprets the relationship between parameters and outcomes.
* The authors have included ablation tests to demonstrate the robustness of their approach.,Does the review address Ablation?,TRUE,FALSE,The review directly mentions ablation tests and their purpose.
2) The authors presented interesting results from intrinsic evaluation of the attention distributions of such a model pretrained on Wikitext-2 and from evaluating the quality of the representation in linguistic probing and text classification.,Does the review address Methodology?,TRUE,FALSE,The review describes evaluation methodology using specific techniques.
Zero-shot and few-shot learning with GPT-3 using prompting had still a large gap with supervised SotA models.,Does the review address Methodology?,TRUE,FALSE,The review discusses different methodological approaches and their effectiveness.
What is needed is a comparison against what the current state of the art is as reported in the literature (ideally reproduced to conduct significance tests where appropriate).,Does the review address Comparison?,TRUE,FALSE,The review calls for specific types of comparisons.
The negative and positive paraphrase augmentation seems like a good mix of balanced data augmentation (though we don’t know how much just adding IBH1 and just adding IBH0 independently contribute to improvement).,Does the review address Result?,FALSE,TRUE,This discusses methodology rather than results.
The motivation and design choice of the proposed method is simple and intuitive.,Does the review address Presentation?,FALSE,TRUE,This addresses methodology and motivation rather than presentation.
"In addition, the proposed approach could include more labels, e.g., from Wikipedia, which may or may not contain the labels of the downstream tasks, and create a larger dataset.",Does the review address Methodology?,TRUE,FALSE,The review suggests methodological improvements regarding data labeling.
The proposed approach is very similar to the basic idea of InstructGPT.,Does the review address Methodology?,TRUE,FALSE,The review compares methodological approaches between models.
Reducing human annotation effort would have significant practical impact.,Does the review address Data/Task?,FALSE,TRUE,This addresses significance rather than data or task aspects.
Among the biggest issues I consider the following:   * Weak baselines: Given the chosen dataset contains much more information than the textual content I would want to see the results of this work compared to the state of the art reported in the literature that looks at the same dataset.,Does the review address Comparison?,TRUE,FALSE,The review criticizes the lack of comparison with state of the art methods.
"On the other hand, directly generating the decomposed sub-claims has been shown to work really well in prior works.",Does the review address Methodology?,TRUE,FALSE,The review discusses alternative methodological approaches from previous work.
1) The GBT technique shows improvement (as per the result tables 3 and 4) and could be applied generally to other tasks as well.,Does the review address Result?,TRUE,FALSE,The review directly references specific results from tables.
"2) The propose technique seems like a good choice for the PI task and some of the analyses (Figure 2 for boosting interval and ratio, table 5 for why to use GBT for hard examples) highlight interesting takeaways about GBT.",Does the review address Methodology?,TRUE,FALSE,The review evaluates the appropriateness of the methodology for a specific task.
Comprehensive empirical analysis on multiple datasets and CIR tasks demonstrates the effectiveness over baselines.,Does the review address Methodology?,TRUE,FALSE,The review describes the methodological approach to analysis.
* I am not entirely convinced by the choice of the authors to use only 4 labels from the 20NG dataset.,Does the review address Data/Task?,TRUE,FALSE,The review critiques specific data selection choices.
A better ablation study could be giving just positive paraphrases (IBH1) and just negative paraphrases (IBH0) 4) Some of the important technical details are unclear.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests more detailed technical explanation is needed.
* The paper is well-written and easy to understand.,Does the review address Presentation?,TRUE,FALSE,The review directly comments on the writing quality and clarity.
"Is the approach well motivated, including being well-placed in the literature?",Does the review address Related Work?,TRUE,FALSE,The review questions how the work relates to existing literature.
"2) The propose technique seems like a good choice for the PI task and some of the analyses (Figure 2 for boosting interval and ratio, table 5 for why to use GBT for hard examples) highlight interesting takeaways about GBT.",Does the review address Analysis?,TRUE,FALSE,The review discusses specific analyses and their insights.
"* I believe the authors should have included one more baseline, i.e., the model trained on the 20NG dataset.",Does the review address Data/Task?,TRUE,FALSE,The review suggests including additional dataset configurations.
"Furthermore, the paper is well written and provides a good background for the problem statement.",Does the review address Presentation?,TRUE,FALSE,The review comments on writing quality and background presentation.
The method consistently approximates full human evaluation with minimal labor.,Does the review address Methodology?,TRUE,FALSE,The review describes the core methodological approach.
The entropy of the messages was only analyzed for the runs where agents have successfully learned to communicate in order to solve the task.,Does the review address Analysis?,TRUE,FALSE,The review describes the scope and conditions of the analysis.
The method consistently approximates full human evaluation with minimal labor.,Does the review address Evaluation?,TRUE,FALSE,The review describes the evaluation approach and its efficiency.
The entropy of the messages was only analyzed for the runs where agents have successfully learned to communicate in order to solve the task.,Does the review address Data/Task?,TRUE,FALSE,The review describes specific conditions of the task analysis.
* The results with InstructGPT (text-davinci-003) cannot be compared with the other results.,Does the review address Result?,TRUE,FALSE,The review discusses limitations in result comparability.
"The paper is well motivated, though I am not an expert in the area.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review comments on the paper's motivation.
"The authors fine-tune an MLM using patterns, which can be seen as instructions, and synthetic data.",Does the review address Methodology?,TRUE,FALSE,The review describes specific methodological details.
After reading the paper a few times I am a bit confused about how the experimental setup supports the claims & conclusions.,Does the review address Presentation?,TRUE,FALSE,The review comments on clarity of presentation regarding experiments and claims.
I think the paper does an interesting analysis and makes an interesting point about the problem being studied.,Does the review address Contribution?,TRUE,FALSE,The review evaluates the paper's analytical contribution to the field.
The approach could inspire more work on human-machine collaboration for efficient system evaluation.,Does the review address Methodology?,TRUE,FALSE,The review discusses potential methodological impact on future work.
1) The GBT technique shows improvement (as per the result tables 3 and 4) and could be applied generally to other tasks as well.,Does the review address Methodology?,TRUE,FALSE,The review discusses the methodology's generalizability and effectiveness.
It would be difficult for readers to understand and evaluate – “we manually observed the generated examples and find the results acceptable.”  6) A very minute point – it may be interesting to compare with openLLM methods like LLaMa (after some instruction tuning for PI  task).,Does the review address Comparison?,TRUE,FALSE,The review suggests specific comparative analyses with other methods.
"If yes, then how would you justify the better performance of your approach since both these approaches also result in accurate questions for verifying the subclaims.",Does the review address Result?,TRUE,FALSE,The review questions the interpretation of performance results.
"- Although SGEPG is model-agnostic, this paper conduct experiments using a specific model, VLTVG, to validate the proposed method.",Does the review address Experiment?,TRUE,FALSE,The review discusses specific experimental choices.
"Make it clear that these points are here to help, and not necessarily part of your decision assessment.",Does the review address Presentation?,TRUE,FALSE,The review suggests improvements to how information is presented.
The additional experiments using the other VLM would be helpful to emphasize the effectiveness of the scene graph-enhanced pseudo-labeling approach.,Does the review address Presentation?,FALSE,TRUE,This addresses experimental methodology rather than presentation.
One limitation is the need for a differentiable evaluation metric to estimate sample hardness (relevance scores addressed via ChatGPT).,Does the review address Evaluation?,TRUE,FALSE,The review discusses specific limitations in evaluation methodology.
There are many more benchmark datasets for text classification (including fake news detection) that could be included to provide more confidence in the findings.,Does the review address Result?,FALSE,TRUE,This suggests additional datasets rather than discussing current results.
3) The authors compared the robustness of the NVIB-regularized model with that of a regular transformer and found the former more robust to noisy input.,Does the review address Methodology?,TRUE,FALSE,The review describes the methodological approach to comparing models.
"On the other hand, directly generating the decomposed sub-claims has been shown to work really well in prior works.",Does the review address Related Work?,TRUE,FALSE,The review references prior work's methodological approaches.
3) The ablation study in table 5 seemed more like good baselines which is good to have as it shows GBT is more effective when applied to only hard examples.,Does the review address Comparison?,TRUE,FALSE,The review compares different experimental conditions.
"For example, which datasets and how was the paraphraser trained to generate candidate sentences for selecting IBH0 and IBH1.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests more detailed explanation of methodology.
"* Only a single dataset is used to explore the problem (well, it is two different parts but in the end it is one fairly specific dataset).",Does the review address Data/Task?,TRUE,FALSE,The review critiques dataset choices and limitations.
"The proposed approach is intuitive, easy to implement, and effective.",Does the review address Methodology?,TRUE,FALSE,The review evaluates qualities of the methodological approach.
This would even strengthen the claims of GBT if improvements are significant.,Does the review address Result?,TRUE,FALSE,The review discusses potential impact on result interpretation.
"Is the approach well motivated, including being well-placed in the literature?",Does the review address Methodology?,TRUE,FALSE,The review questions methodological motivation and context.
The entropy of the messages was only analyzed for the runs where agents have successfully learned to communicate in order to solve the task.,Does the review address Result?,TRUE,FALSE,The review describes conditions under which results were analyzed.
The randomized version has to learn new embeddings from scratch and the mismatched version has to learn a new meaning for each label.,Does the review address Methodology?,TRUE,FALSE,The review explains methodological details of different versions.
- This paper is well-written and easy to follow.,Does the review address Presentation?,TRUE,FALSE,The review directly comments on writing quality and readability.
1) There are potentially numerous baselines as data augmentation for hard examples has several work.,Does the review address Data/Task?,TRUE,FALSE,The review discusses data augmentation approaches for the task.
"A lot of emphasis in the paper has been on generating explanations; however, only 30 examples have been evaluated which may not provide enough evidence to support the claims of the paper.",Does the review address Result?,TRUE,FALSE,The review critiques the limited sample size for results.
There are many more benchmark datasets for text classification (including fake news detection) that could be included to provide more confidence in the findings.,Does the review address Data/Task?,TRUE,FALSE,The review suggests additional datasets that could be used.
"Also, why not 5 or maybe more search results are used as the knowledge because the first result may not always contain sufficient information to verify the sub-claim.",Does the review address Result?,FALSE,TRUE,This questions methodology rather than discussing results.
* The idea to construct synthetic data using only the labels is interesting.,Does the review address Data/Task?,TRUE,FALSE,The review comments on data generation approach.
I am also somewhat confused by the second set of experiments.,Does the review address Related Work?,FALSE,TRUE,This addresses experiment clarity rather than related work.
"- Although SGEPG is model-agnostic, this paper conduct experiments using a specific model, VLTVG, to validate the proposed method.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses justification for model choice.
"* There are no statistical significance tests (and terms such as ""outperform"" should therefore not be used)      [1] Donabauer ""Exploring Fake News Detection with Heterogeneous Social Media Context Graphs"".",Does the review address Result?,TRUE,FALSE,The review critiques the statistical validity of results.
It would be difficult for readers to understand and evaluate – “we manually observed the generated examples and find the results acceptable.”  6) A very minute point – it may be interesting to compare with openLLM methods like LLaMa (after some instruction tuning for PI  task).,Does the review address Evaluation?,TRUE,FALSE,The review critiques evaluation clarity and methodology.
These could possibly be answered with ablation studies.,Does the review address Ablation?,TRUE,FALSE,The review suggests using ablation studies for analysis.
1) The authors propose adaptations of NVIB to self-attention and to use it for learning increasingly abstract representations at higher layers of a transformer encoder.,Does the review address Methodology?,TRUE,FALSE,The review describes specific methodological choices.
1) The specific design choices made in adapting the original NVIB to self-attention could benefit from more justification and discussion.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review requests more justification for methodological choices.
* Conducting an ablation study is a strong aspect of the experimental work as it offers more nuanced insights into what components of the architecture contribute how much  to the overall performance.,Does the review address Ablation?,TRUE,FALSE,The review evaluates the quality of ablation studies.
The authors could do more error analysis and discuss scenarios where the approach may not work as well.,Does the review address Methodology?,TRUE,FALSE,The review suggests methodological improvements for analysis.
The authors could do more error analysis and discuss scenarios where the approach may not work as well.,Does the review address Analysis?,TRUE,FALSE,The review suggests expanding the analysis scope.
3) The ablation study in table 5 seemed more like good baselines which is good to have as it shows GBT is more effective when applied to only hard examples.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological choices in experimental design.
"These type of questions might already exist in the proposed dataset, it would provide more insights to dive deeper into those.",Does the review address Data/Task?,TRUE,FALSE,"The review explicitly refers to a ""proposed dataset"", which relates to the dataset used in the study."
"2.Through a significant number of ablation experiments, this paper extensively researched the model's hyperparameter configurations and training strategies, offering highly instructive guidance for related work.",Does the review address Experiment?,TRUE,FALSE,"The review explicitly mentions ""ablation experiments"" and describes research involving hyperparameter configurations and training strategies."
The key contribution of the paper appears to be the formulation of the Concept-QA model based on query information and answers from GPT + CLIP.,Does the review address Methodology?,TRUE,FALSE,The review discusses the approach (Concept-QA model) and its technical components (GPT + CLIP).
- Ablation study shown in table 5 provides good insights for choices of LoRA params and the benefit of curriculum in staged training.,Does the review address Ablation?,TRUE,FALSE,"The review explicitly mentions ""ablation study"" and discusses its insights about model parameters."
The main concern to me about this paper is its limited novelty and scientific merit.,Does the review address Novelty?,TRUE,FALSE,"The review directly addresses the originality of the work by mentioning ""limited novelty""."
"Having an ablation on the number of GreaseLM layers would also be quite useful to answer if performance improves with more GreaseLM layers, are there diminishing returns or do we need just a few GreaseLM layers, beyond which it is detrimental to the model's performance.",Does the review address Ablation?,TRUE,FALSE,The review explicitly suggests an ablation study on model layers and their impact on performance.
"In experiments, mainly accuracy is shown, but since the major motivation to reduce gradient variance, why not show some comparison of gradient variance of MLM and MLM-FE?",Does the review address Result?,TRUE,FALSE,The review discusses reported results (accuracy) and suggests additional performance metrics (gradient variance).
This looks like an order of magnitude difference in dataset empirical evaluation to me.,Does the review address Comparison?,TRUE,FALSE,The review makes a comparative assessment about the scale of empirical evaluation.
"This is in sharp contrast to computer vision where techniques like rotation, modification of hue, saturation as well as umpteen other techniques exist.",Does the review address Comparison?,TRUE,FALSE,The review explicitly compares techniques between different fields (computer vision vs. presumably NLP).
* The proposed RandomMask is effective but simple.,Does the review address Methodology?,TRUE,FALSE,The review evaluates a specific method (RandomMask) and its characteristics.
"The authors empirically evaluate their N-Bref’s accuracy on a number of problems from the open source LeetCode problem set and generate 25,000 pairs of high-level source and low-level source which are broken into training (60%), validation (20%), and testing (20%).",Does the review address Data/Task?,TRUE,FALSE,"The review describes the dataset composition, source, and split ratios used in the study."
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Result?,TRUE,FALSE,The review discusses the comparability of evaluation results across different experimental setups.
"As the main contribution of this paper is the increased efficiency of the proposed approach, it must be clear how efficiency is measured.",Does the review address Methodology?,TRUE,FALSE,The review discusses the methodology's claimed contribution (efficiency) and calls for clarity in its measurement.
"**Areas of Enhancement & Questions to authors**  - The information about each of the ablations (ID, BM) could be explained better.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out the need for better explanation of specific ablation components.
"The paper then proposes two practical solutions for better inference: 1) tuning dropout rate, softmax temperature, and the power mean parameter; and 2) deterministic inference with tuned softmax temperature.",Does the review address Methodology?,TRUE,FALSE,The review details specific methodological approaches for inference improvement.
"Specifically, for Table 1, the inference time of each algorithm should be reported (retrieval time included).",Does the review address Significance?,FALSE,TRUE,This review focuses on requesting specific metrics rather than discussing the significance or impact of the work.
"- The paper is well written: it gives an appropriate context, presents the main theoretical results, and verifies _some_ of the claims experimentally.",Does the review address Result?,TRUE,FALSE,The review mentions the presentation of theoretical results and their experimental verification.
"Without comparison with SOTA's performance, I will try my best to reject this paper.",Does the review address Result?,TRUE,FALSE,The review criticizes the lack of comparative results with state-of-the-art performance.
"- Because the policy learning procedure utilizes the additionally generated dialogue acts and corresponding responses, it is easy to think that naively fine-tuning the GPT-2 model on the additional generated data may also improve the dialogue model performance in terms of its policy and responses (similar to a data augmentation method).",Does the review address Data/Task?,TRUE,FALSE,The review discusses the data components (dialogue acts and responses) used in the learning procedure.
"For example, Figure 4 validates Assumption 4.1 (log-partition function is roughly quadratic in theta), and Table 1 shows many real tasks are approximately “natural”.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses validation of assumptions and justification of claims through evidence.
It wasn't intuitive for me that it'd be useful for NQ.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review directly addresses intuition by expressing a lack of understanding about the applicability to NQ.
**Weaknesses** * Unclear if there are real practical applications to the insights from this paper.,Does the review address Methodology?,FALSE,TRUE,The review discusses practical applications rather than methodological aspects.
"It's also not explained how Theorem 2 justifies the main conclusion: that ""a prompt engineer aided by enough time and memory can force an LLM to output an arbitrary sequence of ℓ tokens.""",Does the review address Theory?,TRUE,FALSE,The review specifically addresses theoretical aspects through discussion of a theorem and its implications.
"), yet I could not find any actual training experiments, that is training a large LLM from scratch, in the paper.",Does the review address Methodology?,TRUE,FALSE,The review points out missing methodology regarding LLM training experiments.
2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues.,Does the review address Methodology?,TRUE,FALSE,The review suggests methodological improvements to ablation experiments regarding catastrophic forgetting.
Why are all publications not used in training the baselines?,Does the review address Data/Task?,TRUE,FALSE,The review questions the dataset composition regarding training data selection.
"Why are the backbone models (RoBERTa and BERT, respectively) different in Table 1 and Table 2?",Does the review address Methodology?,TRUE,FALSE,The review questions methodological choices regarding model architecture selection across experiments.
The paper also presents a manual evaluation of the inferred time series from a news corpus which is nice to see.,Does the review address Evaluation?,TRUE,FALSE,The review explicitly mentions manual evaluation procedures on a specific dataset.
The authors curated a large-scale dataset for first-stage pretraining and second-stage instruction tuning.,Does the review address Presentation?,FALSE,TRUE,The review discusses data preparation rather than presentation aspects.
Hyper-parameter balancing strategies in Section 3.1 is not a solid theoretical analysis.,Does the review address Methodology?,TRUE,FALSE,The review critiques the theoretical foundation of methodological choices in parameter balancing.
"The paper proposes a new joint learning algorithm that works for two tasks, NER and RE.",Does the review address Methodology?,TRUE,FALSE,The review describes a specific methodological contribution (joint learning algorithm).
"Since one of the main contributions of this paper is the analysis of the BERT pretraining process, more experimental analysis on the optimizer should also be included.",Does the review address Methodology?,TRUE,FALSE,The review suggests additional methodological analysis regarding the optimization process.
"These objectives certainly improve over the original T5 base _and_ larges models that are used as initializations, and especially outperform the base model in the low-data regime.",Does the review address Result?,TRUE,FALSE,The review discusses performance improvements compared to baseline models.
Pros:  - A new framework for understanding why learning how to predict the next word helps the downstream task.,Does the review address Data/Task?,FALSE,TRUE,The review discusses theoretical framework rather than data or task aspects.
2017 (https://arxiv.org/abs/1606.05804) perform relation extraction on unseen entities.,Does the review address Related Work?,TRUE,FALSE,The review cites and discusses previous work in relation extraction.
- It would have been interesting to see a comparison of POS tagging performance with UD-style tags versus ORCHID tags.,Does the review address Comparison?,TRUE,FALSE,The review suggests comparing performance between different tagging schemes.
"However, it is unclear how well they perform to the CASP state-of-the art (see also Rives et al, 2020).",Does the review address Result?,TRUE,FALSE,The review discusses uncertainty about performance comparison with SOTA.
"Last sentence of intro: ""without scarifying accuracy"" seems like an inaccurate description of the results presented in this paper.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the accuracy of specific terminology used in the paper.
"In general, it may help to reorder some of these results, add forward references to the proofs, and indicate how different results depend on one another.",Does the review address Result?,FALSE,TRUE,The review discusses presentation organization rather than results themselves.
I am not sure on this---my intuition is based on your Lemma D.2 and the fact that for a $p_{\cdot\mid s}$ with full support a non-precise reverse version of [Pinsker's inequality](https://en.wikipedia.org/wiki/Pinsker%27s_inequality#Inverse_problem) holds.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review explicitly discusses intuition based on theoretical foundations.
"The first use of the proposed definitions to make a non-trivial claim is in Section 5 with Postulate 1, but this claim is not justified.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses the application and justification of formal definitions in the paper.
"Also, some additional experiments need to be added in order to better justify its claims.",Does the review address Experiment?,TRUE,FALSE,The review explicitly calls for more experimental validation of claims.
I therefore believe that these results show merit.,Does the review address Result?,TRUE,FALSE,The review provides a qualitative assessment of the study's results.
"- Table 5 the VAE(32) method performs the best overall in ""Wiki section"" although the TC (16) method has been highlighted as the best.",Does the review address Result?,TRUE,FALSE,The review discusses specific performance results and points out inconsistency in result highlighting.
"The main contribution are the following innovations: a special attention mechanism called block-diagonal conditional attention, a set of modules for adaptation of a pretrained model, and an uncertainty-based multi-task data sampling method.",Does the review address Novelty?,TRUE,FALSE,The review explicitly lists novel contributions including attention mechanism and adaptation modules.
It would be really useful to have an ablation study to disentangle which piece of the training or method is contributing to what and how in the performance measure.,Does the review address Result?,FALSE,TRUE,The review suggests experimental analysis rather than discussing actual results.
What would happen to the network if compression is removed?,Does the review address Experiment?,TRUE,FALSE,The review suggests an experimental investigation about network compression.
The phrasal RNN (pRNN) architecture is achieved by generating subnetworks of phrases.,Does the review address Methodology?,TRUE,FALSE,The review describes the technical implementation of a specific architecture.
In particular we don't know if the sacrifice of short sequence time would benefit a lot in long sequences for existing methods.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological trade-offs in sequence processing.
"Additionally, showing this for negations and / or examples which GreaseLM gets correct but QA-GNN does not (and vice-versa) can shed some light on what the model improves on (and what are the limitations).",Does the review address Comparison?,TRUE,FALSE,The review suggests comparative analysis between different models' capabilities.
"For experiments, Table 1 shows the FOCAL Reasoner (DeBERTa) brings much performance gain, compared to FOCAL Reasoner (RoBERTa) (the performance seems comparable with DAGN and LReasoner using RoBERTa).",Does the review address Experiment?,TRUE,FALSE,The review discusses experimental results comparing different model variants (FOCAL Reasoner with DeBERTa vs RoBERTa) and their relative performance.
"The authors provide several reasonable insights that might be relevant to the user interface modeling community — using object detection as part of multi-task learning instead of standalone pre-training task, design choices to create a single unified architecture for all the tasks, multi-task learning outperforming single-task learning etc.",Does the review address Data/Task?,TRUE,FALSE,The review discusses multi-task learning setup and task choices including object detection.
"What is the impact of a good OCR for training and testing (prediction of new, unseen documents)?",Does the review address Presentation?,FALSE,TRUE,The review asks about technical aspects of OCR impact rather than presentation elements.
"Strengths: * Novel method of using emergent language for pre-training (as opposed to transferring an entire artificial agent) * Some good ablations to identify what contributes to successful transfer * A new evaluation metric (emergent --> NL translation performance) that best correlates with fine-tuning performance  Weaknesses: * Some parameter choices and the design of some ablations are not completely justified * Some additional related works could be included   # Minor comments / questions  * ""However, this metric is too rigid in its definition of compositionality, ignoring aspects like argument structure, context or morphology which play a key role in determining the combination of word semantics (Goldberg, 2015).""",Does the review address Methodology?,TRUE,FALSE,The review discusses methodological aspects including emergent language pre-training and evaluation metrics.
"- When building the relation between the word and the frame, is there any emphasis on verb, some particular word, or self-learned attention?",Does the review address Methodology?,TRUE,FALSE,The review questions specific implementation details about word-frame relationship modeling.
"It's particularly surprising to me that this works so well on NQ, and I wish the authors had dug a bit deeper into this, but I also recognize that page limits exist.",Does the review address Analysis?,TRUE,FALSE,The review specifically requests deeper analysis of the model's performance on NQ.
Comparison with GECA: I can read from the paper that the performance is on par with GECA.,Does the review address Result?,TRUE,FALSE,The review explicitly mentions performance comparison with GECA baseline.
"They train low resource NMTs using 4 different tokenization strategies, to show that their proposed tokenization method leads to the best NMT results by several metrics.",Does the review address Methodology?,TRUE,FALSE,The review describes training methodology using different tokenization strategies.
It would be really useful to have an ablation study to disentangle which piece of the training or method is contributing to what and how in the performance measure.,Does the review address Presentation?,FALSE,TRUE,The review suggests additional experimental analysis rather than presentation aspects.
"PE seems to be important for wMAN, and the authors provides few sentences analysis about this, but I don't think I fully understand this part.",Does the review address Significance?,FALSE,TRUE,The review discusses understanding of technical aspects rather than significance.
The graph indicates that for MNLI and QNLI 60% seems like a better choice.,Does the review address Methodology?,TRUE,FALSE,The review discusses specific parameter choices and their impact on different tasks.
The analysis shows that it outperforms only all the other baselines only on 5/9 games and matches on 3.,Does the review address Analysis?,TRUE,FALSE,The review describes comparative analysis results across different games.
The margin of change seems even larger than some results which are discussed in the paper as significant.,Does the review address Result?,TRUE,FALSE,The review compares the magnitude of different results and their significance.
"With the proposed CaptionNet dataset, it is now possible to have a fairer comparison between VL models and CE models.",Does the review address Data/Task?,TRUE,FALSE,The review discusses a new dataset (CaptionNet) and its impact on model comparison.
The authors have done further experiments and show that there are still gains on these tasks when model sized is increased significantly.,Does the review address Result?,TRUE,FALSE,The review describes experimental results showing performance gains with increased model size.
"Informally , a task is defined as natural if, just by using the next word distributions as features, the downstream task can be solved with a small loss.",Does the review address Data/Task?,TRUE,FALSE,"The review provides a definition of what constitutes a ""natural"" task."
It appears that a single example was analyzed qualitatively.,Does the review address Analysis?,TRUE,FALSE,The review comments on the limited scope of qualitative analysis.
"The experiments cover loss functions, label noise, caption length, caption quality, VL vs CE etc.",Does the review address Experiment?,TRUE,FALSE,The review lists various experimental aspects covered in the study.
"However, the presented theory suffers from various core issues.",Does the review address Theory?,TRUE,FALSE,The review directly addresses theoretical aspects and their issues.
"Decompilation can mean many things, but the general idea as I understand it, is to take a representation of a software program from one level (e.g., program binary) and then “lift it” to a level that is higher in abstraction (e.g., from binary to assembly, from assembly to C, from C to a lambda calculus, etc.).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review provides a detailed explanation of what decompilation means.
I believe such an experiment will definitely make the submission stronger.,Does the review address Experiment?,TRUE,FALSE,The review suggests additional experimentation would strengthen the submission.
"**Baselines are too weak, leading to a misunderstanding of the effectiveness of the proposed method.",Does the review address Comparison?,TRUE,FALSE,The review criticizes the choice of baselines for comparison.
"One might hypothesize that if using a (subotimal) template that is less natural for language modeling, that zero-shot performance would suffer, but that FLAN performance wouldn't - One might hypothesize that the ""turn the task around"" templates help more than the other more straightforward templates that don't swap information between the prompt and response.",Does the review address Result?,FALSE,TRUE,The review presents hypotheses about potential outcomes rather than actual results.
It is hard to know here which one of these actually made the adversarial setup useful.,Does the review address Methodology?,TRUE,FALSE,The review questions the effectiveness of specific methodological choices in adversarial setup.
"* Fundamentally, beyond simple invariants (array bounds, nullness checks) it is not clear why program invariants would generalize well across different programs.",Does the review address Methodology?,TRUE,FALSE,The review questions methodological assumptions about program invariant generalization.
"In fact, empirical evidence suggest that LMs do memorize n-grams from their training data somewhat, but not full examples (see [McCoy et al.",Does the review address Methodology?,TRUE,FALSE,The review discusses empirical findings about language model memorization behavior.
"In the presence of definitive results, this might be acceptable, but in its absence, as in this paper, there needs to be quantitative analysis across multiple runs to demonstrate the robustness of the phenomenon.",Does the review address Analysis?,TRUE,FALSE,The review calls for more rigorous quantitative analysis across multiple runs.
"Liu Y., Liu Z., Chua T.,Sun M. AAAI 2015 _ Also, the inclusion of the result from those approaches in tables 3 and 4 could be interesting.",Does the review address Result?,TRUE,FALSE,The review suggests including additional results from referenced approaches.
This method should be included in the experiments in order to justify the proposed RL approach is necessary.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review calls for justification of the RL approach through experimental comparison.
Another major concern is the use of two separate RNNs which gives the proposed model more parameters than the baselines.,Does the review address Comparison?,TRUE,FALSE,The review raises concerns about fair model comparison due to parameter count differences.
**Summary** This work relates a pre-training performance with a downstream performance for tasks that _can_ be reformulated as next word prediction tasks.,Does the review address Presentation?,TRUE,FALSE,The review summarizes the work's focus on relating pre-training to downstream performance.
"Therefore, the obtained task performance is far from state-of-the-art.",Does the review address Result?,TRUE,FALSE,The review explicitly comments on performance being below state-of-the-art.
"Because if too many parameters are introduced, the performance improvement may come from overfitting of too many parameters.",Does the review address Result?,TRUE,FALSE,"The review discusses potential reasons for performance improvements, suggesting overfitting concerns."
Complexity-based prompting for multi-step reasoning.,Does the review address Related Work?,TRUE,FALSE,The review references specific work on complexity-based prompting.
The training procedure mentioned in section 5.2.2 talks about joint training but the procedure followed for training for individual tasks or a subset of tasks is not described in detail.,Does the review address Methodology?,TRUE,FALSE,The review points out missing details in the training procedure description.
Pros:  - the paper is well written and very clear - the proposed model has two main advantages: (1) it is very fast to train due to the use of pre-trained BERT representations and (2) it does not depends on any external NLP tool (such as dependency parser)  Cons:   - I think the main source of improvement comes from the BERT representations used as input.,Does the review address Presentation?,TRUE,FALSE,The review explicitly comments on the paper being well-written and clear.
Move to E2E system can be motivated a bit more (allows end-user feedback to be passed through all modules easily and don't have to worry about how a change in one module affects all other modules explicitly etc) 3.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests additional motivation for E2E system choice.
"In order to train reading comprehension models to perform relation extraction, they create a large dataset of 30m “querified” (converted to natural language) relations by asking mechanical turk annotators to write natural language queries for relations from a schema.",Does the review address Methodology?,TRUE,FALSE,The review describes the process of creating training data through MTurk annotations.
I see this work more as an analysis on language-specific parameters for a particular LS-model rather than a novel architecture.,Does the review address Analysis?,TRUE,FALSE,The review characterizes the work as an analysis of language-specific parameters.
This paper is well-written and the idea is interesting.,Does the review address Presentation?,TRUE,FALSE,The review directly comments on the paper's writing quality.
The annotations in baseline [1] are much shorter compared to the annotations by the authors.,Does the review address Comparison?,TRUE,FALSE,The review compares annotation lengths between different approaches.
"- Additionally, in my opinion, the authors are misrepresenting prior work when saying in line 163 that the ""MTL approach has not yet been successful in NLP"".",Does the review address Presentation?,TRUE,FALSE,The review criticizes the presentation of prior work.
"The model is based on a pre-trained BERT model, which provides the word vectors of the input word sequence.",Does the review address Methodology?,TRUE,FALSE,The review describes the model's architectural basis using BERT.
"In particular, you are comparing a small GRU LM to a larger transformer LM, where the latter is, as you mention, a much more powerful model.",Does the review address Methodology?,TRUE,FALSE,The review discusses model architecture comparisons between GRU and transformer.
"Please report the total training and total inference time, and make a comparison with standard Transformer model.",Does the review address Significance?,FALSE,TRUE,The review requests performance metrics rather than discussing significance.
"For example, what is the experiment environment and training receipts.",Does the review address Experiment?,TRUE,FALSE,The review asks for specific experimental environment details.
"The methods have been tested on two benchmarks focusing on the issue, SCAN and morphological analysis.",Does the review address Presentation?,FALSE,TRUE,The review discusses evaluation benchmarks rather than presentation.
"The motivation is very clear, MCTS is generally action agnostic and using language to provide additional semantic information to it can prove to be very effective.",Does the review address Methodology?,TRUE,FALSE,The review discusses the motivation for using MCTS with language information.
"(2) In this paper, similarity and alignment structures are proposed, but no ablation experiments have been carried out to prove the effectiveness of the improved model.",Does the review address Methodology?,TRUE,FALSE,The review points out missing ablation studies for proposed structures.
"In particular, using a carefully selected subset of ""prompt"" words, the authors observe that learning a linear predictor over the next word distributions of these words achieves performance close to a pre-trained GPT-2 model.",Does the review address Result?,TRUE,FALSE,The review describes specific findings about linear predictor performance.
"Without the ablation studies on these two aspects, we cannot determine whether the performance improvement truly comes from the author's contribution or just longer CoT annotations.",Does the review address Result?,TRUE,FALSE,The review questions the source of performance improvements.
"It is naturally expected that vision-language models can benefit from stronger unimodal encoders, for which the best strategies are not very well explored by the community.",Does the review address Methodology?,TRUE,FALSE,The review discusses strategies for vision-language model improvement.
I would appreciate the explanation and further evidence to address these concerns.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests additional explanation and evidence.
"- P24, Figure 2: What are the x and y axis, and what does each dot mean in this figure?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,TRUE,The review asks for clarification about figure axes and data points.
The Ablation Study of the paper also provides useful insights about the impact of different pre-training schemas on large-scale information retrieval tasks.,Does the review address Presentation?,FALSE,TRUE,The review discusses insights from ablation studies rather than presentation.
"Intuitively, this parameter arises from translating the ""natural"" task assumption, which only guarantees transfer on average to the downstream task.",Does the review address Data/Task?,TRUE,FALSE,The review discusses task assumptions and their implications.
"- The proposed architecture is tested on massive experiments including language understanding tasks, optical flow, video audio class autoencoding, image classification, and starcraft II and achieves superior performance.",Does the review address Methodology?,TRUE,FALSE,The review outlines the extensive testing of the architecture across various tasks.
"- `s4.3 Findings p4`: ""the channel ... influences generalisation"" -- Without further explication, this potentially interesting point does not gain any traction.",Does the review address Result?,TRUE,FALSE,The review critiques the lack of explanation for a claimed result.
"The approach, extend the model introduced by Vilnis and McCallum (2014) which represented word as unimodal Gaussian distribution.",Does the review address Methodology?,TRUE,FALSE,The review describes the methodological extension of previous work.
Can PACT be applied to simpler theorem provers like MetaMath where there are no tactics?,Does the review address Theory?,TRUE,FALSE,The review questions theoretical applicability to simpler theorem provers.
Pros:  - the paper is well written and very clear - the proposed model has two main advantages: (1) it is very fast to train due to the use of pre-trained BERT representations and (2) it does not depends on any external NLP tool (such as dependency parser)  Cons:   - I think the main source of improvement comes from the BERT representations used as input.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological advantages including fast training and independence from external tools.
"* It will be cool to show some results on BLEU improvement on machine translation, or user studies on language generation tasks, to demonstrate its practical impact, as the quantitative metrics right now are still kind of artificial.",Does the review address Significance?,TRUE,FALSE,The review suggests ways to demonstrate practical impact through BLEU scores and user studies.
* There has been so much work on static inference of invariants that it is impossible to list even all the closely related work.,Does the review address Related Work?,TRUE,FALSE,The review explicitly comments on the extensive body of related work.
The cold-start problem is actually an urgent problem to several online review analysis applications.,Does the review address Presentation?,FALSE,TRUE,The review discusses a technical problem rather than presentation aspects.
A comparison and discussion of this would be really useful.,Does the review address Comparison?,TRUE,FALSE,The review directly requests comparative discussion.
"Further, the performance improvements are nice, though not impressive.",Does the review address Result?,TRUE,FALSE,The review qualitatively assesses the performance improvements.
It's unclear what the contribution of the paper is.,Does the review address Contribution?,TRUE,FALSE,The review explicitly questions the paper's contribution.
"It also further demonstrates that the BERT model, once fully tuned, could achieve SOTA/competitive performance compared to the recent new models (e.g., XLNet).",Does the review address Methodology?,TRUE,FALSE,The review discusses BERT's performance compared to newer models when properly tuned.
"For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.",Does the review address Experiment?,TRUE,FALSE,"The review compares experimental results across different metrics (R@1, R@5, R@10)."
_ A question to the authors: What do you attribute the loss of performance of w2gm against w2g in the analysis of SWCS?,Does the review address Analysis?,TRUE,FALSE,The review asks about analysis of performance differences between models.
"Since one of the main contributions of this paper is the analysis of the BERT pretraining process, more experimental analysis on the optimizer should also be included.",Does the review address Contribution?,TRUE,FALSE,The review identifies analysis of BERT pretraining as a main contribution.
I encourage the authors to try out ideas they mentioned as future work to have a substantial contribution for a conference publication.,Does the review address Contribution?,TRUE,FALSE,The review suggests expanding the work to strengthen its contribution.
Energy and policy considerations for deep learning in NLP.,Does the review address Related Work?,TRUE,FALSE,The review references work on energy and policy considerations in NLP.
"It is not fully clarified what is the difference between the so-called ""ITM"" (image-text matching) and the contrastive losses used in other  VL pretrained models, such as ALIGN, ALBEF.",Does the review address Methodology?,TRUE,FALSE,The review questions methodological distinctions between different loss functions.
It especially corroborates that certain tasks are innately more challenging for active learning than others.,Does the review address Data/Task?,TRUE,FALSE,The review discusses task difficulty in active learning contexts.
"**Experiment setup** In Table 3, the paper only compares the proposed method against GPT-Neo and GPT-J, which is not sufficient.",Does the review address Comparison?,TRUE,FALSE,The review critiques limited comparison with only specific models.
"Weakness: - paper title is misleading, not directly related to LM - no citation and description for the baseline method T5+KB (Table 4) - As shown in Table 7, the proposed method is very sensitive to many factors.",Does the review address Related Work?,TRUE,FALSE,The review points out missing citations and descriptions of baseline methods.
"2.Through a significant number of ablation experiments, this paper extensively researched the model's hyperparameter configurations and training strategies, offering highly instructive guidance for related work.",Does the review address Ablation?,TRUE,FALSE,The review discusses extensive ablation experiments on hyperparameters and training strategies.
I think the setting of checkpoint depends on the hardware specifications and model architectures.,Does the review address Methodology?,TRUE,FALSE,The review discusses technical aspects of checkpoint settings.
"You forgot to bold the best performer in line 3 of Table 2 (in this case, the original compact model).",Does the review address Presentation?,TRUE,FALSE,The review points out formatting inconsistency in result presentation.
"The authors experiment both with pre-training and fine-tuning of contextual models (BERT-{base,large}) and claim large reduction in training time, with reasonable loss in performance.",Does the review address Result?,TRUE,FALSE,The review discusses performance outcomes including training time reduction and performance trade-offs.
"The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",Does the review address Result?,TRUE,FALSE,The review discusses experimental validation through ablation studies and research robustness.
"(3) multiSkip : Extends the approach presented by Luong et al. (2015b) for embedding using source and target context (via alignment), to the multilingual case by extending the objective function to include components for all available parallel corpora.",Does the review address Methodology?,TRUE,FALSE,The review describes a specific methodological extension (multiSkip) of previous work with details about its objective function.
"Do we need better model design, or more data and computations?",Does the review address Data/Task?,TRUE,FALSE,The review raises questions about data requirements versus model design needs.
"Alongside with qualitative analysis, some quantitative analysis would be good to show what the model learns.",Does the review address Methodology?,TRUE,FALSE,The review suggests methodological improvements through additional quantitative analysis.
"Elaboration on Theorem 1, with an intuitive breakdown of its implications, would significantly enhance the readability and credibility of the results.",Does the review address Presentation?,TRUE,FALSE,The review directly addresses readability and suggests improvements in the presentation of theoretical results.
How effective is the method to capture farther long-term dependencies compared to previous methods?,Does the review address Presentation?,FALSE,TRUE,The review asks about methodological effectiveness rather than presentation aspects.
Their method MC-LAVE used word embeddings on the language action space to help induce a non-uniform distribution over the action space.,Does the review address Methodology?,TRUE,FALSE,The review describes specific technical implementation using word embeddings for action space distribution.
"The proposed method has achieved SOTA performance on a range of Vision-Language benchmarks, spanning image captioning, Visual Question Answering, and visual grounding tasks.",Does the review address Data/Task?,TRUE,FALSE,The review lists multiple benchmark tasks across Vision-Language domains.
"This paper proposes a new understanding of dropout on top of variational dropout, which shows that training with dropout equals to maximizing an empirical variational lower bound on the log-likelihood.",Does the review address Methodology?,TRUE,FALSE,The review describes a new theoretical understanding and implementation of dropout.
"Also, the citation to Universal Dependencies is completely broken.",Does the review address Presentation?,TRUE,FALSE,The review points out a specific citation formatting issue.
My understanding is that contribution of the paper is in exploring using options framework to goal-oriented dialog to handle the issue in question.,Does the review address Contribution?,TRUE,FALSE,The review explicitly identifies the paper's main contribution regarding options framework.
So this contribution seems not practically useful according to the empirical result.,Does the review address Result?,TRUE,FALSE,The review comments on the practical utility of results.
"Perhaps an entropy-regularized setup is a useful comparison to show that it provides marginal benefit over the setup studied, and this might resolve the lack of clarity around the implications of the claims made from the first set of experiments.",Does the review address Comparison?,TRUE,FALSE,The review suggests comparing with an entropy-regularized setup for clarity.
"Also, the lack of attention mechanism provides a disadvantage to the baseline enc-dec system and it's unclear whether the pRNN can outperform or be an additive feature to the enc-dec system with an attention mechanism.",Does the review address Result?,TRUE,FALSE,The review discusses unclear comparative performance between systems.
This approach is simple combination of  Doc2Vec and STE.,Does the review address Presentation?,FALSE,TRUE,The review describes methodology rather than presentation aspects.
Why authors consider questions answering and sentiment analysis as the applications?,Does the review address Analysis?,TRUE,FALSE,The review questions the analysis choices regarding application selection.
It's not really okay to put up the tables and show the perplexity and BLEU scores without some explanation.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review criticizes lack of explanation for presented metrics.
"However, I feel that experiments can be strengthened, and notations can be improved.",Does the review address Presentation?,TRUE,FALSE,The review directly comments on writing quality and notation issues.
"I would have thought this was training an LM on progressively larger portions of the relevant data (being used for fine-tuning the others), in which case I'd also expect a downward trend in perplexity.",Does the review address Presentation?,FALSE,TRUE,The review discusses expected training behavior rather than presentation.
"- In the experiments in MultiWOZ, this paper only evaluates the response generation results.",Does the review address Experiment?,TRUE,FALSE,The review comments on the scope of experimental evaluation in MultiWOZ.
"For example, a lot of BERT-style models exploit dense interactions.",Does the review address Related Work?,TRUE,FALSE,The review references previous BERT-style models.
"- Weaknesses: Though it may not be possible in the time remaining, it would be good to see a comparison (i.e. BLEU scores) with previous related work like hierarchical softmax and differentiated softmax.",Does the review address Comparison?,TRUE,FALSE,The review requests comparison with specific previous work.
PUCT-RL is the only directly comparable baseline given action space and other handicap differences.,Does the review address Comparison?,TRUE,FALSE,The review discusses baseline comparability given constraints.
"- After definition 5.1, what does Omega[w] = Omega[w’] mean?",Does the review address Presentation?,TRUE,FALSE,The review asks for clarification of notation after a definition.
The authors claim that “There are a number of benefits of adopting the adaptive smoothing parameter”.,Does the review address Methodology?,TRUE,FALSE,The review references claims about adaptive smoothing parameter benefits.
"Publication venues are often missing; e.g., where was Boonkwan & Supnithi (2018) published?",Does the review address Presentation?,TRUE,FALSE,The review points out missing publication venue information.
"Details ========= Abstract: In o gur work => In our work P5: ""oracle dialogue state"": What is the oracle dialog state and how is it calculated?",Does the review address Presentation?,TRUE,FALSE,The review identifies specific typos and requests clarification.
3) One main contribution of this paper is the power-mean family of dropout.,Does the review address Contribution?,TRUE,FALSE,The review explicitly identifies power-mean family of dropout as a main contribution.
"The billions that have been pumped into languages like English have in fact resulted in technologies that can be applied at much lower cost to languages like Kanyen’kéha, but there are still costs.",Does the review address Methodology?,TRUE,FALSE,The review discusses technical resource allocation and technology transfer.
"Publication venues are often missing; e.g., where was Boonkwan & Supnithi (2018) published?",Does the review address Related Work?,TRUE,FALSE,The review specifically points out missing publication information in citations of prior work.
In particular the part that argued why B = O(1/alpha).,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses the explanation of a specific mathematical relationship (B = O(1/alpha)).
"But that would also mean that the phrases are determined by token ngrams which produces a sliding window of the ""pyramid encoders"" for each sentence where there are instance where the parameter for these phrases will be set close to zero to disable the phrases and these phrases would be a good intrinsic evaluation of the pRNN in addition to evaluating it purely on perplexity and BLEU extrinsically.",Does the review address Presentation?,FALSE,TRUE,The review discusses technical aspects of model architecture rather than presentation.
Theorem 1 in Section 5 seems to follow directly from the proposed definition of controllability.,Does the review address Theory?,TRUE,FALSE,The review discusses the logical connection between a theorem and controllability definition.
"The design of triggers, in this context, warrants a more nuanced discussion by the authors.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests more detailed discussion about trigger design.
The larger dataset may relate to more many-to-many relationships when training the model.,Does the review address Methodology?,TRUE,FALSE,The review discusses implications of dataset size on model training relationships.
"The method shows some performance gains over BERT on some GLUE tasks, but these are fairly small for the most part, and BERT outperforms the proposed method by a similar amount on a similar number of tasks.",Does the review address Comparison?,TRUE,FALSE,The review provides detailed performance comparison between the method and BERT on GLUE tasks.
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Evaluation?,TRUE,FALSE,The review critiques evaluation approach and requests justification.
Weaknesses * Something that stands out is the lack of discussion and comparison to related works that employ recurrent formulations of attention.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out insufficient discussion of related recurrent attention approaches.
"However, Section 3.1 cannot demonstrate effective theoretical information.",Does the review address Methodology?,TRUE,FALSE,The review criticizes lack of theoretical foundation in a specific section.
"Even with the results that already exist, it is claimed (for example in section 5.1) that MC-LAVE-RL is the only algorithm to pass bottlenecks such as getting the action ""take lantern"" right.",Does the review address Result?,TRUE,FALSE,The review discusses specific performance claims about action prediction.
"Although I understand the experiment setup, missing reference to more recent VL works prevent readers from getting a good research landscape in the multimodal pre-training.",Does the review address Experiment?,TRUE,FALSE,The review comments on experimental setup and missing references to recent work.
- Experiments contain 3 different tasks and each has datasets from different domains.,Does the review address Experiment?,TRUE,FALSE,The review describes experimental scope across different tasks and domains.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Presentation?,FALSE,TRUE,The review discusses empirical validation of theoretical assumptions.
- Improvement over previous state-of-the-art models.,Does the review address Result?,TRUE,FALSE,The review explicitly mentions improvement over previous state-of-the-art.
"The proposed system outperforms or achieves on-par  performance against previous SOTA methods, i.e., AudioGen and AudioLDM, in both objective and subjective metrics.",Does the review address Result?,TRUE,FALSE,The review details performance comparison with specific SOTA methods using multiple metrics.
"What the authors can do is: you can sample some sentences from the test/development set and count how many comparative words are misused in the original model, among which how many are corrected by reranking.",Does the review address Methodology?,TRUE,FALSE,The review suggests specific methodology for error analysis.
Introducing the layer and networks in a simple way would help clarify the implementation and other notation.,Does the review address Methodology?,TRUE,FALSE,The review suggests clearer introduction of technical components.
"In the experiment section, the authors only include the CoT annotations from [1] as the most important baseline.",Does the review address Comparison?,TRUE,FALSE,The review discusses baseline inclusion in experiments.
Simply adding related sentences in the pre training input context helps end performance.,Does the review address Methodology?,TRUE,FALSE,The review describes a specific pre-training approach involving context.
The experimental results mainly address similar networks with similar context lengths.,Does the review address Result?,TRUE,FALSE,The review comments on the scope of experimental results.
"For example, the $p^{\star}$ notation is also defined in Sec 2.1.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review references specific notation definition in the paper.
Empirical results on MultiWoz 2 and 2.1 shows improvement over other state-of-the-art techniques.,Does the review address Data/Task?,TRUE,FALSE,The review mentions specific datasets (MultiWoz 2 and 2.1) and performance.
This is a crucial scientific finding: money works!,Does the review address Significance?,TRUE,FALSE,The review makes a statement about the scientific importance of findings.
"With this definition, a linear model of the logits is also a linear model over the context embeddings f(s) directly.",Does the review address Presentation?,TRUE,FALSE,The review discusses mathematical definition presentation.
"The model leverage pre-trained BERT language models, making it very fast to train.",Does the review address Methodology?,TRUE,FALSE,The review describes specific technical approach using pre-trained BERT models.
Each task is supported with a detailed ablation study to shed light on future research.,Does the review address Data/Task?,TRUE,FALSE,The review mentions detailed ablation studies for multiple tasks.
Making these comparisons would require a heavy rewrite starting from the abstract to the analysis and so I would recommend reject right now but look forward to seeing an updated version of the paper in the future with some of these changes.,Does the review address Analysis?,TRUE,FALSE,The review suggests substantial revision of analysis and comparisons.
"Also, possibly figure 3 can be combined into the pyramid part of figure 4.",Does the review address Presentation?,TRUE,FALSE,The review suggests specific figure reorganization for better presentation.
"Especially, in terms novelty, the paper is relatively limited as the RF is explored in Rawat et al., 19.",Does the review address Novelty?,TRUE,FALSE,The review criticizes limited novelty due to previous exploration in cited work.
"Considering this is the combined benefit of multiple techniques, e.g. distillation, text token selection, contrastive learning, I am not fully convinced by the empirical value of the proposed method.",Does the review address Methodology?,TRUE,FALSE,"The review analyzes multiple technical components (distillation, token selection, contrastive learning)."
"It is not clear how this model would compare to other models using language specific parameters (sparsely gated mixture of experts (Lepikhin et al 2020), light-weight adapters (Bapna et al 2019)  ).",Does the review address Methodology?,TRUE,FALSE,The review compares methodological approaches with specific alternative models.
2) TDE follows the previous work and aims to learn three different level embeddings.,Does the review address Methodology?,TRUE,FALSE,The review describes specific embedding learning approach following prior work.
"In comparison, if we look at Page 17, the actual annotations from the authors are very long and detailed.",Does the review address Data/Task?,TRUE,FALSE,The review compares annotation length and detail between different sources.
This paper studies why language model pre-training has been such an effective technique in improving downstream performance across a wide range of NLP tasks recently.,Does the review address Result?,FALSE,TRUE,The review describes study objectives rather than specific results.
I felt this was quite separate from the theoretical analysis.,Does the review address Analysis?,TRUE,FALSE,The review comments on separation between theoretical and other analyses.
* Related work: I would also include a discussion of this Lazaridou et al paper where they compare ways of combining EC with non-EC learning signals (e.g. image caption training): https://aclanthology.org/2020.acl-main.685.pdf  * Ethics statement: I appreciate this statement and agree with the possible positive impacts.,Does the review address Related Work?,TRUE,FALSE,The review suggests including specific additional related work and citations.
"Reducing these costs could have a very high impact on the field, allowing many more researchers to participate in state-of-the-art research [3].",Does the review address Significance?,TRUE,FALSE,The review discusses potential impact on research accessibility.
There is also a NAACL 2016 paper (https://www.aclweb.org/anthology/N/N16/N16-2016.pdf) which performs relation extraction using a new model based on memory networks… and I’m sure there are more.,Does the review address Related Work?,TRUE,FALSE,The review cites specific related paper and suggests existence of more.
### Notes on text and style  There are parts of the manuscript that felt somewhat informal and confusing to me.,Does the review address Presentation?,TRUE,FALSE,The review directly criticizes writing style and formality.
"The authors cite Bordes et al. (https://arxiv.org/pdf/1506.02075.pdf), who collect a similar dataset and perform relation extraction using memory networks (which are commonly used for reading comprehension).",Does the review address Related Work?,TRUE,FALSE,The review references specific prior work using memory networks.
"- P24, Figure 2: What are the x and y axis, and what does each dot mean in this figure?",Does the review address Presentation?,TRUE,FALSE,The review requests clarification of figure elements.
Why don't the authors of this work do this evaluation as well?,Does the review address Data/Task?,FALSE,TRUE,The review questions evaluation choices rather than data/task aspects.
"I would have liked to see these results (also, please fix grammar in this sentence) 9.",Does the review address Result?,TRUE,FALSE,The review requests to see specific results and notes grammar issues.
The findings of (2)(3)(4)(5) mentioned in the summary section above are especially interesting and can be helpful to the community when comparing new VL methods with existing methods.,Does the review address Methodology?,TRUE,FALSE,The review discusses usefulness of findings for method comparison.
The introduction of the motivation (the concept of in-context bias) is not easy to understand at the very beginning.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review criticizes clarity of motivational concept explanation.
It would be good if the authors could provide some intuition / insight as to why that might be the case.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review requests intuitive explanation for observed phenomena.
Towards making the most of bert in neural machine translation.,Does the review address Related Work?,TRUE,FALSE,The review references specific work on BERT in neural machine translation.
"However, there is no discussion on the latency in the proposed method and experiments.",Does the review address Methodology?,TRUE,FALSE,The review points out missing discussion of methodological latency.
- The ablation experiments and optimized prompt analysis are insightful.,Does the review address Analysis?,TRUE,FALSE,The review positively comments on ablation experiments and prompt analysis.
The paper features extensive experiments that convincingly validate the effectiveness of the proposed method.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review discusses validation through ""extensive experiments that convincingly validate"" the method"
A qualitative analysis might be more revealing here.,Does the review address Analysis?,TRUE,FALSE,"The review directly suggests a ""qualitative analysis"" should be performed"
This along with a regularization reward using language model the paper aims to improve comprehensibility.,Does the review address Methodology?,TRUE,FALSE,"The review discusses methodological components including ""regularization reward"" and ""language model"""
Otherwise for example it is not clear to me if the improvement in Blue compared to LaRL comes from the extra reward using the language model or from the options framework.,Does the review address Result?,TRUE,FALSE,The review discusses improvement in BLEU scores compared to a baseline (LaRL)
"**Strengths** - To the best of my knowledge, this is the first work that _mathematically_ justifies the connection between the pre-training objective and the downstream performance.",Does the review address Methodology?,FALSE,TRUE,The review actually mentions Novelty/Contribution rather than methodology specifically
Please feel free to highlight other major contributions.,Does the review address Contribution?,TRUE,FALSE,"The review explicitly asks about ""major contributions"""
"- Less technical comments: The paper writing is fine to me, but I don't like the typesetting.",Does the review address Presentation?,TRUE,FALSE,The review directly comments on paper writing and typesetting
"Contribution: The authors contribute a new tokenization method, code, and a dataset.",Does the review address Data/Task?,TRUE,FALSE,The review mentions a dataset as part of the contributions
This is the newest of a small but growing body of literature that seeks to connect emergent communication with genuine NLP tasks.,Does the review address Related Work?,TRUE,FALSE,The review explicitly discusses existing literature in the field
"The authors argued that most of the previous multimodal LLMs used shallow connections between vision and models, and thus proposed a new module called visual expert.",Does the review address Related Work?,TRUE,FALSE,The review discusses previous multimodal LLMs and their approaches
"In this case, the authors are using LeetCode coded solutions in MP to compiled the source code into a lower level form (assembly I believe) and then see if N-Bref can return the assembly back to the original form or some semantically equivalent form.",Does the review address Presentation?,FALSE,TRUE,The review describes methodology and implementation details rather than presentation
"- For the classification tasks, what do the label distributions look like over the labeled subset $\mathcal L$?",Does the review address Data/Task?,TRUE,FALSE,The review specifically asks about label distributions in the dataset
* Could the authors provide more details about the evaluation settings and number of parameters of each model for the per-token loss comparison?,Does the review address Methodology?,TRUE,FALSE,The review asks about evaluation settings and model parameters
The paper has explained and empirically showed that this learned generator needs a resampler.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review mentions that the paper has explained and shown something empirically
Hon downstream tasks with smaller learning rate -> Do you mean smaller datasets?,Does the review address Data/Task?,TRUE,FALSE,The review asks about dataset sizes in downstream tasks
"The proposed method has achieved SOTA performance on a range of Vision-Language benchmarks, spanning image captioning, Visual Question Answering, and visual grounding tasks.",Does the review address Methodology?,TRUE,FALSE,The review describes the method's performance across different benchmarks
"The studies here show that, pre-training with Inverse Cloze Task (ICT) the two-tower Transformer models significantly outperform the widely used BM-25 algorithm for large-scale information retrieval.",Does the review address Presentation?,FALSE,TRUE,The review discusses results and methodology rather than presentation
### Overall  Authors used BERT alongside to a 2D-position embedding based on a sinusoidal function and a graph-based decoder to improve performance on document information extraction tasks.,Does the review address Result?,TRUE,FALSE,The review describes improvements in document information extraction tasks
"According to the evaluation, the proposed method shows its effectiveness especially when the finetuning data is limited.",Does the review address Evaluation?,TRUE,FALSE,The review directly discusses evaluation results
I found the result that the LSTM-based model successfully reconstructs the stimuli but fails on the main game to be interesting.,Does the review address Methodology?,FALSE,TRUE,The review actually focuses on Results rather than methodology
It is based on the state-of-the-art language model--augmented memory.,Does the review address Methodology?,TRUE,FALSE,The review describes the methodological basis of the model
"Authors could have provided more in-depth details (visualizations, analysis, examples) to show main differences between the proposed approach and baselines (specially LayoutLM).",Does the review address Comparison?,TRUE,FALSE,The review explicitly asks for comparative analysis with baselines
"For example, the model hyper-parameters are quite different for different tasks.",Does the review address Data/Task?,TRUE,FALSE,The review discusses task-specific hyperparameters
The use of RNN and Copy RNN in the current context is a new idea.,Does the review address Methodology?,TRUE,FALSE,The review discusses the use of specific technical approaches (RNN and Copy RNN)
- There is some missing prior work in creating knowledge graphs from pre-trained language models.,Does the review address Related Work?,TRUE,FALSE,The review explicitly mentions missing prior work
"The motivation is very clear, MCTS is generally action agnostic and using language to provide additional semantic information to it can prove to be very effective.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review explicitly discusses motivation and explains why using language with MCTS can be effective
"If there is some significant difference here, it is not made clear in the paper.",Does the review address Presentation?,TRUE,FALSE,The review criticizes the clarity of presentation regarding significant differences
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Result?,TRUE,FALSE,The review discusses performance comparisons with other approaches and ablation results
The authors should discuss the relationship with other in-context example selection methods and compare the performance.,Does the review address Result?,TRUE,FALSE,The review suggests comparing performance with other methods
It does not only require the optimization ability but also the oracle efficiency.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological requirements regarding optimization and oracle efficiency
This paper proposed a new phrasal RNN architecture for sequence to sequence generation.,Does the review address Presentation?,FALSE,TRUE,The review describes the methodology (phrasal RNN architecture) rather than presentation
- Removing the dependence of engineered perceptual models from the CaP method by using foundation models.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological changes regarding foundation models
"Additionally, there are some minor things I would add or improve: - I would add references to multi-task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE).",Does the review address Methodology?,TRUE,FALSE,The review discusses multi-task training methodology for different languages
"- Additionally, why isn't the the GRU version of pRNNv reported in the FBIS evaluation in Table 3?",Does the review address Presentation?,TRUE,FALSE,The review questions the presentation of results in a specific table
"- Weaknesses: In experiments, the author set the window width of the filters in the CNN module to 2.",Does the review address Experiment?,TRUE,FALSE,The review discusses specific experimental settings (window width in CNN)
Use the text data that comes with each dataset as is and compare this with :   a) Using OpenAQA (current setting)   b) Augmenting the original audio text pairs with OpenAQA  2.,Does the review address Significance?,FALSE,TRUE,The review discusses methodology and experimental setup rather than significance
The methods is evaluated on 5 standard NER+RE datasets with good performances.,Does the review address Data/Task?,TRUE,FALSE,The review mentions evaluation on specific NER+RE datasets
"3.The model excels in various audio-related tasks and open-ended question answering, demonstrating its outstanding performance.",Does the review address Data/Task?,TRUE,FALSE,The review discusses various audio-related tasks
"However, it seems like there's still some open questions about the types of improvements being made and what this implies about the LM's attention mechanism.",Does the review address Methodology?,TRUE,FALSE,The review discusses questions about the LM's attention mechanism
The authors take time to implement and evaluate several prominent baselines.,Does the review address Presentation?,FALSE,TRUE,The review discusses evaluation of baselines rather than presentation
"Kernel-based variants of self-attention have a recurrent formulation and lead to linear complexity (see [1,2,3,4]).",Does the review address Methodology?,TRUE,FALSE,The review discusses technical details of kernel-based self-attention variants
Statistical comparisons of classifiers over multiple data sets.,Does the review address Related Work?,TRUE,FALSE,The review references related work on classifier comparisons
"High-level view:  I don’t think this is necessarily a bad paper, but I think it’s unacceptable for ICLR in its current form.",Does the review address Evaluation?,TRUE,FALSE,The review provides an overall evaluation of the paper's quality for ICLR
This is very likely a confounding factor in the efficacy of active learning and pruning techniques.,Does the review address Methodology?,TRUE,FALSE,The review discusses active learning and pruning techniques
The LSTM classifier is left highly unspecified (L407-409) -- there are multiple different architectures to use an LSTM for classification.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out lack of specification details for the LSTM classifier
"If the authors can adequately address the following issues around presentation and the interpretation of Theorem 5, I would be satisfied raising my score, as I value the research question raised by the paper and believe the conclusions are valid.",Does the review address Theory?,TRUE,FALSE,The review specifically mentions Theorem 5 and its interpretation
The findings from the analysis are an important addition to the understanding of the role of language specific parameters in multilingual NMT.,Does the review address Result?,TRUE,FALSE,The review discusses findings about language-specific parameters in multilingual NMT
- The objectives suggested are cheap to compute and seem to increase the signal available in the data.,Does the review address Data/Task?,TRUE,FALSE,The review discusses objectives related to data signal
"Considering the BERT is leveraged, you should discuss the relation with BERT + NMT [R1,R2].",Does the review address Methodology?,TRUE,FALSE,The review discusses methodological aspects regarding BERT and NMT
The results presented in the paper show strong gains against baseline methods on 3 different datasets.,Does the review address Result?,TRUE,FALSE,The review explicitly mentions strong gains against baselines on multiple datasets
This paper claims that it is the first time designing a reasoning comprehension-capable model.,Does the review address Methodology?,FALSE,TRUE,"The review states a claim about being first to design a reasoning comprehension model, but does not discuss the actual methodology in detail."
"Can the theory extend to cross-language clone detection, e.g., one language is tractable, but the other language is not?",Does the review address Theory?,TRUE,FALSE,"The review directly asks a theoretical question about extending the theory across languages, indicating engagement with theoretical aspects."
This method should be included in the experiments in order to justify the proposed RL approach is necessary.,Does the review address Methodology?,TRUE,FALSE,"The review suggests including a method in experiments to justify the proposed RL approach, directly addressing methodological considerations."
Can the proposed theory help explain if the same code modeling task for some languages is strictly easier than the others?,Does the review address Theory?,TRUE,FALSE,"The review poses a theoretical question about code modeling task difficulty across languages, engaging with theoretical concepts."
"In terms of strenghs - The paper has a very throughout analysis of different models and positional encodings - It proposes several contributions, including a new probing task and several positional encoding methods.",Does the review address Presentation?,TRUE,FALSE,"The review comments on the thoroughness of analysis and structure of the paper, which relates to Presentation aspect."
"- P6, Sec 4.3: ""In fact, $f$ almost always performs better than ..."" This part seems intriguing despite the linear relationship shown in figure 1.",Does the review address Result?,TRUE,FALSE,"The review references a specific part of the results and finds it intriguing, directly addressing the Result aspect."
The results on a mixture of the Parity/Sum task are interesting   2.,Does the review address Result?,TRUE,FALSE,"The review explicitly mentions finding the results interesting, directly addressing the Result aspect."
"Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally.",Does the review address Experiment?,TRUE,FALSE,"The review mentions analysis and experimental validation of recommendations, directly addressing the Experiment aspect."
"Also, can you add a column where a dense linear model over p_f(s) is used?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests adding a column and discussing a model, indicating a desire for more detailed explanation or description."
"* It will be cool to show some results on BLEU improvement on machine translation, or user studies on language generation tasks, to demonstrate its practical impact, as the quantitative metrics right now are still kind of artificial.",Does the review address Data/Task?,TRUE,FALSE,"The review suggests showing results on specific tasks (machine translation, language generation), directly addressing Data/Task."
"Your work is so similar to much of this work that you should really cite and establish novelty wrt at least some of them as early as the introduction -- that's how early I was wondering how your work differed, and it was not made clear.",Does the review address Related Work?,TRUE,FALSE,"The review criticizes lack of citation and novelty establishment in relation to existing work, directly addressing Related Work."
"The article is well-structured, starting with a thorough discussion on the shortcomings of naive backdoor-type watermarking methods before delving into their novel DOUBLE-I WATERMARKING FRAMEWORK.",Does the review address Methodology?,TRUE,FALSE,"The review describes the article's structure and discussion of watermarking methods, addressing Methodology."
"For CSQA, the best number in this paper is 63.32 vs. 79.5 on the current leaderboard.",Does the review address Result?,TRUE,FALSE,"The review compares specific numerical results, directly addressing the Result aspect."
The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).,Does the review address Presentation?,TRUE,FALSE,"The review comments on experimental results highlighting the approach's applicability, which relates to Presentation."
"So I suggest that the authors give a technical introduction of the framework and more precisely discuss how it can solve the problem of interest, possibly with visual illustrations.",Does the review address Methodology?,TRUE,FALSE,"The review suggests a technical introduction and discussion of the framework, directly addressing Methodology."
"For example, if you could give us one or two sentences of Fon in the beginning of the paper, that demonstrate some of the difficulties of the language, I think this would greatly strengthen the motivation.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests providing more descriptive details to strengthen motivation, directly addressing description."
"- The paper is well-written, well-organized, and easy to follow.",Does the review address Presentation?,TRUE,FALSE,"The review explicitly comments on the paper being well-written and organized, addressing Presentation."
"For instance, they ask how different amounts of data influence model behavior or if their data sampling method can react to task difficulty.",Does the review address Methodology?,TRUE,FALSE,"The review discusses data influence and sampling methods, directly addressing Methodology."
"However, the paper does not include detailed descriptions about the proposed method, making readers not easy to understand.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review criticizes lack of detailed descriptions, directly addressing the Elucidation aspect."
"The study sheds light on the amount of language specific parameter sharing, their distribution in the network, impact of language, etc.",Does the review address Methodology?,TRUE,FALSE,"The review discusses language-specific parameter sharing and network distribution, addressing Methodology."
"In a similar vein, I would have appreciated more details about the model architecture and the training regimes used (possibly in the appendix).",Does the review address Presentation?,TRUE,FALSE,"The review requests more details about model architecture, which relates to Presentation."
"However, there is a lack of unified experimental standards and ablation experiments in this paper.",Does the review address Experiment?,TRUE,FALSE,"The review points out a lack of unified experimental standards and ablation experiments, directly addressing Experiment."
"These objectives certainly improve over the original T5 base _and_ larges models that are used as initializations, and especially outperform the base model in the low-data regime.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses model performance across different data regimes, addressing Data/Task."
The authors only conduct the evaluation on sentence similarity tasks and open domain QA tasks.,Does the review address Data/Task?,TRUE,FALSE,"The review specifies the evaluation tasks conducted, directly addressing Data/Task."
I found the result that the LSTM-based model successfully reconstructs the stimuli but fails on the main game to be interesting.,Does the review address Result?,TRUE,FALSE,"The review comments on an interesting result from the LSTM-based model, directly addressing Result."
(3) The loss for answer prediction in Eq 6 is not clearly described: do you use an aggregated embedding over all nodes for prediction?,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review asks for a detailed explanation of the loss prediction method, directly addressing deecription."
"In this way, the conclusion is only supported by the empirical observations but not the presented theoretical analysis.",Does the review address Theory?,TRUE,FALSE,"The review criticizes the lack of theoretical analysis to support empirical observations, engaging with the Theory aspect."
The usage of attention mechanism without some sort of pruning might be problematic at the phrasal level.,Does the review address Methodology?,TRUE,FALSE,"The review critiques the usage of the attention mechanism, directly addressing Methodology."
This paper describes four methods of obtaining multilingual word embeddings and a modified QVEC metric for evaluating the efficacy of these embeddings.,Does the review address Evaluation?,TRUE,FALSE,"The review describes methods of obtaining multilingual word embeddings and a metric for evaluating them, directly addressing Evaluation."
"Detailed comments:  Training (especially pretraining) costs have been going wild in AI and NLP more particularly, which leads to large costs ([1]) as well as potential environmental problems ([2]).",Does the review address Methodology?,TRUE,FALSE,"The review discusses training costs and their implications, which relates to Methodology."
"I would have thought this was training an LM on progressively larger portions of the relevant data (being used for fine-tuning the others), in which case I'd also expect a downward trend in perplexity.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses data usage and training approach, addressing the Data/Task aspect."
"Also, different programmers write comments very differently.",Does the review address Analysis?,TRUE,FALSE,"The review makes an observation about differences in how programmers write comments, addressing Analysis."
"3) Continue with 2), as the experiment results shown in Table 2, TS compiler performs poorly.",Does the review address Result?,TRUE,FALSE,"The review references experimental results showing poor performance, directly addressing Result."
The wide range of datasets and active learning techniques they use (including BALD which prior works shows is very competitive) lends credence to the conclusions.,Does the review address Methodology?,TRUE,FALSE,"The review discusses the range of datasets and active learning techniques, addressing Methodology."
"In Table 1, the baseline models are TreeRNN and DCNN, they are originally used for sentence embedding but one can easily take the node/substructure embedding from them too.",Does the review address Methodology?,TRUE,FALSE,"The review discusses baseline models and their potential embeddings, addressing Methodology."
"## Justification As my primary critique concerns the experiments, I will address each individually mentioning any deficiencies and potential improvements.",Does the review address Experiment?,TRUE,FALSE,"The review explicitly mentions addressing experiments as a primary critique, directly addressing Experiment."
"Result 1: Under the above assumption over the downstream task, this paper provides a bound on the empirical loss of the downstream prediction task.",Does the review address Result?,TRUE,FALSE,"The review discusses a result providing a bound on empirical loss, directly addressing Result."
"It is unclear to me how the authors are going to justify this ""assumption"".",Does the review address Presentation?,TRUE,FALSE,"The review questions the justification of an assumption, relating to Presentation."
"By using a multimodal, the current approach attain the problem of polysemy.",Does the review address Methodology?,TRUE,FALSE,"The review discusses using a multimodal approach to address polysemy, addressing Methodology."
"- Figure 1: unclear why certain input sizes have their accuracy going down, even though they have reached 100% in the earlier epochs.",Does the review address Presentation?,TRUE,FALSE,"The review points out an unclear aspect of Figure 1, directly addressing Presentation."
Concerns around novelty and the multi-task setup was also raised by another reviewer (e7Hg).,Does the review address Novelty?,TRUE,FALSE,"The review mentions concerns about novelty, directly addressing the Novelty aspect."
"However, there is no theoretical result about the effectiveness of assigning the self-knowledge distillation to label smoothing.",Does the review address Methodology?,TRUE,FALSE,"The review discusses the lack of theoretical results about a specific method, addressing Methodology."
The proposed method achieves SoTA results on CommonGen with slightly more than half the parameters of the current SoTA model.,Does the review address Result?,TRUE,FALSE,"The review highlights the achievement of state-of-the-art results, directly addressing Result."
"- P6, Sec 4.3: ""In fact, $f$ almost always performs better than ..."" This part seems intriguing despite the linear relationship shown in figure 1.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review discusses an intriguing part of the description, addressing description."
"- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other ""oracle"" baselines.",Does the review address Evaluation?,TRUE,FALSE,"The review describes the evaluation approach with datasets and comparisons, addressing Evaluation."
It is hard for other users to apply this technique.,Does the review address Methodology?,TRUE,FALSE,"The review suggests difficulty in applying the technique, relating to Methodology."
"Other concerns along these lines: all of this paper's results are averaged over 3 runs while the other baselines are over 5 runs - an indication of variance would be useful to assess whether the differences are significant, especially since some of the margins quite small (23 on MC-LAVE-RL vs 22.8 for the next best on Ludicorp) added to the fact that hyperparameters are different for each game - does that imply that the authors tuned the hyperparameters for each game?",Does the review address Result?,TRUE,FALSE,"The review discusses result reporting, statistical significance, and experimental details, addressing Result."
One very simple way could be to analyze the occurrence frequency of interleaved natural and programming patterns in the dataset.,Does the review address Analysis?,TRUE,FALSE,"The review suggests a method of analysis for dataset patterns, directly addressing Analysis."
First theoretical definition of equivalence-preserving program embedding problem.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review mentions a theoretical definition, addressing definition."
"The first is selecting the most uncertain examples, and the second is making the CoT annotations longer.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses approaches to selecting and annotating examples, addressing Data/Task."
"The evaluation results are based on the authors' implementations, for both baseline and the proposed method.",Does the review address Methodology?,FALSE,TRUE,"The review discusses evaluation results implementation, but does not explicitly describe methodology"
The main weakness of the paper is that it is mainly based on further tuning the existing BERT model and lacks novel contribution in model architecture.,Does the review address Methodology?,TRUE,FALSE,"The review critiques the model architecture, directly addressing methodological aspects"
"... bunch of those errors has should be ""errors have"".",Does the review address Presentation?,TRUE,FALSE,"The review points out a grammatical error, which directly relates to presentation"
The paper provides a comprehensive study on the two-tower Transformer models in terms of the impact of its pre-training tasks on large-scale retrieval applications.,Does the review address Methodology?,TRUE,FALSE,"The review describes a comprehensive study of two-tower Transformer models, which is a methodological description"
The method relies much upon manual designs that seem hard to generalize.,Does the review address Presentation?,FALSE,TRUE,"The review comments on method generalizability, which is more about methodology than presentation"
"So how would it be possible to train with poor annotations, while generalize much better?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,This is a rhetorical question that does not provide a detailed explanation
What if a similar sample exists in a quite different source task?,Does the review address Data/Task?,TRUE,FALSE,"The review raises a question about sample sources, directly relating to data and task considerations"
"In experiments, there is no comparison with previous retrieval based methods.",Does the review address Experiment?,TRUE,FALSE,The review directly comments on the lack of comparison with previous retrieval methods
The need for short sequence acceleration needs to be justified IMO.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review suggests a need for justification, which is about motivation"
"Indeed, the proposed graph model seems to only implicitly convey knowledge across facts in terms of local reasoning.",Does the review address Methodology?,TRUE,FALSE,"The review critically discusses the graph model's knowledge conveyance, addressing methodology"
The idea was (reasonably) well-positioned with respect to prior work and clearly presented.,Does the review address Related Work?,TRUE,FALSE,The review comments on positioning with respect to prior work
Ablation studies show that the model achieves good performance on more complex questions.,Does the review address Result?,TRUE,FALSE,The review mentions ablation studies and performance on complex questions
Hon downstream tasks with smaller learning rate -> Do you mean smaller datasets?,Does the review address Presentation?,TRUE,FALSE,The review points out a potentially confusing or grammatically incorrect phrase
"The paper has ""support set"" and ""support instructions"" at many places but it is unclear to me what it actually means.",Does the review address Presentation?,TRUE,FALSE,The review highlights unclear terminology usage
### Summary ### The paper presents a technique for inference of certain kinds of program invariants directly from the program’s source code.,Does the review address Methodology?,TRUE,FALSE,The review describes a technique for program invariant inference
"However, the BERT analysis results provided in this paper should also be valuable to the community.",Does the review address Methodology?,TRUE,FALSE,"The review discusses BERT analysis results, which relates to methodological aspects"
Strength: + Describes an important property of program embeddings: they should remain invariant to semantic-preserving transformations.,Does the review address Methodology?,TRUE,FALSE,The review describes an important property of program embeddings
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Presentation?,FALSE,TRUE,"The review discusses theoretical performance, which is more about theory than presentation"
"The authors only put a sentence at the end of the Appendix saying that “we still found PEER to generate false statements or claims not backed up by the provided documents in many cases“, but in the main paper there is no discussion or statistics on this weakness.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the lack of detailed discussion about a specific weakness
"- Weaknesses: In experiments, the author set the window width of the filters in the CNN module to 2.",Does the review address Methodology?,TRUE,FALSE,The review mentions a specific experimental setup detail (filter width)
"### Cons and aspects to improve  My main concern is that the overall contribution is seems to be limited.In fact, the original paper of the Transformer approach, already proposed such kind of embedding.",Does the review address Contribution?,TRUE,FALSE,The review discusses the limited overall contribution
"These are not weakness, but I think some work in this direction may help improve the paper.",Does the review address Presentation?,FALSE,TRUE,The review is making a constructive comment about potential improvements
"By associating nodes across different fact units based on coreferences and mentions, a supergraph is built that connects all related information and conducts graph reasoning for answer predictions.",Does the review address Methodology?,TRUE,FALSE,The review describes a specific methodological approach to graph reasoning
A three-line explanation at the end of Section 4.1 seems a bit scarce to me.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the brevity of an explanation
"## Justification As my primary critique concerns the experiments, I will address each individually mentioning any deficiencies and potential improvements.",Does the review address Result?,TRUE,FALSE,The review mentions addressing experimental critiques
"It provides a nice theoretical framework for thinking about the connection between language models and downstream tasks, which future work could build on.",Does the review address Methodology?,FALSE,TRUE,"The review provides a theoretical framework, which relates more to theory rather than specific methodology"
"Figure from LayoutLM is a good example of that, it comprises the entire process and makes it easier to understand the whole architecture.",Does the review address Methodology?,TRUE,FALSE,"The review references a figure explaining the entire architecture, directly addressing methodology"
The experimentation is correct and the qualitative analysis made in table 1 shows results as expected from the approach.,Does the review address Analysis?,TRUE,FALSE,"The review mentions a qualitative analysis in table 1, which directly relates to the Analysis aspect"
"It's ok for the proposed method to be one particular way, but that discussion would be useful.",Does the review address Methodology?,FALSE,TRUE,"The review is a general comment about the method, not a detailed methodological description"
The difference in the ablation results seem quite small (tables 3 and 4).,Does the review address Ablation?,TRUE,FALSE,The review directly references ablation results in tables 3 and 4
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Experiment?,TRUE,FALSE,The review explicitly mentions ablation study and visualization analysis
I can not understand why sample-specific rather than task-specific preference is important for prompt tuning.,Does the review address Methodology?,TRUE,FALSE,"The review questions the specific approach to prompt tuning, addressing methodological considerations"
"HRL in general has been used previously for goal-oriented dialog, using language models to regularize RL models has been used and pertaining using SL is widely used.",Does the review address Methodology?,TRUE,FALSE,The review discusses previous methodological approaches in language models and reinforcement learning
The paper does a systematic analysis on the role of language specific parameters using the proposed architecture.,Does the review address Methodology?,TRUE,FALSE,The review describes a systematic analysis of language-specific parameters
"It would have been better to see the performance gains on more difficult text-classification tasks (non-GLUE), or underperforming models (non-BERT based).",Does the review address Methodology?,TRUE,FALSE,The review suggests exploring performance on different text classification tasks
"For table 4, please also include the significance of the BLEU improvement made by the pRNN with respect to the the baseline, see https://github.com/jhclark/multeval General Discussion ==== As the main contribution of this work is on the phrasal effect of the new RNN architecture, it's rather important to show that the phrases are more coherent than the vanilla LSTM / RNN model.",Does the review address Comparison?,TRUE,FALSE,The review recommends showing significance of improvements and comparing to baseline models
"In the experiment section, the authors only include the CoT annotations from [1] as the most important baseline.",Does the review address Experiment?,TRUE,FALSE,The review comments on the baseline included in the experiment section
This would probably highlight LTU significantly as the two approaches are contemporary in many ways and are very similar in the overarching goal.,Does the review address Significance?,TRUE,FALSE,The review suggests highlighting the approach's significance by comparing to contemporary methods
"Numerous neural architectures have been used to model programs, e.g., large language models, graph neural networks, etc.",Does the review address Presentation?,FALSE,TRUE,"The review lists neural architectures, which is more about methodology than presentation"
**Limitations** - The authors admit that their work is limited to a particular type of downstream tasks.,Does the review address Data/Task?,TRUE,FALSE,The review mentions limitations related to downstream tasks
"1.The paper introduces for the first time a large language model that combines both general audio perception capabilities and language reasoning abilities, along with the datasets used for training.",Does the review address Data/Task?,TRUE,FALSE,The review discusses a language model's capabilities and associated datasets
"There are many confounding factors such as the number and type of pretraining data, the instruction-tuning data, different architecture designs, and finetuning strategies.",Does the review address Methodology?,TRUE,FALSE,The review lists confounding factors in methodological approaches
- It would be great if authors could incorporate more baseline methods.,Does the review address Methodology?,FALSE,TRUE,"The review suggests incorporating more baseline methods, but does not describe methodology"
"Comments on the model: - After computing the substructure embeddings, it seems very natural to compute an attention over them at each word.",Does the review address Methodology?,TRUE,FALSE,The review provides a methodological suggestion about computing embeddings
"It considers the training direction to be ""first to perceive, and then comprehend the sound"" so that the training starts from using close-ended datasets to open-ended datasets.",Does the review address Methodology?,TRUE,FALSE,The review describes the training direction and approach
Details of training and dataset are logical and delicate.,Does the review address Methodology?,TRUE,FALSE,The review comments on the details of training and dataset
Would be great to state them upfront to avoid confusion.,Does the review address Presentation?,TRUE,FALSE,"The review suggests upfront clarification to avoid confusion, directly addressing presentation"
I suspect the size plays an important role in such setups and this hasn't been discussed much in the paper.,Does the review address Significance?,TRUE,FALSE,"The review suggests discussing the role of model size, which relates to significance"
"It provided me with a much more thoughtful explanation for why language model pre-training improves downstream task performance, beyond simply “it helps learn good general representations of language using large amounts of unlabeled text data” (my previous reasoning).",Does the review address Data/Task?,FALSE,TRUE,"The review provides an explanation of language model pre-training, which is more about theory than specific data or task"
"It requires more analysis about experimental results, such as Figure 1 and tables in Section D.",Does the review address Result?,TRUE,FALSE,The review requests more analysis of experimental results
All of the results in this work seem to be previously known: * Theorem 1 is general to any polynomial-size circuit -- there is nothing special about Transformers.,Does the review address Result?,TRUE,FALSE,"The review critiques the results, suggesting they are not novel, which directly addresses the Results aspect"
"But I support given a fixed set of phrase pairs at train time, the attention mechanism at the phrasal level can be pre-computed but at inference (apply the attention on new data at test time), this might be kind of problematic when the architecture is scaled to a larger dataset.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses dataset scaling and potential challenges, relating to Data/Task"
"Furthermore, when there is a gap between the empirical results and the theoretical results (e.g., validation of Lemma 4.3 at the end of Section 4), the paper makes these limitations clear, which I appreciated very much as a reader (paper does not over-claim its contributions).",Does the review address Contribution?,TRUE,FALSE,The review explicitly discusses the paper's contributions and its approach to limitations
"Are there any overheads/disadvantages because of multi-task learning (Like a larger model size, inference time for individual tasks etc)?",Does the review address Methodology?,FALSE,TRUE,"The review raises questions about multi-task learning, but does not describe methodology"
"in Table 2, it's necessary to explain why the LSTM's perplexity from previous work is higher than the author's implementation.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests an explanation for a specific table result
One of the important motivations of multi-modal multi-task learning mentioned was to achieve better or on-par performance with a single model (and supposedly fewer computations) which is crucial for devices with limited computing resources.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review explicitly discusses the motivation behind multi-modal multi-task learning
"Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review mentions validation of recommendations through experimentation
"The authors say ""we focus on larger datasets from GLUE (MNLI, QNLI, QQP and SST-2), as it is less meaningful to discuss efficient training"", but then report and analyze results from other GLUE datasets as well.",Does the review address Result?,TRUE,FALSE,The review points out inconsistencies in reporting and analyzing results
I think the story starts with pointing out the importance for long-sequence but turns to the topic on short sequence which is confusing.,Does the review address Presentation?,TRUE,FALSE,"The review critiques the paper's narrative structure, which relates to Presentation"
"The computation of RFA requires outer product, which is O(D^2d) so overall it's O(M D^2 d), if M is around 64 or 128 (common usage) and D is 64, I actually don't see why RFA could improve 2x.",Does the review address Result?,TRUE,FALSE,The review critically analyzes the computational complexity and performance claims
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Comparison?,TRUE,FALSE,The review discusses comparison with baselines and empirical results
"DP is not ""incorporated"" in a model or multimodality (as the authors mention in different ways a few times throughout the paper), DP is a property of a randomised algorithm (in this context, the training algorithm that produces the distribution of models, not the model).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review provides a detailed clarification about a technical term
I felt this was quite separate from the theoretical analysis.,Does the review address Result?,FALSE,TRUE,The review is a general comment about theoretical analysis
"Furthermore, they have clarified that on the key metric of CommonGen they achieved SoTA with only slightly more than half the parameters of the current SoTA model.",Does the review address Methodology?,TRUE,FALSE,The review mentions achievement of state-of-the-art results with fewer parameters
"So I also have a few doubts about this article:  (1) This paper uses 6B T5-V1.1, but the previous baseline work only GTRxxl has the same size, while ColBERTv2 using multi-vector retrieval model has only 110m model size.",Does the review address Methodology?,TRUE,FALSE,The review discusses specific model sizes and comparisons
"Your work obviously is different enough to stand on its own, but it might be good to make a mention of this work and others (e.g. do more of a lit search / related work on low rank compression).",Does the review address Related Work?,TRUE,FALSE,The review suggests expanding the literature search and related work
Strengths: - Unifying generative and contrastive training is an important and interesting goal.,Does the review address Presentation?,FALSE,TRUE,"The review discusses a research goal, which is more about contribution"
The PACT methodology: The paper proposes a methodology for extracting auxiliary tasks that can be trained jointly along with the main task (tactic prediction task).,Does the review address Methodology?,TRUE,FALSE,The review describes a methodology for extracting auxiliary tasks
"However, it seems like there's still some open questions about the types of improvements being made and what this implies about the LM's attention mechanism.",Does the review address Result?,FALSE,TRUE,The review raises questions about improvements but does not directly discuss results
"The main contribution are the following innovations: a special attention mechanism called block-diagonal conditional attention, a set of modules for adaptation of a pretrained model, and an uncertainty-based multi-task data sampling method.",Does the review address Methodology?,TRUE,FALSE,The review lists specific methodological innovations
The evaluation method uses CCA to maximize the correlation between the word embeddings and possibly hand crafted linguistic data.,Does the review address Evaluation?,TRUE,FALSE,The review describes the evaluation method using CCA
The findings illustrate the substantial impact this choice can have on the final model's behavior.,Does the review address Methodology?,FALSE,TRUE,The review makes a general comment about model behavior
Both settings show the better performance of the proposed method.,Does the review address Result?,TRUE,FALSE,The review mentions performance of the proposed method
"Secondly, the design of the specific neural network cannot describe the theory behind proposed binding-unbinding mechanism properly.",Does the review address Theory?,TRUE,FALSE,The review critiques the neural network's ability to describe a theoretical mechanism
"* In the abstract, authors say ""BROS utilizes a powerful graph-based decoder that can capture the relation between text segment""* Though in the text such a component (that is from other work) is only mentioned twice without further detail.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out lack of detailed discussion about a specific component
The findings of (2)(3)(4)(5) mentioned in the summary section above are especially interesting and can be helpful to the community when comparing new VL methods with existing methods.,Does the review address Result?,FALSE,TRUE,The review references findings but does not provide a direct analysis of results
"This paper makes comparison with techniques used in active learning (AL), domain shift detection (DS), and multi-domain sampling to combine data from multiple sources.",Does the review address Comparison?,TRUE,FALSE,The review explicitly discusses comparisons with various techniques
"Unfortunately, as the paper overall does not seem to contain significant novelty, neither in methodology nor in results, I cannot recommend acceptance at this point.",Does the review address Methodology?,TRUE,FALSE,The review critiques the lack of novelty in methodology
"First of all, the dense interaction between vision and language tokens has been heavily studied prior to the so-called multimodal LLM era.",Does the review address Methodology?,FALSE,TRUE,The review makes a historical comment about token interactions
"However, in its current state - the comparisons made are not meaningful which makes the claim of state of the art tenuous (state of the art does not matter so much as showing that you make progress in line with the motivation).",Does the review address Comparison?,TRUE,FALSE,The review critically discusses the meaningfulness of comparisons
"Additionally, there are some minor things I would add or improve: - I would add references to multi-task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE).",Does the review address Data/Task?,TRUE,FALSE,The review suggests adding references to multi-task training across languages
Is it possible to import a public SOTA implementation and conduct comparisons based on that?,Does the review address Comparison?,FALSE,TRUE,The review raises a question about comparisons but does not actually compare
- I don't see why your theory does not generalize to a _masked_ language modeling (MLM).,Does the review address Methodology?,FALSE,TRUE,The review questions theoretical generalizability
The paper provides a comprehensive study on the two-tower Transformer models in terms of the impact of its pre-training tasks on large-scale retrieval applications.,Does the review address Data/Task?,TRUE,FALSE,The review describes a comprehensive study on Transformer models and retrieval applications
"- OpenAQA-5M is a good contribution to provide open-ended question answering in audio domain, especially it is verified with human evaluation.",Does the review address Data/Task?,TRUE,FALSE,The review highlights a contribution to open-ended question answering in the audio domain
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Comparison?,TRUE,FALSE,The review describes comparisons with existing selective annotation approaches
"How does Theorem 2 come into play when proving Theorem 3, if Theorem 3 can be proved independently?",Does the review address Theory?,TRUE,FALSE,The review asks about the relationship between theoretical theorems
An additional ablation experiment trying different number of tokens to optimize could be illuminating (even for just 1 dataset).,Does the review address Ablation?,TRUE,FALSE,The review suggests an additional ablation experiment
"That is, by ""general learner"" the authors mean a model that can *express* a universal circuit.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review provides a clarification of a technical term
Could the authors list some possible approaches to automatically choose this hyper-parameter please?,Does the review address Methodology?,FALSE,TRUE,The review requests approaches for choosing a hyperparameter
"- From the diversity and representativeness measures shown in Table 10 in Appendix F, the difference between Random and vote-*k* does not appear to be very large.",Does the review address Presentation?,TRUE,FALSE,The review comments on the presentation of diversity measures in a table
Such a comparison would highlight the advantages of the multi-task model and would be helpful for the relevant audience.,Does the review address Comparison?,FALSE,TRUE,The review suggests a potential comparison without actually comparing
"This line of work could be much stronger if the models comprised the whole process (detection, text extraction, recognition) in an end-to-end manner.",Does the review address Methodology?,TRUE,FALSE,The review suggests an improvement to the overall methodology
"While the exact choice depends on the dataset characteristics, a framework will be more attractive if it can perform well on different scenarios.",Does the review address Presentation?,FALSE,TRUE,The review makes a general comment about model performance
## Strengths - The environment is novel and provides a good basis for studying certain traits of continuous-channel referential games.,Does the review address Novelty?,TRUE,FALSE,The review highlights the novelty of the environment
"The proposed method has achieved SOTA performance on a range of Vision-Language benchmarks, spanning image captioning, Visual Question Answering, and visual grounding tasks.",Does the review address Result?,TRUE,FALSE,The review discusses state-of-the-art performance across benchmarks
The use of RNN and Copy RNN in the current context is a new idea.,Does the review address Novelty?,TRUE,FALSE,The review points out the novelty of using RNN and Copy RNN
"Running a baseline model that runs *for the same amount of time* is essential to appreciate the contribution of this work (e.g., repeat the same analysis in Figure 3 for the vanilla BERT).",Does the review address Contribution?,TRUE,FALSE,The review suggests a way to better appreciate the contribution
"This is immediate from Theorem 2, and this kind of separation appears to have been the implicit the point of Merrill and Sabharwal 2023  * This statement seems overly strong and minimizes prior work: ""This work takes the first step towards rigorously answering the fundamental question by considering a theoretical boundary of model capacity to be general learner""      * e.g., ""Saturated Transformers are Constant-Depth Threshold Circuits"" shows that transformers lie in TC^0 under a saturation condition     * e.g., ""The Parallelism Tradeoff: Limitations of Log-Precision Transformers"" shows that log-precision transformers lie in log-space-uniform TC^0",Does the review address Related Work?,TRUE,FALSE,The review critiques the paper's treatment of prior work
"This is mentioned several times, but there are no initial results or anything suggesting that it might be a promising direction to pursue.",Does the review address Result?,TRUE,FALSE,The review comments on the lack of initial results
"The dialog needs to be polite, follow natural language, short, etc which are hard to automatically measure.",Does the review address Evaluation?,TRUE,FALSE,"The review discusses challenges in automatically measuring dialog qualities, which relates to evaluation"
"In sec3.1, you used S_t for minibatch, but in sec3.4, you use S_i for ""a text sequence"", which is confusing.",Does the review address Presentation?,TRUE,FALSE,The review points out inconsistent notation usage across sections
"The authors switch between using BERT_base and RoBERTa_base without being very clear about when and why, e.g., in Table 2 they have both models, but only in different sections.",Does the review address Comparison?,TRUE,FALSE,The review critiques inconsistent use of different models (BERT and RoBERTa)
The evaluation method uses CCA to maximize the correlation between the word embeddings and possibly hand crafted linguistic data.,Does the review address Methodology?,TRUE,FALSE,The review describes a specific evaluation method using CCA
- The title of the paper is a bit strongly worded and may be over-claiming what is shown quantitatively in this paper.,Does the review address Result?,FALSE,TRUE,"The review comments on the paper's title, which is more about presentation"
"The unfair disadvantage is even more prevalent when the pRNN uses multiple phrasal attention layers within a single sentence while a simple enc-dec system without attention is used as a benchmark =( Question: Wouldn't a simpler way to get phrasal RNN is to put the ""pyramid"" RNNs of a phrase into some soft of a average pooling layer?",Does the review address Methodology?,TRUE,FALSE,The review discusses methodological details of phrasal attention and benchmarking
How much does the system rely on the capabilities of LLMs?,Does the review address Methodology?,FALSE,TRUE,The review raises a question about system capabilities without describing methodology
TacticZero by Wu et al 2021 is missing from the related work.,Does the review address Related Work?,TRUE,FALSE,The review points out a missing reference in related work
"If the authors can adequately address the following issues around presentation and the interpretation of Theorem 5, I would be satisfied raising my score, as I value the research question raised by the paper and believe the conclusions are valid.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses interpretation of a theorem
I felt similar conclusions can be drawn from the results of that paper as well.,Does the review address Comparison?,FALSE,TRUE,The review makes a vague comment about drawing similar conclusions
"However, this was already proposed and implemented by an earlier paper (Oikarinen et al.).",Does the review address Contribution?,TRUE,FALSE,The review suggests the proposed idea was already implemented
"This is immediate from Theorem 2, and this kind of separation appears to have been the implicit the point of Merrill and Sabharwal 2023  * This statement seems overly strong and minimizes prior work: ""This work takes the first step towards rigorously answering the fundamental question by considering a theoretical boundary of model capacity to be general learner""      * e.g., ""Saturated Transformers are Constant-Depth Threshold Circuits"" shows that transformers lie in TC^0 under a saturation condition     * e.g., ""The Parallelism Tradeoff: Limitations of Log-Precision Transformers"" shows that log-precision transformers lie in log-space-uniform TC^0",Does the review address Theory?,TRUE,FALSE,The review critically discusses theoretical claims and prior work
The community will be interested how the model type / scale affect the LFLL capability.,Does the review address Methodology?,FALSE,TRUE,The review raises a general question about model type and scale
"With the strengths being said, I hope to also point out that the paper's application of adversarial training is one attempt in many possibilities, and in many cases it is not clear where the improvements come from.",Does the review address Presentation?,FALSE,TRUE,The review comments on the application of adversarial training
Comparison with GECA: I can read from the paper that the performance is on par with GECA.,Does the review address Comparison?,TRUE,FALSE,The review directly discusses performance comparison with GECA
"Clarification of contribution  Eq 6,7 reads like RNN style update but the intuition is lacking.",Does the review address Contribution?,TRUE,FALSE,The review critiques the lack of intuition in the contribution
"For table 4, please also include the significance of the BLEU improvement made by the pRNN with respect to the the baseline, see https://github.com/jhclark/multeval General Discussion ==== As the main contribution of this work is on the phrasal effect of the new RNN architecture, it's rather important to show that the phrases are more coherent than the vanilla LSTM / RNN model.",Does the review address Result?,TRUE,FALSE,The review suggests including significance of performance improvements
"The organization is not perfect and readers might find it hard to follow here and there, but the main idea is understandable.",Does the review address Presentation?,TRUE,FALSE,The review comments on the paper's organization and readability
"It is unclear to me how the authors are going to justify this ""assumption"".",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions the justification of an assumption
5.2 visualizations: this seems pretty ad-hoc without much justification for the choices.,Does the review address Intuition/Justification/Motivation/Validation?,FALSE,FALSE,The review critiques the lack of justification for visualization choices
The latter ratio seems proportional to the ratio $\frac{\ell_\mathcal{T}(\\{p_{\cdot\mid s}\\}) - \tau}{\ell_\text{xent}(\\{p_{\cdot\mid s}\\})-\ell_\text{xent}^\ast}$.,Does the review address Methodology?,FALSE,TRUE,The review includes a mathematical notation without methodological discussion
I suspect that a statistical analysis [1] might conclude that BERT and the proposed method are indistinguishable on the GLUE suite.,Does the review address Analysis?,TRUE,FALSE,The review suggests a potential statistical analysis of results
"More importantly, the experiments are not convincing as it is presented now.",Does the review address Presentation?,TRUE,FALSE,The review critiques the unconvincing nature of the experiments
"The experimental settings in Section 3 lack detailed descriptions, potentially making reproduction difficult and potentially misleading.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out lack of detailed experimental descriptions
"The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",Does the review address Methodology?,TRUE,FALSE,The review discusses theoretical assumptions in the methodology
Having additional ways to improve data efficiency by changing the model design is definitely of interest.,Does the review address Data/Task?,FALSE,TRUE,The review makes a general comment about data efficiency without specific task details
The paper describes the idea of multiple temporal scales.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,The review briefly mentions an idea without providing detailed explanation
"- P8, Table 2: The results from using Quad look worse than the above two.",Does the review address Presentation?,TRUE,FALSE,"The review comments on results in a specific table, which relates to presentation"
This is the first such dataset for the Lean Theorem prover.,Does the review address Theory?,TRUE,FALSE,The review highlights the novelty of a dataset for a specific theorem prover
"Since one of the main contributions of this paper is the analysis of the BERT pretraining process, more experimental analysis on the optimizer should also be included.",Does the review address Experiment?,TRUE,FALSE,The review suggests additional experimental analysis on the optimizer
This could be another area to investigate  ---- Misc:  ----  - UnifiedQA seems potentially worth citing as prior work,Does the review address Related Work?,TRUE,FALSE,The review suggests citing additional prior work
I believe RFA should only refer one thing and I don't think eq(6) and eq(5) leads to the same result.,Does the review address Result?,FALSE,TRUE,The review discusses technical details about notation
"Then, most of the paper is spent discussing preliminaries and introducing notation and definitions.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review notes the paper's focus on preliminaries and definitions
"It describes a mapping of ORCHID, a Thai-specific POS tagset, to the Universal Dependencies (UD) scheme, and evaluates various state-of-the-art POS taggers on this scheme.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review describes a mapping and evaluation process in detail
An ablation analysis would be most appropriate for quantifying this.,Does the review address Methodology?,FALSE,TRUE,The review suggests an ablation analysis without describing methodology
Why do the authors use the Quora dataset in particular?,Does the review address Data/Task?,TRUE,FALSE,The review questions the choice of a specific dataset
"So, In this case, it will be interesting to see the results (or will be helpful in evaluating ""absent type"" keyphrases): if we identify all the topical phrases of the entire corpus by using tf-idf and relate the document to the high-ranked extracted topical phrases (by using Normalized Google Distance, PMI, etc.).",Does the review address Presentation?,FALSE,TRUE,The review suggests a potential analysis approach
Another limitation is that it is unclear whether the improvement would hold when the size of the model increases; the evaluation is dealing with scaling laws after all.,Does the review address Methodology?,TRUE,FALSE,The review discusses a limitation related to model scaling
- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.,Does the review address Experiment?,TRUE,FALSE,The review suggests adding more ablation analysis to experiments
Some experimental settings only include the baselines Random and Vote-k. More methods as mentioned in 4.3.2 can be also included.,Does the review address Comparison?,TRUE,FALSE,The review suggests including more baselines in comparisons
"Maybe I've missed this in the paper, if there is, please be more explicit about it because it affects the model quite drastically if for every sentence the largest phrase length is the sentence length.",Does the review address Methodology?,TRUE,FALSE,The review raises a question about a specific methodological detail
3) The usage of graph is somewhat straightforward to me.,Does the review address Methodology?,FALSE,TRUE,The review makes a brief comment about graph usage
It does not follow from the theoretical results that adding similar sentences will be a good thing.,Does the review address Theory?,FALSE,TRUE,The review discusses theoretical implications without detailed analysis
"Moreover, I have some comments on the model and experiments.",Does the review address Methodology?,FALSE,TRUE,The review indicates an intention to comment on model and experiments
"The paper can be better if adding the real-user interactions, because the performance may be different between the simulation environment and the real-user interactions reported by prior results (DSTC in ConvLab).",Does the review address Result?,FALSE,TRUE,The review suggests comparing simulated and real-user interactions
*  The claims regarding the 10x better data efficiency are not well supported and I would suggest the authors to compare with transformer models on standard LM benchmarks and potentially to some downstream tasks such as MT to make a stronger case.,Does the review address Comparison?,TRUE,FALSE,The review critiques data efficiency claims and suggests additional comparisons
"Specific criteria: - Correctness: 4     - The claims are supported, but I do not think the claims go far enough (e.g., ""noise has an effect on generalization"" is claimed when instead what that effect is needs to be characterized).",Does the review address Methodology?,TRUE,FALSE,The review discusses the support and characterization of claims
**Novelty** The idea of utilizing weak supervision of interleaved patterns is intuitive and convincing.,Does the review address Novelty?,TRUE,FALSE,The review assesses the novelty of the proposed approach
"This paper suggests a number of cheap-to-compute corruptions of the input data that, when used to reconstruct the input, enrich the underlying model.",Does the review address Data/Task?,TRUE,FALSE,The review describes data corruption approaches
"However, it should be straightforward to extend the results from these papers to the poly(n) case, at least in the nonuniform setting considered here.",Does the review address Result?,FALSE,TRUE,The review makes a speculative comment about extending results
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Experiment?,TRUE,FALSE,The review critically discusses the evaluation and experimental configuration
"In algorithm 1, in each iteration, only data sample (S_i) is used, how is this choice motivated?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions the motivation behind a specific algorithmic choice
"If not, the presentation requires to change and reflect only the controllability analysis.",Does the review address Analysis?,TRUE,FALSE,The review suggests modifying the presentation to reflect controllability analysis
I will be more convinced if evaluation is done on a wider range of tasks.,Does the review address Evaluation?,TRUE,FALSE,The review suggests expanding evaluation across a wider range of tasks
"- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other ""oracle"" baselines.",Does the review address Comparison?,TRUE,FALSE,The review describes evaluation against state-of-the-art methods and baselines
The authors experiment their method on three datasets and get the state of the art results.,Does the review address Data/Task?,TRUE,FALSE,The review mentions experiments on multiple datasets
How many include simple string operations and/or other simple method calls as implied by Table 2?,Does the review address Methodology?,FALSE,TRUE,The review raises a question about method implementation details
The paper presents a novel way of combining information from text and a KB in a bidirectional way.,Does the review address Novelty?,TRUE,FALSE,The review highlights a novel approach to combining information
"(2) What’is more, if tx contains s_k, can we say that the selected $tx$ is similar to $x$?",Does the review address Presentation?,FALSE,TRUE,The review asks a technical question about notation
"Why do you choose case-insensitive BLEU score for En->Fr, which is not commonly used in previous baselines.",Does the review address Significance?,TRUE,FALSE,The review questions the choice of evaluation metric
The idea was (reasonably) well-positioned with respect to prior work and clearly presented.,Does the review address Presentation?,TRUE,FALSE,The review comments on the clarity of presentation relative to prior work
"- How to find a discriminant for meaning is left out as the authors explicitly assume that “the mechanism is provided by human annotators and other providers of training data.” While the authors emphasize in the introduction that such information can be used in the LLM training without external reward model: “This observation shows that sentence-level annotations can be incorporated directly into the trained model without the need for any external reward model nor external policy model, simply by sentence-level feedback,” I do not see the advantage of this approach over using the very same data to train a reward model and use that either during the training (as in RLHF) or as an augmentation (as in Rectification method), the latter indeed provides quite strong theoretical guarantees.",Does the review address Theory?,TRUE,FALSE,The review critically discusses theoretical assumptions and approach
"While the exact choice depends on the dataset characteristics, a framework will be more attractive if it can perform well on different scenarios.",Does the review address Result?,FALSE,TRUE,The review makes a general comment about framework performance
I think as an ACL paper there should be more takeaways.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests need for more substantive takeaways
"Informally , a task is defined as natural if, just by using the next word distributions as features, the downstream task can be solved with a small loss.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review provides an informal definition of a task
The authors try to interpret the design of the neural networks using the concepts in the proposed binding-unbinding theorybut are not convincible.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses attempts to interpret neural network design
"I would suggest the following:   * To make the comparison more fair, I would suggest to train transformer models with varying size and derive a power law based on the exact same experimental configuration used for LMU models.",Does the review address Comparison?,TRUE,FALSE,The review suggests a more fair comparison approach
"While this paper provides extensive empirical results and quantitively demonstrates the effectiveness of RandomMask, there are several areas where it could be further enhanced.",Does the review address Methodology?,TRUE,FALSE,The review discusses empirical results and potential enhancements
"The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",Does the review address Ablation?,FALSE,FALSE,The review praises the ablation study for validating design components
Weaknesses: Some of the design choices need to be elaborated on further and additional analysis-based experiments would also be useful.,Does the review address Experiment?,TRUE,FALSE,The review suggests additional analysis-based experiments
There is a lot missing to actually justify this claim: 1.,Does the review address Intuition/Justification/Motivation/Validation?,FALSE,TRUE,The review questions the justification of a claim
"Before describing your algorithm, humans are only mentioned once in the algorithm.",Does the review address Presentation?,TRUE,FALSE,The review comments on algorithmic presentation
I appreciate the additional figures and other results that you have provided.,Does the review address Result?,FALSE,TRUE,The review offers general appreciation of additional results
"* Strength     * This paper proposes an interesting idea and interpretation to connect RM and DM paradigm     * This paper proposes a variance reduction method for DPG which demonstrates its improvement on performance, stability and sample efficiency * Weakness     * From my understanding, the baseline mostly comes from the observation in 3.3, which has limited technical novelty.",Does the review address Presentation?,FALSE,TRUE,The review discusses strengths and weaknesses of the approach
"Main strengths: - Mapping existing Thai corpora to the UD scheme is a useful contribution for Thai NLP, as the UD scheme has become popular for multilingual work, and this will allow Thai NLP to profit better from advances in this area.",Does the review address Contribution?,TRUE,FALSE,The review highlights the contribution to Thai NLP
The new established benchmark is another good contribution.,Does the review address Data/Task?,TRUE,FALSE,The review highlights the establishment of a new benchmark
"Previous work [2] has already shown that by selecting the most complex examples from the training dataset, the performance can be largely improved compared to the original annotations from [1].",Does the review address Result?,TRUE,FALSE,The review discusses performance improvements from previous work
"There is no comparison with other public masking methods in Table 2, such as whole-word-masking, span masking, etc.",Does the review address Comparison?,TRUE,FALSE,The review points out missing comparisons with other masking methods
"Though the paper promises faster training speeds in the introduction, Table 3 shows only modest (less than x2) speedups for training.",Does the review address Result?,TRUE,FALSE,The review critically discusses the reported training speed improvements
- Using “concept” to stand in for verbs and nouns is somewhat confusing.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the use of terminology
"For the first ablation, it just gives out the performance of intermediate models on a single task.",Does the review address Data/Task?,FALSE,TRUE,The review describes an ablation experiment without specific task details
"Overall, the authors show better accuracy for their tested problem set against REWARD, a baseline system (a transformer), lang2logic, and Ins2AST across two dimensions: data type recovery and abstract syntax tree (AST) generation.",Does the review address Comparison?,TRUE,FALSE,The review details comparisons with multiple baseline systems
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Novelty?,TRUE,FALSE,The review questions the novelty and impact of the contributions
I had to read it a couple of times before I could fully follow the method.,Does the review address Presentation?,TRUE,FALSE,The review comments on the difficulty of understanding the method
The proposed method achieves SoTA results on CommonGen with slightly more than half the parameters of the current SoTA model.,Does the review address Methodology?,TRUE,FALSE,The review discusses state-of-the-art results with parameter efficiency
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Comparison?,TRUE,FALSE,The review critiques the lack of experiments and comparisons
Weaknesses:  - The notation/description of section 4 is not immediately intuitive.,Does the review address Presentation?,TRUE,FALSE,The review comments on the notation and description clarity
- Each component in perceiver IO is necessary and well defined for the proposed tasks.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review comments on the definition of components
"In addition, the authors empirically demonstrate that the token-level masked-LM model used by BERT is not a good choice as pre-training task for the two-tower Transformer when deployed for large-scale information retrieval applications.",Does the review address Methodology?,FALSE,TRUE,"The review discusses the token-level masked-LM model, but does not provide a comprehensive methodological description."
"- The paper mentioned that the standard RL methods easily fail and generate responses diverging from human language, even when fine-tuning a pre-trained LM.",Does the review address Methodology?,TRUE,FALSE,"The review directly references standard RL methods and their limitations, which relates to the study's methodology."
"With these two elements, the approach performs on par with recently proposed GECA (where the data is not augmented via a neural generator) on two datasets.",Does the review address Data/Task?,TRUE,FALSE,"The review mentions datasets and performance comparison between approaches, addressing the Data/Task aspect."
"Last sentence of intro: ""without scarifying accuracy"" seems like an inaccurate description of the results presented in this paper.",Does the review address Presentation?,TRUE,FALSE,"The review critiques a sentence's description, directly addressing the paper's presentation."
Which script did you choose to evaluate BLEU score?,Does the review address Presentation?,TRUE,FALSE,"The review asks a specific question about the BLEU score script, which relates to the paper's presentation."
"Strengths: - Thorough theoretical analysis that reveals the connection between (practically-necessary) small learning rates and inability to use dependencies across text chunks - Useful framing and discussion of the ""in-context bias"", where models are more likely to learn dependencies within text chunks seen during pre-training.",Does the review address Analysis?,TRUE,FALSE,"The review highlights a thorough theoretical analysis and discusses the ""in-context bias"", clearly relating to the Analysis aspect."
"* Why are the lines for ""from scratch"" flat in Figure 2?",Does the review address Methodology?,TRUE,FALSE,"The review questions the ""from scratch"" lines in Figure 2, engaging with the methodology."
"Although the complexity analysis is thorough, I'd like to see empirical results of memory/compute requirements as a function of the context length.",Does the review address Result?,TRUE,FALSE,"The review suggests empirical results are missing, directly addressing the Results aspect."
"## ""General Learner"": Missing Formal Definition and Misleading Name  The ""general learner"" concept used in the title and throughout is named in a somewhat misleading way, as the results here have to do more with *expressive power* than learning.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review critically discusses the definition and naming of the ""general learner"" concept, relating to Elucidation."
"The motivation is to reduce the undesirable large variance of MLM objective, based on the hypothesis that randomly sampled masks in MLM would lead to undesirably large gradient variance, which as a result typically hurts the training efficiency with stochastic gradient optimization algorithms.",Does the review address Methodology?,TRUE,FALSE,The review explicitly describes the motivation and hypothesis behind a specific methodological approach.
"Empirically, it demonstrates that several NLP tasks are “natural”.",Does the review address Data/Task?,TRUE,FALSE,"The review mentions empirical demonstration of NLP tasks, addressing the Data/Task aspect."
"After reading other reviews and the authors’ responses to all of the reviewers, I recommend this paper by accepted—extensive results show that the CALM objectives offer more signal from data than current pretraining methods.",Does the review address Data/Task?,TRUE,FALSE,"The review references extensive results and data objectives, relating to the Data/Task aspect."
"- Strengths: Useful modeling contribution, and potentially useful annotated data, for an important problem -- event extraction for the relationships between countries as expressed in news text.",Does the review address Methodology?,TRUE,FALSE,"The review highlights a ""useful modeling contribution"" for event extraction, addressing Methodology."
"After thinking over the concepts in the paper more, I might lean more strongly toward rejection or toward acceptance (if the authors can address the issues I raise below).",Does the review address Evaluation?,TRUE,FALSE,"The review discusses potential acceptance/rejection, directly relating to Evaluation."
"- Table 5 the VAE(32) method performs the best overall in ""Wiki section"" although the TC (16) method has been highlighted as the best.",Does the review address Methodology?,TRUE,FALSE,"The review compares performance of different methods in a table, addressing Methodology."
Are these rather the ppl resulting from training an LM on the full dataset?,Does the review address Data/Task?,TRUE,FALSE,"The review asks about dataset and perplexity, relating to Data/Task."
"There are numerous works and existing methods working on connecting LLM to perform various tasks, e.g., AutoGPT.",Does the review address Methodology?,TRUE,FALSE,"The review mentions existing methods for connecting LLMs, addressing Methodology."
"Other concerns along these lines: all of this paper's results are averaged over 3 runs while the other baselines are over 5 runs - an indication of variance would be useful to assess whether the differences are significant, especially since some of the margins quite small (23 on MC-LAVE-RL vs 22.8 for the next best on Ludicorp) added to the fact that hyperparameters are different for each game - does that imply that the authors tuned the hyperparameters for each game?",Does the review address Presentation?,TRUE,FALSE,"The review critiques experimental setup details, directly addressing Presentation."
#### Strength - The idea of perceiver IO is novel and solid -- a general architecture capable of handling general-purpose inputs and outputs across different tasks and modalities.,Does the review address Novelty?,TRUE,FALSE,The review explicitly discusses the novelty of the Perceiver IO architecture.
Their thorough ablation experiments and other analysis yield some interesting findings the authors could emphasize more.,Does the review address Experiment?,TRUE,FALSE,"The review directly mentions ""thorough ablation experiments"", addressing the Experiment aspect."
There is limited contribution in terms of machine learning algorithms.,Does the review address Contribution?,TRUE,FALSE,The review comments on the limited contribution in machine learning algorithms.
"Similar idea also exists in [R3], which is missing from this paper.",Does the review address Related Work?,TRUE,FALSE,"The review references a missing similar idea from another work, addressing Related Work."
"-----General Discussion----- This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths).",Does the review address Data/Task?,TRUE,FALSE,"The review discusses the model's performance on a dataset, relating to Data/Task."
It also includes the recurrent memory extension from Transformer-XL from Dai et al.,Does the review address Related Work?,TRUE,FALSE,"The review mentions a specific previous work (Transformer-XL), addressing Related Work."
"This is relevant because, by training end to end, that work effectively generates arbitrary amounts of training data through interaction the the HOL4 ITP system (intermediate theorems which are proven give some reward in that work).",Does the review address Theory?,TRUE,FALSE,"The review discusses training approach and theorem generation, relating to Theory."
This is an interesting work on the investigation of learning effects with a mix of tasks.,Does the review address Data/Task?,TRUE,FALSE,"The review discusses tasks and learning effects, directly addressing the nature of the study's data and tasks."
"While I appreciate the environment introduced and believe it to be promising, the experiments presented fail to highlight the novelty of the environment.",Does the review address Experiment?,TRUE,FALSE,The review explicitly discusses and critiques the experiments presented in the paper.
The authors present a new approach called: neural-based binary reverse engineering framework (N-Bref).,Does the review address Methodology?,TRUE,FALSE,"The review mentions a specific methodological approach (N-Bref framework), highlighting the study's methodology."
"As a result, this paper has a great potential, and its results seem very promising.",Does the review address Result?,TRUE,FALSE,"The review discusses the paper's results as ""promising"" and having ""great potential""."
"There is no comparison with other public masking methods in Table 2, such as whole-word-masking, span masking, etc.",Does the review address Presentation?,TRUE,FALSE,"The review points out a lack of comparison in Table 2, which relates to the paper's presentation of information."
"Specifically, for Table 1, the inference time of each algorithm should be reported (retrieval time included).",Does the review address Presentation?,TRUE,FALSE,The review suggests an improvement in table presentation by recommending additional information reporting.
Summary: + Appealing theoretical contributions + Empirical results are encouraging + The use of discriminator for reward shaping in addition to task success rate is interesting  - Writing and explanation can be improved.,Does the review address Result?,TRUE,FALSE,"The review explicitly mentions ""empirical results"" as encouraging, directly addressing the paper's results."
"If I understand correctly, the sub-linear results depend on particular settings of the memory length and compression rate.",Does the review address Methodology?,TRUE,FALSE,The review discusses specific methodological details about results depending on memory length and compression rate.
"* Were the proposed architectural additions conceived with the HANS ""counterexamples"" in mind (i.e. is there a specific reason to think that these types of methods would avoid the ""superficial"" reasoning that these examples are supposed to reveal)?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions the motivation behind the proposed architectural additions.
"The methods have been tested on two benchmarks focusing on the issue, SCAN and morphological analysis.",Does the review address Analysis?,TRUE,FALSE,"The review discusses methods tested on benchmarks, which involves analytical examination."
"At the least, it would be worth proposing that the languages in this study can offer a test of rule-based vs. inference-based processes, and propose performing such comparisons when the data for the study languages is sufficiently mature.",Does the review address Data/Task?,TRUE,FALSE,The review discusses specific study languages and potential comparisons of data.
"For example, on VQA, more recent works (BEiT-3) achieve 84+, while the best reported result in the manuscript is ~76.",Does the review address Result?,TRUE,FALSE,"The review compares results from the manuscript with other works, focusing on performance metrics."
*  The claims regarding the 10x better data efficiency are not well supported and I would suggest the authors to compare with transformer models on standard LM benchmarks and potentially to some downstream tasks such as MT to make a stronger case.,Does the review address Data/Task?,TRUE,FALSE,The review suggests comparisons across different tasks and benchmarks.
"I do not believe that SoTA results are necessary to write a good paper, and indeed the obsession our field has with SoTA is unhealthy.",Does the review address Result?,TRUE,FALSE,"The review discusses state-of-the-art (SoTA) results, directly addressing the paper's outcomes."
"Secondly, the design of the specific neural network cannot describe the theory behind proposed binding-unbinding mechanism properly.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the explanation of the proposed mechanism.
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Analysis?,TRUE,FALSE,The review points out limitations in experimental validation and lack of error analysis.
"That raises the question -- Gerrish and O'Connor both conduct evaluations with an external database of country relations developed in political science (""MID"", military interstate disputes).",Does the review address Evaluation?,TRUE,FALSE,The review discusses evaluation methods and external databases used for assessment.
"This paper makes comparison with techniques used in active learning (AL), domain shift detection (DS), and multi-domain sampling to combine data from multiple sources.",Does the review address Data/Task?,TRUE,FALSE,The review discusses multiple data sources and sampling techniques.
The simple combination of the audio model and LLM does not seem to be novel.,Does the review address Novelty?,TRUE,FALSE,The review directly questions the novelty of the combination approach.
-  Consistent performance improvement over the baseline models on all of the three QA benchmarks.,Does the review address Methodology?,TRUE,FALSE,The review mentions performance improvement over baseline models.
"- The paper is well written: it gives an appropriate context, presents the main theoretical results, and verifies _some_ of the claims experimentally.",Does the review address Theory?,TRUE,FALSE,The review references theoretical results and their experimental verification.
"Additionally, the rationale for choosing (Ma et al., 2023) as a benchmark, along with the significance of the improvements observed, even if minute, should be clearly articulated.",Does the review address Significance?,TRUE,FALSE,The review discusses the significance of improvements and benchmark choices.
Experimental evaluation shows competitive performance.,Does the review address Result?,TRUE,FALSE,"The review directly states ""Experimental evaluation shows competitive performance""."
"The authors analyze the in-context bias of the self-attention model, which could inspire some research works on designing training examples.",Does the review address Analysis?,TRUE,FALSE,The review discusses analysis of in-context bias in the self-attention model.
"For example, if for the baseline model, we also only use one data sample and apply different masks, will there be improvement?",Does the review address Result?,FALSE,TRUE,"This review poses a hypothetical question about potential improvements, but does not discuss actual results."
"This bound consists of two parts: - The first part measures how ""natural"" the task is, that is, how well can the task be solved using the next word distributions as features.",Does the review address Data/Task?,FALSE,TRUE,"The review discusses a task's ""naturalness"" but does not describe the specific benchmark, dataset, or task characteristics as defined in the guidelines."
"However, with most Indigenous languages, existing corpora are not large enough to produce accurate statistical models.""",Does the review address Methodology?,FALSE,TRUE,"This is a comment about corpus limitations, not about the approaches, techniques, or processes used in the study."
"3.2.2 presents the observation that choosing a set of queries from the dataset a-priori (agnostic to the image), does not result in either an optimal or interpretable query set.",Does the review address Data/Task?,TRUE,FALSE,"The review directly discusses dataset query selection and its characteristics, which aligns with the Data/Task aspect definition."
This paper provides a mathematical framework to understand this question.,Does the review address Methodology?,FALSE,TRUE,"Mentioning a mathematical framework is too abstract; the guidelines require discussion of specific approaches, techniques, or processes used in the study."
What happens when the extra reward for using the language model is added to LaRL (that might be tough if you have to modify others code).,Does the review address Methodology?,TRUE,FALSE,"The review suggests a specific modification to the method's implementation, directly addressing the methodology."
"In Sec2, you said ""yet is outperformed by the proposed fully-explored masking (see Table 2).",Does the review address Related Work?,TRUE,FALSE,"The review references comparison with other work in the paper, which aligns with the Related Work aspect."
"The main issue of the paper is in the experiments and results reporting, it needs quite a bit of reworking.",Does the review address Experiment?,TRUE,FALSE,"The review explicitly critiques the experiments and results reporting, directly addressing the Experiment aspect."
"Contribution: The authors contribute a new tokenization method, code, and a dataset.",Does the review address Methodology?,TRUE,FALSE,"The review lists specific methodological contributions like tokenization method, clearly relating to the methodology."
# Summary  The authors propose to use corpora generated from _emergent communication_ as a fine-tuning signal for NLP tasks (language modeling and image captioning in particular).,Does the review address Methodology?,TRUE,FALSE,"The review describes the proposed approach for using corpora in NLP tasks, which directly speaks to the methodology."
"- Excellent clarity and presentation of ideas  ## Weaknesses - The experiments provided do not analyze the unique characteristics of the environment introduced; instead, the experiments are similar to the typical gamut for a discrete symbol-based referential game.",Does the review address Presentation?,TRUE,FALSE,"The review explicitly discusses the clarity and presentation of ideas, matching the Presentation aspect definition."
"I also wanted to mention that I appreciate the addition of the suggested related work, but I would still suggest that the authors consider looking into more detailed means of comparison in the future (especially to the Petroni work), since this seemed to be a concern in multiple reviews.",Does the review address Comparison?,TRUE,FALSE,"The review suggests more detailed comparisons with related work, directly addressing the Comparison aspect."
Weaknesses * Something that stands out is the lack of discussion and comparison to related works that employ recurrent formulations of attention.,Does the review address Related Work?,TRUE,FALSE,"The review points out a lack of discussion and comparison with related works, which is a direct engagement with the Related Work aspect."
Other questions for the authors: (1) What is the loss in performance by fixing the word embeddings in the dependency parsing task?,Does the review address Data/Task?,TRUE,FALSE,"The review asks about performance in a specific task (dependency parsing), which relates to the Data/Task aspect."
"So how would it be possible to train with poor annotations, while generalize much better?",Does the review address Methodology?,TRUE,FALSE,"The review questions the generalization capability of the method, which directly addresses the methodology."
"If you remove the RE component, does the NER performance suffer?",Does the review address Ablation?,TRUE,FALSE,"The review suggests an ablation study by proposing removal of a component, which perfectly matches the Ablation aspect definition."
"It also further demonstrates that the BERT model, once fully tuned, could achieve SOTA/competitive performance compared to the recent new models (e.g., XLNet).",Does the review address Result?,TRUE,FALSE,"The review discusses performance comparisons and competitive results, directly addressing the Result aspect."
"**The method is simple with limited contribution, while performance improvement is not significant.",Does the review address Methodology?,TRUE,FALSE,"The review critiques the method's contribution and performance improvement, which relates to the methodology."
The theory is a bit complicated and not easy to follow.,Does the review address Theory?,TRUE,FALSE,"The review comments on the complexity of the theoretical approach, engaging with the Theory aspect."
Having additional ways to improve data efficiency by changing the model design is definitely of interest.,Does the review address Methodology?,TRUE,FALSE,"The review discusses potential improvements in model design and data efficiency, which addresses the methodology."
"**Baselines are too weak, leading to a misunderstanding of the effectiveness of the proposed method.",Does the review address Methodology?,TRUE,FALSE,"The review critiques the baseline weakness and its impact on method effectiveness, directly relating to methodology."
"A discussion on how to add new tasks to the same framework might help, or a discussion on why the current framework is enough.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests additional discussion on framework expansion, which aligns with the Elucidation aspect."
The authors introduce a BACKDOOR DATA PARADIGM that aptly fulfills the requirements for Uniqueness and Imperceptibility in watermark embedding.,Does the review address Presentation?,TRUE,FALSE,"The review discusses the introduction of a new paradigm, which relates to the Presentation aspect."
I highly recommend bringing this assumption earlier to avoid readers confusion.,Does the review address Presentation?,TRUE,FALSE,"The review provides a recommendation about improving the paper's clarity and structure, matching the Presentation aspect."
"The result will stand out to compare against Codex, the state-of-the-art program synthesis model.",Does the review address Comparison?,TRUE,FALSE,"The review mentions comparing results against a state-of-the-art model, directly addressing the Comparison aspect."
Theoretical discussion proves that the gradients derived from the new masking schema have a smaller variance and can lead to more efficient self-supervised training.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review provides a theoretical discussion explaining gradient properties, which aligns with the Elucidation aspect."
(Current experiments only include the results of models that are free from this issue.),Does the review address Experiment?,TRUE,FALSE,"The review discusses the selection of experimental results, directly addressing the Experiment aspect."
"This isn't clear from the current structure if so, since it's stated as a corollary of Theorem 3.",Does the review address Theory?,FALSE,TRUE,The review comments on the structure of a theorem but does not discuss the conceptual or theoretical foundations of the study.
lead to performance decrease for individual tasks.,Does the review address Result?,FALSE,TRUE,This is a fragment about performance that lacks context or substantive discussion of results.
"Moerover, there seem to be some errors about the correctness of the theory (See the first point below).",Does the review address Theory?,TRUE,FALSE,"The review explicitly questions the correctness of the theory, directly addressing the Theory aspect."
The source for generating the data is a big contribution to the theorem prover and machine learning community.,Does the review address Contribution?,TRUE,FALSE,The review highlights the significance of the data generation source as a contribution to the field.
- Not accounting for the privacy loss incurred in tuning the hyperparameters is a problem.,Does the review address Methodology?,FALSE,TRUE,"This is a critique about privacy loss, not a discussion of the research approach or techniques."
Would be great to state them upfront to avoid confusion.,Does the review address Methodology?,FALSE,TRUE,"This is a general suggestion about clarity, not a discussion of methodological approaches."
"In section 3.3.3 ""THE MIX-UP OF MULTIPLE TYPES,"" the authors mention that ""it is possible to embed multiple Double-I watermarks in a model, which theoretically has the potential to enhance the robustness of our watermarking technique.""",Does the review address Methodology?,TRUE,FALSE,The review discusses a specific methodological aspect of embedding multiple watermarks.
The authors experiment their method on three datasets and get the state of the art results.,Does the review address Result?,TRUE,FALSE,The review directly discusses experimental results across multiple datasets.
"For a fair comparison, I think the baseline should add those methods as claimed in the introduction (Lee et al., 2019; Child et al., 2019; Sukhbaatar et al., 2019; Beltagy et al., 2020, inter alia), (Kitaev et al., 2020; Wang et al., 2020; Roy et al., 2020, inter alia) and let us know how badly they performed under the short sequence.",Does the review address Comparison?,TRUE,FALSE,"The review suggests additional comparisons with specific baseline methods, directly addressing the Comparison aspect."
"There is no time complexity in the proposed method, which is very crucial if it needs to run for every inference.",Does the review address Methodology?,TRUE,FALSE,"The review critiques the lack of time complexity analysis, which is a methodological concern."
"The paper demonstrates that naively using CLIP-score between (query-concept, image) does not work well out-of-the-box, and proposes learning a new light-weight network based on pseudo-labels.",Does the review address Contribution?,TRUE,FALSE,"The review describes a novel approach as a contribution, highlighting the innovative aspect of the work."
"I'm concerned whether these improvements will hold after optimizing BERT carefully like RoBERTa, or using more advanced backbone methods like ALBERT.",Does the review address Result?,FALSE,TRUE,"This is a speculative question about potential improvements, not a discussion of actual results."
"The experments are fairly convincing, although it is not entirely surprising that this approach works, and to repeat, the basic idea of extracting additional training data in this way is not entirely new.",Does the review address Data/Task?,FALSE,TRUE,"The review discusses data extraction but does not specifically address the benchmark, dataset, or task characteristics."
Contrastive training (negative sampling) is one of the crucial contributions of this work.,Does the review address Contribution?,TRUE,FALSE,The review explicitly identifies contrastive training as a crucial contribution.
"Maybe I've missed this in the paper, if there is, please be more explicit about it because it affects the model quite drastically if for every sentence the largest phrase length is the sentence length.",Does the review address Significance?,TRUE,FALSE,The review raises a point about the model's impact and significance of a particular aspect.
The first is based on integrating information from all layers of the encoder via a method called Squeeze and Excitation.,Does the review address Methodology?,TRUE,FALSE,The review describes a specific methodological approach (Squeeze and Excitation).
i. e. representing a word by a set of many Gaussian distributions.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review provides a detailed description of word representation.
I would argue that this is not a fair comparison: did the authors intentionally choose weak baselines?,Does the review address Comparison?,TRUE,FALSE,"The review questions the fairness of the comparison, directly addressing the Comparison aspect."
"First of all, the dense interaction between vision and language tokens has been heavily studied prior to the so-called multimodal LLM era.",Does the review address Related Work?,TRUE,FALSE,The review discusses prior work in vision and language token interactions.
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Experiment?,TRUE,FALSE,The review discusses theoretical analysis and experimental validation.
The graph visualization shown does not seem to illustrate much.,Does the review address Presentation?,TRUE,FALSE,"The review critiques the graph visualization, relating to the Presentation aspect."
The paper's presentation could be improved in several ways:     1.,Does the review address Presentation?,TRUE,FALSE,The review suggests improvements to the paper's presentation.
**Strengths**:  The paper is well-written and easy to follow.,Does the review address Presentation?,TRUE,FALSE,The review comments on the paper's writing clarity and readability.
"The paper shows the reasonable claim that it is necessary to gradually train the model from close-ended datasets to open-ended ones because if the open-ended dataset is trained first, the model is heavily dependent on language capability so it is hard to train the audio representation.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses dataset characteristics and training approaches, addressing the Data/Task aspect."
It seems to be making every previously known augmentation approach better.,Does the review address Methodology?,FALSE,TRUE,This is a vague statement about augmentation approaches without discussing specific methodological details.
"Conventionally the ITM loss is a binary prediction task, while the particular one used in this work is more often referred as contrastive learning loss.",Does the review address Data/Task?,FALSE,TRUE,The review discusses a loss function type but does not address specific task or dataset characteristics.
"A discussion on how to add new tasks to the same framework might help, or a discussion on why the current framework is enough.",Does the review address Data/Task?,FALSE,TRUE,"While mentioning tasks, this is a general suggestion about framework expansion, not a description of the task or dataset."
"Only the video-level annotation is available for training, and the goal is retrieving the video segment described by the sentence.",Does the review address Data/Task?,TRUE,FALSE,The review directly describes the task's annotation and retrieval objectives.
"It might be interesting to see some examples, especially when the annotation budget is 18, of the kinds of instances that get selected depending on the task.",Does the review address Data/Task?,TRUE,FALSE,The review discusses task-specific annotation and instance selection.
"Paper is mostly clearly written, and easy to read.",Does the review address Presentation?,TRUE,FALSE,The review comments on the paper's clarity and readability.
Questions for the authors: - How the parameter study was conducted?,Does the review address Presentation?,FALSE,TRUE,"This is a question about methodology, not a comment on the paper's presentation."
Just trying to say that automatic evaluation of dialog systems is a hard problem.,Does the review address Evaluation?,FALSE,TRUE,"This is a general statement about evaluation difficulty, not a specific discussion of the study's evaluation."
"They show that, especially in small-data regimes, pre-training on an emergent language can yield significant performance boosts in both tasks.",Does the review address Result?,TRUE,FALSE,The review describes performance results in different data regimes.
"Further, how does the network perform when a longer context is obtained *maintaining the same number of parameters* as a network with less temporal scales?",Does the review address Result?,FALSE,TRUE,"This is a speculative question about potential network performance, not a discussion of actual results."
"For example, the model hyper-parameters are quite different for different tasks.",Does the review address Methodology?,FALSE,TRUE,This is a brief observation about hyper-parameters without substantive methodological discussion.
The experimentation is correct and the qualitative analysis made in table 1 shows results as expected from the approach.,Does the review address Experiment?,TRUE,FALSE,The review discusses the correctness of experimentation and qualitative analysis.
Could you explain more precisely what exactly is new?,Does the review address Presentation?,FALSE,TRUE,"This is a generic question about novelty, not a comment on presentation."
"# Typographic comments  * p 1, ""the input out of detractors"" --> ""the input out of distractors""   * p 2: ""transferable benefits for downstream natural language tasks"" the single hyphens surrounding the subsequent list should be em dashes (three hyphens in TeX)  * p 3: ""uses another GRU layer to decode the message m into a hidden vector hl"" I would use ""encode"" instead of ""decode"" here, since text-->representation is usually what an encoder does  * p 3: ""The most straightforward metric is the accuracy of playing the referential game p(guess = Ii).""",Does the review address Presentation?,TRUE,FALSE,The review provides detailed typographic comments about the paper's presentation.
- Any comments / results on the model's sensitivity to parser errors?,Does the review address Methodology?,FALSE,TRUE,"This is a question about model sensitivity, not a discussion of methodological approaches."
"Also, some additional experiments need to be added in order to better justify its claims.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests additional experiments to justify claims.
"Thus, it seems to me that you are essentially applying past results to answer a specific question you have (which is still a valuable contribution).",Does the review address Result?,FALSE,TRUE,"This is a commentary on the approach's contribution, not a discussion of specific results."
More theoretical proofs or appropriate literature citations are needed to validate this assertion.,Does the review address Related Work?,TRUE,FALSE,The review suggests additional literature citations.
- The ablation experiments and optimized prompt analysis are insightful.,Does the review address Ablation?,TRUE,FALSE,The review explicitly praises the ablation experiments.
"References Yining Wang, Jiajun Zhang, Feifei Zhai, Jingfang Xu, and Chengqing Zong.",Does the review address Related Work?,FALSE,TRUE,"This is simply a list of references, not a discussion of related work."
Authors could have plugged their embedding strategy in LayoutLM to understand the impact of that particular component.,Does the review address Significance?,TRUE,FALSE,The review suggests a way to understand the component's impact.
"Rules may be ""outdated"" because they are inefficient for certain languages with reams of available data and scads of phenomena that don't fit.",Does the review address Data/Task?,FALSE,TRUE,"This is a general comment about language rules, not a specific discussion of the task or dataset."
The theory can be more practically useful if it can be extended to quantify the intractability level so the resulting embeddings' error can be bounded or compared.,Does the review address Methodology?,FALSE,TRUE,"This is a suggestion about theoretical extension, not a discussion of the study's methodology."
"- Table 5 on the right for the training curriculum, it would be great to also include the language instruction following rate.",Does the review address Methodology?,FALSE,TRUE,"This is a suggestion about adding information to a table, not a methodological discussion."
"Hence, the model relies on whether the parser accurately discovers the crucial information.",Does the review address Methodology?,FALSE,TRUE,"This is a brief comment about parser dependency, not a substantive methodological analysis."
The empirical part of the paper shows improved performance of adding similar sentences to the context of LM training.,Does the review address Result?,TRUE,FALSE,The review discusses improved performance of adding similar sentences.
It would be beneficial to further explore whether sparse attention is indeed a problem for DNA sequence representation.,Does the review address Methodology?,FALSE,TRUE,"This is a speculative suggestion about attention, not a discussion of methodological approaches."
Does the baseline system (groundhog) contains the attention mechanism?,Does the review address Methodology?,FALSE,TRUE,"This is a question about baseline system components, not a substantive methodological discussion."
Weaknesses: - Somewhat weaker results on some CommonGen metrics are disappointing.,Does the review address Result?,TRUE,FALSE,The review directly comments on performance metrics and results.
"You hypothesize that more templates doesn't help because ""models at such scale do not easily overfit to a finetuning single task"" - but my intuition is for an opposite explanation -- that the models at such scale easily memorize a small number of templates!",Does the review address Presentation?,FALSE,TRUE,"This is a discussion of a hypothesis about model behavior, not a comment on the paper's presentation."
"-----Post-rebuttal----- The authors did not address my main concern, which is whether the baselines (e.g. TreeRNN) are used to compute substructure embeddings independent of the sentence embedding and the joint tagger.",Does the review address Comparison?,TRUE,FALSE,The review raises concerns about baseline comparisons.
But the diagrams in the appendix for the policy the MC!Q*BERT agent learns as well as the original paper for that agent show otherwise?,Does the review address Methodology?,FALSE,TRUE,"This is a reference to diagrams and prior work, not a methodological analysis."
I also read the original gSCAN paper but they didn't use this term at all.,Does the review address Comparison?,FALSE,TRUE,"This is a brief comment about terminology usage, not a substantive comparison."
"**Related work** The authors clearly describe the related prior works from both the perspectives of program synthesis, large language models, and benchmarks for program synthesis.",Does the review address Methodology?,FALSE,TRUE,"This is a description of related work, not the study's specific methodology."
* Ablation: the model vs corpus transfer comparison seems unfair to me.,Does the review address Methodology?,FALSE,TRUE,"This is a brief critique of a comparison, not a methodological discussion."
The proposed method is reasonable and moderately novel.,Does the review address Novelty?,TRUE,FALSE,The review directly comments on the method's novelty.
"The authors say in the introduction that the approach (Andreas, 2020) is task specific which seems not correct.",Does the review address Data/Task?,FALSE,TRUE,"This is a comment about a previous approach, not a description of the current study's data or task."
Their findings on learning complex tasks contribute to the understanding of large language model learning and provide valuable insights for future related work on efficient training.,Does the review address Data/Task?,TRUE,FALSE,The review discusses complex tasks and their learning characteristics.
The experiment results in Tables 1 & 2 cannot plausibly prove OTTER is more effective than CLIP.,Does the review address Methodology?,TRUE,FALSE,The review critiques the experimental methodology and its effectiveness.
"* The paper repeatedly emphasizes ""training"" in FP8 (e.g., in the title, in the abstract, etc.",Does the review address Methodology?,FALSE,TRUE,"This is a comment about paper emphasis, not a methodological analysis."
The motivation behind the study is somewhat unclear.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests the motivation is unclear.
"The motivation is to reduce the undesirable large variance of MLM objective, based on the hypothesis that randomly sampled masks in MLM would lead to undesirably large gradient variance, which as a result typically hurts the training efficiency with stochastic gradient optimization algorithms.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review provides a detailed explanation of the study's motivation.
"However, GTR is a single vector retrieval model, so there is no unified standard to show that the effect of the proposed model in this paper is better than the previous model.",Does the review address Methodology?,FALSE,TRUE,"This is a critique of comparison standards, not a methodological discussion."
"The proposed models -- which seem to be an application of various tree-structured recursive neural network models -- demonstrate a nice performance increase compared to a fairly convincing, broad set of baselines (if we are able to trust them; see below).",Does the review address Result?,TRUE,FALSE,The review discusses performance increase compared to baselines.
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Data/Task?,TRUE,FALSE,The review points out limitations in dataset validation.
"The layers are described in a textual fashion, barely any math (and extended in the pseudo-code).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review comments on the description of layers.
"However, there are many other tasks that involve sentence pairs.",Does the review address Data/Task?,FALSE,TRUE,"This is a general comment about task types, not a specific description."
The problem is a terrific one and the application of the recursive models seems like a contribution to this problem.,Does the review address Contribution?,TRUE,FALSE,The review highlights the contribution of applying recursive models.
I also read the original gSCAN paper but they didn't use this term at all.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,This is a brief comment about terminology usage.
"Indeed, it is not clear how one can reformulate e.g. linguistic tasks (like POS-tagging or dependency parsing) as a next word prediction task.",Does the review address Data/Task?,TRUE,FALSE,The review discusses the applicability of tasks to the proposed approach.
"Granted, the final effect of MTL depends on task similarities, but that's probably the same for the proposed approach.",Does the review address Data/Task?,FALSE,TRUE,"This is a general comment about multi-task learning, not a specific description of the task or dataset."
"It is good to know that it works for 2D-coordinates for the task at hand, though it seems to be more a marginal improvement on existing work rather than a standalone contribution.",Does the review address Contribution?,TRUE,FALSE,The review comments on the marginal nature of the contribution.
"Similar numbers are true for the rest of the tasks: 60.90 vs. 87 for OBQA, 71.01 vs. 90 for PIQA, and 63.20 vs.  89.70 for aNLI.",Does the review address Data/Task?,TRUE,FALSE,The review discusses specific task performance metrics.
"The key ideas are: (i) training longer with bigger batches over more data, (ii) removing NSP, (iii) training over long sequences, and (iv) dynamically changing the masking pattern.",Does the review address Methodology?,TRUE,FALSE,The review explicitly lists key methodological approaches.
"Compared to the related work, the novel part of this work is: (i) a new retrieval way, which is not quite clear and convincing to me.",Does the review address Methodology?,TRUE,FALSE,The review discusses the novel retrieval approach.
"### Cons and aspects to improve  My main concern is that the overall contribution is seems to be limited.In fact, the original paper of the Transformer approach, already proposed such kind of embedding.",Does the review address Result?,FALSE,TRUE,"This is a critique of contribution, not a discussion of results."
"Moreover, I have some comments on the model and experiments.",Does the review address Experiment?,FALSE,TRUE,"This is a generic statement about having comments, not a substantive discussion of experiments."
"It provided me with a much more thoughtful explanation for why language model pre-training improves downstream task performance, beyond simply “it helps learn good general representations of language using large amounts of unlabeled text data” (my previous reasoning).",Does the review address Result?,TRUE,FALSE,The review discusses improvements in understanding language model performance.
"* Authors perform experimentally sound experiments, following closely LayoutLM.",Does the review address Experiment?,TRUE,FALSE,The review praises the experimental approach.
"Theoretical Advantages and Theorem Justification:  While you mention that quantum features are theoretically more expressive, the paper falls short of explaining the underlying intuition and proof for this assertion.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions the theoretical justification of the approach.
- General Discussion: The authors perform relation extraction as reading comprehension.,Does the review address Methodology?,FALSE,TRUE,"This is a brief statement about relation extraction, not a methodological analysis."
And are the previous work using the same training set?,Does the review address Methodology?,FALSE,TRUE,"This is a question about training sets, not a discussion of methodology."
"2) As the authors claimed in Introduction, ‘plenty of training data is available’.",Does the review address Data/Task?,FALSE,TRUE,"This is a quoted claim about training data, not a specific description of the task."
More discussions on comparing with symbolic logic reasoner model LReasoner are needed.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests more discussion and comparison.
"Also, can you add a column where a dense linear model over p_f(s) is used?",Does the review address Presentation?,FALSE,TRUE,"This is a suggestion about adding a column, not a comment on presentation."
The notations in equation 2 and 3 are also inconsistent with equation 5.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out inconsistencies in notation.
"Altogether, I think this paper makes an interesting contribution to the question of: How can we get the most pretraining signal from unstructured data using off-the-shelf tools?",Does the review address Contribution?,TRUE,FALSE,The review highlights the paper's interesting contribution.
"Since the selective annotation is based entirely on similarities derived from sentence embeddings, there is nothing explicit ensuring that the label distribution over the selected subset is not skewed.",Does the review address Data/Task?,TRUE,FALSE,The review discusses issues with data selection and label distribution.
"The only two tasks examined are sentence similarity tasks (which seem a bit more like a sanity check), and NaturalQuestions.",Does the review address Data/Task?,TRUE,FALSE,The review describes the specific tasks examined in the study.
"- I think it makes sense in the comparison with CaP to compare using an oracle object detector, but one of the main novelties of the work is replacing the perceptual modules of CaP with foundation models.",Does the review address Comparison?,TRUE,FALSE,The review discusses comparisons with other approaches.
"The authors provide OTTER using hard labels (InfoNCE) as a baseline, but ZSL methods are sensitive to hyper-parameters and training sets.",Does the review address Methodology?,TRUE,FALSE,The review comments on methodological aspects of baseline creation.
"The billions that have been pumped into languages like English have in fact resulted in technologies that can be applied at much lower cost to languages like Kanyen’kéha, but there are still costs.",Does the review address Significance?,TRUE,FALSE,The review discusses the broader impact and significance of the work.
"Result 1: Under the above assumption over the downstream task, this paper provides a bound on the empirical loss of the downstream prediction task.",Does the review address Presentation?,FALSE,TRUE,"This is a statement about a research result, not a comment on presentation."
- The ablation experiments and optimized prompt analysis are insightful.,Does the review address Experiment?,TRUE,FALSE,The review praises the ablation experiments.
"And it's the averaged test scores that pRNN performs better - Please also make it clear whether the ""Test Avg.""",Does the review address Result?,TRUE,FALSE,The review discusses test scores and performance metrics.
"- Additionally, why isn't the the GRU version of pRNNv reported in the FBIS evaluation in Table 3?",Does the review address Evaluation?,TRUE,FALSE,The review raises a specific question about evaluation reporting.
"The result will stand out to compare against Codex, the state-of-the-art program synthesis model.",Does the review address Experiment?,FALSE,TRUE,"This is a statement about comparison, not a discussion of experiments."
"Given the issued pointed out in 1 and 2, I am not sure if the results are really sound as the authors claimed.",Does the review address Methodology?,FALSE,TRUE,"This is a general comment about result soundness, not a methodological analysis."
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Result?,TRUE,FALSE,The review discusses performance improvements and training efficiency.
The introduction of two different positional encoding methods in different sections is confusing (even if one only serves the purpose of understanding the role of positional encodings).,Does the review address Presentation?,TRUE,FALSE,The review critiques the confusing introduction of positional encoding methods.
"Unfortunately, as the paper overall does not seem to contain significant novelty, neither in methodology nor in results, I cannot recommend acceptance at this point.",Does the review address Novelty?,TRUE,FALSE,The review explicitly comments on the lack of novelty in methodology and results.
"* Section 6.3 - Please change ""The results from Table 2 and Table 1"" to say ""Table 1 and Table 2"".",Does the review address Presentation?,TRUE,FALSE,The review suggests a specific textual correction.
"Given the way p(guess=Ii) is used above, I think this should be more like E[argmax(p(guess=Ii)) = i].",Does the review address Presentation?,TRUE,FALSE,The review offers a mathematical notation correction.
"Once those are answered, a significant test had better be done since the improvement seems small.",Does the review address Result?,TRUE,FALSE,The review comments on the small improvement in results.
### Positive aspects   * Positional encoder based on sinusoidal function seems to be effective.,Does the review address Methodology?,TRUE,FALSE,The review positively highlights the positional encoder methodology.
"Without comparison with SOTA's performance, I will try my best to reject this paper.",Does the review address Comparison?,TRUE,FALSE,The review demands comparison with state-of-the-art performance.
"Furthermore, the authors are neglecting parameter efficient fine-tuning baselines, for instance like [1].",Does the review address Comparison?,TRUE,FALSE,The review points out missing comparisons with baseline methods.
"Weakness: - paper title is misleading, not directly related to LM - no citation and description for the baseline method T5+KB (Table 4) - As shown in Table 7, the proposed method is very sensitive to many factors.",Does the review address Methodology?,TRUE,FALSE,The review critiques various methodological aspects of the paper.
** The method is quite intuitive and can be regarded as an in-context example selection method (followed by annotations).,Does the review address Methodology?,TRUE,FALSE,The review describes the method as an intuitive example selection approach.
The hypothesis are clearly stated and the experiments are well designed.,Does the review address Experiment?,TRUE,FALSE,The review praises the experiment design.
"In Sec2, you said ""yet is outperformed by the proposed fully-explored masking (see Table 2).",Does the review address Result?,TRUE,FALSE,The review references performance comparison in a table.
"* The current analysis doesn’t apply directly to BERT, which is trained to predict masked words in a sentence, instead of the next word.",Does the review address Methodology?,TRUE,FALSE,The review comments on the training approach's limitations.
(4) How exactly is the interaction module processed?,Does the review address Methodology?,FALSE,TRUE,"This is a question about a specific module, not a substantive methodological analysis."
There are also neural architectures that particularly target to ensure some symbolic famous properties such as [3].,Does the review address Methodology?,FALSE,TRUE,"This is a brief mention of neural architectures, not a detailed methodological discussion."
Reducing it to 80% seems to be a sweet point with the best balance between performance and efficiency.,Does the review address Methodology?,TRUE,FALSE,The review discusses performance and efficiency trade-offs.
Therefore the novelty of these components of the paper is negligible.,Does the review address Novelty?,TRUE,FALSE,The review explicitly states the negligible novelty of components.
"The architecture does not look entirely novel, but I kind of like the simple and practical approach compared to prior work.",Does the review address Novelty?,TRUE,FALSE,The review comments on the lack of architectural novelty.
I believe that this contribution isn't enough for me to recommend acceptance.,Does the review address Contribution?,TRUE,FALSE,The review suggests the contribution is insufficient.
"This paper shows that the log posterior have the same lower bound when the inference model p(y|x) is defined by different methods, i.e., the arithmetic mean of predictions with different dropout masks, the geometric mean, and a power-mean family as an interpolation between these two cases.",Does the review address Presentation?,FALSE,TRUE,"This is a technical description of log posterior, not a comment on presentation."
I think it will be helpful for authors to have a complete graph of the computational model used instead of only figure 1 concept graph.,Does the review address Methodology?,FALSE,TRUE,"This is a suggestion about visualization, not a methodological analysis."
- There is some missing prior work in creating knowledge graphs from pre-trained language models.,Does the review address Methodology?,FALSE,TRUE,"This is a comment about missing prior work, not a methodological analysis."
"Also it seems that these are not fully annotated, and the ‘forward type inference functionality from TypeScript’ is required to obtain labels.",Does the review address Data/Task?,TRUE,FALSE,The review discusses annotation and labeling characteristics of the dataset.
So this contribution seems not practically useful according to the empirical result.,Does the review address Contribution?,TRUE,FALSE,The review critiques the practical usefulness of the contribution.
"Alongside with qualitative analysis, some quantitative analysis would be good to show what the model learns.",Does the review address Analysis?,TRUE,FALSE,The review suggests adding quantitative analysis to understand the model.
It is a bit hard to identify the interestingness or novelty in the approach.,Does the review address Novelty?,TRUE,FALSE,The review finds it difficult to identify the approach's novelty.
2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues.,Does the review address Evaluation?,TRUE,FALSE,The review suggests adding subjective evaluations to the experiments.
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.,Does the review address Result?,TRUE,FALSE,The review discusses the model's performance on available datasets.
"They show improved total performance in MultiWoz dataset compared to recent, relevant baselines.",Does the review address Result?,TRUE,FALSE,The review highlights improved performance compared to baselines.
The key contribution of the paper is the approach to overcome the limitation of annotating  query sets and labels.,Does the review address Methodology?,TRUE,FALSE,The review describes the key approach to overcoming labeling limitations.
"For fine-tuning, the authors run their model for 2.2 epochs, while their baseline model runs for 3 epochs, roughly 30% more which accounts for much of the reduction observed in Table 2.",Does the review address Methodology?,TRUE,FALSE,The review discusses experimental setup details like training epochs.
"Particularly because the reported accuracy margins are so slim, either of these variables could modify the empirical conclusions.",Does the review address Result?,TRUE,FALSE,The review comments on the slim margins of reported accuracy.
It is hard to know here which one of these actually made the adversarial setup useful.,Does the review address Presentation?,FALSE,TRUE,"This is a comment about experimental setup, not presentation."
"DP is not ""incorporated"" in a model or multimodality (as the authors mention in different ways a few times throughout the paper), DP is a property of a randomised algorithm (in this context, the training algorithm that produces the distribution of models, not the model).",Does the review address Methodology?,TRUE,FALSE,The review provides a technical clarification about the methodology.
The method can select appropriate batch sizes by assessing the working memory requirements per token during benchmarking.,Does the review address Methodology?,TRUE,FALSE,The review describes a method for selecting batch sizes.
"Given the nature of the problem statement (with multiple tasks, inputs and outputs), the authors have done a good job in explaining each of them properly.",Does the review address Data/Task?,TRUE,FALSE,"The review praises the explanation of tasks, inputs, and outputs."
May I know many questions are in each data split shown in Table 5?,Does the review address Data/Task?,TRUE,FALSE,The review asks about data split details.
"A significant part of the contribution was in the analysis of the results, obtained by this learning-based parameter sharing approach, which was quite informative and revealed some interesting insights about where and when a language-specific computation is required.",Does the review address Contribution?,TRUE,FALSE,The review highlights the contribution of results analysis.
Maybe add a comment saying Step 2 is the human-in-the-loop step of the algorithm?,Does the review address Methodology?,FALSE,TRUE,"This is a suggestion about adding a comment, not a methodological analysis."
They also empirically show that it is easier and faster for the learner if the signals from easily inferred labels to learn target are provided.,Does the review address Result?,TRUE,FALSE,The review discusses empirical findings about learning signals.
The authors only conduct the evaluation on sentence similarity tasks and open domain QA tasks.,Does the review address Evaluation?,TRUE,FALSE,The review points out the limited scope of evaluation tasks.
"In a nutshell, aren't you showing that $$\text{downstream error}=\mathcal{O}\left(\sqrt{\text{pre-training error}\cdot\frac{\text{downstream error}}{\text{pre-training error}}}\right)\qquad ?$$  **Issues** - Why don't you verify the main claim---$\epsilon$-optimality in pre-training propagates as $\mathcal{O}(\sqrt{\epsilon})$-optimality on downstream---empirically?For this, you may want to vary the language modeling performance (e.g. by pruning the language model) and then verifying that the downstream loss increase is indeed $\mathcal{O}(\sqrt{\text{pre-training loss increase}})$.",Does the review address Presentation?,FALSE,TRUE,This is a technical discussion of mathematical notation and claims.
It is highly innovative and holds significant importance for the development of general artificial intelligence.,Does the review address Significance?,TRUE,FALSE,The review comments on the work's importance for artificial intelligence.
"You are clearly not trying to infer any loop invariants, and it would help clarify that upfront.",Does the review address Presentation?,TRUE,FALSE,The review suggests clarifying an approach upfront.
"Also in Table 2, they claim that they outperform other approaches.",Does the review address Comparison?,TRUE,FALSE,The review references performance claims in a table.
"The latter is typically used in two different ways in the transformer architecture, each resulting in a different computation for RF  is confusing as the RFA is now redefined.",Does the review address Presentation?,TRUE,FALSE,The review critiques the confusing redefinition of a term.
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review raises concerns about the evaluation's validity and comparability.
"Given the barrier of reproducing the reported results and also the limited insights delivered by this work, I am sharing a huge concern regarding the current trend of building multimodal LLMs manifested by this work or other related ones.",Does the review address Methodology?,FALSE,TRUE,"This is a broader critique about multimodal LLMs, not a specific methodological analysis."
The authors take time to implement and evaluate several prominent baselines.,Does the review address Comparison?,TRUE,FALSE,The review notes the authors' effort in evaluating baselines.
"This is misleading as usually it is used to refer to world / external knowledge such as a knowledge base of entities, whereas here it is really just syntax, or arguably semantics if AMR parsing is used.",Does the review address Presentation?,TRUE,FALSE,The review critiques the potentially misleading use of terminology.
"For checking the generalization of the method and better comparison w/ InDIGO (though InDIGO also conducted on MSCOCO, Django and the current comparison is sufficiently fair), I would like to increase my rating if seeing more experiments on large scale machine translation benchmarks as those in InDIGO.",Does the review address Experiment?,TRUE,FALSE,The review suggests additional experiments for better generalization.
I'd like some confirmation that larger batch size won't get much improvement for the baseline model.,Does the review address Methodology?,FALSE,TRUE,"This is a speculative question about batch size, not a methodological analysis."
It is unclear which sequences were used for training the Transformer models and how similar they are to test sequences.,Does the review address Methodology?,TRUE,FALSE,The review questions the details of sequence selection for Transformer models.
"Also, the citation to Universal Dependencies is completely broken.",Does the review address Related Work?,TRUE,FALSE,The review points out a broken citation to related work.
"in CVPR, 2020  [2] J. Lu, V. Goswami, M. Rohrbach, D. Parikh, S. Lee, 12-in-1: Multi-Task Vision and Language Representation Learning.",Does the review address Related Work?,TRUE,FALSE,The review cites a related work reference.
"Liu Y., Liu Z., Chua T.,Sun M. AAAI 2015 _ Also, the inclusion of the result from those approaches in tables 3 and 4 could be interesting.",Does the review address Presentation?,FALSE,TRUE,"This is a suggestion about including results, not a comment on presentation."
"Since the data is generated by T-5, couldn't we generate as much as we want?",Does the review address Data/Task?,TRUE,FALSE,The review discusses data generation characteristics.
"Since it's a efficiency paper, I think it should be complete.",Does the review address Methodology?,FALSE,TRUE,"This is a generic comment about completeness, not a methodological analysis."
The paper mentions that the entity extraction was done following Yasunaga et al.,Does the review address Methodology?,TRUE,FALSE,The review references a specific methodology for entity extraction.
"- Additionally, in my opinion, the authors are misrepresenting prior work when saying in line 163 that the ""MTL approach has not yet been successful in NLP"".",Does the review address Related Work?,TRUE,FALSE,The review critiques the representation of prior work in the field.
Why authors consider questions answering and sentiment analysis as the applications?,Does the review address Methodology?,FALSE,TRUE,"This is a question about application selection, not a methodological analysis."
Such gaps make the main contribution questionable and make it as a pure empirical paper on its value.,Does the review address Contribution?,TRUE,FALSE,The review questions the main contribution's value.
"In the 6.2.3 visualization of clusters, it would be very useful to have a visualization of clusters from some baselines on other ways of learning.",Does the review address Comparison?,TRUE,FALSE,The review suggests additional baseline comparisons.
As the current system captures the semantics through RNN based models.,Does the review address Methodology?,TRUE,FALSE,The review describes the system's semantic capture method.
"- I know GPT3 access is hard to get, but I wish experiments with k=8 prompts could be compared against  Post rebuttal: I think another pass for clarity over the paper would be good for the final version, but otherwise I'm happy with the paper updates and I'm happy to see the ablation numbers aren't too sensitive to token count.",Does the review address Presentation?,TRUE,FALSE,The review suggests a pass for clarity in the paper.
"- The experiments contain two setups, one is offline response evaluation via MultiWOZ, and another is interactive simulation via ConvLab.",Does the review address Evaluation?,TRUE,FALSE,The review describes the experimental evaluation setups.
"And further discuss the correlation between the classification performance and the instruction following rate, if there is any insights that can be drawn.",Does the review address Result?,FALSE,TRUE,"This is a suggestion about further analysis, not a discussion of results."
Cons: - wMAN model the relation for all possible pairs of the word and the video frame.,Does the review address Methodology?,TRUE,FALSE,The review describes the model's approach to relation modeling.
"If these method can also achieve very good results, then I feel that the novelty and effectiveness of DeFo may be challenged.",Does the review address Novelty?,TRUE,FALSE,The review questions the novelty if alternative methods achieve similar results.
"In experimental details, the slightly better performance in Table 2, can it be attributed to finer generation powered by the RNN generator?",Does the review address Experiment?,TRUE,FALSE,The review asks about the source of performance improvement.
This paper proposes a reranking architecture with a LogicForm-to-NaturalLanguage preprocessing step for semantic parsing.,Does the review address Methodology?,TRUE,FALSE,The review describes the proposed reranking architecture.
The motivation behind Transformer-QL is to increase the context length processed beyond what other methods can.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review describes the motivation behind the Transformer-QL approach.
"By using the first inference solution, the performance on PTB and Wikitext2 LM can be improved by 2-3 on perplexity but is still slightly worse than the SOTA achieved by the mixture of softmaxes.",Does the review address Result?,TRUE,FALSE,The review discusses performance improvements on specific datasets.
Nit: I would have tried to move the (datasets per cluster/templates per dataset) ablation to the main body as well and shortened Section 3  - The 4.2 (scaling laws) ablation is perhaps the most interesting of all.,Does the review address Ablation?,TRUE,FALSE,The review comments on ablation studies in different sections.
"It would be useful if following the suggestions of [2,3] the authors could present results in settings with low data regimes and with significant distribution shift with respect to the pre-training set, which represents a more realistic application setting.",Does the review address Presentation?,FALSE,TRUE,"This is a suggestion about additional experimental settings, not presentation."
A uniform framework for resampling Different recombinations perform more or less favorably across different datasets.,Does the review address Data/Task?,TRUE,FALSE,The review discusses performance across different datasets.
Casting the optimization of discrete latent variables as a one-step MDP is interesting 3.,Does the review address Methodology?,TRUE,FALSE,The review highlights an interesting methodological approach.
"Overall, I thought the paper was easy to read and understand.",Does the review address Presentation?,TRUE,FALSE,The review comments on the paper's readability.
"In terms of strenghs - The paper has a very throughout analysis of different models and positional encodings - It proposes several contributions, including a new probing task and several positional encoding methods.",Does the review address Contribution?,TRUE,FALSE,"The review lists the paper's contributions, including probing tasks and encoding methods."
Time analysis on language modeling is not presented.,Does the review address Methodology?,FALSE,TRUE,"This is a brief note about missing time analysis, not a methodological discussion."
"For a more comprehensive analysis, it would be instructive to see how the approach compares with a broader spectrum of state-of-the-art methods.",Does the review address Comparison?,TRUE,FALSE,The review suggests broader comparisons with state-of-the-art methods.
"The proposed system outperforms or achieves on-par  performance against previous SOTA methods, i.e., AudioGen and AudioLDM, in both objective and subjective metrics.",Does the review address Comparison?,TRUE,FALSE,The review describes performance compared to previous state-of-the-art methods.
"However, this does not hold theoretically due to the extra bias on expectation.",Does the review address Analysis?,TRUE,FALSE,The review comments on theoretical limitations.
- The evaluation on PTB (table 2) isn't a fair one since the model was trained on a larger corpus (FBIS) and then tested on PTB.,Does the review address Evaluation?,TRUE,FALSE,The review critiques the fairness of the evaluation setup.
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Analysis?,TRUE,FALSE,The review highlights a thorough analysis across multiple datasets and settings.
"As the paper points out, the success rate alone is not enough.",Does the review address Evaluation?,TRUE,FALSE,The review suggests that success rate alone is insufficient.
"- In figure 6A, why was performance not increasing for untuned models w.r.t model size?",Does the review address Result?,FALSE,TRUE,"This is a question about performance, not a discussion of results."
"Since the architecture (ignoring the compression) is similar to multi-scale approaches, it would be good to compare against empirically.",Does the review address Comparison?,TRUE,FALSE,The review suggests comparing with multi-scale approaches.
Their thorough ablation experiments and other analysis yield some interesting findings the authors could emphasize more.,Does the review address Ablation?,TRUE,FALSE,The review praises the thoroughness of ablation experiments.
"For example, a Figure to define what are $n_s, n_c, n_m$ would help to understand the paper with a nice visual benefit.",Does the review address Presentation?,TRUE,FALSE,The review suggests adding a figure to improve understanding.
"Given the ending of the paper, I interpreted that the set of dialog acts (i.e. options) are learnt automatically but I could not find this to be communicated explicitly.",Does the review address Methodology?,FALSE,TRUE,"This is a comment about unclear communication, not a methodological analysis."
"With the strengths being said, I hope to also point out that the paper's application of adversarial training is one attempt in many possibilities, and in many cases it is not clear where the improvements come from.",Does the review address Methodology?,TRUE,FALSE,The review comments on the application of adversarial training.
"The in-depth experimental analysis of the BERT pretraining process in this paper answers many open questions (e.g., the usefulness of NSP objective) and also provide some guidance in how to effectively tweak the performance of pretrained model (e.g., large batch size).",Does the review address Methodology?,TRUE,FALSE,The review discusses experimental analysis of pretraining process.
"Since they both use $m$ nodes, does it mean the supergraph also operates on each sub fact node?",Does the review address Methodology?,FALSE,TRUE,"This is a technical question about graph operations, not a methodological analysis."
The authors also introduce the recent developed Gumbel-matching techniques to derive the close-form of the posterior distribution.,Does the review address Methodology?,TRUE,FALSE,The review describes the introduction of Gumbel-matching techniques.
"After reading it several times, I get the idea that the authors view a model as a general learner if it can simulate a universal circuit for all poly-size circuits.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review provides an interpretation of the authors' perspective.
"For the theoretical analysis, it was not clear to me what is the contribution of the current analysis compared to the Levine 2020 paper.",Does the review address Contribution?,TRUE,FALSE,The review questions the theoretical analysis contribution.
Experiments on both continual pre-training and general pre-training from scratch show the effectiveness of the proposed method.,Does the review address Experiment?,TRUE,FALSE,The review discusses experiments on pre-training methods.
"Setting and Main Result:  This paper focuses on classification tasks, and the bulk of the work goes into how to model the next word distributions as features or representations.",Does the review address Data/Task?,TRUE,FALSE,The review describes the focus on classification tasks.
Questions:  * How can we be sure that the specific power law derived from a different experimental configuration in Kaplan et al. (2020) corresponds to the empirical law that can be derived for transformers in this particular evaluation setting?,Does the review address Experiment?,TRUE,FALSE,The review raises questions about experimental configuration.
"While I think it's nice to analyze the connection between RM and DM, the math provided in the paper is simple, and the main contribution is just to add a baseline to the algorithm of Khalifa et al.",Does the review address Analysis?,TRUE,FALSE,The review comments on the analysis of connection between methods.
- The empirical validation is thoughtful and relatively thorough.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review praises the empirical validation.
"However, there is no discussion on the latency in the proposed method and experiments.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review notes the lack of discussion on method latency.
The optimality of deterministic inference does not hold empirically due to class imbalance or discrepancy between training and test sets.,Does the review address Analysis?,TRUE,FALSE,The review discusses empirical limitations of deterministic inference.
"### Weaknesses ###  * The paper falls short on the framing of the invariant inference problem, and on the technical details of what does it mean to infer a meaningful local invariant.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the framing of the inference problem.
"Regarding that CLIP does not release the 400M dataset (mentioned in this paper by the authors), the authors may not be able to train OTTER on the 400M dataset.",Does the review address Data/Task?,TRUE,FALSE,The review discusses dataset availability limitations.
---------------------------------------------- Original: This paper is aimed at using pre-trained language models to create open-ended knowledge graphs.,Does the review address Methodology?,FALSE,TRUE,"This is a generic statement about the paper's aim, not a methodological analysis."
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests need for discussion of evaluation approach.
"other state-of-the-arts/benchmark systems on only ""present"" type of key phrases.",Does the review address Comparison?,FALSE,TRUE,"This is a fragment about key phrases, not a substantive comparison."
"Important research can make great strides regarding languages that are usually neglected, if and only if funding is available for people to take the time to do the work.",Does the review address Significance?,TRUE,FALSE,The review discusses the broader impact of research on neglected languages.
The notations in equation 2 and 3 are also inconsistent with equation 5.,Does the review address Methodology?,FALSE,TRUE,"This is a comment about notation inconsistency, not methodology."
"In Sec 5.5 Gradient Variance, $\pi$ is missing in ""$G_\theta(x)=A(x)\nabla_\theta \log_{\theta}(x)$""",Does the review address Presentation?,TRUE,FALSE,The review points out a notation error in an equation.
"Overall, a very strong paper, well structured and clear.",Does the review address Presentation?,TRUE,FALSE,The review praises the paper's structure and clarity.
"I have no experience with these kinds of NLU models, so I can't say with confidence whether the architectural additions proposed are well-motivated, but to me it feels like there is not a strong justification for adding these particular features to the BERT architecture, and the results do not clearly demonstrate their utility except in the ""lexical_overlap"" case.",Does the review address Result?,TRUE,FALSE,The review discusses the utility of architectural additions.
This paper tackles a very important and under-studied problem: reducing the cost of training NLP models.,Does the review address Presentation?,FALSE,TRUE,"This is a comment about the paper's problem statement, not presentation."
"**Update (after the author's response)**: During the rebuttal, the authors clarified my major concern, as well as provided additional experiments that verify the main claim of the paper.",Does the review address Experiment?,TRUE,FALSE,The review mentions additional experiments during rebuttal.
"Intuitively, this parameter arises from translating the ""natural"" task assumption, which only guarantees transfer on average to the downstream task.",Does the review address Methodology?,FALSE,TRUE,"This is a comment about parameter intuition, not methodology."
"For instance, the greater instability of larger Transformers to active learning bodes poorly for practitioners leveraging ever increasing model sizes for low-resource datasets.",Does the review address Data/Task?,TRUE,FALSE,The review discusses challenges with model sizes on low-resource datasets.
"Second, the authors neither 1) evaluate their model on another dataset or 2) evaluate any previously published models on their dataset.",Does the review address Evaluation?,TRUE,FALSE,The review critiques the lack of dataset evaluation.
"I understand that a single model is helpful for multiple UI tasks, but I wonder if this approach is scalable beyond the 5 tasks and 5 modalities mentioned.",Does the review address Data/Task?,TRUE,FALSE,The review questions the scalability of the approach across tasks.
"Compared to the related work, the novel part of this work is: (i) a new retrieval way, which is not quite clear and convincing to me.",Does the review address Significance?,FALSE,TRUE,"This is a comment about retrieval method novelty, not significance."
"The in-depth experimental analysis of the BERT pretraining process in this paper answers many open questions (e.g., the usefulness of NSP objective) and also provide some guidance in how to effectively tweak the performance of pretrained model (e.g., large batch size).",Does the review address Analysis?,TRUE,FALSE,The review provides an in-depth analysis of the BERT pretraining process.
"As pointed by one public comment, the ablation study should show how much improvement is from BERT vectors.",Does the review address Methodology?,FALSE,TRUE,"This is a suggestion about an ablation study, not a methodological analysis."
"Prior work has explored ""learning-to-share""  strategies for parameter sharing in multi-task learning (see Ruder et al., AAAI 2018), and using gating/masking to control computational paths in a differentiable way (see Fan et al., ICLR 2019, Sukhbaatar et al., ACL 2019); it is clear that the focus is NMT but it should be worth mentioning/discussing such studies to better situate the work and to help the reader assess the actual contributions.",Does the review address Data/Task?,FALSE,TRUE,"This is a discussion of related work strategies, not a specific data or task description."
"A lot of attention/space is dedicated to locality and symmetry properties of positional encodings, which from my understanding, isn’t very novel and has been explored in previous work.",Does the review address Related Work?,TRUE,FALSE,The review comments on previous work's exploration of positional encoding properties.
The paper pointed out that ELECTRA framework [1] explored the idea of using REINFORCE [2] as the the way of adding adversarial training signals to the model but observed degenerated results.,Does the review address Comparison?,TRUE,FALSE,The review discusses a comparison with previous framework approaches.
It is unclear which sequences were used for training the Transformer models and how similar they are to test sequences.,Does the review address Data/Task?,TRUE,FALSE,The review questions the details of training and test sequences.
"* Theorem 2 is a restatement of past work, showing that transformers lie in logspace-uniform TC^0 * Theorem 3 assumes TC^0 \neq P / poly, and then derives that transformers cannot simulate any poly-time circuit.",Does the review address Methodology?,TRUE,FALSE,The review describes theorems related to transformer capabilities.
"Please report the total training and total inference time, and make a comparison with standard Transformer model.",Does the review address Comparison?,TRUE,FALSE,The review suggests comparing training and inference times.
Can the theory guide how to develop new models to learn program representations?,Does the review address Methodology?,FALSE,TRUE,"This is a speculative question about theoretical guidance, not methodology."
- Using “concept” to stand in for verbs and nouns is somewhat confusing.,Does the review address Presentation?,TRUE,FALSE,The review finds the use of terminology confusing.
The authors may add more details about the previous work in the related work section.,Does the review address Related Work?,TRUE,FALSE,The review suggests adding more details about previous work.
"In Section 2, the basics of binding-unbinding are introduced and many mathematical properties are required to make the binding-unbinding work.",Does the review address Theory?,TRUE,FALSE,The review discusses mathematical properties of binding-unbinding.
This might depend on different sub-sequences and the various functions of different layers when modeling cross-attention.,Does the review address Methodology?,FALSE,TRUE,"This is a speculative comment about modeling approaches, not a methodological analysis."
"- Since a major part of the model contains shared parameters, was there a need for new set of shared parameters along with the language-specific parameters.",Does the review address Methodology?,TRUE,FALSE,The review questions the need for parameter sharing approaches.
"This paper shows that the log posterior have the same lower bound when the inference model p(y|x) is defined by different methods, i.e., the arithmetic mean of predictions with different dropout masks, the geometric mean, and a power-mean family as an interpolation between these two cases.",Does the review address Evaluation?,TRUE,FALSE,The review describes the method of calculating log posterior.
"The authors switch between using BERT_base and RoBERTa_base without being very clear about when and why, e.g., in Table 2 they have both models, but only in different sections.",Does the review address Methodology?,TRUE,FALSE,The review critiques the inconsistent use of different model bases.
There's also some missing related work in extracting knowledge from pretrained models that should probably be discussed.,Does the review address Related Work?,TRUE,FALSE,The review notes missing related work on knowledge extraction.
"Although I understand the experiment setup, missing reference to more recent VL works prevent readers from getting a good research landscape in the multimodal pre-training.",Does the review address Methodology?,FALSE,TRUE,"This is a comment about missing references, not methodology."
"Hence, it will be better to additionally include the results of other standard RL algorithms for better justifying this claim.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests additional validation of claims.
"In the experiments, the authors make comparisons with traditional methods, and show the effectiveness of their model.",Does the review address Methodology?,TRUE,FALSE,The review describes comparative experiments with traditional methods.
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Result?,TRUE,FALSE,The review highlights the analysis of performance across different settings.
5.2 visualizations: this seems pretty ad-hoc without much justification for the choices.,Does the review address Presentation?,TRUE,FALSE,The review critiques the visualization choices.
"In Sec2, you said ""yet is outperformed by the proposed fully-explored masking (see Table 2).",Does the review address Presentation?,TRUE,FALSE,The review points out a reference to a table.
It is then not clear how each fact block (grey squares in Figure 4) functions as a whole.,Does the review address Presentation?,TRUE,FALSE,The review questions the clarity of a figure's representation.
How about the benefits compared with the proposed one?,Does the review address Methodology?,FALSE,TRUE,"This is a vague question about benefits, not a methodological analysis."
"You *tell* us that Fon is ""a language with special tokenization needs"" and that ""standard tokenization methods do not alwaysadequately deal with the grammatical, diacritical, and tonal properties of some African language"", and you cite the relevant papers.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses detailed description of language tokenization characteristics.
How do the settings used in the experiments compare to those used for the analysis?,Does the review address Experiment?,FALSE,TRUE,"This is a question about experimental settings, not a discussion of experiments."
"- Followed by previous question, in the qualitative results, it seems the boundary parts of the predicted video segments are less accurate.",Does the review address Result?,TRUE,FALSE,The review comments on the accuracy of predicted video segments.
"- unconstrained, multi-concept:     This needs a direct comparison to a traditional discrete-channel referential game.",Does the review address Experiment?,TRUE,FALSE,The review suggests a direct comparison with a traditional experimental approach.
Introducing the layer and networks in a simple way would help clarify the implementation and other notation.,Does the review address Presentation?,TRUE,FALSE,The review suggests clarifying implementation and notation.
The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).,Does the review address Significance?,TRUE,FALSE,The review highlights the importance of the data augmentation approach.
"First, much of the improvement (I think) comes from reducing the number of epochs and/or the number of steps.",Does the review address Methodology?,FALSE,TRUE,"This is a speculative comment about improvement sources, not methodology."
In general the writing does not make the mechanisms by which proof artifacts may be extracted from Lean clear enough.,Does the review address Presentation?,TRUE,FALSE,The review critiques the clarity of mechanism explanation.
- `Table 2`: Are these values computed over a single or multiple runs (in which case include stddev/confidence intervals).,Does the review address Presentation?,TRUE,FALSE,The review asks about statistical reporting in a table.
"Does the definition of ""event word""s here come from any particular previous work that motivates it?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions the motivation behind a specific definition.
"- If there is a limit set on the phrase length of pRNN, then it makes the system more tractable.",Does the review address Presentation?,FALSE,TRUE,This is a conditional statement about system tractability.
The proposed beam enumeration significantly outperforms REINVENT (the strongest baseline in the existing benchmark).,Does the review address Result?,TRUE,FALSE,The review discusses performance compared to a baseline.
-  Consistent performance improvement over the baseline models on all of the three QA benchmarks.,Does the review address Data/Task?,TRUE,FALSE,The review notes consistent performance across QA benchmarks.
The paper contributes LEANSTEP dataset and the Learning environment.,Does the review address Data/Task?,TRUE,FALSE,The review mentions the contribution of a dataset and learning environment.
This method should be included in the experiments in order to justify the proposed RL approach is necessary.,Does the review address Experiment?,TRUE,FALSE,The review suggests including additional methods in experiments.
"It would be to show more experiment results for some settings, for example, performance on Sum task when training with a mixture distribution, or more Sum task samples and fewer Parity task samples ( p range from 0.5 to 1.",Does the review address Result?,TRUE,FALSE,The review suggests showing more experimental results.
This logical progression effectively addresses the challenges initially posed.,Does the review address Methodology?,TRUE,FALSE,The review praises the logical progression addressing challenges.
The model architecture should be better justified.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests better justification of the model architecture.
This paper describes four methods of obtaining multilingual word embeddings and a modified QVEC metric for evaluating the efficacy of these embeddings.,Does the review address Presentation?,FALSE,TRUE,"This is a description of methods, not a comment on presentation."
"The authors comment that the model architecture is designed to remain stable for a growing set of tasks, but this seems to be under the assumption that the input and output modalities would remain constant.",Does the review address Methodology?,TRUE,FALSE,The review discusses design assumptions of the model architecture.
Experiments on LEGO and code interpretation task are done.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review describes experimental tasks.
Possibly a dataset like common crawl or enwiki8 would be more appropriate for language modelling experiments.,Does the review address Methodology?,FALSE,TRUE,"This is a suggestion about dataset selection, not methodology."
"- P2, Sec 2: ""where $p^{\star}_{\cdot | s}$ is used as a vector on the left and distribution on the right"".",Does the review address Presentation?,TRUE,FALSE,The review points out a notation issue in the paper.
"Is there a perplexity/efficiency tradeoff, and can you characterize that experimentally?",Does the review address Experiment?,TRUE,FALSE,The review suggests characterizing a trade-off experimentally.
Is it possible to run an ablation study using the combination of REINFORCE and mixture-of-signals to verify whether Gumble-Softmax relaxation is the reason for it to work?,Does the review address Ablation?,TRUE,FALSE,The review suggests an ablation study to verify method effectiveness.
"It's important to discuss why these improvements are non-trivial and how they advance the field, considering the rapidly evolving landscape of both quantum computing and graph analysis.",Does the review address Result?,FALSE,TRUE,"This is a suggestion about discussing improvements, not a result analysis."
"Additionally, showing this for negations and / or examples which GreaseLM gets correct but QA-GNN does not (and vice-versa) can shed some light on what the model improves on (and what are the limitations).",Does the review address Methodology?,FALSE,TRUE,"This is a suggestion about comparative analysis, not methodology."
- The methods and results are presented in an understandable manner.,Does the review address Methodology?,FALSE,TRUE,"This is a general comment about presentation, not a methodological analysis."
"LeetCode problems tend to be fairly simple, self-contained, and, to my knowledge, are coding problems that are meant to help train new programmers or prepare software developers for coding interviews, amongst other things.",Does the review address Data/Task?,TRUE,FALSE,The review describes the characteristics of LeetCode problems.
* Ablation: the model vs corpus transfer comparison seems unfair to me.,Does the review address Ablation?,TRUE,FALSE,The review critiques the fairness of a model vs. corpus transfer comparison.
"* ""Moreover, it should be noted that BROS achieves higher f1 score than 79.27 of LayoutLM using visual features"".",Does the review address Comparison?,TRUE,FALSE,The review references a performance comparison with another approach.
"I compared their numbers explicitly to Liu et al. (2019), and RoBERTa_base outperforms their approach on nearly all tasks (and on average).",Does the review address Comparison?,TRUE,FALSE,The review compares performance across different tasks.
"This paper finds that the next word distributions of a subset of ""prompt"" words contain discriminative signals and are good features.",Does the review address Methodology?,TRUE,FALSE,The review describes the method of using word distribution signals.
Strengths * Improving the data efficiency in language models is an important problem that so far studies have shown that can be achieved by scaling the size of the model.,Does the review address Data/Task?,TRUE,FALSE,The review discusses data efficiency in language models.
The authors used RNN based generative models (discussed as RNN and Copy RNN) for keyphrase prediction and copy mechanism in RNN to predict the already occurred phrases.,Does the review address Methodology?,TRUE,FALSE,The review describes the use of RNN-based generative models.
Theoretical analysis is provided to demonstrate the effectiveness of the proposed method under a greedy search algorithm.,Does the review address Theory?,TRUE,FALSE,The review mentions theoretical analysis of the proposed method.
"- Easy but probably not great thing to try:  held-out tasks with wrong/useless templates  A final thought:  It's not obvious that using as many training examples per dataset as possible is optimal, given that the model could overfit to dataset-specific spurious correlations.",Does the review address Data/Task?,TRUE,FALSE,The review discusses potential issues with training example selection.
"Given that one of the primary goals of this paper was to create embeddings that perform well under the word translation metric (intra-language), it is disappointing that the method that performs best (by far) is the invariance approach.",Does the review address Methodology?,TRUE,FALSE,The review critiques the performance of embedding approaches.
The framework of Variational Information Pursuit is quite similar to the Concept Bottleneck Models.,Does the review address Methodology?,TRUE,FALSE,The review compares the framework to existing models.
"I think it would improve the paper if you could focus on a certain kind of invariants, and show that these invariants can in fact generalize across programs.",Does the review address Result?,FALSE,TRUE,"This is a suggestion about focusing on invariants, not a result analysis."
But there should be no reason that it is restricted to be so.,Does the review address Data/Task?,FALSE,TRUE,"This is a vague comment about restrictions, not a task description."
The proposed model is then experimentally verified on three logic-driven datasets which demonstrates some performance gain.,Does the review address Experiment?,TRUE,FALSE,The review describes experimental verification on datasets.
"Below are my major concerns:  If the major motivation is to reduce gradient variance, can we just use larger mini-batch size?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions the motivation for reducing gradient variance.
* Assume T-LLMs are general learners by contradiction.,Does the review address Methodology?,FALSE,TRUE,"This is a technical statement about assumption, not methodology."
"However, it is unclear how well they perform to the CASP state-of-the art (see also Rives et al, 2020).",Does the review address Related Work?,TRUE,FALSE,The review suggests comparing with state-of-the-art approaches.
- Weaknesses: The comparison against similar approaches could be extended.,Does the review address Comparison?,TRUE,FALSE,The review suggests extending comparisons with similar approaches.
How effective is the method to capture farther long-term dependencies compared to previous methods?,Does the review address Comparison?,TRUE,FALSE,The review asks about comparing long-term dependency capture.
"For example, what if the authors don’t use a LogicForm-to-NaturalLanguage conversion?",Does the review address Methodology?,FALSE,TRUE,This is a speculative question about method modification.
### Overall  Authors used BERT alongside to a 2D-position embedding based on a sinusoidal function and a graph-based decoder to improve performance on document information extraction tasks.,Does the review address Methodology?,TRUE,FALSE,The review describes the methodological approach using BERT and embeddings.
"you explained this in page 6, in Task Description.",Does the review address Presentation?,TRUE,FALSE,The review references a specific page for task description.
"Strengths:  - The paper is generally well-written, with excellent motivation and empirical setup/analysis  - The overall strategy of differentiable prompt optimized to maintain fluency is reasonable and novel.",Does the review address Analysis?,TRUE,FALSE,The review highlights the excellent empirical setup and analysis.
"## (Minor) Imprecise Claim about Poly(n) Size  In Theorem 1, the authors claim: > We consider log-precision, constant-depth, and polynomial-size Transformers: for Transformers whose input is of length n, the values at all neurons are represented with O(log n) bits, the depth is constant, and the number of neurons is O(poly (n)).",Does the review address Methodology?,FALSE,TRUE,"This is a detailed quote about theorem characteristics, not methodology."
"* Authors perform experimentally sound experiments, following closely LayoutLM.",Does the review address Comparison?,FALSE,TRUE,"This is a statement about experimental approach, not a comparison."
"This paper proposes to model the generation order as latent variables for sequence generation tasks, by optimizing the ELBO involving a proposed process of Variational Order Inference (VOI).",Does the review address Presentation?,FALSE,TRUE,"This is a description of the proposed method, not a presentation comment."
- Figure 1 is helpful in comprehending the effect of different loss functions vs robustness.,Does the review address Result?,FALSE,TRUE,"This is a comment about a figure's helpfulness, not results."
The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).,Does the review address Experiment?,TRUE,FALSE,The review discusses experimental results on RoBERTa.
"Detailed comments:  - P2, Sec 1.1: ""analyze the efficiency language model features"" -> analyze the efficiency of language model features  - P2, Sec 2: you started introducing these notations without explaining what they mean.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out issues with notation explanation.
Weaknesses: - I felt like the empirical validation could have been stronger.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests the empirical validation could be stronger.
Solid experiments demonstrating the proposed method outperforms other existing approaches.,Does the review address Methodology?,FALSE,TRUE,This is a general statement about experimental performance.
The authors experiment their method on three datasets and get the state of the art results.,Does the review address Experiment?,TRUE,FALSE,The review describes experiments on multiple datasets.
"The latter aims at avoiding catastrophic forgetting, while the former avoid having to share all (or no) parameters.",Does the review address Methodology?,TRUE,FALSE,The review discusses parameter sharing approaches.
There is limited contribution in terms of machine learning algorithms.,Does the review address Methodology?,FALSE,TRUE,"This is a generic comment about contribution, not methodology."
The source for generating the data is a big contribution to the theorem prover and machine learning community.,Does the review address Theory?,TRUE,FALSE,The review highlights the contribution to theorem proving.
"However, the baseline may be much weaker than the current SOTA solution.",Does the review address Comparison?,TRUE,FALSE,The review suggests the baseline might be weaker than state-of-the-art.
Both settings show the better performance of the proposed method.,Does the review address Methodology?,FALSE,TRUE,"This is a brief comment about performance, not methodology."
"However, this does not hold theoretically due to the extra bias on expectation.",Does the review address Theory?,TRUE,FALSE,The review discusses theoretical limitations.
"Overall the paper presentation is okay, although the clarity could be improved.",Does the review address Presentation?,TRUE,FALSE,The review comments on the paper's presentation clarity.
"You can then argue informally for why you think this definition makes sense, akin to, e.g., the Church-Turing thesis.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests informal argumentation for a definition.
It should be stated more clearly in the text what this means.,Does the review address Presentation?,TRUE,FALSE,The review suggests clearer text explanation.
"**Experiment setup** In Table 3, the paper only compares the proposed method against GPT-Neo and GPT-J, which is not sufficient.",Does the review address Experiment?,TRUE,FALSE,The review critiques the limited comparison in the experiment setup.
"- I did not learn much from the evaluation; monolingual BERT achieves the highest accuracy, which by itself is not very surprising nor insightful.",Does the review address Evaluation?,TRUE,FALSE,The review finds the evaluation lacking in insights.
"Weakness While the ablation study and visualization analysis are done, the key evaluations are missing.",Does the review address Evaluation?,TRUE,FALSE,The review notes missing key evaluations despite ablation study.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Result?,TRUE,FALSE,The review discusses the empirical results and theoretical assumptions.
"It'll be good to have some ablation study of the combined effect of using only one data sample in a mini-batch, and the full-explored masking.",Does the review address Ablation?,TRUE,FALSE,The review suggests an additional ablation study.
The authors investigate how to use multi-task training on top of a pretrained model for a variety of unrelated tasks from the GLUE benchmark.,Does the review address Methodology?,TRUE,FALSE,The review describes the multi-task training approach.
"It is clear that Shaw et al. (2019) didn't experiment on OVERNIGHT dataset, but setting up the baseline on a dataset should not be classified as ``our method’’.",Does the review address Related Work?,TRUE,FALSE,The review discusses the context of previous work and baseline setting.
The model is tested in a long range language modeling task.,Does the review address Data/Task?,TRUE,FALSE,The review mentions a long-range language modeling task.
"Hence, it will be better to additionally include the results of other standard RL algorithms for better justifying this claim.",Does the review address Methodology?,FALSE,TRUE,"This is a suggestion about including additional results, not methodology."
My hunch is LTU would be far better than Pengi in open ended tasks although Pengi might be better on Close-ended tasks.,Does the review address Significance?,TRUE,FALSE,The review speculates about the potential significance of different approaches.
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.,Does the review address Result?,FALSE,TRUE,"This is a suggestion about figure placement, not a result discussion."
5.1 aggregations: this seems fine though fairly ad-hoc.,Does the review address Intuition/Justification/Motivation/Validation?,FALSE,TRUE,This is a brief comment about aggregation methods.
Weaknesses:  - The notation/description of section 4 is not immediately intuitive.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the intuitiveness of section 4's notation.
- Too much detail in related work: I think the related work section is too long and just a list of papers rather than helping to place the work in the research area.,Does the review address Related Work?,TRUE,FALSE,The review critiques the related work section's structure.
"In terms of the experiments, there are only dev results reported on GLUE (Table 2).",Does the review address Experiment?,TRUE,FALSE,The review points out limited experimental reporting.
"In the experiments, the authors make comparisons with traditional methods, and show the effectiveness of their model.",Does the review address Comparison?,TRUE,FALSE,The review describes comparisons with traditional methods.
(2) Is table 1 an average over the 17 embeddings described in section 5.1?,Does the review address Presentation?,TRUE,FALSE,The review asks a clarifying question about table representation.
"**Weakness/Suggestions/Questions**  * Although The paper is well written overall, I think section 3.2 Proof Artifact Training can be improved by adding an example explaining the Lean terminology proof term, proof type, tactic, tactic state, etc.",Does the review address Presentation?,TRUE,FALSE,The review suggests improving section clarity with examples.
"However, evaluating dialogue policy is also important to justify the learned policy is suitable.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review emphasizes the importance of justifying the learned policy.
"This is immediate from Theorem 2, and this kind of separation appears to have been the implicit the point of Merrill and Sabharwal 2023  * This statement seems overly strong and minimizes prior work: ""This work takes the first step towards rigorously answering the fundamental question by considering a theoretical boundary of model capacity to be general learner""      * e.g., ""Saturated Transformers are Constant-Depth Threshold Circuits"" shows that transformers lie in TC^0 under a saturation condition     * e.g., ""The Parallelism Tradeoff: Limitations of Log-Precision Transformers"" shows that log-precision transformers lie in log-space-uniform TC^0",Does the review address Methodology?,TRUE,FALSE,The review discusses theoretical limitations and prior work.
"- The proposed architecture is tested on massive experiments including language understanding tasks, optical flow, video audio class autoencoding, image classification, and starcraft II and achieves superior performance.",Does the review address Experiment?,TRUE,FALSE,The review describes extensive experiments across multiple tasks.
Massively multilingual neural machine translation.,Does the review address Related Work?,FALSE,TRUE,"This is a fragment about machine translation, not a substantive discussion."
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.,Does the review address Presentation?,TRUE,FALSE,The review suggests relocating the model figure.
The main weakness of the paper is that it is mainly based on further tuning the existing BERT model and lacks novel contribution in model architecture.,Does the review address Contribution?,TRUE,FALSE,The review critiques the lack of novel model architecture.
- Experiments are well-designed: many baselines are implemented to compare proposed method with traditional lifelong learning methods.,Does the review address Methodology?,FALSE,TRUE,"This is a comment about experimental design, not methodology."
"- §2: ""study that implement"" -> ""study that implements"" - §3: ""adjectives has"" -> ""adjectives have"" - §4: ""analyzing sub-component"" -> ""analyzing sub-components"" - §5: ""Syllables features also generally performs"" -> ""Syllable features also generally perform""",Does the review address Presentation?,TRUE,FALSE,The review provides multiple grammatical corrections.
Missing period at the end of the first paragraph in the related work section.,Does the review address Presentation?,TRUE,FALSE,The review notes a missing punctuation mark.
This paper proposed to use Graph Neural Networks (GNN) to do type inference for dynamically typed languages.,Does the review address Methodology?,TRUE,FALSE,The review describes the proposed methodology using Graph Neural Networks.
"Weaknesses, suggested improvements and requested clarifications  1.",Does the review address Presentation?,FALSE,TRUE,"This is a generic heading about weaknesses, not a presentation comment."
"However, Section 3.1 cannot demonstrate effective theoretical information.",Does the review address Theory?,TRUE,FALSE,The review critiques the theoretical information in a section.
"If the authors can adequately address the following issues around presentation and the interpretation of Theorem 5, I would be satisfied raising my score, as I value the research question raised by the paper and believe the conclusions are valid.",Does the review address Presentation?,TRUE,FALSE,The review suggests addressing presentation and interpretation issues.
"* Strength     * This paper proposes an interesting idea and interpretation to connect RM and DM paradigm     * This paper proposes a variance reduction method for DPG which demonstrates its improvement on performance, stability and sample efficiency * Weakness     * From my understanding, the baseline mostly comes from the observation in 3.3, which has limited technical novelty.",Does the review address Result?,TRUE,FALSE,"The review discusses performance improvement, stability, and sample efficiency."
"Other designs include beam size, whether or not to use a pretrained model, etc.",Does the review address Methodology?,FALSE,TRUE,"This is a brief comment about design considerations, not methodology."
"Hence, the model relies on whether the parser accurately discovers the crucial information.",Does the review address Result?,FALSE,TRUE,"This is a comment about parser dependency, not results."
"**The method is simple with limited contribution, while performance improvement is not significant.",Does the review address Result?,TRUE,FALSE,The review critiques the limited performance improvement.
"Figure 1 is presently not pleasant to look at, even though it has interesting results`!",Does the review address Presentation?,TRUE,FALSE,The review comments on the figure's visual appeal.
"Finally, a number of ablation studies are performed and demonstrate the effectiveness of the proposed method to some extent.",Does the review address Ablation?,TRUE,FALSE,The review mentions ablation studies demonstrating method effectiveness.
"3) Continue with 2), as the experiment results shown in Table 2, TS compiler performs poorly.",Does the review address Experiment?,TRUE,FALSE,The review discusses experimental results showing poor performance.
- The methods and results are presented in an understandable manner.,Does the review address Presentation?,TRUE,FALSE,The review finds the methods and results understandable.
It’s very hard to compare the absolute differences Tables 1 and 2 for ourselves.,Does the review address Comparison?,TRUE,FALSE,The review finds it difficult to compare differences in tables.
"####Minor Comments:  The paper mentions in several places symbolic scaffolding without citations, literature is certainly rich here, e.g. [1,2] are papers integrating symbolic constraints for semantic parsing.",Does the review address Related Work?,TRUE,FALSE,The review suggests adding citations for symbolic scaffolding.
The threshold is definitely related to hardware specifications and model architectures.,Does the review address Presentation?,FALSE,TRUE,"This is a comment about threshold relationships, not presentation."
"- In figure 6A, why was performance not increasing for untuned models w.r.t model size?",Does the review address Methodology?,FALSE,TRUE,"This is a question about performance, not methodology."
"If not, the presentation requires to change and reflect only the controllability analysis.",Does the review address Presentation?,TRUE,FALSE,The review suggests changing presentation to reflect analysis.
Weaknesses * Something that stands out is the lack of discussion and comparison to related works that employ recurrent formulations of attention.,Does the review address Methodology?,FALSE,TRUE,"This is a comment about lack of discussion, not methodology."
"- P3, Sec 2.2: ""... achieve lower test perplexity than traditional n-gram models"" Why is this true?",Does the review address Related Work?,FALSE,TRUE,"This is a question about a performance claim, not related work."
"However, $R$ is defined as a non-square matrix in the previous paragraph.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out a matrix definition inconsistency.
What recommendation the authors would give for those interested in using it?,Does the review address Result?,FALSE,TRUE,This is a speculative question about recommendations.
"In addition, improvements on full-shot cases are mostly marginal.",Does the review address Result?,TRUE,FALSE,The review notes marginal improvements in full-shot cases.
"However, the contribution of this paper is not clear.",Does the review address Contribution?,TRUE,FALSE,The review suggests the contribution is unclear.
They introduce an unsupervised approach (MAMA) to construct a knowledge graph in two phases in which they take a target corpus and output a knowledge graph.,Does the review address Methodology?,TRUE,FALSE,The review describes the unsupervised approach for knowledge graph construction.
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Data/Task?,FALSE,TRUE,"This is a description of experimental comparisons, not data/task."
The model is tested in a long range language modeling task.,Does the review address Methodology?,FALSE,TRUE,"This is a brief mention of a language modeling task, not methodology."
"------- Minors: - figure 1: could consider adding x, which would better match the descriptions of the paper (modeling p(y|x) instead of p(y))  Missing references:   [1] Chan, W., Kitaev, N., Guu, K., Stern, M. and Uszkoreit, J., 2019.",Does the review address Related Work?,TRUE,FALSE,The review suggests adding missing references.
The task opens up a huge space for AI-powered general audio creation.,Does the review address Methodology?,FALSE,TRUE,"This is a comment about the task's potential, not methodology."
The current paper only indicates that a small gap gives more consistency between the true objective and the optimized objective defined on the training set: they can be still far away from the expected posterior over data distribution.,Does the review address Methodology?,FALSE,TRUE,"This is a technical comment about objective optimization, not methodology."
- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.,Does the review address Analysis?,TRUE,FALSE,The review critiques the experimental analysis's dataset limitations.
"- unconstrained, single-concept:     This is adquate to demonstrate that a minimal environment works (as stated in the paper).",Does the review address Experiment?,TRUE,FALSE,The review discusses the adequacy of the experimental environment.
Weaknesses: There is no contribution/novelty from the modeling/methods side.,Does the review address Methodology?,TRUE,FALSE,The review points out lack of novelty in modeling methods.
"Furthermore, the authors deliberately avoid settings where DP is known to be hard due to the relatively low amount of training data per class (e.g. CIFAR-100/ImageNet).",Does the review address Methodology?,FALSE,TRUE,"This is a comment about experimental settings, not methodology."
- Many interesting robustness capabilities of VL models only emerge when trained with hundreds of millions of samples.,Does the review address Methodology?,FALSE,TRUE,"This is a general observation about model training, not methodology."
The proposed RoBERTa achieves/matches state-of-the-art performance on many standard NLU downstream tasks.,Does the review address Result?,TRUE,FALSE,The review highlights performance on downstream tasks.
The authors should conduct experiments beyond English-to-French.,Does the review address Significance?,TRUE,FALSE,The review suggests expanding experimental scope.
"In this paper, the authors present a study of different aspects of language-specific model capacity for massively multilingual machine translation.",Does the review address Methodology?,TRUE,FALSE,The review describes the study's approach to language-specific model capacity.
It is great to have a theoretical analysis of the property of the influence function.,Does the review address Theory?,TRUE,FALSE,The review appreciates the theoretical analysis.
The applicability and the novelty of the SCS representation seem limited.,Does the review address Methodology?,TRUE,FALSE,The review questions the applicability of the representation.
This paper is an interesting application of a data augmentation or self-supervised learning type of approach for tactic based theorem proving.,Does the review address Theory?,TRUE,FALSE,The review describes the approach to theorem proving.
it is likely a relatively minor effect given the results from Appendix B but it seems like it could slightly prevent overfitting  - The ablation in 4.1 was great (number of clusters).,Does the review address Ablation?,TRUE,FALSE,The review praises the ablation study on number of clusters.
- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.,Does the review address Ablation?,TRUE,FALSE,The review suggests additional ablation analysis.
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses theoretical analysis and experimental validation.
"Simply because baselines have done that, it doesn't justify the authors from reporting inflated numbers.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review critiques reporting of inflated numbers.
An additional experimental results with multi-task finetuning should also be added.,Does the review address Data/Task?,FALSE,TRUE,"This is a suggestion about adding experimental results, not a data/task description."
The state-of-the-art performance should be appreciated.,Does the review address Result?,TRUE,FALSE,The review appreciates the state-of-the-art performance.
QA- GNN: Reasoning with language models and knowledge graphs for question answering.,Does the review address Related Work?,FALSE,TRUE,"This is a fragment about a work title, not a substantive discussion."
"- General Discussion: This work tackles an important and interesting event extraction problem -- identifying positive and negative interactions between pairs of countries in the world (or rather, between actors affiliated with countries).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review describes the event extraction problem.
"- Extensive ablation studies to demonstrate the importance of modality interaction layer  - selection, parameter sharing, graph connectivity, and parameter initialization.",Does the review address Methodology?,TRUE,FALSE,The review mentions extensive ablation studies on various aspects.
The paper is mostly clearly written and discusses server interesting ablation experiments.,Does the review address Presentation?,TRUE,FALSE,The review comments on the paper's clarity.
The results presented in the paper show strong gains against baseline methods on 3 different datasets.,Does the review address Data/Task?,TRUE,FALSE,The review discusses results across different datasets.
"When you map ORCHID to UD, you lose information, since the ORCHID tagset is more fine-grained; does this make a big difference for taggers?",Does the review address Comparison?,TRUE,FALSE,The review raises a question about information loss in mapping.
"According to the evaluation, the proposed method shows its effectiveness especially when the finetuning data is limited.",Does the review address Methodology?,TRUE,FALSE,The review discusses the method's effectiveness with limited fine-tuning data.
"* It will be cool to show some results on BLEU improvement on machine translation, or user studies on language generation tasks, to demonstrate its practical impact, as the quantitative metrics right now are still kind of artificial.",Does the review address Result?,TRUE,FALSE,The review suggests additional experiments to demonstrate practical impact.
"Under these assumptions, the gradient over the parity distribution samples is zero.",Does the review address Methodology?,FALSE,TRUE,"This is a technical statement about gradient distribution, not methodology."
What is the number of resulting features that were used to train the logistic regression model?,Does the review address Methodology?,FALSE,TRUE,"This is a specific question about feature count, not methodology."
"---- Detailed comments: ----  - ""For each dataset, we manually compose ten unique templates"":  Why not have templates per task cluster instead of per dataset?",Does the review address Data/Task?,TRUE,FALSE,The review questions the approach to template creation.
I think if the paper will be improved if it resolves the lack of clarity around the temperature in GS being an implicit entropy-regularization parameter.,Does the review address Result?,FALSE,TRUE,"This is a suggestion about improving clarity, not results."
The authors have done further experiments and show that there are still gains on these tasks when model sized is increased significantly.,Does the review address Methodology?,FALSE,TRUE,"This is a comment about experimental findings, not methodology."
In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (pp.,Does the review address Related Work?,FALSE,TRUE,"This is a fragment of a reference, not a discussion of related work."
"- If not, please remove the attention layer after the encoder in figure 5.",Does the review address Presentation?,TRUE,FALSE,The review suggests removing an attention layer in a figure.
"In experiments, mainly accuracy is shown, but since the major motivation to reduce gradient variance, why not show some comparison of gradient variance of MLM and MLM-FE?",Does the review address Experiment?,TRUE,FALSE,The review suggests comparing gradient variance in experiments.
I provide details below examination of how I’ve come to my evaluation rating below.,Does the review address Evaluation?,FALSE,TRUE,This is a generic statement about providing evaluation details.
"As proposed in the comments, this should be assessed in the paper by replacing BERT representations by non-contextual representations such as GloVE.",Does the review address Presentation?,FALSE,TRUE,This is a suggestion about representation replacement.
"It would be great to define and identify beyond current close-ended tasks with new lower level tasks which really require using the audio, such as counting sound events, ordering of events, etc.",Does the review address Data/Task?,TRUE,FALSE,The review suggests expanding task definitions.
"It is found that the published results of [1], (see reference below) performs better than (with a sufficiently high difference) the current system on Inspec (Hulth, 2003) abstracts dataset.",Does the review address Result?,TRUE,FALSE,The review compares performance on a specific dataset.
"‘Wang & Cho’ were not the first who used Transformers generativity (see Vaswani, 2017).",Does the review address Related Work?,TRUE,FALSE,The review corrects a claim about Transformer generativity.
More importantly the PACT methodology is more general; the idea of incorporating diverse auxiliary tasks as a language modeling task by introducing a distinct token for each task is novel.,Does the review address Novelty?,TRUE,FALSE,The review highlights the novelty of the methodology.
Weaknesses: Some of the design choices need to be elaborated on further and additional analysis-based experiments would also be useful.,Does the review address Analysis?,TRUE,FALSE,The review suggests additional analysis-based experiments.
"| s) which performs well, instead of a model directly over p*( .",Does the review address Result?,FALSE,TRUE,"This is a fragment about model performance, not results."
I therefore consider the contributions as insufficient for an ICLR submission.,Does the review address Contribution?,TRUE,FALSE,The review considers the contributions insufficient.
More theoretical proofs or appropriate literature citations are needed to validate this assertion.,Does the review address Theory?,TRUE,FALSE,The review suggests additional theoretical proofs.
"The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",Does the review address Result?,FALSE,TRUE,"This is a comment about theoretical assumptions, not results."
I will be more convinced if evaluation is done on a wider range of tasks.,Does the review address Data/Task?,TRUE,FALSE,The review suggests evaluating on a wider range of tasks.
"Some of the details for model description are missing and confusing, e.g., (1) How the representation is initialized for a supernode corresponding to a fact triplet and how does the supernode propagate information to the sub-nodes?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out missing details in model description.
The paper use FLOPS to quantify the arithmetic intensity.,Does the review address Evaluation?,TRUE,FALSE,The review notes the use of FLOPS for quantification.
"There's not much justification for it, especially given something simpler like a fixed window average could have been used.",Does the review address Methodology?,FALSE,TRUE,"This is a critique about justification, not methodology."
And the results of the proposed model can also be available for downstream detection models.,Does the review address Methodology?,FALSE,TRUE,"This is a generic statement about model results, not methodology."
"The authors propose to include related texts retrieved by the kNN method in a single training sample, which is proved effective in solving sentence similarity tasks.",Does the review address Data/Task?,TRUE,FALSE,The review describes the approach to including related texts.
"Section 4.8: Using transformers for generating proteins with natural properties is not new (see Madani et al, 2020, ‘ProGen’ or Rives et al, 2020).",Does the review address Novelty?,TRUE,FALSE,The review questions the novelty of using transformers for protein generation by referencing prior work.
"(4) In general, the results in table 3 do not tell a consistent story.",Does the review address Presentation?,TRUE,FALSE,The review critiques the consistency of results in a table.
However in experiment only 300 projects are involved.,Does the review address Data/Task?,FALSE,TRUE,"The review mentions the number of projects (300), but does not discuss the dataset or task characteristics in depth"
"For this purpose, the authors introduced the definition of a ""natural"" task.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review directly mentions introducing a definition of a ""natural"" task, which aligns with the Elucidation aspect of describing and defining elements"
Summary ========= Authors applied reinforcement learning framework to the problem of task-oriented dialog.,Does the review address Methodology?,TRUE,FALSE,"The review explicitly describes applying a reinforcement learning framework to task-oriented dialog, which directly relates to the methodology aspect"
I also think it makes sense to switch Figure 1 and Figure 2 entirely.,Does the review address Presentation?,TRUE,FALSE,"The review discusses the arrangement of figures, which falls under the Presentation aspect of paper organization"
"Leave ""general learner"" imprecise but reframe proposition 1 as your formal definition attempting to capture it: you view an LM hypothesis class is a general learner if it can express a universal circuit family for all poly-size circuits.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review provides a detailed explanation and suggestion about defining a ""general learner"", which aligns with the Elucidation aspect"
"around 1% might be reasonable for 30-40% reduction in training time, but it is certainly a reduction in accuracy.",Does the review address Result?,TRUE,FALSE,"The review discusses reduction in accuracy and training time, which directly relates to the Result aspect"
It's great the authors supplied code for part of the system so I don't want to penalize them for missing it -- but this is relevant since the paper itself has so few details on the baselines that they could not really be replicated based on the explanation in the paper.),Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review provides a detailed discussion about the lack of details in baselines, which corresponds to the Elucidation aspect of explanation and interpretation"
i. e. representing a word by a set of many Gaussian distributions.,Does the review address Presentation?,TRUE,FALSE,"The review describes a technical representation method, which can be considered part of the Presentation aspect"
"Theoretical Advantages and Theorem Justification:  While you mention that quantum features are theoretically more expressive, the paper falls short of explaining the underlying intuition and proof for this assertion.",Does the review address Theory?,TRUE,FALSE,"The review explicitly discusses theoretical advantages and theorem justification, directly addressing the Theory aspect"
"* p 4: ""es should set a upper bound"" --> ""es should set an upper bound""  * p 5: "" ec perform better than or "" --> "" ec performs better than or """,Does the review address Presentation?,TRUE,FALSE,"The review points out grammatical and typographical errors, which is a clear indication of the Presentation aspect"
See section-2.6 of this tutorial for more details about using neural models to rank: https://www.microsoft.com/en-us/research/uploads/prod/2017/06/INR-061-Mitra-neuralir-intro.pdf.,Does the review address Related Work?,TRUE,FALSE,"The review references an external tutorial, which aligns with the Related Work aspect"
The performance drops significantly when we change any of them.,Does the review address Result?,TRUE,FALSE,"The review mentions performance drops, which relates to the Result aspect"
- Extensive results show improvements over a base model and a larger model across a range of tasks.,Does the review address Result?,TRUE,FALSE,"The review highlights improvements over base and larger models across tasks, directly addressing the Result aspect"
The author have opted for some sort of greedy pruning as described in the caption of figure 4.,Does the review address Methodology?,TRUE,FALSE,"The review describes a greedy pruning approach, which falls under the Methodology aspect"
"Page 5, line 1: should \tilde{e}^{(l-1)} be \tilde{e}^{l} instead ?",Does the review address Presentation?,TRUE,FALSE,"The review points out a potential notation error, which is part of the Presentation aspect"
"If it is the extension to multilingual embeddings, a few lines explaining the novelty would help.",Does the review address Methodology?,TRUE,FALSE,"The review suggests explaining the novelty of multilingual embeddings, relating to Methodology"
"To make the method more convincing, authors may consider use more recent VL models as student works, and try to further push their limits.",Does the review address Methodology?,TRUE,FALSE,"The review provides suggestions about improving the method, directly addressing Methodology"
"In experimental details, the slightly better performance in Table 2, can it be attributed to finer generation powered by the RNN generator?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review asks for an explanation about experimental details, which aligns with the Elucidation aspect"
"The main limitation to me is that, the two novel pre-training tasks proposed in this paper are specific for Wikipedia and they are less effective than the ICT strategy (as shown in Table 5).",Does the review address Presentation?,TRUE,FALSE,"The review discusses limitations of the paper, which can be considered part of the Presentation aspect"
t-SNE plots of these selected examples in the larger context of unlabeled instances might also be a good visualization to show.,Does the review address Presentation?,TRUE,FALSE,"The review suggests a visualization technique, which relates to the Presentation aspect"
"- Well Structured Experiments sections with 4 RQs and results that confirm each of the hypotheses  - Reproducibility and Transparency in reporting of experiments in terms of available source code, dataset information, details about human evaluation, generation examples.",Does the review address Evaluation?,TRUE,FALSE,"The review highlights well-structured experiments and reproducibility, which directly addresses the Evaluation aspect"
"Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review describes various tests and motivations behind the research approach
Enhancing the paper with the aforementioned suggestions could substantially improve its impact and reception by the research community.,Does the review address Result?,TRUE,FALSE,"The review discusses potential improvements and impact, which relates to the Result aspect"
There are also some typos to be corrected: Sec 1: ``...making purchase decision...'' should be ``making a/the purchase decision'' Sec 1: ``...are devoted to explore... '' should be `` are devoted to exploring'' Sec 1: ``...there is on sufficient behaviors...'' should be “there are no sufficient behaviors'' Sec 1: ``...on business trip...'' should be ``on a business trip'' Sec 1: ``...there are abundant behavior information...'' should be ``there is abundant behavior'' Sec 3: ``The new reviewer only provide us...'' should be ``...The new reviewer only provides us...'' Sec 3: ``...features need not to take much...'' should be ``...features need not take much...'' Sec 4: ``...there is not any historical reviews...'' should be ``...there are not any historical reviews...'' Sec 4: ``...utilizing a embedding learning model...'' should be ``...utilizing an embedding learning model...'' Sec 5.2 ``...The experiment results proves...'' should be ``...The experiment results prove...'' - General Discussion: It is a good paper and should be accepted by ACL.,Does the review address Presentation?,TRUE,FALSE,"The review lists multiple typographical errors, which is a clear indication of the Presentation aspect"
** I would like to urge the authors to include more powerful baselines in the experiment rather than hide them.,Does the review address Comparison?,TRUE,FALSE,"The review suggests including more powerful baselines, which relates to the Comparison aspect"
"Prior work has explored ""learning-to-share""  strategies for parameter sharing in multi-task learning (see Ruder et al., AAAI 2018), and using gating/masking to control computational paths in a differentiable way (see Fan et al., ICLR 2019, Sukhbaatar et al., ACL 2019); it is clear that the focus is NMT but it should be worth mentioning/discussing such studies to better situate the work and to help the reader assess the actual contributions.",Does the review address Related Work?,TRUE,FALSE,"The review discusses prior work on parameter sharing and gating strategies, directly addressing the Related Work aspect"
Manual parameter sharing schemes are generally costly to come up with and when they are obtained for certain language pairs they do not necessarily generalize well to arbitrary language pairs in multilingual NMT.,Does the review address Methodology?,TRUE,FALSE,"The review discusses parameter sharing schemes in multilingual NMT, which relates to the Methodology aspect"
"However, the paper does not include detailed descriptions about the proposed method, making readers not easy to understand.",Does the review address Methodology?,TRUE,FALSE,"The review critiques the lack of detailed descriptions of the proposed method, which is directly related to the Methodology aspect"
- multi-concept and noise:     The noise you add to the channel has a number of different components; there should be an ablation study to illustrate the effects of these components.,Does the review address Experiment?,TRUE,FALSE,"The review suggests an ablation study to illustrate the effects of noise components, which aligns with the Experiment aspect"
Simply adding related sentences in the pre training input context helps end performance.,Does the review address Result?,TRUE,FALSE,"The review discusses how adding related sentences helps end performance, which relates to the Result aspect"
The authors refer to the fact that MTL can (and often does!),Does the review address Result?,TRUE,FALSE,The review is an incomplete statement about MTL that does not clearly address any specific result
The submission has evaluated the proposed algorithms on four datasets and improved SOTA performances.,Does the review address Evaluation?,TRUE,FALSE,"The review mentions evaluating algorithms on four datasets and improving state-of-the-art performances, which directly addresses the Evaluation aspect"
"Although the presentation can be polished, the overall narrative and explanation is clear and easy to follow.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review provides an explanation about the narrative and clarity of the paper, which corresponds to the Elucidation aspect"
"The authors show that for such tasks, if the pre-training objective is $\epsilon$-optimal, then the downstream objective of a linear classifier is $\mathcal{O}(\sqrt{\epsilon})$-optimal.",Does the review address Methodology?,TRUE,FALSE,"The review describes a mathematical approach to pre-training objectives, which relates to the Methodology aspect"
"Setting and Main Result:  This paper focuses on classification tasks, and the bulk of the work goes into how to model the next word distributions as features or representations.",Does the review address Result?,TRUE,FALSE,"The review discusses the main result of focusing on classification tasks and modeling word distributions, which relates to the Result aspect"
The paper is well-written and the idea is well-motivated.,Does the review address Presentation?,TRUE,FALSE,"The review comments on the paper being well-written and well-motivated, which falls under the Presentation aspect"
"The annotations from [1] are very simple and short, only including some easy examples as in-context examples.",Does the review address Comparison?,TRUE,FALSE,"The review compares annotations to previous work, which aligns with the Comparison aspect"
"## Logical Flow of Main Results and Relation to Prior Work Should be Clarified  The paper defines T-LLMs as general learners if ""the expressive power of realistic T-LLM model class can cover universal circuits for all circuits of polynomial size"" and says that:  > It is unknown whether the realistic Transformers are expressive enough to be general learners   In fact, it seems that Theorem 3 essentially follows from the TC0 upper bound in previous work.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review provides a detailed discussion about the definition of T-LLMs and relates it to previous work, which corresponds to the Elucidation aspect"
"The design of the architecture is novel, but it is also not groundbreaking.",Does the review address Methodology?,TRUE,FALSE,"The review discusses the design of the architecture, which directly relates to the Methodology aspect"
Summary: + Appealing theoretical contributions + Empirical results are encouraging + The use of discriminator for reward shaping in addition to task success rate is interesting  - Writing and explanation can be improved.,Does the review address Presentation?,TRUE,FALSE,"The review comments on the writing and explanation, which falls under the Presentation aspect"
- The methods and results are presented in an understandable manner.,Does the review address Result?,TRUE,FALSE,"The review mentions methods and results being presented in an understandable manner, which relates to the Result aspect"
"around 1% might be reasonable for 30-40% reduction in training time, but it is certainly a reduction in accuracy.",Does the review address Methodology?,TRUE,FALSE,"The review discusses training time reduction and accuracy, which relates to the Methodology aspect"
The proposed ideas in isolation do not yield significant improvements.,Does the review address Result?,TRUE,FALSE,"The review states that proposed ideas do not yield significant improvements, which directly addresses the Result aspect"
* Related work: I would also include a discussion of this Lazaridou et al paper where they compare ways of combining EC with non-EC learning signals (e.g. image caption training): https://aclanthology.org/2020.acl-main.685.pdf  * Ethics statement: I appreciate this statement and agree with the possible positive impacts.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests additional related work discussion and comments on the ethics statement, which corresponds to the Elucidation aspect"
"If that is the case, that should be made more explicit.",Does the review address Data/Task?,FALSE,TRUE,The review is a vague statement that does not clearly address the Data/Task aspect
It would be really useful to have an ablation study to disentangle which piece of the training or method is contributing to what and how in the performance measure.,Does the review address Ablation?,TRUE,FALSE,"The review explicitly suggests an ablation study, which directly addresses the Ablation aspect"
4) It is not clear how the prediction variance is reduced gradually in order to generate the results in Figure 1(b).,Does the review address Presentation?,TRUE,FALSE,"The review points out lack of clarity in how prediction variance is reduced, which relates to the Presentation aspect"
After author response: See reply comment in the thread below for further score justification.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review references a response comment for score justification, which aligns with the Justification/Motivation aspect"
"* Were the proposed architectural additions conceived with the HANS ""counterexamples"" in mind (i.e. is there a specific reason to think that these types of methods would avoid the ""superficial"" reasoning that these examples are supposed to reveal)?",Does the review address Methodology?,TRUE,FALSE,"The review questions the architectural additions and their reasoning, which relates to the Methodology aspect"
"But for some of the words, say ""hold"" and ""sits"", could it play a more important role?",Does the review address Significance?,TRUE,FALSE,"The review asks about the potential importance of certain words, which relates to the Significance aspect"
"It might be good to find the best hyperparameters for each setting to truly do a fair comparison (avoiding hyperparameter tuning isn't really a fair comparison, IMO -- but this depends on how much compute you have available).",Does the review address Comparison?,TRUE,FALSE,"The review discusses finding the best hyperparameters for a fair comparison, which directly relates to the Comparison aspect"
"With this approach, that requirement doesn’t exist anymore.",Does the review address Significance?,FALSE,TRUE,The review is an incomplete statement that does not clearly address the Significance aspect
The experimentation is correct and the qualitative analysis made in table 1 shows results as expected from the approach.,Does the review address Result?,TRUE,FALSE,"The review discusses experimentation and qualitative analysis showing expected results, which relates to the Result aspect"
What was the gain by simply using these embeddings as alternatives to the random embeddings in the LSTM stack parser?,Does the review address Methodology?,TRUE,FALSE,"The review questions the gain of using specific embeddings, which relates to the Methodology aspect"
"Weaknesses:   The primary weakness of the paper is the lack of convincing justification that the authors have discovered a phenomenon distinct from “collective outliers” (Karamcheti et al., 2021) -- or if it is distinct, how exactly is it distinct?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review critiques the lack of justification for distinguishing the paper's phenomenon, which directly addresses the Justification/Motivation aspect"
The current experimental baseline can't reflect this.,Does the review address Comparison?,TRUE,FALSE,"The review suggests that the current experimental baseline is insufficient, which relates to the Comparison aspect"
Figure 1 clearly shows the code generation process.,Does the review address Presentation?,TRUE,FALSE,"The review comments on Figure 1 showing the code generation process, which falls under the Presentation aspect"
Some comments:  _ It may be interesting to include a brief explanation of the differences between the approach from Tian et al. 2014 and the current one.,Does the review address Comparison?,TRUE,FALSE,"The review suggests including an explanation of differences with a previous approach, which directly addresses the Comparison aspect"
"Then, taking inspiration from recent work that shows that many downstream tasks can be reframed as sentence completion tasks, it defines a “natural task” as one on which a sparse linear model over the output of the “true” language model (next word probability distribution, conditioned on context) attains strong performance.",Does the review address Methodology?,TRUE,FALSE,"The review describes the methodology of defining a ""natural task"" and using sentence completion, which relates to the Methodology aspect"
The authors find that the main ingredients for the success of in-context learning are a combination of selective annotation with similarity-based prompt retrieval.,Does the review address Methodology?,TRUE,FALSE,"The review discusses the main ingredients of in-context learning, which directly relates to the Methodology aspect"
Providing a more comprehensive elucidation of these processes would aid in bridging the gap between classical and quantum approaches.,Does the review address Methodology?,TRUE,FALSE,"The review suggests providing a more comprehensive explanation of processes, which relates to the Methodology aspect"
"In terms of strenghs - The paper has a very throughout analysis of different models and positional encodings - It proposes several contributions, including a new probing task and several positional encoding methods.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses the analysis of models and a new probing task, which relates to the Data/Task aspect"
"Given a validation corpus (X,Y), and the corresponding retrieved (tX, tY), the authors should at least show the similarity between (X,tX), (Y,tY), which measures the retrieval quality.",Does the review address Significance?,TRUE,FALSE,"The review suggests showing similarities to measure retrieval quality, which relates to the Significance aspect"
"The description of the baselines is lacking and quite confusing: it's not clear why the authors have two DP-SGD baselines, and what they're exactly updating during training.",Does the review address Presentation?,TRUE,FALSE,"The review critiques the description of baselines as lacking and confusing, which falls under the Presentation aspect"
3) This paper shows visualization of the interaction between words and latent topics in the embedding space.,Does the review address Methodology?,TRUE,FALSE,"The review mentions visualization of word and topic interactions in embedding space, which relates to the Methodology aspect"
- Slight improvements over CaP via the different prompting method.,Does the review address Methodology?,TRUE,FALSE,"The review discusses improvements via different prompting methods, which relates to the Methodology aspect"
Clarity on Quantum Enhancements:  Section 3.2.2 seems to lack depth in the explanation of how the quantum correlations are calculated and utilized within the graph transformers.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review points out a lack of depth in explaining quantum correlations, which corresponds to the Elucidation aspect"
"While this is not a downside by itself, it is probably something that one implement as a baseline.",Does the review address Methodology?,FALSE,TRUE,The review is an incomplete statement that does not clearly address the Methodology aspect
"One might hypothesize that if using a (subotimal) template that is less natural for language modeling, that zero-shot performance would suffer, but that FLAN performance wouldn't - One might hypothesize that the ""turn the task around"" templates help more than the other more straightforward templates that don't swap information between the prompt and response.",Does the review address Presentation?,TRUE,FALSE,"The review discusses hypothetical template variations, which relates to the Presentation aspect"
## Summary The paper shows that Transformers trained unsupervised on millions of protein sequences learn information about protein contacts by using attention maps for contact prediction.,Does the review address Methodology?,TRUE,FALSE,"The review summarizes the methodology of using Transformers to learn about protein contacts, which directly relates to the Methodology aspect"
"Considering the BERT is leveraged, you should discuss the relation with BERT + NMT [R1,R2].",Does the review address Related Work?,TRUE,FALSE,"The review suggests discussing the relation with BERT + NMT, which directly addresses the Related Work aspect"
Is any care taken to handle this in training data?,Does the review address Data/Task?,FALSE,TRUE,The review is an incomplete question that does not clearly address the Data/Task aspect
Both split single word representation into multiple prototypes by using a mixture model.,Does the review address Comparison?,TRUE,FALSE,"The review compares two approaches in splitting word representations, which relates to the Comparison aspect"
"Further, the performance improvements are nice, though not impressive.",Does the review address Evaluation?,TRUE,FALSE,"The review comments on performance improvements, which directly addresses the Evaluation aspect"
"* Why are the lines for ""from scratch"" flat in Figure 2?",Does the review address Presentation?,TRUE,FALSE,"The review asks about the appearance of lines in Figure 2, which falls under the Presentation aspect"
"There are many confounding factors such as the number and type of pretraining data, the instruction-tuning data, different architecture designs, and finetuning strategies.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses various factors related to data and tasks, including pretraining data, instruction-tuning data, and architecture designs"
The PACT methodology: The paper proposes a methodology for extracting auxiliary tasks that can be trained jointly along with the main task (tactic prediction task).,Does the review address Data/Task?,TRUE,FALSE,"The review describes a methodology for extracting auxiliary tasks, which directly relates to the Data/Task aspect"
"However, for tasks that require more information on prior decoding context (machine translation or image generation tasks), does the proposed model can still perform well on those tasks?",Does the review address Result?,TRUE,FALSE,"The review questions the model's performance on tasks requiring prior decoding context, which relates to the Result aspect"
--------------------------------------- Strength:  The hypothesis from the variance reduction is interesting.,Does the review address Methodology?,TRUE,FALSE,"The review highlights the interesting hypothesis about variance reduction, which relates to the Methodology aspect"
"Result 1: Under the above assumption over the downstream task, this paper provides a bound on the empirical loss of the downstream prediction task.",Does the review address Data/Task?,TRUE,FALSE,"The review mentions a result related to a downstream task, which connects to the Data/Task aspect"
"- If so, please be more specific in describing it in section 4.2 and Table 4.",Does the review address Presentation?,TRUE,FALSE,"The review suggests being more specific in describing something in a section and table, which falls under the Presentation aspect"
"Mainly, for most of the intrinsic metrics, the multilingual embedding techniques do not seem to perform the best.",Does the review address Result?,TRUE,FALSE,"The review discusses performance of multilingual embedding techniques, which directly relates to the Result aspect"
Which layers and heads were used and how were they aggregated?,Does the review address Methodology?,TRUE,FALSE,"The review asks about layers, heads, and their aggregation, which relates to the Methodology aspect"
Section 4.5 discusses that Transformers can be also used for secondary structure prediction.,Does the review address Methodology?,TRUE,FALSE,"The review mentions using Transformers for secondary structure prediction, which relates to the Methodology aspect"
"I.e., Figure 1 should be your results table, and figure 2 should be the examples for us to see.",Does the review address Presentation?,TRUE,FALSE,"The review suggests rearranging figures, which falls under the Presentation aspect"
"- Extensive ablation studies to demonstrate the importance of modality interaction layer  - selection, parameter sharing, graph connectivity, and parameter initialization.",Does the review address Ablation?,TRUE,FALSE,"The review highlights extensive ablation studies, directly addressing the Ablation aspect"
"It would have been fascinating if the authors were to do an ablation study to train their model in the format of (Audio, Text) --> Text format - something similar to what PENGI does.",Does the review address Significance?,TRUE,FALSE,"The review suggests an alternative ablation study approach, which relates to the Significance aspect"
"This is a bit confusing and I would suggest either changing the terminology or explicitly clarifying that you are talking about expressive power and not learning (which is fine, limitations on expressive power translate to limitations on what can be learned).",Does the review address Presentation?,TRUE,FALSE,"The review suggests clarifying terminology, which falls under the Presentation aspect"
This paper presents a replication study of BERT pretraining and carefully measures the impact of many key hyperparameters and training data size.,Does the review address Data/Task?,TRUE,FALSE,"The review describes a replication study measuring hyperparameters and training data size, which relates to the Data/Task aspect"
Can the proposed theory help explain if the same code modeling task for some languages is strictly easier than the others?,Does the review address Data/Task?,TRUE,FALSE,"The review asks about the difficulty of code modeling tasks across languages, which relates to the Data/Task aspect"
"**Areas of Enhancement & Questions to authors**  - The information about each of the ablations (ID, BM) could be explained better.",Does the review address Ablation?,TRUE,FALSE,"The review suggests better explanation of ablation information, directly addressing the Ablation aspect"
How to efficiently complete the fine-tuning of the pre-trained model is also a direction worthy of attention.,Does the review address Methodology?,TRUE,FALSE,"The review discusses fine-tuning of pre-trained models, which relates to the Methodology aspect"
The experiments are conducted on datasets from questions answering and sentiment analysis.,Does the review address Data/Task?,TRUE,FALSE,"The review specifies datasets used (question answering and sentiment analysis), which directly relates to the Data/Task aspect"
"The primary contribution is an application of supervised, structured neural network models for sentence-level event/relation extraction.",Does the review address Contribution?,TRUE,FALSE,"The review describes the primary contribution as an application of neural network models, which directly addresses the Contribution aspect"
What would happen if the number of scales is increased to capture  longer contexts?,Does the review address Experiment?,TRUE,FALSE,"The review asks about changing the number of scales, which relates to the Experiment aspect"
* The proposed method RandomMask achieves SOTA on various downstream tasks.,Does the review address Methodology?,TRUE,FALSE,"The review mentions a proposed method achieving state-of-the-art results, which relates to the Methodology aspect"
We failed at finding an alpha meeting the requirements for the FT model.,Does the review address Methodology?,FALSE,TRUE,"The review is an incomplete statement about failing to find an alpha, which does not clearly address the Methodology aspect"
The introductions discusses existing work on Transformers for protein languages models.,Does the review address Methodology?,TRUE,FALSE,"The review discusses Transformers for protein language models, which relates to the Methodology aspect"
"The selected student networks, VL-BERT, UNITER, VILLA, while they are great and highly reputable works in the community, their performance is not as competitive as for today.",Does the review address Result?,TRUE,FALSE,"The review comments on the performance of selected student networks, which directly relates to the Result aspect"
The paper does not discuss the computational complexity of the proposed methods.,Does the review address Methodology?,TRUE,FALSE,"The review points out a lack of discussion on computational complexity, which relates to the Methodology aspect"
"- I also think it is reasonable to include a baseline that just input additional knowledge as features to the RNN, e.g. the head of each word, NER results etc.",Does the review address Comparison?,TRUE,FALSE,"The review suggests including a baseline with additional features, which relates to the Comparison aspect"
"Although the complexity analysis is thorough, I'd like to see empirical results of memory/compute requirements as a function of the context length.",Does the review address Methodology?,TRUE,FALSE,"The review discusses complexity analysis and suggests empirical results on memory/compute requirements, which relates to the Methodology aspect"
What recommendation the authors would give for those interested in using it?,Does the review address Methodology?,TRUE,FALSE,"The review asks for recommendations on using the method, which relates to the Methodology aspect"
"**The method is simple with limited contribution, while performance improvement is not significant.",Does the review address Contribution?,TRUE,FALSE,"The review critiques the method's contribution and performance improvement, directly addressing the Contribution aspect"
The paper has explained and empirically showed that this learned generator needs a resampler.,Does the review address Result?,TRUE,FALSE,"The review discusses the need for a resampler for a learned generator, which relates to the Result aspect"
- Too much detail in related work: I think the related work section is too long and just a list of papers rather than helping to place the work in the research area.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review critiques the related work section's lack of meaningful discussion, which relates to the Elucidation aspect"
- The visualization section is only a minor contribution; there isn't really any innovation or findings about what works or doesn't work here.,Does the review address Contribution?,TRUE,FALSE,"The review suggests the visualization section is a minor contribution, directly addressing the Contribution aspect"
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Methodology?,TRUE,FALSE,"The review suggests the need to discuss or justify the evaluation approach, which relates to the Methodology aspect"
"Mainly, for most of the intrinsic metrics, the multilingual embedding techniques do not seem to perform the best.",Does the review address Presentation?,FALSE,TRUE,"The review discusses performance of multilingual embedding techniques, which relates more to Result than Presentation"
"## Logical Flow of Main Results and Relation to Prior Work Should be Clarified  The paper defines T-LLMs as general learners if ""the expressive power of realistic T-LLM model class can cover universal circuits for all circuits of polynomial size"" and says that:  > It is unknown whether the realistic Transformers are expressive enough to be general learners   In fact, it seems that Theorem 3 essentially follows from the TC0 upper bound in previous work.",Does the review address Result?,TRUE,FALSE,"The review discusses the definition of T-LLMs and their expressive power, which relates to the Result aspect"
Will the attention model pays more attention to this similar sample resulting in a negative impact on the target task performance since the source task and target task are quite different?,Does the review address Result?,TRUE,FALSE,"The review questions the potential negative impact on target task performance, which relates to the Result aspect"
"It is found that the published results of [1], (see reference below) performs better than (with a sufficiently high difference) the current system on Inspec (Hulth, 2003) abstracts dataset.",Does the review address Comparison?,TRUE,FALSE,"The review compares current results with published results from a reference, which directly addresses the Comparison aspect"
"I would have liked to see these results (also, please fix grammar in this sentence) 9.",Does the review address Presentation?,TRUE,FALSE,"The review suggests fixing grammar in a sentence, which falls under the Presentation aspect"
I think I'd like to see a discussion of sufficient number D analytically or empirically.,Does the review address Analysis?,TRUE,FALSE,"The review suggests a discussion of a sufficient number analytically or empirically, which relates to the Analysis aspect"
"Therefore, it is not necessary to carry out the forward of the text encoder every iteration during training.",Does the review address Methodology?,TRUE,FALSE,"The review discusses a specific training methodology about text encoder forwarding, which relates to the Methodology aspect"
The Ablation Study of the paper also provides useful insights about the impact of different pre-training schemas on large-scale information retrieval tasks.,Does the review address Data/Task?,TRUE,FALSE,"The review mentions an ablation study's insights on pre-training schemas, which relates to the Data/Task aspect"
"Given a validation corpus (X,Y), and the corresponding retrieved (tX, tY), the authors should at least show the similarity between (X,tX), (Y,tY), which measures the retrieval quality.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review suggests showing similarity to measure retrieval quality, which relates to Justification/Motivation"
- Weaknesses: Comparison and credit to existing work is severely lacking.,Does the review address Comparison?,TRUE,FALSE,"The review critiques the lack of comparison and credit to existing work, directly addressing the Comparison aspect"
"A discussion on how to add new tasks to the same framework might help, or a discussion on why the current framework is enough.",Does the review address Methodology?,TRUE,FALSE,"The review suggests discussing how to add new tasks to the framework, which relates to the Methodology aspect"
"Considering the BERT is leveraged, you should discuss the relation with BERT + NMT [R1,R2].",Does the review address Significance?,TRUE,FALSE,"The review suggests discussing the relation with BERT + NMT, which relates to the Significance aspect"
"Summary ------- Using multi-scale hierarchical and compressive techniques, this paper examines a way to increase the context length of transformers.",Does the review address Methodology?,TRUE,FALSE,"The review summarizes the methodology of using multi-scale hierarchical and compressive techniques, which directly relates to the Methodology aspect"
An additional experimental results with multi-task finetuning should also be added.,Does the review address Result?,TRUE,FALSE,"The review suggests adding experimental results with multi-task fine-tuning, which relates to the Result aspect"
"The techniques used in the paper (multi-branch transformer, pointing mechanism, cross-modal attention, global positional encodings, etc) have been shown to work in the past for image-text tasks [1, 2].",Does the review address Methodology?,TRUE,FALSE,"The review discusses various techniques used in the paper, which directly relates to the Methodology aspect"
"Since one of the main contributions of this paper is the analysis of the BERT pretraining process, more experimental analysis on the optimizer should also be included.",Does the review address Analysis?,TRUE,FALSE,"The review suggests more experimental analysis on the optimizer, which relates to the Analysis aspect"
The training objective allow budgetary constraints on the amount of language-specific parameters.,Does the review address Methodology?,TRUE,FALSE,"The review discusses the training objective allowing budgetary constraints, which relates to the Methodology aspect"
A layman's explanation or intuitive reasoning behind the adoption of quantum features and their computational advantages in graph analysis would be invaluable for the reader's understanding.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests providing a layman's explanation of quantum features, which directly relates to the Elucidation aspect"
It appears to vary by orders of magnitude according to Table 10 in the Appendix.,Does the review address Presentation?,TRUE,FALSE,"The review references a table in the Appendix, which falls under the Presentation aspect"
"In experiments, there is no comparison with previous retrieval based methods.",Does the review address Comparison?,TRUE,FALSE,"The review points out the lack of comparison with previous retrieval methods, which relates to the Comparison aspect"
"Thus, while concatenating the audio feature and the text feature can introduce desired performance, there could be some advancements not just combining pretrained audio model and LLM.",Does the review address Methodology?,TRUE,FALSE,"The review discusses combining audio and text features, which relates to the Methodology aspect"
"Additionally, the authors conclude that pre-training is not a significant factor in the efficacy of active learning, but their numerical results suggest active learning methods (Entropy and Coreset) narrow the gap with the random baseline significantly from BERT-Base to RoBERTa-Base!",Does the review address Methodology?,TRUE,FALSE,"The review discusses pre-training and active learning methods, which relates to the Methodology aspect"
Typos: - synthesis -> synthesise - DeepHOLZero -> DeepHOL - wrong bold number in Figure 3,Does the review address Presentation?,TRUE,FALSE,"The review lists several typos and formatting issues, which directly addresses the Presentation aspect"
Conference on Empirical Methods in Natural Language Processing (2019).,Does the review address Related Work?,TRUE,FALSE,"The review mentions a conference reference, which relates to the Related Work aspect"
In my opinion this is a significant paper as it explores one of the straight-forward ways to couple an audio encoder with a trained LLM and carefully examines this coupling from several different viewpoints and contributes the OpenAQA dataset which can be a useful public resource for future research.,Does the review address Significance?,TRUE,FALSE,"The review discusses the paper's significance in exploring audio encoder coupling and contributing a dataset, which directly addresses the Significance aspect"
The proposed RoBERTa achieves/matches state-of-the-art performance on many standard NLU downstream tasks.,Does the review address Methodology?,TRUE,FALSE,"The review discusses RoBERTa's performance on NLU tasks, which relates to the Methodology aspect"
The paper starts with the motivation of handling comprehensibility.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review mentions the paper's motivation of handling comprehensibility, which directly addresses the Justification/Motivation aspect"
"Mainly, Table 4 provides understandable results showing that multi-turn specifications achieve better performance compared to single-turn specifications.",Does the review address Experiment?,TRUE,FALSE,"The review discusses experimental results comparing multi-turn and single-turn specifications, which relates to the Experiment aspect"
"- The definitions, models, and assumptions in the paper are intuitive and clear (e.g., natural task).",Does the review address Methodology?,TRUE,FALSE,"The review comments on the intuitiveness of definitions, models, and assumptions, which relates to the Methodology aspect"
Will the attention model pays more attention to this similar sample resulting in a negative impact on the target task performance since the source task and target task are quite different?,Does the review address Data/Task?,TRUE,FALSE,"The review questions the potential impact of attention on different tasks, which relates to the Data/Task aspect"
Some experimental settings only include the baselines Random and Vote-k. More methods as mentioned in 4.3.2 can be also included.,Does the review address Experiment?,TRUE,FALSE,"The review suggests including more experimental methods, which directly addresses the Experiment aspect"
"However, if we considered this view, it seems like the problem they are solving should be more impactful than type recovery and AST generation.",Does the review address Significance?,TRUE,FALSE,"The review questions the impact of the problem being solved, which relates to the Significance aspect"
The results on a mixture of the Parity/Sum task are interesting   2.,Does the review address Data/Task?,TRUE,FALSE,"The review mentions results on a Parity/Sum task, which relates to the Data/Task aspect"
Strength: - Thorough study on the robustness of recent popular VL models vs conventional CE models.,Does the review address Result?,TRUE,FALSE,"The review highlights a thorough study on the robustness of models, which relates to the Result aspect"
"Compared to this, the paper made 2 changes to the model: 1) using Gumble-Softmax instead of REINFORCE, and 2) using mixture-of-signals instead of straightforward gradient back-propagation.",Does the review address Presentation?,TRUE,FALSE,"The review describes changes made to the model, which falls under the Presentation aspect"
The paper describes the idea of multiple temporal scales.,Does the review address Methodology?,TRUE,FALSE,"The review describes the idea of multiple temporal scales, which relates to the Methodology aspect"
"The main issue of the paper is in the experiments and results reporting, it needs quite a bit of reworking.",Does the review address Result?,TRUE,FALSE,"The review critiques the experiments and results reporting, which directly addresses the Result aspect"
"Both those works try to do both (1) extract time series or other statistical information about the polarity of the relationships between countries, and *also* (2) extract topical keywords to explain aspects of the relationships.",Does the review address Related Work?,TRUE,FALSE,"The review describes previous works and their approaches, which relates to the Related Work aspect"
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Experiment?,TRUE,FALSE,"The review suggests insufficient experiments and comparisons, which directly addresses the Experiment aspect"
There are a couple decisions related to methodology that may need some further examination.,Does the review address Methodology?,TRUE,FALSE,"The review suggests examining methodology-related decisions, which relates to the Methodology aspect"
"On top of that, the only data is coming from LeetCode.",Does the review address Data/Task?,TRUE,FALSE,"The review comments on the data source (LeetCode), which relates to the Data/Task aspect"
is a micro-average (all testsets are concatenated and evaluated as one set) or macro-average (average taken across the scores of individual test sets) score.,Does the review address Result?,TRUE,FALSE,"The review discusses scoring methods, which relates to the Result aspect"
I understand that LMU might have limited capacity but this is not specifically discussed and it is unclear how each component contributes to the end performance.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests a lack of discussion about component contributions, which relates to the Elucidation aspect"
"While previous work has examined tasks in the overall area, to my knowledge there has not been any publicly availble sentence-level annotated data for the problem -- the authors here make a contribution as well by annotating some data included with the submission; if it is released, it could be useful for future researchers in this area.",Does the review address Related Work?,TRUE,FALSE,"The review discusses previous work and the authors' contribution of annotated data, which directly addresses the Related Work aspect"
Clarification on the task setting: Is it the case that the agent's current utterance does not decide what the next user utterance is?,Does the review address Data/Task?,TRUE,FALSE,"The review asks for clarification about the task setting, which relates to the Data/Task aspect"
"Therefore, the obtained task performance is far from state-of-the-art.",Does the review address Data/Task?,TRUE,FALSE,"The review comments on task performance, which relates to the Data/Task aspect"
I also encourage the authors to simplify the experiment described in section 3.1 to make it more clear.,Does the review address Experiment?,TRUE,FALSE,"The review suggests simplifying an experiment description, which directly addresses the Experiment aspect"
It is a bit difficult to understand the task definitions without first understanding the various constituents of the proof.,Does the review address Presentation?,TRUE,FALSE,"The review comments on the difficulty of understanding task definitions, which falls under the Presentation aspect"
"Such rarity, however, could potentially be a drawback for these types of watermarking methods.",Does the review address Methodology?,TRUE,FALSE,"The review discusses potential drawbacks of watermarking methods, which relates to the Methodology aspect"
"For example, what is the experiment environment and training receipts.",Does the review address Methodology?,TRUE,FALSE,"The review asks about experiment environment and training details, which relates to the Methodology aspect"
"This indicates that with the same training objective, different inference methods have different gaps to the posterior lower bound.",Does the review address Methodology?,TRUE,FALSE,"The review discusses training objectives and inference methods, which relates to the Methodology aspect"
"They train low resource NMTs using 4 different tokenization strategies, to show that their proposed tokenization method leads to the best NMT results by several metrics.",Does the review address Evaluation?,TRUE,FALSE,"The review describes training NMTs with different tokenization strategies and evaluating results, which directly addresses the Evaluation aspect"
Is it a margin of an SVM classifier that solves $\mathcal{T}$?,Does the review address Data/Task?,FALSE,TRUE,The review is an incomplete question about a classification task
"-----Weaknesses----- I'm not very convinced by the empirical results, mostly due to the lack of details of the baselines.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests a lack of details about baselines, which relates to the Elucidation aspect"
- The presentation could be improved and distracts from the content at times.,Does the review address Presentation?,TRUE,FALSE,"The review directly comments on the need to improve presentation, which falls under the Presentation aspect"
"Given that there is a wealth of existing work that performs the same task and the lack of novelty of this work, the authors need to include experiments that demonstrate that their technique outperforms others on this task, or otherwise show that their dataset is superior to others (e.g. since it is much larger than previous, does it allow for better generalization?)",Does the review address Novelty?,TRUE,FALSE,"The review questions the lack of novelty and suggests demonstrating superiority, which directly addresses the Novelty aspect"
"- Also, regarding section 3.3, please cite appropriate publications the ""previous work"" presented in the tables.",Does the review address Related Work?,TRUE,FALSE,"The review suggests citing publications for previous work, which relates to the Related Work aspect"
The curriculum learning is yet another contribution which makes a lot of sense and the authors have proposed an intuitive curriculum and backed it up with apt ablation study to show its utility.,Does the review address Novelty?,TRUE,FALSE,"The review highlights curriculum learning as a novel contribution, which directly addresses the Novelty aspect"
"Some kind of analysis of the qualitative strengths and weaknesses of the binary code prediction would be welcome -- what kind of mistakes does the system make, and how does this compare to standard softmax and/or hierarchical and differentiated softmax?",Does the review address Comparison?,TRUE,FALSE,"The review suggests a qualitative analysis comparing different methods, which relates to the Comparison aspect"
(ii) a new way to aggregate multiple inputs (using M-BERT) and several different decoding methods.,Does the review address Methodology?,TRUE,FALSE,"The review mentions a new way to aggregate inputs and decoding methods, which relates to the Methodology aspect"
"I think more could be done here, some ideas, probably there are better ways to test: - Have templates that leave out ""instructions"":  I would guess it wouldn't affect held-in task performance much, but would affect held-out tasks.",Does the review address Data/Task?,TRUE,FALSE,"The review suggests testing templates and task performance, which relates to the Data/Task aspect"
They have to tune this parameter empirically instead of configure it theoretically.,Does the review address Methodology?,TRUE,FALSE,"The review comments on empirical parameter tuning, which relates to the Methodology aspect"
**Experimental results** The presentation of the experimental results is clear.,Does the review address Result?,TRUE,FALSE,"The review comments on the clear presentation of experimental results, which relates to the Result aspect"
The model sizes are varied across experiments to achieve on par performance which makes the comparison of the computational cost not so obvious.,Does the review address Result?,TRUE,FALSE,"The review discusses variations in model sizes and performance comparisons, which relates to the Result aspect"
"For experiments, Table 1 shows the FOCAL Reasoner (DeBERTa) brings much performance gain, compared to FOCAL Reasoner (RoBERTa) (the performance seems comparable with DAGN and LReasoner using RoBERTa).",Does the review address Result?,TRUE,FALSE,"The review describes performance gains in experimental results, which directly addresses the Result aspect"
"- The authors have evaluated their models on multiple settings, proving that their models trained on Wikipedia can potentially generalize to multiple downstream tasks.",Does the review address Methodology?,TRUE,FALSE,"The review highlights model evaluation across multiple settings, which relates to the Methodology aspect"
The authors also propose two novel pre-training settings which also show improvement over the baseline BM-25.,Does the review address Methodology?,TRUE,FALSE,"The review discusses novel pre-training settings and improvements, which relates to the Methodology aspect"
"Before describing your algorithm, humans are only mentioned once in the algorithm.",Does the review address Methodology?,FALSE,TRUE,The review is an incomplete comment about humans in an algorithm
But a direct head to head comparison for the computational cost of a multi-task model and individual models is not provided.,Does the review address Data/Task?,TRUE,FALSE,"The review suggests a lack of direct comparison of computational costs, which relates to the Data/Task aspect"
"It is a report of various NLP efforts for several Indigenous languages of Canada It goes deeply enough into the technical details of the projects to show that the efforts are viable and successful, without getting bogged down in numbers or linguistic details that are unimportant to people external to the projects.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review provides a detailed description of NLP efforts for Indigenous languages, which corresponds to the Elucidation aspect"
The paper is mainly an empirical analysis of a different way of formulating an existing problem.,Does the review address Analysis?,TRUE,FALSE,"The review describes the paper as an empirical analysis of problem formulation, which directly addresses the Analysis aspect"
"The authors should make it clear that on different evaluation sets, the scores differs.",Does the review address Result?,TRUE,FALSE,"The review suggests making clear how scores differ across evaluation sets, which relates to the Result aspect"
The paper pointed out that ELECTRA framework [1] explored the idea of using REINFORCE [2] as the the way of adding adversarial training signals to the model but observed degenerated results.,Does the review address Methodology?,TRUE,FALSE,"The review discusses a framework and training signals, which relates to the Methodology aspect"
The authors should discuss the relationship with other in-context example selection methods and compare the performance.,Does the review address Comparison?,TRUE,FALSE,"The review suggests discussing and comparing in-context example selection methods, which directly addresses the Comparison aspect"
The idea that combining the output of several models using the attention strategy is not novel in deep learning.,Does the review address Novelty?,TRUE,FALSE,"The review critiques the lack of novelty in combining model outputs, which directly addresses the Novelty aspect"
"The claimed contributions include: 1) The proposed method is free from the common issue of diverging from human language, because it learns from the sentences sampled from the pre-trained LM.",Does the review address Contribution?,TRUE,FALSE,"The review describes the claimed contributions of the proposed method, which directly addresses the Contribution aspect"
Experiments on LEGO and code interpretation task are done.,Does the review address Data/Task?,TRUE,FALSE,"The review mentions experiments on LEGO and code interpretation tasks, which relates to the Data/Task aspect"
"For example, if for the baseline model, we also only use one data sample and apply different masks, will there be improvement?",Does the review address Data/Task?,TRUE,FALSE,"The review suggests an alternative data sampling approach, which relates to the Data/Task aspect"
The bad: * Figure 1 is difficult to read and messy.,Does the review address Presentation?,TRUE,FALSE,"The review criticizes Figure 1 as difficult to read, which falls under the Presentation aspect"
"However, the BERT analysis results provided in this paper should also be valuable to the community.",Does the review address Analysis?,TRUE,FALSE,"The review highlights the value of BERT analysis results, which directly addresses the Analysis aspect"
The training procedure mentioned in section 5.2.2 talks about joint training but the procedure followed for training for individual tasks or a subset of tasks is not described in detail.,Does the review address Data/Task?,TRUE,FALSE,"The review points out a lack of detailed description of training procedures, which relates to the Data/Task aspect"
- Experiments are well-designed: many baselines are implemented to compare proposed method with traditional lifelong learning methods.,Does the review address Comparison?,TRUE,FALSE,"The review praises the well-designed experiments with multiple baselines, which directly addresses the Comparison aspect"
Did the authors try this as another compared baseline?,Does the review address Comparison?,TRUE,FALSE,"The review suggests trying an additional baseline for comparison, which relates to the Comparison aspect"
Ad-hoc regularization parameter selection is necessary for getting performance gains.,Does the review address Result?,TRUE,FALSE,"The review discusses ad-hoc regularization for performance gains, which relates to the Result aspect"
- Extensive results show improvements over a base model and a larger model across a range of tasks.,Does the review address Methodology?,TRUE,FALSE,"The review highlights results showing improvements across tasks, which relates to the Methodology aspect"
The proposed ConceptQA architecture is intuitive and quite straightforward.,Does the review address Methodology?,TRUE,FALSE,"The review describes the proposed architecture as intuitive, which relates to the Methodology aspect"
The task opens up a huge space for AI-powered general audio creation.,Does the review address Data/Task?,TRUE,FALSE,"The review discusses the potential of the task for AI-powered audio creation, which relates to the Data/Task aspect"
What recommendation the authors would give for those interested in using it?,Does the review address Contribution?,TRUE,FALSE,"The review asks for recommendations about using the method, which relates to the Contribution aspect"
I think if the paper will be improved if it resolves the lack of clarity around the temperature in GS being an implicit entropy-regularization parameter.,Does the review address Presentation?,TRUE,FALSE,"The review suggests improving clarity around a technical parameter, which falls under the Presentation aspect"
Each task is supported with a detailed ablation study to shed light on future research.,Does the review address Ablation?,TRUE,FALSE,"The review mentions detailed ablation studies for each task, which directly addresses the Ablation aspect"
"Figure 1 is presently not pleasant to look at, even though it has interesting results`!",Does the review address Result?,TRUE,FALSE,"The review comments on Figure 1 having interesting results, which relates to the Result aspect"
Users cannot follow their strategy to set hyper-parameters in an optimal way.,Does the review address Methodology?,TRUE,FALSE,"The review critiques the difficulty of setting optimal hyperparameters, which relates to the Methodology aspect"
"Is it possible to split Thai words into syllables without any ambiguity, or do you need a heuristic?",Does the review address Methodology?,TRUE,FALSE,"The review asks about methodology for splitting Thai words, which relates to the Methodology aspect"
"Rather than using the ad-hoc approach for selecting which augmentation ""stacking"" scheme is helpful, it would have been better to compare/use an approach highlighted in ""Learning to Compose Domain-Specific Transformations for Data Augmentation"" [NeuRIPS 2017].",Does the review address Comparison?,TRUE,FALSE,"The review suggests comparing augmentation approaches with previous work, which directly addresses the Comparison aspect"
"These prior methods do not incorporate the SFT stage, making it unclear how the model performs before this crucial phase.",Does the review address Presentation?,TRUE,FALSE,"The review comments on the lack of clarity about model performance before a crucial phase, which falls under the Presentation aspect"
"Why do you choose case-insensitive BLEU score for En->Fr, which is not commonly used in previous baselines.",Does the review address Comparison?,TRUE,FALSE,"The review questions the choice of BLEU score compared to previous baselines, which relates to the Comparison aspect"
"In the experimental sections, it seems that only two scales are used.",Does the review address Experiment?,TRUE,FALSE,"The review notes the number of scales used in experiments, which directly addresses the Experiment aspect"
"In terms of the experiments, there are only dev results reported on GLUE (Table 2).",Does the review address Result?,TRUE,FALSE,"The review points out limited results reported on GLUE, which relates to the Result aspect"
"Placing Figure 1 and Table 1 on page 1 would improve readability, given that the main content describing Figure 1 and Table 1 is in the first page.",Does the review address Presentation?,TRUE,FALSE,"The review suggests improving readability by repositioning figures and tables, which falls under the Presentation aspect"
"Revisiting GNN for Question Answering](https://openreview.net/forum?id=hzmQ4wOnSb), whose hypothesis seems to be that by only using embeddings for node types and relation types, the models are able to attain good performance (86.67 acc on OpenBookQA) without needing any cross-modal information.",Does the review address Result?,TRUE,FALSE,"The review discusses performance results of a previous study, which relates to the Result aspect"
(And the comparison to their BERT_base-based model yields roughly equal scores.),Does the review address Comparison?,TRUE,FALSE,"The review mentions a comparison yielding equal scores, which relates to the Comparison aspect"
"**Pros**  - The paper is well structured and easy to follow, the idea of modeling sentences to a Brownian bridge latent space is neat and generic enough to (1) allow for noise given its stochasticity (2) doesn't require explicit domain knowledge for planning.",Does the review address Presentation?,TRUE,FALSE,"The review praises the paper's structure and presentation, which falls under the Presentation aspect"
"- OpenAQA-5M is a good contribution to provide open-ended question answering in audio domain, especially it is verified with human evaluation.",Does the review address Evaluation?,TRUE,FALSE,"The review highlights the contribution of a dataset verified by human evaluation, which directly addresses the Evaluation aspect"
"A qualitative analysis was required in Karamcheti et al., (2021) to explain “collective outliers”.",Does the review address Analysis?,TRUE,FALSE,"The review references a qualitative analysis from a previous study, which relates to the Analysis aspect"
"Result 2: The authors further extend this result to word embedding features, which are obtained by a weighted average of word embedding vectors based on the next word distributions.",Does the review address Result?,TRUE,FALSE,"The review describes a result about word embedding features, which directly addresses the Result aspect"
"However, they only mention a single pruning rate of 50%, which could easily over-prune (all challenging as well as outlier examples) for the NLP datasets used here.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses pruning rates and their impact on NLP datasets, which relates to the Data/Task aspect"
But a direct head to head comparison for the computational cost of a multi-task model and individual models is not provided.,Does the review address Methodology?,TRUE,FALSE,"The review suggests a lack of computational cost comparison, which relates to the Methodology aspect"
The authors should discuss the relationship with other in-context example selection methods and compare the performance.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests discussing relationships with other methods, which relates to the Elucidation aspect"
"Within the evaluation section, there are numerous intriguing findings that hold significant value for dissemination within the wider research community.",Does the review address Evaluation?,TRUE,FALSE,"The review mentions intriguing findings in the evaluation section, which directly addresses the Evaluation aspect"
"The primary contribution is an application of supervised, structured neural network models for sentence-level event/relation extraction.",Does the review address Methodology?,TRUE,FALSE,"The review describes the primary contribution as an application of neural network models, which relates to the Methodology aspect"
The key contribution of the paper appears to be the formulation of the Concept-QA model based on query information and answers from GPT + CLIP.,Does the review address Contribution?,TRUE,FALSE,"The review highlights the key contribution of formulating a specific model, which directly addresses the Contribution aspect"
* Additional general discussion and statistics studies are presented in the Appendix.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review mentions additional discussion and statistics in the Appendix, which relates to the Elucidation aspect"
"The authors experiment both with pre-training and fine-tuning of contextual models (BERT-{base,large}) and claim large reduction in training time, with reasonable loss in performance.",Does the review address Methodology?,TRUE,FALSE,"The review discusses pre-training and fine-tuning approaches, which relates to the Methodology aspect"
"I thought that this paper was very thought-provoking, and I appreciated the attempts to better understand what is going on with pre-trained language models, why they work well, and what might we be able to improve from theses insights.",Does the review address Methodology?,TRUE,FALSE,"The review appreciates attempts to understand pre-trained language models, which relates to the Methodology aspect"
Will need some clarification to better judge the results.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests needing clarification to better judge results, which relates to the Elucidation aspect"
The proposed method is simple and relatively straightforward to implement.,Does the review address Methodology?,TRUE,FALSE,"The review describes the proposed method as simple and straightforward, which relates to the Methodology aspect"
"However, Section 3.1 cannot demonstrate effective theoretical information.",Does the review address Analysis?,TRUE,FALSE,"The review critiques a section's lack of theoretical information, which relates to the Analysis aspect"
"-----Weaknesses----- I'm not very convinced by the empirical results, mostly due to the lack of details of the baselines.",Does the review address Comparison?,TRUE,FALSE,"The review critiques the lack of details about baselines, which relates to the Comparison aspect"
"I look forward to seeing the authors discuss a comprehensive comparison of DeFo's training time and other methods, such as CoOp and CLIP-adapter.",Does the review address Methodology?,TRUE,FALSE,"The review suggests a comprehensive comparison of training time with other methods, which relates to the Methodology aspect"
Why are all publications not used in training the baselines?,Does the review address Methodology?,TRUE,FALSE,"The review questions the use of publications in training baselines, which relates to the Methodology aspect"
* The proposed method RandomMask achieves SOTA on various downstream tasks.,Does the review address Data/Task?,TRUE,FALSE,"The review mentions achieving state-of-the-art results on downstream tasks, which relates to the Data/Task aspect"
Compilers tend to lower a representation of a software program into something that is closer to the hardware and therefore potentially more efficient.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review provides a description of compiler functionality, which corresponds to the Elucidation aspect"
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Analysis?,TRUE,FALSE,"The review discusses a theoretical analysis of hyper-parameter selection, which directly addresses the Analysis aspect"
"Unfortunately, many aspects of the models, experimentation, and evaluation are not explained very well.",Does the review address Evaluation?,TRUE,FALSE,"The review critiques the lack of explanation in models, experimentation, and evaluation, which relates to the Evaluation aspect"
I suspect that a statistical analysis [1] might conclude that BERT and the proposed method are indistinguishable on the GLUE suite.,Does the review address Result?,TRUE,FALSE,"The review suggests statistical indistinguishability between methods, which relates to the Result aspect"
It is a bit difficult to understand the task definitions without first understanding the various constituents of the proof.,Does the review address Data/Task?,TRUE,FALSE,"The review finds it difficult to understand task definitions, which relates to the Data/Task aspect"
Maybe adding another ablation on this would be a good idea.,Does the review address Ablation?,TRUE,FALSE,"The review suggests adding another ablation study, which directly addresses the Ablation aspect"
This makes their empirical results extremely weak.,Does the review address Result?,TRUE,FALSE,"The review describes the empirical results as extremely weak, which relates to the Result aspect"
"The experiments in the paper demonstrated the superiority of adding adversarial training to a self-supervision framework, in that significant improvements can be obtained for similar-sized networks.",Does the review address Result?,TRUE,FALSE,"The review discusses improvements from adversarial training, which relates to the Result aspect"
Their findings on learning complex tasks contribute to the understanding of large language model learning and provide valuable insights for future related work on efficient training.,Does the review address Methodology?,TRUE,FALSE,"The review highlights findings on learning complex tasks, which relates to the Methodology aspect"
"As proposed in the comments, this should be assessed in the paper by replacing BERT representations by non-contextual representations such as GloVE.",Does the review address Presentation?,TRUE,FALSE,"The review suggests assessing representations by replacing with non-contextual representations, which falls under the Presentation aspect"
Such a comparison would highlight the advantages of the multi-task model and would be helpful for the relevant audience.,Does the review address Data/Task?,TRUE,FALSE,"The review suggests a comparison to highlight multi-task model advantages, which relates to the Data/Task aspect"
it doesn't seem straightforward for me to use constituent parse as knowledge here.,Does the review address Methodology?,TRUE,FALSE,"The review finds it challenging to use constituent parse as knowledge, which relates to the Methodology aspect"
"This idea is novel and interesting to me, and the derivation and experiment results look encouraging.",Does the review address Novelty?,TRUE,FALSE,"The review describes the idea as novel and interesting, which directly addresses the Novelty aspect"
Weaknesses: - Somewhat weaker results on some CommonGen metrics are disappointing.,Does the review address Evaluation?,TRUE,FALSE,"The review mentions weaker results on some metrics, which relates to the Evaluation aspect"
"The authors investigate L=12 in the ablation, but in a real setting, it seems unlikely practitioners will label <50 examples before re-training.",Does the review address Ablation?,TRUE,FALSE,"The review discusses an ablation study with a specific number of labeled examples, which directly addresses the Ablation aspect"
"The paper could make more of an advocacy point for what relatively modest funding could do for languages in places where leaders have not yet had the same impetuses as witnessed in Canada, including India and Africa where ""minority"" language is often a misnomer.",Does the review address Significance?,TRUE,FALSE,"The review suggests broader implications for language research, which relates to the Significance aspect"
Theoretical discussion proves that the gradients derived from the new masking schema have a smaller variance and can lead to more efficient self-supervised training.,Does the review address Methodology?,TRUE,FALSE,"The review describes a theoretical discussion of gradient variance, which relates to the Methodology aspect"
"> However, in every task except CommonGEN the authors do not discuss any methods that are even close to the state of the art.",Does the review address Data/Task?,TRUE,FALSE,"The review points out lack of state-of-the-art methods in most tasks, which relates to the Data/Task aspect"
The authors clearly present their ideas and describe the technical details.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review praises the clear presentation of ideas and technical details, which corresponds to the Elucidation aspect"
"Some things that are worth looking into are the work on Scalable static analysis [Scaling], the inference of necessary preconditions [Logozzo], and bug detection that is based on ""belief"" [deviant, belief], which is closely related to your intuition about naturalness and human-written invariants.",Does the review address Related Work?,TRUE,FALSE,"The review suggests looking into related work in static analysis and bug detection, which relates to the Related Work aspect"
There are few places (see details) that authors have assumptions in mind but do not provide those assumptions until later.,Does the review address Methodology?,TRUE,FALSE,"The review notes assumptions not provided until later, which relates to the Methodology aspect"
The findings of (2)(3)(4)(5) mentioned in the summary section above are especially interesting and can be helpful to the community when comparing new VL methods with existing methods.,Does the review address Comparison?,TRUE,FALSE,"The review suggests the findings can help compare VL methods, which relates to the Comparison aspect"
"- If so, please be more specific in describing it in section 4.2 and Table 4.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests being more specific in describing something in a section and table, which relates to the Elucidation aspect"
Empirical results on MultiWoz 2 and 2.1 shows improvement over other state-of-the-art techniques.,Does the review address Result?,TRUE,FALSE,"The review discusses empirical results showing improvement over state-of-the-art techniques, which relates to the Result aspect"
"Even, Ref-[2] can be a strong baseline to compare the performance of the current system.",Does the review address Comparison?,TRUE,FALSE,"The review suggests using a reference as a strong baseline for comparison, which directly addresses the Comparison aspect"
"The paper said: “the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between text segments that appeared in different training examples.”  Acutally it seems quite natural for me and I did not realize it is a problem until I saw more explanations in section 1.1.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review discusses an explanation of dependencies between text segments, which corresponds to the Elucidation aspect"
It does not follow from the theoretical results that adding similar sentences will be a good thing.,Does the review address Result?,FALSE,TRUE,The review is an incomplete statement about theoretical results
I would also urge the authors to have a speculative discussion on what successful inductive biases might look like.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests a speculative discussion on inductive biases, which relates to the Elucidation aspect"
The experimental results are promising for both settings.,Does the review address Experiment?,TRUE,FALSE,"The review describes the experimental results as promising, which directly addresses the Experiment aspect"
"It is widely acknowledged and studied that the complexity (i.e., the length or reasoning steps of the CoT annotations) significantly influences the performance of the LLMs.",Does the review address Result?,TRUE,FALSE,"The review discusses the influence of complexity on LLM performance, which relates to the Result aspect"
"Typos: 1. compared with Enhanced baseline… -> Comparison with enhanced baseline   ** Refereces **  R1: Zhu, Jinhua, Yingce Xia, Lijun Wu, Di He, Tao Qin, Wengang Zhou, Houqiang Li, and Tie-Yan Liu.",Does the review address Presentation?,TRUE,FALSE,"The review points out typos and formatting issues, which falls under the Presentation aspect"
The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).,Does the review address Result?,TRUE,FALSE,"The review highlights experimental results on RoBERTa, which relates to the Result aspect"
Do the authors expect better results with a larger vocab size?,Does the review address Result?,TRUE,FALSE,"The review asks about potential results with a larger vocabulary size, which relates to the Result aspect"
"For example, Figure 4 validates Assumption 4.1 (log-partition function is roughly quadratic in theta), and Table 1 shows many real tasks are approximately “natural”.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses validation of assumptions and tasks, which relates to the Data/Task aspect"
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review suggests discussing and justifying the evaluation approach, which relates to Justification/Motivation"
- Strengths: The paper is well organized and clearly written.,Does the review address Presentation?,TRUE,FALSE,"The review praises the paper's organization and clarity, which falls under the Presentation aspect"
Can the proposed theory help explain some of the successes of one architecture over others?,Does the review address Theory?,TRUE,FALSE,"The review asks about the theory explaining architectural successes, which directly addresses the Theory aspect"
"In particular, it considers language models which compute a probability distribution over the next word in a text, given the previous context.",Does the review address Methodology?,TRUE,FALSE,"The review describes language models computing word probabilities, which relates to the Methodology aspect"
It seems that the authors have the infrastructure for computing single-model test-set results.,Does the review address Result?,TRUE,FALSE,"The review comments on the infrastructure for computing test-set results, which relates to the Result aspect"
1.The performance of this model is closely related to both the AST encoding frontend and the LLaMA model's performance.,Does the review address Methodology?,TRUE,FALSE,"The review discusses the model's performance related to encoding and LLaMA, which relates to the Methodology aspect"
"However, if the video is quite long, say 10 minutes, 30 minutes, or even few hours, will the method still be efficient and effective?",Does the review address Methodology?,TRUE,FALSE,"The review questions the method's efficiency for long videos, which relates to the Methodology aspect"
"I'm concerned whether these improvements will hold after optimizing BERT carefully like RoBERTa, or using more advanced backbone methods like ALBERT.",Does the review address Methodology?,TRUE,FALSE,"The review expresses concern about improvements with different model optimizations, which relates to the Methodology aspect"
Cluster embeddings are then obtained which serve as embeddings for the words that reside in each cluster.,Does the review address Methodology?,TRUE,FALSE,"The review describes cluster embedding methodology, which relates to the Methodology aspect"
"The proposed method represents a novel approach to multimodal techniques, distinguishing itself from previous Vision-Language Models (VLMs) like Flamingo and PaLI.",Does the review address Methodology?,TRUE,FALSE,"The review describes a novel approach to multimodal techniques, which relates to the Methodology aspect"
"However, there are unclear parts to be addressed or clarified.",Does the review address Presentation?,TRUE,FALSE,"The review suggests there are unclear parts to be addressed, which falls under the Presentation aspect"
"* Extensive empirical results and analysis, providing some findings about overlapping strategy in DNA tokenization, could benefit the community.",Does the review address Analysis?,TRUE,FALSE,"The review highlights extensive empirical results and analysis, which directly addresses the Analysis aspect"
"After reading other reviews and the authors’ responses to all of the reviewers, I recommend this paper by accepted—extensive results show that the CALM objectives offer more signal from data than current pretraining methods.",Does the review address Methodology?,TRUE,FALSE,"The review discusses CALM objectives and pretraining methods, which relates to the Methodology aspect"
The paper proposes a  HRL/options framework based method to learn a dialog policy over learned latent dialog acts which can then guide the lower level NLG.,Does the review address Methodology?,TRUE,FALSE,"The review describes a hierarchical reinforcement learning framework for dialog policy, which relates to the Methodology aspect"
"I still feel that the authors’ use of “concept” and “commonsense” is vague, when their method can be defined more clearly with more mundane terminology.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review critiques the vagueness of terminology, which corresponds to the Elucidation aspect"
"The authors empirically evaluate their N-Bref’s accuracy on a number of problems from the open source LeetCode problem set and generate 25,000 pairs of high-level source and low-level source which are broken into training (60%), validation (20%), and testing (20%).",Does the review address Evaluation?,TRUE,FALSE,"The review describes the empirical evaluation of N-Bref on LeetCode problems, which directly addresses the Evaluation aspect"
"Some of the details for model description are missing and confusing, e.g., (1) How the representation is initialized for a supernode corresponding to a fact triplet and how does the supernode propagate information to the sub-nodes?",Does the review address Methodology?,TRUE,FALSE,"The review points out missing details in model description, which relates to the Methodology aspect"
Will need some clarification to better judge the results.,Does the review address Result?,TRUE,FALSE,"The review suggests needing clarification to judge results, which relates to the Result aspect"
"* Even though this paper proposes a new efficient transformer, the evaluation does not focus on computational efficiency aspects and comes across as incomplete.",Does the review address Evaluation?,TRUE,FALSE,"The review critiques the incomplete evaluation of computational efficiency, which directly addresses the Evaluation aspect"
"The strongest result is the HANS ""lexical_overlap"" case, where the proposed method has a clear advantage.",Does the review address Result?,TRUE,FALSE,"The review highlights the strongest result in the HANS case, which relates to the Result aspect"
"For instance, they ask how different amounts of data influence model behavior or if their data sampling method can react to task difficulty.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses data influence and sampling methods, which relates to the Data/Task aspect"
"Then it solves two tasks with two network branches: the first branch minimizes the loss for NER, and the second branch minimizes the loss for RE.",Does the review address Data/Task?,TRUE,FALSE,"The review describes solving two tasks with different network branches, which relates to the Data/Task aspect"
And the results of the proposed model can also be available for downstream detection models.,Does the review address Result?,TRUE,FALSE,"The review mentions the model's results being available for downstream detection, which relates to the Result aspect"
I highly recommend bringing this assumption earlier to avoid readers confusion.,Does the review address Methodology?,TRUE,FALSE,"The review suggests bringing an assumption earlier to avoid confusion, which relates to the Methodology aspect"
"Minor: Only half the datasets are shown in Tables 3 and 4, but it’s unclear how/why those were chosen?",Does the review address Data/Task?,TRUE,FALSE,"The review questions the selection of datasets in tables, which relates to the Data/Task aspect"
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Presentation?,TRUE,FALSE,"The review discusses the contributions without an ablation study, which falls under the Presentation aspect"
The results on Split H are positive and they also conducted a range of ablation and error analysis.,Does the review address Analysis?,TRUE,FALSE,"The review mentions positive results and conducting ablation and error analysis, which directly addresses the Analysis aspect"
I'd like to see another ablation study of whether RE helps NER.,Does the review address Ablation?,TRUE,FALSE,"The review suggests an additional ablation study, which directly addresses the Ablation aspect"
This is the newest of a small but growing body of literature that seeks to connect emergent communication with genuine NLP tasks.,Does the review address Data/Task?,TRUE,FALSE,"The review situates the work in a literature connecting communication with NLP tasks, which relates to the Data/Task aspect"
(ii) a new way to aggregate multiple inputs (using M-BERT) and several different decoding methods.,Does the review address Novelty?,TRUE,FALSE,"The review describes a new way of aggregating inputs and decoding methods, which directly addresses the Novelty aspect"
"For table 4, please also include the significance of the BLEU improvement made by the pRNN with respect to the the baseline, see https://github.com/jhclark/multeval General Discussion ==== As the main contribution of this work is on the phrasal effect of the new RNN architecture, it's rather important to show that the phrases are more coherent than the vanilla LSTM / RNN model.",Does the review address Significance?,TRUE,FALSE,"The review suggests including significance of improvements and showing phrase coherence, which relates to the Significance aspect"
It will be great if authors can justify more on the technical novelty.,Does the review address Novelty?,TRUE,FALSE,"The review requests justification of technical novelty, which directly addresses the Novelty aspect"
(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.,Does the review address Data/Task?,TRUE,FALSE,"The review mentions achieving better results on tasks, which relates to the Data/Task aspect"
"The paper is clear and detailed, and well situated in the literature.",Does the review address Presentation?,TRUE,FALSE,"The review praises the paper's clarity and detailed situating in literature, which falls under the Presentation aspect"
Definition of Variables and Positional Encodings:  The paper would greatly benefit from a more detailed explanation of the positional encodings used.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests a more detailed explanation of positional encodings, which corresponds to the Elucidation aspect"
The paper then uses an existing result from Liao & Berg (2017) to show that the gap can be bounded by the variance of prediction probability.,Does the review address Result?,TRUE,FALSE,"The review describes using an existing result to bound a gap, which relates to the Result aspect"
"Based on the large-scale training data and the proposed visual expert module, the proposed method achieves a number of state-of-the-art results across a wide range of vision-language tasks.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses achieving state-of-the-art results across vision-language tasks, which relates to the Data/Task aspect"
"However, it is confusing to me how this interacts with the prior results in the paper.",Does the review address Result?,FALSE,TRUE,The review is an incomplete statement about confusion with prior results
A figure containing the whole process could be helpful to better understand the processing required to train / test such models.,Does the review address Methodology?,TRUE,FALSE,"The review suggests creating a figure to understand the training/testing process, which relates to the Methodology aspect"
"1.The paper introduces for the first time a large language model that combines both general audio perception capabilities and language reasoning abilities, along with the datasets used for training.",Does the review address Methodology?,TRUE,FALSE,"The review describes introducing a large language model with audio and language capabilities, which relates to the Methodology aspect"
"They do pre-train their model (BROS) on a large dataset with 11M documents, and then used such models to perform downstream tasks in four smaller datasets.",Does the review address Methodology?,TRUE,FALSE,"The review describes pre-training and downstream task approaches, which relates to the Methodology aspect"
"So, it would be better to compare this system, which also captures semantics.",Does the review address Comparison?,TRUE,FALSE,"The review suggests comparing systems that capture semantics, which directly addresses the Comparison aspect"
I can not understand why sample-specific rather than task-specific preference is important for prompt tuning.,Does the review address Related Work?,TRUE,FALSE,"The review questions the importance of sample-specific preferences, which relates to the Related Work aspect"
"Positives --------- Increasing the context length of transformers is an interesting and relevant topic, and the proposed solution can have real impact in moving the state of the art forward.",Does the review address Significance?,TRUE,FALSE,"The review highlights the importance of increasing transformer context length, which relates to the Significance aspect"
The embedding methods are:  (1) multiCluster : Uses a dictionary to map words to multilingual clusters.,Does the review address Methodology?,TRUE,FALSE,"The review describes embedding methods using multilingual clusters, which relates to the Methodology aspect"
"Also, the lack of attention mechanism provides a disadvantage to the baseline enc-dec system and it's unclear whether the pRNN can outperform or be an additive feature to the enc-dec system with an attention mechanism.",Does the review address Methodology?,TRUE,FALSE,"The review discusses limitations of attention mechanisms, which relates to the Methodology aspect"
The auxiliary tasks themselves will be useful for designing similar tasks for other theorem provers.,Does the review address Data/Task?,TRUE,FALSE,"The review suggests the auxiliary tasks will be useful for other theorem provers, which relates to the Data/Task aspect"
- Ablation study shown in table 5 provides good insights for choices of LoRA params and the benefit of curriculum in staged training.,Does the review address Presentation?,TRUE,FALSE,"The review praises the ablation study for providing insights, which falls under the Presentation aspect"
"Empirically, it demonstrates that several NLP tasks are “natural”.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review empirically demonstrates the ""naturalness"" of NLP tasks, which relates to Justification/Motivation"
Weaknesses * Something that stands out is the lack of discussion and comparison to related works that employ recurrent formulations of attention.,Does the review address Comparison?,TRUE,FALSE,"The review critiques the lack of comparison with related works, which directly addresses the Comparison aspect"
- General Discussion: The authors perform relation extraction as reading comprehension.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review describes performing relation extraction as reading comprehension, which relates to the Elucidation aspect"
"Moreover, the authors better answer questions in 2 so I can gauge if their hyper-parameters were chosen in the principled ways.",Does the review address Presentation?,TRUE,FALSE,"The review suggests better explaining hyperparameter choices, which falls under the Presentation aspect"
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Theory?,TRUE,FALSE,"The review mentions a theoretical analysis of hyperparameter selection, which directly addresses the Theory aspect"
"In the ablation study, the authors only consider the fixed \alpha as the base.",Does the review address Ablation?,TRUE,FALSE,"The review discusses the ablation study considering a fixed base, which directly addresses the Ablation aspect"
It also compares different subword representation strategies and finds that syllable representations perform best (when not using BERT).,Does the review address Comparison?,TRUE,FALSE,"The review compares different subword representation strategies, which relates to the Comparison aspect"
"The motivation is to leverage unimodal data, which are assumed easier to obtain than image-text pairs.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review describes the motivation of leveraging unimodal data, which relates to Justification/Motivation"
####Pros:  The paper proposes the first RNN based neural generator to perform data augmentation for “extreme” compositionality inference.,Does the review address Data/Task?,TRUE,FALSE,"The review highlights proposing the first RNN-based generator for compositionality inference, which relates to the Data/Task aspect"
I am also wondering if the extracted facts could bring too much noise to the question.,Does the review address Methodology?,TRUE,FALSE,"The review questions the potential noise from extracted facts, which relates to the Methodology aspect"
"(In particular, pre-training on emergent language performs on average better than synthetic hierarchical data, but not quite as well as a different natural language, and all of these pre-training methods do better than training from scratch.)",Does the review address Data/Task?,TRUE,FALSE,"The review discusses pre-training performance on different types of data, which relates to the Data/Task aspect"
"The authors argued that most of the previous multimodal LLMs used shallow connections between vision and models, and thus proposed a new module called visual expert.",Does the review address Methodology?,TRUE,FALSE,"The review describes proposing a new module for multimodal connections, which relates to the Methodology aspect"
"If the authors would like to compare the number of additional parameters of DeFo with CoOp and CLIP-adapter, I think it may be very helpful for us to comprehensively evaluate and compare these methods.",Does the review address Methodology?,TRUE,FALSE,"The review suggests comparing additional parameters of different methods, which relates to the Methodology aspect"
The description of how you compare your invariants to those inferred by Daikon is not clear unless all relevant cases related to (pre)conditions on method parameters.,Does the review address Methodology?,TRUE,FALSE,"The review critiques the description of comparing invariants, which relates to the Methodology aspect"
These papers and other methods for contact prediction beyond Gremlin are not described.,Does the review address Methodology?,FALSE,TRUE,The review discusses what is not described (contact prediction methods) rather than addressing any specific methodology.
"The true contribution appears to be the improvement of the overlapping strategy tokenization for DNA pretraining, which diverges from the broader theme of ""rethinking the pretraining for DNA sequence.""",Does the review address Methodology?,TRUE,FALSE,The review discusses a specific methodological aspect - the overlapping strategy tokenization for DNA pretraining.
"A significant part of the contribution was in the analysis of the results, obtained by this learning-based parameter sharing approach, which was quite informative and revealed some interesting insights about where and when a language-specific computation is required.",Does the review address Result?,TRUE,FALSE,"The review explicitly mentions ""analysis of results"" and ""interesting insights"" obtained from the approach."
**Reproducibility** I believe reproducing the results is possible given the clear description provided in the main paper and the appendix.,Does the review address Presentation?,TRUE,FALSE,The review directly addresses the clarity of description in the paper and appendix.
"The layers are described in a textual fashion, barely any math (and extended in the pseudo-code).",Does the review address Presentation?,TRUE,FALSE,The review comments on how the layers are described and the lack of mathematical presentation.
"Given the way p(guess=Ii) is used above, I think this should be more like E[argmax(p(guess=Ii)) = i].",Does the review address Result?,TRUE,FALSE,The review discusses a specific mathematical result and suggests a correction.
It is then not clear how each fact block (grey squares in Figure 4) functions as a whole.,Does the review address Methodology?,TRUE,FALSE,"The review discusses the functionality of fact blocks, which is part of the method's architecture."
"- The paper uses code clone detection and semantic labeling to motivate their theory, but the theory focuses on characterizing language tractability.",Does the review address Theory?,TRUE,FALSE,The review explicitly mentions theory and its focus on language tractability.
Experimental results show improvements over both the base T5 model and the large T5 model.,Does the review address Experiment?,TRUE,FALSE,The review directly references experimental results and model comparisons.
"Additionally, there are some minor things I would add or improve: - I would add references to multi-task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE).",Does the review address Result?,FALSE,TRUE,The review suggests adding references about multi-task training but doesn't discuss results.
"Additionally, the authors conclude that pre-training is not a significant factor in the efficacy of active learning, but their numerical results suggest active learning methods (Entropy and Coreset) narrow the gap with the random baseline significantly from BERT-Base to RoBERTa-Base!",Does the review address Result?,TRUE,FALSE,The review discusses numerical results and their implications for active learning methods.
"If these method can also achieve very good results, then I feel that the novelty and effectiveness of DeFo may be challenged.",Does the review address Methodology?,TRUE,FALSE,The review questions the effectiveness of the DeFo method.
"Even if pruning is ineffective (at multiple pruning rates), it’s never really explained why, despite this being a core contribution of the paper.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out a lack of explanation for why pruning is ineffective.
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Data/Task?,TRUE,FALSE,The review explicitly mentions Multiple-Choice Question-Answering and multiple datasets.
Section 3.4  does not describe clearly enough how attention maps were used for predicting contact maps.,Does the review address Presentation?,TRUE,FALSE,The review criticizes the clarity of description in Section 3.4.
"Regarding that CLIP does not release the 400M dataset (mentioned in this paper by the authors), the authors may not be able to train OTTER on the 400M dataset.",Does the review address Methodology?,TRUE,FALSE,The review discusses training constraints related to the CLIP dataset.
- The authors perform quite a lot of ablation studies.,Does the review address Ablation?,TRUE,FALSE,The review explicitly mentions ablation studies being performed.
Why don't the authors of this work do this evaluation as well?,Does the review address Evaluation?,TRUE,FALSE,The review questions why certain evaluation wasn't performed.
The provided experiments are more like baselines for self-evaluation other than state-of-the-art performance.,Does the review address Experiment?,TRUE,FALSE,The review discusses the nature of the experiments as baselines.
"For example, the paper https://arxiv.org/abs/1505.06798 also goes beyond simply considering the reconstruction objective on the weights, and includes the nonlinearity as well in the reconstruction objective.",Does the review address Related Work?,TRUE,FALSE,The review explicitly references and discusses related work.
"- Proposition 3.1 is a trivial consequence of the basic theorems of DP, and Algorithm 1 is a simple modification of DP-SGD (that is already available in standard DP-training libraries).",Does the review address Methodology?,TRUE,FALSE,The review discusses Proposition 3.1 and Algorithm 1 as methodological components.
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Comparison?,TRUE,FALSE,The review discusses comparison with empirical law from different experimental configurations.
"Negatives --------- The experiments do not compare to many other approaches, even though those approaches are cited throughout the paper.",Does the review address Comparison?,TRUE,FALSE,The review explicitly mentions lack of comparison to other approaches.
"Contributions: - A new algorithm for unsupervised knowledge graph creation from a target corpus - Demonstrating the utility of large pre-trained language models towards knowledge graph creation (though, there are other works in this area that should probably be discussed more.",Does the review address Contribution?,TRUE,FALSE,The review explicitly lists contributions including a new algorithm and utility demonstration.
"It's important to discuss why these improvements are non-trivial and how they advance the field, considering the rapidly evolving landscape of both quantum computing and graph analysis.",Does the review address Analysis?,TRUE,FALSE,The review discusses the importance of analyzing improvements in the context of the field.
"It would help to clarify when what you predict is a guard, a precondition, an invariant, or something else.",Does the review address Result?,FALSE,TRUE,The review asks for clarification about predictions types but doesn't discuss results.
- Weaknesses: Many points are not explained well in the paper.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review directly criticizes the quality of explanations in the paper.
"- Extensive results and discussions are put in the Appendix, costing great effort in going back and forth.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses the placement and accessibility of discussions in the appendix.
More discussions on comparing with symbolic logic reasoner model LReasoner are needed.,Does the review address Comparison?,TRUE,FALSE,The review explicitly requests more comparative discussion with LReasoner model.
"* Extensive empirical results and analysis, providing some findings about overlapping strategy in DNA tokenization, could benefit the community.",Does the review address Result?,TRUE,FALSE,The review discusses empirical results and findings about DNA tokenization.
"For the theoretical analysis, it was not clear to me what is the contribution of the current analysis compared to the Levine 2020 paper.",Does the review address Analysis?,TRUE,FALSE,The review questions the contribution of the theoretical analysis compared to previous work.
Case studies show that the method can help improve training efficiency.,Does the review address Methodology?,TRUE,FALSE,The review discusses how the method improves training efficiency.
"- reasonable initial experimental results demonstrating some ways to help models better use cross-text-chunk dependencies (put them into a contiguous text chunk), providing some hope that these results could make models better.",Does the review address Result?,TRUE,FALSE,The review discusses experimental results regarding cross-text-chunk dependencies.
This work tries to address the issue by proposing a technique that carefully amalgamates multiple previously known approaches to generate diverse label preserving examples.,Does the review address Methodology?,TRUE,FALSE,The review describes a technique that combines multiple approaches.
Is the speedup over total computational time or just the attention part?,Does the review address Methodology?,TRUE,FALSE,The review questions specific methodological details about computational speedup.
(I assumed authors used the same strategy as LayoutLM).,Does the review address Comparison?,TRUE,FALSE,The review makes an assumption about using the same strategy as LayoutLM.
"(2) In this paper, similarity and alignment structures are proposed, but no ablation experiments have been carried out to prove the effectiveness of the improved model.",Does the review address Ablation?,TRUE,FALSE,The review points out the lack of ablation experiments for proposed structures.
"Terms such as θ, t, δ, and especially the adjacency matrix A, which are crucial for understanding the method, require clear definitions and contextual usage within the proposed quantum framework.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests clearer definitions for specific mathematical terms and concepts.
"The two datasets have some “toy flavor”, while SCAN great favors example combination (with recomb-2 performs much better than recomb-1), recomb-1 seem to perform better for morphological analysis dataset, leaving questions about how to choose the exact models in general.",Does the review address Analysis?,TRUE,FALSE,The review analyzes the performance differences between models on different datasets.
The paper then does a good job of showing how using one-hot encodings compared to SCS change the problem definition leading to a difference in performance on the same task.,Does the review address Comparison?,TRUE,FALSE,The review discusses performance comparison between one-hot encodings and SCS.
- How will the pseudo data generation amount affect the learning / forgetting performance?,Does the review address Result?,TRUE,FALSE,The review questions how data generation affects performance outcomes.
This is the first such dataset for the Lean Theorem prover.,Does the review address Data/Task?,TRUE,FALSE,The review identifies a novel dataset for the Lean Theorem prover.
"It is just a combination of the strong pretrained LLM and the existing audio encoder, AST.",Does the review address Methodology?,TRUE,FALSE,The review describes the methodology as a combination of LLM and audio encoder.
The visualization of OTTER’s matching illustrates its effectiveness in handling many-to-many relationships.,Does the review address Methodology?,TRUE,FALSE,The review discusses OTTER's effectiveness in handling relationships.
It would be impossible to replicate based on the two-line explanation here.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review criticizes the brevity of explanation making replication impossible.
The authors should conduct experiments on more types of sentence pair tasks.,Does the review address Data/Task?,TRUE,FALSE,The review suggests expanding experiments to more sentence pair tasks.
The concept of fact units is interesting and novel which are easily constructed via dependency trees.,Does the review address Novelty?,TRUE,FALSE,The review explicitly mentions the novelty of fact units concept.
"Furthermore, when there is a gap between the empirical results and the theoretical results (e.g., validation of Lemma 4.3 at the end of Section 4), the paper makes these limitations clear, which I appreciated very much as a reader (paper does not over-claim its contributions).",Does the review address Presentation?,TRUE,FALSE,The review praises the clear presentation of limitations and results.
"I also believe that the downstream tasks are also somewhat similar (language command grounding, tappability, UI object detection, UI summarization, widget captioning).",Does the review address Data/Task?,TRUE,FALSE,The review lists several downstream tasks in the study.
"I still feel that the authors’ use of “concept” and “commonsense” is vague, when their method can be defined more clearly with more mundane terminology.",Does the review address Presentation?,TRUE,FALSE,The review criticizes the vague use of terminology in the paper.
Otherwise for example it is not clear to me if the improvement in Blue compared to LaRL comes from the extra reward using the language model or from the options framework.,Does the review address Methodology?,TRUE,FALSE,The review discusses methodological components (extra reward and options framework) and their impact on improvement.
"However, they merely note that their data was annotated at the “relation” level rather than at the triple (relation, entity pair) level… but couldn’t Bordes et al. have done the same in their annotation?",Does the review address Data/Task?,TRUE,FALSE,The review discusses annotation level details in the data.
"Although the individual components are similar to previous work, they are combined in a novel way that shows a path toward longer and more efficient context lengths.",Does the review address Novelty?,TRUE,FALSE,The review explicitly discusses novel combination of components.
"Running a baseline model that runs *for the same amount of time* is essential to appreciate the contribution of this work (e.g., repeat the same analysis in Figure 3 for the vanilla BERT).",Does the review address Presentation?,TRUE,FALSE,The review suggests improvements for presenting baseline comparisons in Figure 3.
The same applies to Table 3: it is unclear to me why or how the baseline T5 model has been chosen.,Does the review address Comparison?,TRUE,FALSE,The review questions the selection of baseline T5 model for comparison.
"Summary:  The augmentation of NLP samples is an important task with no clear ""applicable to all"" mechanism.",Does the review address Data/Task?,TRUE,FALSE,The review discusses NLP sample augmentation as a task.
"- Extensive results and discussions are put in the Appendix, costing great effort in going back and forth.",Does the review address Result?,TRUE,FALSE,The review mentions results and their placement in the appendix.
(3) Are there any advantages of using the multi-Skip approach instead of learning bilingual embeddings and performing multi-CCA to learning projections across the distinct spaces?,Does the review address Methodology?,TRUE,FALSE,The review compares methodological approaches (multi-Skip vs. bilingual embeddings).
The paper made a significant contribution to idea of using adversarial training as part of the self-supervision signal for language learning.,Does the review address Contribution?,TRUE,FALSE,The review explicitly discusses the paper's contribution to adversarial training.
Summary: + Appealing theoretical contributions + Empirical results are encouraging + The use of discriminator for reward shaping in addition to task success rate is interesting  - Writing and explanation can be improved.,Does the review address Theory?,TRUE,FALSE,"The review explicitly mentions ""theoretical contributions"" in the summary."
Clustering to find exemplar terms for keyphrase extraction.,Does the review address Related Work?,TRUE,FALSE,The review references existing work on clustering for keyphrase extraction.
"The second sentence is confusing to me, and I am a native English speaker.",Does the review address Presentation?,TRUE,FALSE,The review criticizes the clarity of language in a sentence.
P5: Section 4.4: I am still eager to know how you select your dialog actions.,Does the review address Methodology?,TRUE,FALSE,The review questions the selection process for dialog actions.
The performance is impressive and could be a better baseline for the future work.,Does the review address Comparison?,TRUE,FALSE,The review discusses the performance as a baseline for future work.
"Since they both use $m$ nodes, does it mean the supergraph also operates on each sub fact node?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review asks for clarification about technical details of the supergraph operation.
"The authors analyze the in-context bias of the self-attention model, which could inspire some research works on designing training examples.",Does the review address Methodology?,TRUE,FALSE,The review discusses the analysis of self-attention model's in-context bias.
"It may be useful to show how the performance changes when using different M. - According to [2], the CommonsenseQA IH-dev set contains 1,221 questions in total.",Does the review address Result?,TRUE,FALSE,The review suggests showing performance changes with different M parameters.
* It is hypothesized that PACT acts a regularizer while imparting useful knowledge to the model due to mutual information across tasks.,Does the review address Methodology?,TRUE,FALSE,The review discusses PACT's hypothesized role as a regularizer.
"- Well Structured Experiments sections with 4 RQs and results that confirm each of the hypotheses  - Reproducibility and Transparency in reporting of experiments in terms of available source code, dataset information, details about human evaluation, generation examples.",Does the review address Data/Task?,TRUE,FALSE,The review discusses experimental structure and dataset information.
"\phi(x) as introduced in eq 2 is in R^{2D} but S_{t-1} is in R{D}, not sure what does + mean in this context.",Does the review address Presentation?,TRUE,FALSE,The review points out unclear mathematical notation in equation 2.
"- Strengths: Useful modeling contribution, and potentially useful annotated data, for an important problem -- event extraction for the relationships between countries as expressed in news text.",Does the review address Contribution?,TRUE,FALSE,The review explicitly discusses modeling contribution and annotated data.
All of the results in this work seem to be previously known: * Theorem 1 is general to any polynomial-size circuit -- there is nothing special about Transformers.,Does the review address Theory?,TRUE,FALSE,The review discusses theoretical results and their novelty.
"Experiments show that the induced ""best-first"" order outperforms fixed orders, which verifies the motivation of the paper` 4.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses experimental verification of the paper's motivation.
"* ""Moreover, it should be noted that BROS achieves higher f1 score than 79.27 of LayoutLM using visual features"".",Does the review address Presentation?,TRUE,FALSE,The review quotes a poorly worded performance comparison.
More discussion is required on a) what are the reasons of loss in comprehensibility in this case (it is briefly mentioned in the intro) b) why their individual design choices and how they handles the different reasons c) some evaluation to verify this 2.,Does the review address Evaluation?,TRUE,FALSE,The review requests more discussion on evaluation of comprehensibility.
"It is reported that current system uses 527,830 documents for training, while 40,000 publications are held out for training baselines.",Does the review address Methodology?,TRUE,FALSE,The review discusses the dataset split methodology for training.
"For the second ablation, why do all the larger splits lead to similar performance?",Does the review address Result?,TRUE,FALSE,The review questions performance results from ablation experiments.
"While I think it's nice to analyze the connection between RM and DM, the math provided in the paper is simple, and the main contribution is just to add a baseline to the algorithm of Khalifa et al.",Does the review address Methodology?,TRUE,FALSE,The review discusses the addition of a baseline to an existing algorithm.
"* Strength     * This paper proposes an interesting idea and interpretation to connect RM and DM paradigm     * This paper proposes a variance reduction method for DPG which demonstrates its improvement on performance, stability and sample efficiency * Weakness     * From my understanding, the baseline mostly comes from the observation in 3.3, which has limited technical novelty.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review provides interpretation of the connection between RM and DM paradigm.
"Furthermore, BERT doesn’t predict these masked words using a linear softmax model over a contextual embedding for the whole sentence, which is the assumed structure for the softmax language models considered in the analysis.",Does the review address Methodology?,TRUE,FALSE,The review discusses BERT's prediction methodology and model structure.
The authors present a simple technique for in-context learning with large language models that achieves consistently good results across a variety of NLP tasks.,Does the review address Data/Task?,TRUE,FALSE,The review mentions various NLP tasks for in-context learning.
"The main motivation/result of the paper appears to be that the authors can perform zero-shot relation extraction, extracting relations only seen at test time.",Does the review address Result?,TRUE,FALSE,The review discusses the main result of zero-shot relation extraction.
"Hence, the overall novelty of the work appears very low.",Does the review address Novelty?,TRUE,FALSE,The review explicitly comments on the work's low novelty.
"It may be useful to show how the performance changes when using different M. - According to [2], the CommonsenseQA IH-dev set contains 1,221 questions in total.",Does the review address Data/Task?,TRUE,FALSE,The review references specific dataset details (CommonsenseQA IH-dev).
Cons:  - The main result (Thm 4.1) applies to next/conditional word distributions that are very close to the optimal distribution.,Does the review address Result?,TRUE,FALSE,The review discusses limitations of the main theoretical result.
- Table 1 would be much more readable if you didn't use horizontal lines after every ORCHID tag.,Does the review address Presentation?,TRUE,FALSE,The review suggests improvements for table readability.
The submission has evaluated the proposed algorithms on four datasets and improved SOTA performances.,Does the review address Data/Task?,TRUE,FALSE,The review mentions evaluation on four datasets.
"Now consider a prior accepted ICLR 2020 paper, Hoppity (Dinella et al. ), which trained on nearly 300k code change commits in GitHub.",Does the review address Comparison?,TRUE,FALSE,The review compares with a prior ICLR paper's training data.
"For example, experiments could investigate if using words which are phonologically similar (e.g., ""boat"" and ""moat"") is harder to distinguish than dissimilar words.",Does the review address Experiment?,TRUE,FALSE,The review suggests experimental investigations with phonologically similar words.
Using Transformer attention maps for protein contact prediction is not new.,Does the review address Novelty?,TRUE,FALSE,The review explicitly states that using Transformer attention maps for protein contact prediction isn't new.
"In particular, instead of modeling the context information between the sentence and each video frame, wMAN tried to learn the representation with multi-level and co-attention, which considers all possible pairs between the word and the frame.",Does the review address Presentation?,TRUE,FALSE,The review explains the representation learning approach of wMAN.
"Clarification of contribution  Eq 6,7 reads like RNN style update but the intuition is lacking.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review points out lacking intuition for equations.
-  Consistent performance improvement over the baseline models on all of the three QA benchmarks.,Does the review address Result?,TRUE,FALSE,The review mentions consistent performance improvements across benchmarks.
"For instance, the greater instability of larger Transformers to active learning bodes poorly for practitioners leveraging ever increasing model sizes for low-resource datasets.",Does the review address Methodology?,TRUE,FALSE,The review discusses implications of Transformer stability for active learning.
"Good set of ablation studies to show that each component of the model is necessary, especially because the entire model already has many moving parts in addition to adversarial training.",Does the review address Ablation?,TRUE,FALSE,The review explicitly mentions ablation studies showing component necessity.
The key contribution of the paper is the approach to overcome the limitation of annotating  query sets and labels.,Does the review address Contribution?,TRUE,FALSE,The review explicitly states the key contribution.
"Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.",Does the review address Data/Task?,TRUE,FALSE,The review discusses improvements on LM tasks.
This could be done by visualizing the planning trajectory difference between coherent and incoherent text.,Does the review address Presentation?,TRUE,FALSE,The review suggests visualization of planning trajectory differences.
"- grounded language learning:     In both of these experiments, there is analysis provided on what aspects of the audio-based communication channel make the problem harder, easier, or just different from the same experiment with a discrete channel.",Does the review address Experiment?,TRUE,FALSE,The review discusses analysis of audio-based communication experiments.
"- Overall the paper would have benefited from an intrinsic visualization of the latent space, to make sure for example that there's no  Information collapse of the embeddings when dealing with long sentences.",Does the review address Presentation?,TRUE,FALSE,The review suggests adding visualization of the latent space.
It handles the hallucination problem of LLM by training close-ended dataset and then non-answerable question-answer pairs.,Does the review address Methodology?,TRUE,FALSE,The review discusses the method for handling LLM hallucination through training.
"The two datasets have some “toy flavor”, while SCAN great favors example combination (with recomb-2 performs much better than recomb-1), recomb-1 seem to perform better for morphological analysis dataset, leaving questions about how to choose the exact models in general.",Does the review address Result?,TRUE,FALSE,The review discusses comparative performance results between models on different datasets.
"I compared their numbers explicitly to Liu et al. (2019), and RoBERTa_base outperforms their approach on nearly all tasks (and on average).",Does the review address Related Work?,TRUE,FALSE,The review explicitly compares results with Liu et al. (2019).
"- P8, Table 2: The results from using Quad look worse than the above two.",Does the review address Result?,TRUE,FALSE,The review discusses performance results from Table 2 regarding Quad.
"This idea is novel and interesting to me, and the derivation and experiment results look encouraging.",Does the review address Experiment?,TRUE,FALSE,The review mentions experiment results being encouraging.
"Therefore it would be interesting to see how this affects performance, i.e. just run the method on the CaP benchmark without the oracle.",Does the review address Methodology?,TRUE,FALSE,The review suggests running the method without the oracle on CaP benchmark.
The explanation at the end of Section 4 is not persuasive.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review criticizes the explanation provided in Section 4.
"3.The model excels in various audio-related tasks and open-ended question answering, demonstrating its outstanding performance.",Does the review address Result?,TRUE,FALSE,The review discusses model performance across audio-related tasks.
"- Do you have any initial experiments on the ""self-improving"" aspect of this technique?",Does the review address Experiment?,TRUE,FALSE,The review asks about experiments on self-improving aspects.
"- In Table 1, can you explain more explicitly (in caption and text) what “subset” and “class words” means?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests clearer explanation of terms in Table 1.
The authors present a method that builds on the lottery ticket hypothesis (LTH).,Does the review address Methodology?,TRUE,FALSE,The review discusses method based on lottery ticket hypothesis.
In case of the textual prompts benchmarks its also not clear to me why no standard errors on results are reported?,Does the review address Methodology?,TRUE,FALSE,The review questions lack of standard errors in results reporting.
"With this approach, that requirement doesn’t exist anymore.",Does the review address Methodology?,TRUE,FALSE,The review notes a change in methodological requirements.
"I would suggest using the phrase ""weighted SVD"" early on in the introduction (e.g., exactly when you introduce your new method).",Does the review address Methodology?,TRUE,FALSE,"The review suggests early introduction of ""weighted SVD"" method."
**Empirical**:  One issue with the language modelling experiment is the choice of evaluation and train set.,Does the review address Evaluation?,TRUE,FALSE,The review critiques choice of evaluation and train set.
- General Discussion: The main focus of this paper is the introduction of a new model for learning multimodal word distributions formed from Gaussian mixtures for multiple word meanings.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses the paper's focus on a new model for multimodal word distributions.
Can the theory guide how to develop new models to learn program representations?,Does the review address Theory?,TRUE,FALSE,The review questions theory's potential for guiding new model development.
The paper's presentation could be improved in several ways:     1.,Does the review address Result?,FALSE,TRUE,The review mentions presentation improvements but doesn't discuss results.
This paper studies why language model pre-training has been such an effective technique in improving downstream performance across a wide range of NLP tasks recently.,Does the review address Data/Task?,TRUE,FALSE,The review discusses pre-training's effect on NLP tasks.
This paper demonstrates why self-knowledge distillation as a prior distribution is a form of regularization with theoretical analysis on the gradients.,Does the review address Theory?,TRUE,FALSE,The review mentions theoretical analysis of self-knowledge distillation.
The model sizes are varied across experiments to achieve on par performance which makes the comparison of the computational cost not so obvious.,Does the review address Presentation?,TRUE,FALSE,The review discusses unclear presentation of computational cost comparisons.
- multi-concept and noise:     The noise you add to the channel has a number of different components; there should be an ablation study to illustrate the effects of these components.,Does the review address Ablation?,TRUE,FALSE,The review suggests ablation study for noise components.
"- I know GPT3 access is hard to get, but I wish experiments with k=8 prompts could be compared against  Post rebuttal: I think another pass for clarity over the paper would be good for the final version, but otherwise I'm happy with the paper updates and I'm happy to see the ablation numbers aren't too sensitive to token count.",Does the review address Experiment?,TRUE,FALSE,The review discusses experiments with k=8 prompts and ablation numbers.
Contrastive training (negative sampling) is one of the crucial contributions of this work.,Does the review address Methodology?,TRUE,FALSE,The review identifies contrastive training as a crucial contribution.
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Presentation?,TRUE,FALSE,The review summarizes the paper's contributions regarding BERT representations.
"In addition, the authors empirically demonstrate that the token-level masked-LM model used by BERT is not a good choice as pre-training task for the two-tower Transformer when deployed for large-scale information retrieval applications.",Does the review address Data/Task?,TRUE,FALSE,The review discusses pre-training task suitability for information retrieval applications.
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses how the paper motivates its approach to Multiple-Choice Question-Answering.
- Using capital and lower case tau in Theorem 4.2 is confusing notation.,Does the review address Presentation?,TRUE,FALSE,The review criticizes confusing notation in Theorem 4.2.
"While it is also true that corpus transfer _enables_ this divergence in model types, to really test whether transferring the whole model versus using the corpus works or not, I would think you would want to compare fine-tuning the sender GRU on the LM data vs. starting from scratch _with a GRU of the same type_ and pre-training on the EC corpus before fine-tuning.",Does the review address Experiment?,TRUE,FALSE,The review suggests specific experimental comparisons for model transfer testing.
"I will discuss my concerns one-by-one in detail: - Most importantly, the evaluation is confusing.",Does the review address Evaluation?,TRUE,FALSE,The review explicitly mentions evaluation being confusing.
"FLOPS is a measure of computer performance, while arithmetic intensity is the ratio of total floating-point operations to total data movement.",Does the review address Data/Task?,TRUE,FALSE,The review defines technical performance metrics (FLOPS and arithmetic intensity).
The methodology is explained clearly and experiments are executed with a considerable amount of detail.,Does the review address Experiment?,TRUE,FALSE,The review praises clear methodology and detailed experiment execution.
"Specifically, I would expect authors provide more detailed recommendation for AL, DS, and multi-domain sampling in terms of sampling techniques, and population of different sources for certain application.",Does the review address Methodology?,TRUE,FALSE,The review requests more detailed recommendations for various sampling techniques.
It's great the authors supplied code for part of the system so I don't want to penalize them for missing it -- but this is relevant since the paper itself has so few details on the baselines that they could not really be replicated based on the explanation in the paper.),Does the review address Comparison?,TRUE,FALSE,The review discusses lack of baseline replication details.
- Definition of equivalence seems to be insufficient and lacks important components.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review criticizes insufficient definition of equivalence.
I think adapting CaP to the VIMA benchmark would be a more insightful baseline.,Does the review address Data/Task?,TRUE,FALSE,The review suggests adapting to VIMA benchmark.
"- Extensive ablation studies that showcase specific abilities of the model (types of OOD generalization), investigate the role of the foundation models and study the importance of the components of the prompt.",Does the review address Ablation?,TRUE,FALSE,The review discusses extensive ablation studies of model capabilities.
2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues.,Does the review address Experiment?,TRUE,FALSE,The review suggests adding subjective evaluations to ablation experiments.
"Another question: does ""prompts of complexity n"" mean prompts of length n?",Does the review address Methodology?,TRUE,FALSE,The review asks for clarification about methodological terminology.
The wide range of datasets and active learning techniques they use (including BALD which prior works shows is very competitive) lends credence to the conclusions.,Does the review address Data/Task?,TRUE,FALSE,The review discusses range of datasets and active learning techniques.
"There are several follow-up results built on these two results, such as a new loss objective for predicting the downstream task, but to the best of my understanding, these two results are the main claims of this paper.",Does the review address Result?,TRUE,FALSE,The review discusses main claims and follow-up results.
The complexity of learning options would be way different in the two different settings.,Does the review address Methodology?,TRUE,FALSE,The review compares learning complexity in different settings.
"So there's a 3x3 contingency table of gold and predicted (POS, NEU, NEG) classes, but this sentence leaves ambiguous how precision and recall are calculated from this information.",Does the review address Presentation?,TRUE,FALSE,The review points out ambiguity in precision/recall calculation description.
The paper does a systematic analysis on the role of language specific parameters using the proposed architecture.,Does the review address Analysis?,TRUE,FALSE,The review mentions systematic analysis of language-specific parameters.
I think significant presentation changes are required to clarify that the paper focuses on inference and finetuning.,Does the review address Presentation?,TRUE,FALSE,The review suggests clarifying the paper's focus on inference and finetuning.
"I think more could be done here, some ideas, probably there are better ways to test: - Have templates that leave out ""instructions"":  I would guess it wouldn't affect held-in task performance much, but would affect held-out tasks.",Does the review address Result?,TRUE,FALSE,The review discusses potential impact on task performance.
"Second, it is really hard to capture which part is really making the main contribution to the final performance.",Does the review address Result?,TRUE,FALSE,The review discusses difficulty in determining contribution to final performance.
Combining Translation Memory with Neural Machine Translation.,Does the review address Related Work?,TRUE,FALSE,The review references work on combining Translation Memory with Neural Machine Translation.
"Comparative Analysis and Benchmarking:  The comparisons presented in Tables 1 and 2 focus solely on the improvements over one reference work (Ma et al., 2023).",Does the review address Analysis?,TRUE,FALSE,The review discusses comparative analysis focus in Tables 1 and 2.
"Yet, it is difficult for me to trust that the effects in this paper will generalize to better performing models without further evidence: what if the CALM intermediate objectives only help with mistakes that larger models do not make in the first place?",Does the review address Methodology?,TRUE,FALSE,The review questions generalizability of CALM intermediate objectives.
"Maybe I've missed this in the paper, if there is, please be more explicit about it because it affects the model quite drastically if for every sentence the largest phrase length is the sentence length.",Does the review address Presentation?,TRUE,FALSE,The review requests more explicit explanation about sentence length implications.
"Unfortunately, many aspects of the models, experimentation, and evaluation are not explained very well.",Does the review address Methodology?,TRUE,FALSE,"The review criticizes explanation of models, experimentation, and evaluation."
"In addition, I have several notation confusions:  Assumption1: What is the hamming distance m_1 and m_2, when m_i are random variables?",Does the review address Presentation?,TRUE,FALSE,The review points out notation confusion regarding Hamming distance.
"Second paragraph of related work: McCarley et al. (2019) appears twice with different descriptions, is this intentional?",Does the review address Related Work?,TRUE,FALSE,The review identifies potential duplicate reference with different descriptions.
"**Strengths** - To the best of my knowledge, this is the first work that _mathematically_ justifies the connection between the pre-training objective and the downstream performance.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review praises mathematical justification of pre-training objective connection.
I find the analysis presented in the paper very interesting and insightful - and distinguishes it from previous work in this area.,Does the review address Related Work?,TRUE,FALSE,The review distinguishes the analysis from previous work in the area.
"However, there is a lack of unified experimental standards and ablation experiments in this paper.",Does the review address Ablation?,TRUE,FALSE,The review notes lack of ablation experiments.
"- Easy but probably not great thing to try:  held-out tasks with wrong/useless templates  A final thought:  It's not obvious that using as many training examples per dataset as possible is optimal, given that the model could overfit to dataset-specific spurious correlations.",Does the review address Methodology?,TRUE,FALSE,The review discusses training example strategy and potential overfitting.
"The presented method chooses action primitives such as ""PickAndPlace"" but does not need much training data (apart from the examples).",Does the review address Data/Task?,TRUE,FALSE,The review discusses action primitives and training data requirements.
"These prior methods do not incorporate the SFT stage, making it unclear how the model performs before this crucial phase.",Does the review address Result?,TRUE,FALSE,The review discusses unclear model performance before SFT stage.
"Ablation studies on the varying parameter counts of these two components would be valuable, if possible.",Does the review address Presentation?,TRUE,FALSE,The review suggests ablation studies on parameter counts.
"The paper in general is well-written and easy to follow, the qualitative analysis and the additional diagrams in the appendix illustrating the variations in policies are appreciated.",Does the review address Analysis?,TRUE,FALSE,The review praises qualitative analysis and diagrams.
"Comparative Analysis and Benchmarking:  The comparisons presented in Tables 1 and 2 focus solely on the improvements over one reference work (Ma et al., 2023).",Does the review address Result?,TRUE,FALSE,The review discusses comparative results presented in Tables 1 and 2.
"Additionally,        The topical details of the dataset (527,830 scientific documents) used in training RNN and Copy RNN are also missing.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out missing dataset details.
The analysis shows that it outperforms only all the other baselines only on 5/9 games and matches on 3.,Does the review address Result?,TRUE,FALSE,The review discusses comparative performance across games.
"In algorithm 1, in each iteration, only data sample (S_i) is used, how is this choice motivated?",Does the review address Data/Task?,TRUE,FALSE,The review questions motivation for data sample choice in algorithm.
The comparison in Observation 1 does not seem to be an apples-to-apples comparison.,Does the review address Comparison?,TRUE,FALSE,The review criticizes comparison methodology in Observation 1.
"what part of the performance is coming from pretraining (especially if using VAE type is novel, then quantifying that is important with and without VAE type SL), etc.",Does the review address Result?,TRUE,FALSE,The review questions source of performance gains from pretraining.
"Therefore it would be interesting to see how this affects performance, i.e. just run the method on the CaP benchmark without the oracle.",Does the review address Result?,TRUE,FALSE,The review suggests testing performance without oracle.
"* Most of the methodology appears to me like standard low quantized training techniques, e.g., using additional scales that are determined dynamically, adapted directly to FP8.",Does the review address Methodology?,TRUE,FALSE,The review discusses standard low quantized training techniques.
It is better to compare with more demonstration selection methods such as similarity-based and diversity-based methods which are widely used in practice.,Does the review address Methodology?,TRUE,FALSE,The review suggests comparing with additional demonstration selection methods.
"Running a baseline model that runs *for the same amount of time* is essential to appreciate the contribution of this work (e.g., repeat the same analysis in Figure 3 for the vanilla BERT).",Does the review address Analysis?,TRUE,FALSE,The review suggests comparative analysis with baseline model.
* It is interesting to know that WebMath pre-training is still helpful even in the presence of PACT.,Does the review address Methodology?,TRUE,FALSE,The review discusses helpfulness of WebMath pre-training with PACT.
"Related Work: Contrastive learning - Under an unsupervised setting, ontrastive -> contrastive  Overall:  This work highlights the importance of incorporating contrastive training for data augmentation.",Does the review address Related Work?,TRUE,FALSE,The review points out typo in related work section and discusses contrastive training.
"i,.e the agent is given the ground truth context every time and asked to predict the correct next utterance.",Does the review address Methodology?,TRUE,FALSE,The review describes methodology regarding ground truth context and prediction.
"You *tell* us that Fon is ""a language with special tokenization needs"" and that ""standard tokenization methods do not alwaysadequately deal with the grammatical, diacritical, and tonal properties of some African language"", and you cite the relevant papers.",Does the review address Related Work?,TRUE,FALSE,The review references cited papers about language tokenization needs.
It seems possible that these improvements could instead be due to the high quality semantic/syntactic relations encoded in the attention mechanism.,Does the review address Presentation?,TRUE,FALSE,The review suggests alternative explanation for improvements.
"* ""Moreover, it should be noted that BROS achieves higher f1 score than 79.27 of LayoutLM using visual features"".",Does the review address Result?,TRUE,FALSE,The review quotes specific performance comparison with LayoutLM.
"Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.",Does the review address Experiment?,TRUE,FALSE,The review discusses experimental results of hyperparameter tuning.
"Previous work [2] has already shown that by selecting the most complex examples from the training dataset, the performance can be largely improved compared to the original annotations from [1].",Does the review address Related Work?,TRUE,FALSE,The review references previous work [2] and [1] on example selection.
It would be nice if these baselines are described before Fig.,Does the review address Comparison?,TRUE,FALSE,The review suggests earlier description of baselines.
"Was this using the development set, and if so for which dataset?",Does the review address Data/Task?,TRUE,FALSE,The review asks for clarification about dataset usage.
More specifically description would help the readers to understand the task clearly.,Does the review address Presentation?,TRUE,FALSE,The review requests more specific description for task clarity.
"However, all the parameters/variables in the neural networks are freely designated and are not correlated to each other, thus they cannot work together to meet the requirements in the binding-unbinding mechanism.",Does the review address Methodology?,TRUE,FALSE,The review discusses limitations of neural network parameters in binding-unbinding mechanism.
"For the first ablation, it just gives out the performance of intermediate models on a single task.",Does the review address Methodology?,TRUE,FALSE,The review discusses ablation methodology focusing on single task.
Theoretical analysis is provided to demonstrate the effectiveness of the proposed method under a greedy search algorithm.,Does the review address Analysis?,TRUE,FALSE,The review mentions theoretical analysis of method effectiveness.
The results are intriguing and promising and should be of interest both to the emergent communication community as well as to the broader community working on low-resource NLP.,Does the review address Result?,TRUE,FALSE,The review characterizes results as intriguing and promising.
"Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",Does the review address Experiment?,TRUE,FALSE,The review describes multiple experimental tests including non-harmful test and robustness tests.
"Second, it is really hard to capture which part is really making the main contribution to the final performance.",Does the review address Contribution?,TRUE,FALSE,The review discusses difficulty in identifying main performance contributors.
It would be great if the authors discuss this or provide some supporting evidence about its correctness.,Does the review address Comparison?,TRUE,TRUE,The review requests supporting evidence but doesn't mention comparison.
Implementation details are only given for the vanilla BERT Are they similar to the EarlyBERT model as well?,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review questions implementation details for EarlyBERT model.
Strengths:   The authors connect active learning example selection to more severe training instability than random selection.,Does the review address Methodology?,TRUE,FALSE,The review discusses connection between active learning and training instability.
My another is concern is that the motivation of the experimental design is not clear.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review explicitly criticizes unclear experimental motivation.
It is nontrivial to gather the data as it involves hooking into the Lean's compilation process.,Does the review address Data/Task?,TRUE,FALSE,The review discusses complexity of data gathering process.
"The main limitations seem to be: (1) the proposed method is a bit limited in that it can only be used with a corpus in which the target head, relation, and tail spans need to be directly mentioned in a single sentence (2) it’s not clear whether the quantitative improvements are due to factual knowledge in the pretrained model or the syntactic/semantic relationships encoded in the self-attention.",Does the review address Methodology?,TRUE,FALSE,The review outlines methodological limitations regarding corpus requirements.
"I know you cite the Abbott & Martinus, 2018 paper, stating that BPE is bad for analytical languages, but I still think it would prove a point to show BPE performing badly for your data.",Does the review address Comparison?,TRUE,FALSE,The review suggests demonstrating BPE's poor performance for comparison.
The current experimental baseline can't reflect this.,Does the review address Experiment?,TRUE,FALSE,The review criticizes experimental baseline's inadequacy.
I liked the idea of removing conditionals to infer likely necessary preconditions.,Does the review address Result?,FALSE,TRUE,The review expresses appreciation for an idea but doesn't discuss results.
"The proposed models -- which seem to be an application of various tree-structured recursive neural network models -- demonstrate a nice performance increase compared to a fairly convincing, broad set of baselines (if we are able to trust them; see below).",Does the review address Comparison?,TRUE,FALSE,The review discusses performance comparison with baselines.
The system performs on par with recently proposed GECA for SCAN and favorably to GECA on morphological analysis.,Does the review address Result?,TRUE,FALSE,The review discusses comparative performance against GECA.
"Contributions: - A new algorithm for unsupervised knowledge graph creation from a target corpus - Demonstrating the utility of large pre-trained language models towards knowledge graph creation (though, there are other works in this area that should probably be discussed more.",Does the review address Presentation?,TRUE,FALSE,The review discusses how contributions should be presented with more related work discussion.
Is there any special reason for restraining it to single-task finetuning if earlier results demonstrates multi-task finetuning is better?,Does the review address Data/Task?,TRUE,FALSE,The review questions choice of single-task vs multi-task finetuning.
"However, they only show that the hyperparameter search on \alpha is removed and the adaptive smoothing parameter can be connected to the gradient rescaling effect on self-distillation.",Does the review address Methodology?,TRUE,FALSE,The review discusses hyperparameter search and adaptive smoothing methodology.
"The methods have been tested on two benchmarks focusing on the issue, SCAN and morphological analysis.",Does the review address Data/Task?,TRUE,FALSE,The review mentions testing on SCAN and morphological analysis benchmarks.
"- It's because if the largest phrase length is the sentence length, then model can be simplified into a some sort of convolution RNN where the each state of the RNN goes through some convolution layer before a final softmax and attention.",Does the review address Presentation?,TRUE,FALSE,The review explains model simplification based on phrase length conditions.
Were the same hyperparameters used for all configurations?,Does the review address Methodology?,TRUE,FALSE,The review asks about hyperparameter consistency across configurations.
"In terms of modelling, the work follows in the line of recent work on language-specific parameters for multilingual NMT.",Does the review address Methodology?,TRUE,FALSE,The review discusses modeling approach in context of language-specific parameters.
"- Because the policy learning procedure utilizes the additionally generated dialogue acts and corresponding responses, it is easy to think that naively fine-tuning the GPT-2 model on the additional generated data may also improve the dialogue model performance in terms of its policy and responses (similar to a data augmentation method).",Does the review address Presentation?,TRUE,FALSE,The review explains relationship between policy learning and model performance.
Theorem 2 is presented with no intuition and the proof in the appendix is only for a special case.,Does the review address Theory?,TRUE,FALSE,The review criticizes lack of intuition in Theorem 2 presentation.
"2) As the authors claimed in Introduction, ‘plenty of training data is available’.",Does the review address Methodology?,TRUE,FALSE,The review references authors' claim about training data availability.
"Rather than using the ad-hoc approach for selecting which augmentation ""stacking"" scheme is helpful, it would have been better to compare/use an approach highlighted in ""Learning to Compose Domain-Specific Transformations for Data Augmentation"" [NeuRIPS 2017].",Does the review address Methodology?,TRUE,FALSE,The review suggests alternative approach for augmentation scheme selection.
"Reasons for Score ----------------- The idea proposed in the paper is novel and exciting, but I have some concerns about whether the gains promised by the theoretical analysis can be realized while maintaining modeling quality.",Does the review address Analysis?,TRUE,FALSE,The review discusses concerns about theoretical analysis and modeling quality.
- Discussion in Section 4.1 - I think Figure 4 should be explained in more detail (in caption and/or text).,Does the review address Presentation?,TRUE,FALSE,The review requests more detailed explanation of Figure 4.
Weaknesses: There is no contribution/novelty from the modeling/methods side.,Does the review address Novelty?,TRUE,FALSE,The review explicitly states lack of modeling/methods novelty.
# Summary  The authors propose to use corpora generated from _emergent communication_ as a fine-tuning signal for NLP tasks (language modeling and image captioning in particular).,Does the review address Data/Task?,TRUE,FALSE,The review describes use of emergent communication corpora for specific NLP tasks.
"While the authors describe two applications (Section 2), these applications often deal with common programming languages that are intractable, e.g., code clones across binary code for vulnerability detection.",Does the review address Methodology?,TRUE,FALSE,The review discusses applications dealing with intractable programming languages.
"In semantic parsing problem, langugae to programatic language is a typical task.",Does the review address Data/Task?,TRUE,FALSE,The review mentions language to programmatic language as typical task.
"However, we should credit the core idea and (part of the implementation) to the earlier work on label-free CBMs.",Does the review address Presentation?,TRUE,FALSE,The review suggests crediting core idea to earlier work.
CALM shows better results with less data than the base model.,Does the review address Data/Task?,TRUE,FALSE,The review discusses model performance with less data.
"Where the paper does get technical is in a discussion of the differing difficulties of speech recognition for different languages, providing a useful case study to demonstrate that one-size technology approaches are not necessarily universal stand-alone solutions.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses technical explanation of speech recognition difficulties.
But the authors didn’t compare against these agent-based system design.,Does the review address Comparison?,TRUE,FALSE,The review notes lack of comparison with agent-based systems.
"I appreciate that the authors do not read too much into it and focus more on the analysis of the results, but one thing that remains unanswered in this paper is how the proposed method fairs against multilingual baselines that utilize (roughly) the same number of parameters; currently, the best models outperform the LS baseline by ~28M and ~10M parameters on OPUS-100 and WMT-14 respectively.",Does the review address Comparison?,TRUE,FALSE,The review discusses comparison with multilingual baselines regarding parameter counts.
That more templates per dataset didn't help is particularly interesting and suggests some questions.,Does the review address Data/Task?,TRUE,FALSE,The review discusses impact of templates per dataset.
"Given the issued pointed out in 1 and 2, I am not sure if the results are really sound as the authors claimed.",Does the review address Result?,TRUE,FALSE,The review questions soundness of claimed results.
"Put in another way, using RFA in transformer is from Rawat et al., 19 so do you think your major contribution is to design such  a gated usage of RFA?",Does the review address Methodology?,TRUE,FALSE,The review questions contribution regarding gated usage of RFA in transformer.
- Section 3: ...append a prompt like “This movie is” (the final quotation mark is on the next line).,Does the review address Methodology?,TRUE,FALSE,The review discusses prompt formatting methodology.
"Overall, I think this paper has a clear motivation and some interesting ideas on how to incorporate semantic language information into planning algorithms.",Does the review address Methodology?,TRUE,FALSE,The review discusses incorporation of semantic language information into planning algorithms.
"**Updates after rebuttal period**  The authors addressed some of the concerns -- showing inference time, model size and a discussion about training details and hyperparameters in the appendix.",Does the review address Methodology?,TRUE,FALSE,The review mentions additions of model details and hyperparameters.
"- Even though there is a “explain” component in PEER, it is not evaluated and studied regarding its correctness.",Does the review address Evaluation?,TRUE,FALSE,The review points out lack of evaluation for 'explain' component.
The authors did not provide what the retrieved sentences are like.,Does the review address Significance?,TRUE,FALSE,The review notes missing description of retrieved sentences.
"It would be to show more experiment results for some settings, for example, performance on Sum task when training with a mixture distribution, or more Sum task samples and fewer Parity task samples ( p range from 0.5 to 1.",Does the review address Experiment?,TRUE,FALSE,The review suggests additional experimental settings to explore.
- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.,Does the review address Result?,TRUE,FALSE,The review suggests adding more ablation analysis to results.
Experiments on LEGO and code interpretation task are done.,Does the review address Experiment?,TRUE,FALSE,The review mentions completed experiments on specific tasks.
The experiment results in Tables 1 & 2 cannot plausibly prove OTTER is more effective than CLIP.,Does the review address Result?,TRUE,FALSE,The review questions effectiveness proof in comparison results.
"Weakness While the ablation study and visualization analysis are done, the key evaluations are missing.",Does the review address Ablation?,TRUE,FALSE,The review mentions completed ablation study while noting missing evaluations.
"The main motivation/result of the paper appears to be that the authors can perform zero-shot relation extraction, extracting relations only seen at test time.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses main motivation of zero-shot relation extraction.
"As I understand it, this result shows that any part of p_f(s) orthogonal to row-span(Phi) doesn’t affect the cross-entropy of the language model (first order optimality condition would still be satisfied).",Does the review address Methodology?,TRUE,FALSE,The review explains technical aspects of cross-entropy and optimization.
"While previous work has examined tasks in the overall area, to my knowledge there has not been any publicly availble sentence-level annotated data for the problem -- the authors here make a contribution as well by annotating some data included with the submission; if it is released, it could be useful for future researchers in this area.",Does the review address Contribution?,TRUE,FALSE,The review discusses contribution of new annotated dataset.
Ablation studies show that the model achieves good performance on more complex questions.,Does the review address Methodology?,TRUE,FALSE,The review discusses ablation studies showing model performance.
The authors utilize figures and tables well to illustrate the ideas.,Does the review address Presentation?,TRUE,FALSE,The review praises use of figures and tables.
"The introduction is somewhat verbose, indirectly causing the first two weaknesses and making the paper hard to read.",Does the review address Presentation?,TRUE,FALSE,The review criticizes verbose introduction affecting readability.
-  The proposed model has two main parts: sentence embedding and substructure embedding.,Does the review address Methodology?,TRUE,FALSE,The review describes two main components of proposed model.
"- What is the ""margin of task $\mathcal{T}$"" mentioned on p.5?",Does the review address Data/Task?,TRUE,FALSE,"The review questions definition of ""margin of task""."
"Additionally,        The topical details of the dataset (527,830 scientific documents) used in training RNN and Copy RNN are also missing.",Does the review address Data/Task?,TRUE,FALSE,The review notes missing dataset details.
"For example, what if the authors don’t use a LogicForm-to-NaturalLanguage conversion?",Does the review address Result?,FALSE,TRUE,The review poses hypothetical question about methodology but doesn't discuss results.
"If the tasks are not similar, and the learning objectives are not aligned, then the motivation for multi-task learning is solely for reducing memory footprint and computational cost.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses motivation for multi-task learning.
"Starting from trivialities like the fact that the problem is generally undecidable (and not as stated in Section 2), through the use of incorrect terminology for invariants, guards, pre/post conditions, etc.",Does the review address Presentation?,TRUE,FALSE,The review criticizes incorrect terminology and problem statement.
"First, much of the improvement (I think) comes from reducing the number of epochs and/or the number of steps.",Does the review address Result?,TRUE,FALSE,The review discusses source of performance improvement.
Since the authors point out that using class labels to generate text embeddings may bring challenges with expressive sensitivity.,Does the review address Methodology?,TRUE,FALSE,The review discusses challenges with text embedding generation.
"- Consider HellaSwag/PiQA/etc, where FLAN underperformed few-shot and even zero-shot.",Does the review address Data/Task?,TRUE,FALSE,The review references specific datasets where FLAN underperformed.
"Your work obviously is different enough to stand on its own, but it might be good to make a mention of this work and others (e.g. do more of a lit search / related work on low rank compression).",Does the review address Methodology?,FALSE,TRUE,"The review suggests expanding related work discussion, not discussing methodology."
"I also wanted to mention that I appreciate the addition of the suggested related work, but I would still suggest that the authors consider looking into more detailed means of comparison in the future (especially to the Petroni work), since this seemed to be a concern in multiple reviews.",Does the review address Related Work?,TRUE,FALSE,The review discusses addition of related work and suggests more detailed comparisons.
"It requires more analysis about experimental results, such as Figure 1 and tables in Section D.",Does the review address Analysis?,TRUE,FALSE,The review requests more analysis of experimental results and figures.
"This is in sharp contrast to computer vision where techniques like rotation, modification of hue, saturation as well as umpteen other techniques exist.",Does the review address Presentation?,TRUE,FALSE,The review contrasts with computer vision techniques for context.
I would recommend the authors to at least assume the availability of some public data that is kept out of training and evaluations and to run all the baselines fairly in this setting.,Does the review address Methodology?,TRUE,FALSE,The review suggests methodology changes regarding public data usage.
is a micro-average (all testsets are concatenated and evaluated as one set) or macro-average (average taken across the scores of individual test sets) score.,Does the review address Methodology?,TRUE,FALSE,The review discusses scoring methodology (micro vs macro averaging).
* Section 4 - I think you really need to re-state that the algorithm has a human-in-the-loop for clarity.,Does the review address Presentation?,TRUE,FALSE,The review suggests clarifying human-in-the-loop aspect in Section 4.
"I appreciate that the authors do not read too much into it and focus more on the analysis of the results, but one thing that remains unanswered in this paper is how the proposed method fairs against multilingual baselines that utilize (roughly) the same number of parameters; currently, the best models outperform the LS baseline by ~28M and ~10M parameters on OPUS-100 and WMT-14 respectively.",Does the review address Result?,TRUE,FALSE,The review discusses performance comparison with multilingual baselines.
"The authors say ""we focus on larger datasets from GLUE (MNLI, QNLI, QQP and SST-2), as it is less meaningful to discuss efficient training"", but then report and analyze results from other GLUE datasets as well.",Does the review address Analysis?,TRUE,FALSE,The review points out inconsistency in dataset analysis.
There are several parts to the method and there are I assume several differences in the architecture etc with baselines etc.,Does the review address Methodology?,TRUE,FALSE,The review discusses architectural differences with baselines.
"These objectives certainly improve over the original T5 base _and_ larges models that are used as initializations, and especially outperform the base model in the low-data regime.",Does the review address Methodology?,TRUE,FALSE,"The review discusses improvement over T5 models, especially in low-data regime."
"Given the success of MLM as a powerful pre-training objective, please consider formulating your claims in a more general way.",Does the review address Methodology?,TRUE,FALSE,The review suggests generalizing claims about MLM pre-training objective.
The Ablation Study of the paper also provides useful insights about the impact of different pre-training schemas on large-scale information retrieval tasks.,Does the review address Ablation?,TRUE,FALSE,The review discusses insights from ablation study about pre-training schemas.
Do you want to claim that this structure design is inspired by RNN and it leads to a better result?,Does the review address Result?,TRUE,FALSE,The review questions relationship between RNN-inspired structure and results.
"Provide a formal definition for ""general learner"" before stating the proposition.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review requests formal definition of ""general learner""."
* One idea I had here: Could you define a natural task as one for which there exists a sparse linear model over the *logits* of p*( .,Does the review address Result?,FALSE,TRUE,The review suggests a definition but doesn't discuss results.
"But from the paper, I can hardly tell what the researchers should proceed to further improve the performance.",Does the review address Result?,TRUE,FALSE,The review discusses lack of clarity about performance improvement directions.
"Concerning the claim, “the proposed fully-explored masking strategies lead to pre-trained models with stronger generalization ability.”, it is not clear how the proposed method yields stronger generalization ability.",Does the review address Methodology?,TRUE,FALSE,The review questions claim about generalization ability from masking strategies.
"- wMAN explicitly utilized multi-level context information between the sentence and the video frame, and used the graph neural network and the message passing to model the representation.",Does the review address Presentation?,TRUE,FALSE,The review explains wMAN's utilization of multi-level context information.
"Without the experimental results using the same training settings, I do not think the authors are able to prove the superiority of OTTER over CLIP fully.",Does the review address Result?,TRUE,FALSE,The review discusses inability to prove OTTER's superiority without comparable settings.
"Also it seems that these are not fully annotated, and the ‘forward type inference functionality from TypeScript’ is required to obtain labels.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses annotation and label acquisition process.
CALM shows better results with less data than the base model.,Does the review address Methodology?,TRUE,FALSE,The review mentions CALM's performance with less data.
"What is ""in-distribution"" instructions and how would an instruction from non-oracle look to an instruction from oracle?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review asks for clarification about ""in-distribution"" instructions."
"It's ok for the proposed method to be one particular way, but that discussion would be useful.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests adding discussion about proposed method.
"Indeed, the proposed graph model seems to only implicitly convey knowledge across facts in terms of local reasoning.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review explains how the graph model conveys knowledge.
Can the proposed theory help explain if the same code modeling task for some languages is strictly easier than the others?,Does the review address Methodology?,FALSE,TRUE,"The review asks about theoretical implications for different languages, not methodology."
Their models achieve better quantitative results when compared to the provided baselines.,Does the review address Comparison?,TRUE,FALSE,The review discusses quantitative results compared to baselines.
"Also, the authors did a great job in terms of conducting evaluations from different angles.",Does the review address Evaluation?,TRUE,FALSE,The review praises comprehensive evaluation approach.
- Choice of baselines: For the VIMABench I find the choice of baselines not insightful.,Does the review address Comparison?,TRUE,FALSE,The review criticizes choice of baselines for VIMABench.
Using a model capable of streaming would make sense from the point of view of inductive biases.,Does the review address Methodology?,TRUE,FALSE,The review discusses model choice regarding streaming capabilities.
Will need some clarification to better judge the results.,Does the review address Presentation?,TRUE,FALSE,The review requests clarification for better result interpretation.
I suggest the authors investigate the effect of such differences.,Does the review address Analysis?,TRUE,FALSE,The review suggests investigating effect of differences.
"- (The supplied code does not seem to include the baselines, just the recursive NN models.",Does the review address Comparison?,TRUE,FALSE,The review notes missing baseline code.
"With the strengths being said, I hope to also point out that the paper's application of adversarial training is one attempt in many possibilities, and in many cases it is not clear where the improvements come from.",Does the review address Result?,TRUE,FALSE,The review discusses unclear source of improvements.
The methods is evaluated on 5 standard NER+RE datasets with good performances.,Does the review address Result?,TRUE,FALSE,The review mentions performance on NER+RE datasets.
"The architecture does not look entirely novel, but I kind of like the simple and practical approach compared to prior work.",Does the review address Methodology?,TRUE,FALSE,The review discusses architectural approach compared to prior work.
"Given the nature of the problem statement (with multiple tasks, inputs and outputs), the authors have done a good job in explaining each of them properly.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review praises explanation of multiple tasks, inputs and outputs."
"PE seems to be important for wMAN, and the authors provides few sentences analysis about this, but I don't think I fully understand this part.",Does the review address Analysis?,TRUE,FALSE,The review discusses insufficient analysis of PE's importance.
"This is especially disappointing as the objectives introduced _directly_ match the task in CommonGEN, making this intermediate training a form of noisy training data rather than pretraining.",Does the review address Methodology?,TRUE,FALSE,The review criticizes matching of objectives to CommonGEN task.
"Within the evaluation section, there are numerous intriguing findings that hold significant value for dissemination within the wider research community.",Does the review address Result?,TRUE,FALSE,The review mentions valuable findings in evaluation section.
The authors present a simple technique for in-context learning with large language models that achieves consistently good results across a variety of NLP tasks.,Does the review address Result?,TRUE,FALSE,The review discusses consistent performance across NLP tasks.
"Weakness While the ablation study and visualization analysis are done, the key evaluations are missing.",Does the review address Analysis?,TRUE,FALSE,The review mentions completed analyses but missing key evaluations.
Some important concepts are repeatedly used without a definition.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review criticizes undefined important concepts.
lead to performance decrease for individual tasks.,Does the review address Data/Task?,TRUE,FALSE,The review mentions performance impact on individual tasks.
"For example, is there any restriction on the parameters in encoder and decoder respectively to reflect the property $UR=I$ as in Section 2.",Does the review address Theory?,TRUE,FALSE,The review questions theoretical property implementation.
"Indeed, at first, the words ""The following algorithm"" confused me, because I thought it was more a ""methodology"", since Step 2 is where the humans are in the loop, unless you have a Fon POS tagger and I am misunderstanding?",Does the review address Methodology?,TRUE,FALSE,The review discusses confusion about algorithm vs methodology terminology.
"(3) This model still needs to calculate the similarity matrix for queries and documents, so the computational efficiency is not improved compared with other multi-vector retrieval models in the training stage.",Does the review address Methodology?,TRUE,FALSE,The review discusses computational efficiency of similarity matrix calculation.
"This is relevant because, by training end to end, that work effectively generates arbitrary amounts of training data through interaction the the HOL4 ITP system (intermediate theorems which are proven give some reward in that work).",Does the review address Methodology?,TRUE,FALSE,The review explains end-to-end training methodology with HOL4 ITP system.
Concerns around novelty and the multi-task setup was also raised by another reviewer (e7Hg).,Does the review address Data/Task?,TRUE,FALSE,The review mentions concerns about multi-task setup.
"- P3, Sec 2.2: ""... achieve lower test perplexity than traditional n-gram models"" Why is this true?",Does the review address Methodology?,TRUE,FALSE,The review questions claim about test perplexity comparison.
There’s not much that can be faulted and all my comments below are meant to help the paper gain additional clarity.,Does the review address Presentation?,TRUE,FALSE,The review discusses paper clarity improvements.
The findings illustrate the substantial impact this choice can have on the final model's behavior.,Does the review address Result?,TRUE,FALSE,The review discusses impact of choices on model behavior.
"For example, is there any restriction on the parameters in encoder and decoder respectively to reflect the property $UR=I$ as in Section 2.",Does the review address Methodology?,TRUE,FALSE,The review questions parameter restrictions in encoder-decoder setup.
Weakness   The paper is poorly organized and very hard to follow.,Does the review address Presentation?,TRUE,FALSE,The review criticizes poor organization and difficulty following the paper.
They have evaluated their architecture based on (i) the language modelling test evaluated on PTB and FBIS and (ii) Chinese-English machine translation task on NIST MT02-08 evaluation sets.,Does the review address Evaluation?,TRUE,FALSE,The review describes specific evaluation tasks and datasets.
- How will the pseudo data generation amount affect the learning / forgetting performance?,Does the review address Data/Task?,TRUE,FALSE,The review questions impact of pseudo data generation on performance.
NIT:  - Grammar last sentence of Section 1.1 (“…analyze the efficiency *of* …”) - Proposition 2.2: Maybe write “\forall s \in S” instead of “\forall s ~ p_L”.,Does the review address Presentation?,TRUE,FALSE,The review points out grammar and notation issues.
An emerging use of LeetCode is to use it as a baseline for machine programming (MP) in a variety of different ways.,Does the review address Data/Task?,TRUE,FALSE,The review discusses LeetCode's use as baseline for machine programming.
"- Technical Novelty and Significance: 3 - Empirical Novelty and Significance: 1  ## Questions _What_ is unique about the environment has been presented well, so my primary question is _how_ is it unique?",Does the review address Novelty?,TRUE,FALSE,The review discusses technical and empirical novelty scores.
"While this is not a downside by itself, it is probably something that one implement as a baseline.",Does the review address Comparison?,TRUE,FALSE,The review suggests implementation as a baseline.
"- After definition 5.1, what does Omega[w] = Omega[w’] mean?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review asks for clarification of definition terms.
Conducting real-human interactions can better justify the effectiveness of the proposed RL method in practical scenarios.,Does the review address Presentation?,TRUE,FALSE,The review suggests real-human interactions for better justification.
"In the first phase (match), they extract knowledge tuples from each sentence in a corpus using a beam search over the self-attention within a pre-trained language model.",Does the review address Methodology?,TRUE,FALSE,The review describes knowledge tuple extraction methodology.
Since we observe that the randomly pruned models do not competitive performance ...: how uncompetitive?,Does the review address Presentation?,TRUE,FALSE,The review requests clarification about performance comparison.
"To name a few:   -“Language Models as Knowledge Bases?” EMNLP 2019   -“Commonsense Knowledge Mining from Pretrained Models.” EMNLP 2019   -“Comet: Commonsense Transformers for Automatic Knowledge Graph Construction.” ACL 2019 - Although the proposed model achieves quantitative improvements over Angeli et al. (2015), it seems unclear whether these improvements are due to the factual knowledge encoded in the pre-trained LM, as claimed.",Does the review address Related Work?,TRUE,FALSE,The review lists related papers and discusses improvements over prior work.
The theory is a bit complicated and not easy to follow.,Does the review address Methodology?,FALSE,TRUE,"The review discusses theory complexity, not methodology."
"- Similarly, using bold and not-bold B in Theorem 5.2 is confusing notation.",Does the review address Theory?,TRUE,FALSE,The review criticizes confusing notation in theoretical presentation.
I feel that the conclusions are in general well supported by the results.,Does the review address Result?,TRUE,FALSE,The review states conclusions are supported by results.
"Then it is reasonable to include the baseline suggest above, i.e. input additional features.",Does the review address Comparison?,TRUE,FALSE,The review suggests including additional baseline comparison.
"Writing:  The writing is overall clear and easy to follow, although it took me quite some time to map out the definitions of various notations.",Does the review address Presentation?,TRUE,FALSE,The review discusses writing clarity and notation complexity.
"## Justification As my primary critique concerns the experiments, I will address each individually mentioning any deficiencies and potential improvements.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review announces critique of experimental justification.
The method proposed has limited methodology contribution to the research community.,Does the review address Methodology?,TRUE,FALSE,The review suggests definition of natural task.
* One idea I had here: Could you define a natural task as one for which there exists a sparse linear model over the *logits* of p*( .,Does the review address Data/Task?,TRUE,FALSE,The review discusses comprehensive evaluation of prompt example selection.
This paper conducts comprehensive evaluations on the influence of selecting specific examples for inclusion in the prompt.,Does the review address Evaluation?,TRUE,FALSE,The review references MTL (Multi-Task Learning) literature.
The authors refer to the fact that MTL can (and often does!),Does the review address Related Work?,TRUE,FALSE,The review discusses lack of experimental results with comparable training settings.
"Without the experimental results using the same training settings, I do not think the authors are able to prove the superiority of OTTER over CLIP fully.",Does the review address Experiment?,TRUE,FALSE,The review explicitly mentions and praises ablations in section B.
---- Appendix: ----  I liked the section B ablations (as implied above).,Does the review address Ablation?,TRUE,FALSE,The review discusses potential application to other domains.
"In my opinion, this idea has a potential to be applied to domains other than theorem proving.",Does the review address Methodology?,TRUE,FALSE,The review suggests discussing specific related work in spatial visualization.
Should also discuss related work in 2d spatial visualization of country-country relationships by Peter Hoff and Michael Ward.,Does the review address Related Work?,TRUE,FALSE,The review discusses focus on training and inference efficiency.
"The paper focuses on a critical and urgent issue, the training and inference efficiency of LLMs.",Does the review address Methodology?,TRUE,FALSE,The review describes improvement from adding similar sentences to context.
The empirical part of the paper shows improved performance of adding similar sentences to the context of LM training.,Does the review address Methodology?,TRUE,FALSE,The review suggests adding references to multi-task training examples.
"Additionally, there are some minor things I would add or improve: - I would add references to multi-task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE).",Does the review address Related Work?,TRUE,FALSE,The review discusses justification for RNN vs deep recurrent neural networks.
"As, deep recurrent neural networks are already used in keyphrase extraction (shows very good performance also), so, it will be interesting to have a proper motivation to justify the use of  RNN and Copy RNN over deep recurrent neural networks.",Does the review address Methodology?,TRUE,FALSE,The review discusses novelty of replacing perceptual modules with foundation models.
"- I think it makes sense in the comparison with CaP to compare using an oracle object detector, but one of the main novelties of the work is replacing the perceptual modules of CaP with foundation models.",Does the review address Methodology?,TRUE,FALSE,The review explicitly discusses novelty compared to previous VLMs.
"The proposed method represents a novel approach to multimodal techniques, distinguishing itself from previous Vision-Language Models (VLMs) like Flamingo and PaLI.",Does the review address Novelty?,TRUE,FALSE,The review discusses BERT pretraining sensitivity to optimizers.
This reminds us of the sensitivity of BERT pretraining to the optimizers.,Does the review address Methodology?,TRUE,FALSE,The review questions justification of choices and thresholds.
Such choice and associated thresholds seem arbitrary: how were they actually found out?,Does the review address Presentation?,TRUE,FALSE,"The review explains the term ""decompilation""."
"As I understand it, it’s called decompilation because it tends to do the opposite of what a compiler does.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review questions mathematical notation and dimensions.
"\phi(x) as introduced in eq 2 is in R^{2D} but S_{t-1} is in R{D}, not sure what does + mean in this context.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review notes thorough study of model robustness.
Strength: - Thorough study on the robustness of recent popular VL models vs conventional CE models.,Does the review address Presentation?,FALSE,TRUE,"The review discusses value of human evaluation, not novelty."
The Human evaluation study adds a ton of value in judging LTU in my perspective.,Does the review address Novelty?,TRUE,FALSE,The review discusses new method for symbolic stimuli representation.
**SCS**  The authors propose a new method to represent symbolic stimuli as continuous representations as an alternative to one-hot encodings.,Does the review address Methodology?,TRUE,FALSE,The review discusses experimental validation of method effectiveness.
Experiments on both continual pre-training and general pre-training from scratch show the effectiveness of the proposed method.,Does the review address Methodology?,TRUE,FALSE,The review explicitly mentions novelty of the proposed idea.
"Reasons for Score ----------------- The idea proposed in the paper is novel and exciting, but I have some concerns about whether the gains promised by the theoretical analysis can be realized while maintaining modeling quality.",Does the review address Novelty?,TRUE,FALSE,The review discusses substitution of self-attention with Legendre Memory Unit.
* Using the Legendre Memory Unit to substitute self-attention in transformers is interesting and has several potential merits: it can reduce the complexity and does not increase the size of the layer.,Does the review address Methodology?,TRUE,FALSE,The review discusses experimental results comparing orders.
"Experiments show that the induced ""best-first"" order outperforms fixed orders, which verifies the motivation of the paper` 4.",Does the review address Experiment?,TRUE,FALSE,The review suggests analysis of comparative model performance.
"Additionally, showing this for negations and / or examples which GreaseLM gets correct but QA-GNN does not (and vice-versa) can shed some light on what the model improves on (and what are the limitations).",Does the review address Result?,TRUE,FALSE,The review criticizes lack of explanation for core contribution.
"Even if pruning is ineffective (at multiple pruning rates), it’s never really explained why, despite this being a core contribution of the paper.",Does the review address Contribution?,TRUE,FALSE,The review discusses importance of parameter reduction methodology.
"Overall, I like the idea of the paper: it is important to reduce the parameters needed for sets of tasks, to enable NLP models to be deployed in a larger variety of settings, and reducing the amount of data needed.",Does the review address Methodology?,TRUE,FALSE,The review discusses various methodological insights about architecture and learning approaches.
"The authors provide several reasonable insights that might be relevant to the user interface modeling community — using object detection as part of multi-task learning instead of standalone pre-training task, design choices to create a single unified architecture for all the tasks, multi-task learning outperforming single-task learning etc.",Does the review address Methodology?,TRUE,FALSE,The review discusses novel approach to combining text and KB information.
The paper presents a novel way of combining information from text and a KB in a bidirectional way.,Does the review address Methodology?,TRUE,FALSE,The review discusses fairer comparison enabled by CaptionNet dataset.
"With the proposed CaptionNet dataset, it is now possible to have a fairer comparison between VL models and CE models.",Does the review address Comparison?,TRUE,FALSE,The review discusses approach to generating diverse label preserving examples.
This work tries to address the issue by proposing a technique that carefully amalgamates multiple previously known approaches to generate diverse label preserving examples.,Does the review address Data/Task?,TRUE,FALSE,The review suggests broader comparison with state-of-the-art methods.
"For a more comprehensive analysis, it would be instructive to see how the approach compares with a broader spectrum of state-of-the-art methods.",Does the review address Analysis?,TRUE,FALSE,The review suggests adapting CaP as a more insightful baseline.
I think adapting CaP to the VIMA benchmark would be a more insightful baseline.,Does the review address Comparison?,TRUE,FALSE,The review comments on clarity of experimental results presentation.
**Experimental results** The presentation of the experimental results is clear.,Does the review address Experiment?,TRUE,FALSE,The review questions methodology through authors' approach.
What did the authors do in their attempt to find it?,Does the review address Methodology?,TRUE,FALSE,The review discusses lack of clarity about model's reliance on inputs.
It is not intuitive to understand to what extent the model relies on the input audio versus on the common sense knowledge that is already encoded in the LLMs.,Does the review address Presentation?,TRUE,FALSE,The review suggests need for more pruning rates for fair comparison.
"Especially because of the surprising magnitude by which this pruning degrades absolute performance, it is unfortunately necessary to try more pruning rates for a fair comparison.",Does the review address Comparison?,TRUE,FALSE,The review discusses VIP application in interpretable approaches.
It paves the way for more widespread application of VIP in scenarios where interpretable-by-design approaches are critical.,Does the review address Methodology?,TRUE,FALSE,The review discusses similar conclusions from paper results.
I felt similar conclusions can be drawn from the results of that paper as well.,Does the review address Result?,TRUE,FALSE,The review discusses generality of theorem to polynomial-size circuits.
All of the results in this work seem to be previously known: * Theorem 1 is general to any polynomial-size circuit -- there is nothing special about Transformers.,Does the review address Methodology?,TRUE,FALSE,"The review criticizes explanation of models, experimentation, and evaluation."
"Unfortunately, many aspects of the models, experimentation, and evaluation are not explained very well.",Does the review address Experiment?,TRUE,FALSE,The review discusses gradient analysis for regularization effect.
This paper set an assumption that the teacher network makes a less confident prediction than that of the student and extends gradient analysis in the perspective of regularization effect in the proposed adaptive label smoothing.,Does the review address Analysis?,TRUE,FALSE,The review describes word representation splitting methodology.
Both split single word representation into multiple prototypes by using a mixture model.,Does the review address Methodology?,TRUE,FALSE,The review criticizes lack of consideration for model structure and loss.
There seems to be a lack of thought about model structure and loss.,Does the review address Methodology?,TRUE,FALSE,The review requests supporting evidence for correctness.
It would be great if the authors discuss this or provide some supporting evidence about its correctness.,Does the review address Evaluation?,TRUE,FALSE,The review describes key technique using type dependency graph.
The key technique is to construct a type dependency graph and infer the type on top of it.,Does the review address Methodology?,TRUE,FALSE,The review discusses technical and empirical significance ratings.
"- Technical Novelty and Significance: 3 - Empirical Novelty and Significance: 1  ## Questions _What_ is unique about the environment has been presented well, so my primary question is _how_ is it unique?",Does the review address Significance?,TRUE,FALSE,The review discusses fair comparison requirements.
"For instance, ensuring that comparisons are fair (same number of parameters, etc) for the object detection task.",Does the review address Comparison?,TRUE,FALSE,The review suggests table formatting improvements.
"Try using horizontal lines only after each UD tag category, and consider the ""booktabs"" guidelines for making good-looking tables.",Does the review address Presentation?,TRUE,FALSE,The review discusses use of cosine similarity in word embeddings.
The idea of using cosine similarity in word embeddings is a simple but effective way of biasing the MCTS in the right directions.,Does the review address Methodology?,TRUE,FALSE,The review discusses findings' contribution to understanding.
Their findings on learning complex tasks contribute to the understanding of large language model learning and provide valuable insights for future related work on efficient training.,Does the review address Result?,TRUE,FALSE,The review mentions promising experimental results compared to existing models.
The experimental results also look promising in compared with the exsiting models.,Does the review address Experiment?,TRUE,FALSE,The review discusses experimental convincingness as evaluation criteria.
"The paper appraisal therefore rests on the clarity of presentation, how convincing the experiments are, and how reproducible.",Does the review address Experiment?,TRUE,FALSE,The review mentions experiments containing 3 different tasks with different domain datasets.
- Experiments contain 3 different tasks and each has datasets from different domains.,Does the review address Data/Task?,TRUE,FALSE,
"For polysynthetic languages, though, one could posit that a fairly small set of rules might be highly predictive - humans invoke algorithms to construct patterned speech that would otherwise be incomprehensible for the listener to deconstruct, and those same algorithms can be encoded for use by machines.",Does the review address Methodology?,TRUE,FALSE,The review discusses algorithmic approach for polysynthetic languages.
"It seems like a hard task (there are hundreds of those CAMEO categories....) Did the authors consider using the Goldstein scaling, which has been used in political science, as well as the cited work by O'Connor et al.?",Does the review address Related Work?,TRUE,FALSE,The review references Goldstein scaling and O'Connor's work.
"**Strengths** - To the best of my knowledge, this is the first work that _mathematically_ justifies the connection between the pre-training objective and the downstream performance.",Does the review address Result?,FALSE,TRUE,"The review discusses mathematical justification of connection, not results."
"The results are highly correlated with concepts that are actually present in the images; i.e., there seems to be very little confabulation (often called “hallucination”).",Does the review address Result?,TRUE,FALSE,The review discusses correlation between results and actual image concepts.
"Other designs include beam size, whether or not to use a pretrained model, etc.",Does the review address Experiment?,TRUE,FALSE,The review mentions experimental design choices.
A single value of $k=150$ was chosen for experiments across all tasks.,Does the review address Experiment?,TRUE,FALSE,The review discusses specific experimental parameter choice (k=150).
"In addition, I have several notation confusions:  Assumption1: What is the hamming distance m_1 and m_2, when m_i are random variables?",Does the review address Methodology?,TRUE,FALSE,The review questions methodological notation about Hamming distance.
One may also refer to https://opencompass.org.cn/leaderboard-llm for the performance of LLMs (I acknowledge that the performance of ChatGPT on GSM8K from that website is possibly still underestimated).,Does the review address Result?,TRUE,FALSE,The review references performance metrics from leaderboard.
"Some discussions are required on the convergence of the proposed joint learning process (for RNN and CopyRNN), so that readers can understand, how the stable points in probabilistic metric space are obtained?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests discussion of convergence process.
"Their goal is to reduce the amount of parameters and data needed, while improving (or maintaining) state-of-the-art performance.",Does the review address Result?,TRUE,FALSE,The review discusses goals regarding parameter reduction and performance.
"- There are also many typos in the text, for example page 2: “Our results that when” -> “Our results show that when”, page 5: “CaptionNet subset can be found in Section ?",Does the review address Presentation?,TRUE,FALSE,The review points out specific typos in the text.
"For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.",Does the review address Result?,TRUE,FALSE,The review compares performance metrics between models.
"The authors switch between using BERT_base and RoBERTa_base without being very clear about when and why, e.g., in Table 2 they have both models, but only in different sections.",Does the review address Evaluation?,TRUE,FALSE,The review criticizes unclear model choice between BERT and RoBERTa.
I would appreciate the explanation and further evidence to address these concerns.,Does the review address Result?,FALSE,TRUE,The review requests explanation but doesn't discuss results.
In case of the textual prompts benchmarks its also not clear to me why no standard errors on results are reported?,Does the review address Result?,TRUE,FALSE,The review questions lack of standard errors in results reporting.
"The experimental settings in Section 3 lack detailed descriptions, potentially making reproduction difficult and potentially misleading.",Does the review address Experiment?,TRUE,FALSE,The review criticizes lack of experimental setting details.
"For checking the generalization of the method and better comparison w/ InDIGO (though InDIGO also conducted on MSCOCO, Django and the current comparison is sufficiently fair), I would like to increase my rating if seeing more experiments on large scale machine translation benchmarks as those in InDIGO.",Does the review address Comparison?,TRUE,FALSE,The review discusses comparison with InDIGO and suggests additional experiments.
A key parameter that occurs in obtaining the above results is a worst-case coefficient that bounds the distributional shift between language model distributions of the training dataset and that of the downstream task.,Does the review address Methodology?,TRUE,FALSE,The review discusses key parameter for distributional shift.
"- There's a clear Inconsistency in the best TC method between different latent dimensions (8,6,32), in most of the experiments there's at least one of the 3 that is performing drastically worse than the other baselines, while there's overall no clear winner.",Does the review address Result?,TRUE,FALSE,The review discusses inconsistency in TC method performance.
"It's also not explained how Theorem 2 justifies the main conclusion: that ""a prompt engineer aided by enough time and memory can force an LLM to output an arbitrary sequence of ℓ tokens.""",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review criticizes lack of explanation for Theorem 2's implications.
It is hard to know here which one of these actually made the adversarial setup useful.,Does the review address Result?,TRUE,FALSE,The review discusses uncertainty about adversarial setup effectiveness.
"Altogether, I think this paper makes an interesting contribution to the question of: How can we get the most pretraining signal from unstructured data using off-the-shelf tools?",Does the review address Data/Task?,TRUE,FALSE,The review discusses pretraining signal from unstructured data.
The evaluation method uses CCA to maximize the correlation between the word embeddings and possibly hand crafted linguistic data.,Does the review address Data/Task?,TRUE,FALSE,The review describes evaluation method using linguistic data.
"To best of my knowledge, under many circumstances in particular for short sequence, attention alone might not be the  most time-consuming part of the model.",Does the review address Methodology?,TRUE,FALSE,The review discusses computational aspects of attention mechanism.
This may strengthen the contribution of the paper.,Does the review address Contribution?,TRUE,FALSE,The review discusses potential strengthening of paper's contribution.
"The evaluation results are based on the authors' implementations, for both baseline and the proposed method.",Does the review address Evaluation?,TRUE,FALSE,The review discusses implementation basis of evaluation results.
- Using capital and lower case tau in Theorem 4.2 is confusing notation.,Does the review address Theory?,TRUE,FALSE,The review criticizes confusing notation in theoretical presentation.
"In algorithm 1, in each iteration, only data sample (S_i) is used, how is this choice motivated?",Does the review address Methodology?,TRUE,FALSE,The review questions motivation for data sample usage in algorithm.
There's also some missing related work in extracting knowledge from pretrained models that should probably be discussed.,Does the review address Presentation?,TRUE,FALSE,The review notes missing discussion of related work.
"As such, in my opinion this is unquestionably an important subtopic for the field of machine programming and the authors approach also seems satisfactory to me for ICLR (described below).",Does the review address Significance?,TRUE,FALSE,The review discusses importance of topic for machine programming field.
"More importantly, the experiments are not convincing as it is presented now.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review criticizes experiment presentation.
"If the tasks are not similar, and the learning objectives are not aligned, then the motivation for multi-task learning is solely for reducing memory footprint and computational cost.",Does the review address Data/Task?,TRUE,FALSE,The review discusses task similarity and learning objectives.
"Further, how does the network perform when a longer context is obtained *maintaining the same number of parameters* as a network with less temporal scales?",Does the review address Methodology?,TRUE,FALSE,The review questions network performance with parameter constraints.
"This paper proposes the adaptive \alpha computed by the entropic level of model probability distribution per sample, which leads to updating the model parameters to lower the predictive score on the ground-truth target, as opposed to the effect of the cross-entropy with hard targets.",Does the review address Methodology?,TRUE,FALSE,The review describes adaptive alpha computation methodology.
"Compared to Pengi, the closed-ended audio task performances are lower.",Does the review address Result?,TRUE,FALSE,The review compares performance with Pengi on audio tasks.
"In sum, the proposed method is relatively novel and the idea is reasonable.",Does the review address Novelty?,TRUE,FALSE,The review explicitly mentions method's relative novelty.
- What is it about an audio channel model that makes compositionality easier or more difficult to learn?,Does the review address Methodology?,TRUE,FALSE,The review questions impact of audio channel model on compositionality.
"Their goal is to reduce the amount of parameters and data needed, while improving (or maintaining) state-of-the-art performance.",Does the review address Data/Task?,TRUE,FALSE,The review discusses goals for parameter and data reduction.
The authors chose to not rerank if the candidates' scores are too low or high but close.,Does the review address Experiment?,TRUE,FALSE,The review discusses experimental choice about candidate reranking.
"In the least, it's unclear how to assess the differences shown in this table.",Does the review address Presentation?,TRUE,FALSE,The review criticizes unclear table differences presentation.
My main problem with this paper at the moment is that it could be much better written: The overall narrative of the paper is unpolished and it’s hard at first to understand the contributions of the paper.,Does the review address Presentation?,TRUE,FALSE,The review criticizes overall paper writing and narrative.
The idea of learning which parameters to share across languages in multilingual transformer models is original and potentially useful for designing and analyzing multilingual models in the context of NMT.,Does the review address Methodology?,TRUE,FALSE,The review discusses originality of parameter sharing approach.
"I do understand that the main point is the reduction of the amount of parameters (per task), but this doesn't mean that the evaluation should paint a wrong picture.",Does the review address Methodology?,TRUE,FALSE,The review discusses parameter reduction evaluation concerns.
It is therefore not surprising that multi-task learning should help these tasks.,Does the review address Data/Task?,TRUE,FALSE,The review discusses multi-task learning benefits.
"Had `calculateTime()` been part of some standard library shared between programs, the case for generalization would have been much stronger.",Does the review address Methodology?,TRUE,FALSE,The review discusses generalization implications of library usage.
- General Discussion: It would be nice if the survey of prior work in 2.2 explicitly related those methods to the desiderata in the introduction (i.e. specify which they satisfy).,Does the review address Related Work?,TRUE,FALSE,The review suggests relating prior work to introduction desiderata.
"Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",Does the review address Ablation?,TRUE,FALSE,The review mentions ablation study among multiple tests.
This paper demonstrates why self-knowledge distillation as a prior distribution is a form of regularization with theoretical analysis on the gradients.,Does the review address Analysis?,TRUE,FALSE,The review discusses theoretical analysis of self-knowledge distillation.
Performance better than previous approaches (although minor).,Does the review address Comparison?,TRUE,FALSE,The review mentions performance comparison with previous approaches.
"Steinert-Threlkeld (2020) ""Towards the Emergence of Non-trivial Compositionality"" makes similar points and could be cited here as well.",Does the review address Related Work?,TRUE,FALSE,The review suggests citing specific related work by Steinert-Threlkeld.
It could be easy to be re-implemented and deployed for further research.,Does the review address Methodology?,TRUE,FALSE,The review discusses implementation and deployment potential.
"Additionally, it would be good if the authors could report the number of examples (either raw number or as a fraction of the total dev set) for each of the categories: having that would help draw better conclusions.",Does the review address Data/Task?,TRUE,FALSE,The review requests reporting of example counts for categories.
"For example, the $p^{\star}$ notation is also defined in Sec 2.1.",Does the review address Presentation?,TRUE,FALSE,The review points out notation definition redundancy.
The evaluation process shows that the current system (which extracts 1.,Does the review address Evaluation?,TRUE,FALSE,The review discusses evaluation process.
I think the presentation of the paper needs to be improved.,Does the review address Presentation?,TRUE,FALSE,The review explicitly states need for presentation improvement.
So my point 5 is important to answer and I would like to see all the details are clarified in order to make the contribution stronger.,Does the review address Presentation?,TRUE,FALSE,The review requests clarification of details for stronger contribution.
Is this threshold a hyper-parameter need to be configured?,Does the review address Presentation?,TRUE,FALSE,The review questions threshold configuration clarity.
"-----General Discussion----- This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths).",Does the review address Methodology?,TRUE,FALSE,The review discusses practicality and novelty of model.
"The overall problem is framed as a judgment question, further enhancing the method's Uniqueness and Efficiency.",Does the review address Methodology?,TRUE,FALSE,The review discusses problem framing methodology.
And more space can be freed up to further explain the results section.,Does the review address Result?,TRUE,FALSE,The review suggests expanding results section explanation.
"As similar efforts are already applied in several query expansion techniques (with the aim to relate the document with the query, if matching terms are absent in document).",Does the review address Related Work?,TRUE,FALSE,The review references similar query expansion techniques.
The authors also propose two novel pre-training settings which also show improvement over the baseline BM-25.,Does the review address Result?,TRUE,FALSE,The review discusses improvement over BM-25 baseline.
There are some unclear expressions and inconsistent explanations.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out unclear and inconsistent explanations.
"In order to train reading comprehension models to perform relation extraction, they create a large dataset of 30m “querified” (converted to natural language) relations by asking mechanical turk annotators to write natural language queries for relations from a schema.",Does the review address Data/Task?,TRUE,FALSE,The review describes dataset creation process for relation extraction.
I also did not find a Related Work section discussing this in more detail.,Does the review address Related Work?,TRUE,FALSE,The review notes missing Related Work section.
"The description of the baselines is lacking and quite confusing: it's not clear why the authors have two DP-SGD baselines, and what they're exactly updating during training.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review criticizes unclear baseline descriptions.
Experimental results show improvements over both the base T5 model and the large T5 model.,Does the review address Methodology?,TRUE,FALSE,The review discusses model improvement over T5 models.
This is very promising to simplify the construction of highly tuned task-specific neural pipelines and improve the multimodal and multi-task problems.,Does the review address Methodology?,TRUE,FALSE,The review discusses implications for neural pipeline construction.
strengths 1) This paper is well written and easy to read.,Does the review address Presentation?,TRUE,FALSE,The review praises paper writing and readability.
The world oracle conveys the meaning of being absolute truth which sounds a bit unexpected.,Does the review address Presentation?,TRUE,FALSE,"The review discusses unexpected use of term ""oracle""."
The method proposed has limited methodology contribution to the research community.,Does the review address Contribution?,TRUE,FALSE,The review criticizes limited methodological contribution.
"We expect that the model can not only achieve good performance on a single dataset, but also have the potential to transfer beyond a single dataset.",Does the review address Data/Task?,TRUE,FALSE,The review discusses cross-dataset transfer potential.
"I think authors wanted to say that even though BROS does not rely on visual features, it does outperform LayoutLM which, in turn, uses visual features.",Does the review address Result?,TRUE,FALSE,The review clarifies performance comparison with LayoutLM.
"Authors could have provided more in-depth details (visualizations, analysis, examples) to show main differences between the proposed approach and baselines (specially LayoutLM).",Does the review address Analysis?,TRUE,FALSE,The review suggests need for more in-depth analysis and comparisons.
"Please report the total training and total inference time, and make a comparison with standard Transformer model.",Does the review address Methodology?,TRUE,FALSE,The review requests comparison of training and inference times with standard model.
"Generally speaking, this paper puts forward a universal retrieval scheme, and achieves good results, the specific advantages are as follows:  (1) The sparse alignment of multi-vector retrieval is a good solution to solve the retrieval effect and efficiency.",Does the review address Result?,TRUE,FALSE,The review discusses good results of sparse alignment retrieval scheme.
"Are the authors using off-the-shelf code (in which case, please refer and cite, which would also make it easier for the reader to understand and replicate if necessary)?",Does the review address Related Work?,TRUE,FALSE,The review asks about code references and citations.
"I am concerned this is quite low and could yield exaggerated instability, especially for large Transformer models.",Does the review address Methodology?,TRUE,FALSE,The review discusses concerns about instability in large Transformer models.
"Although the presentation can be polished, the overall narrative and explanation is clear and easy to follow.",Does the review address Presentation?,TRUE,FALSE,The review discusses clarity and narrative despite need for polish.
"Theoretically, they showed that synchronized updates to the low-level and high-level policy may never converge, yet asynchronized updates guarantees convergence.",Does the review address Methodology?,TRUE,FALSE,The review discusses theoretical findings about update synchronization.
"The authors say ""we focus on larger datasets from GLUE (MNLI, QNLI, QQP and SST-2), as it is less meaningful to discuss efficient training"", but then report and analyze results from other GLUE datasets as well.",Does the review address Data/Task?,TRUE,FALSE,The review points out inconsistency in dataset selection and reporting.
", do you mean Table 3?Does the review address Presentation?
1936The Non-trivial Sub-network"" paragraph feels like it should be part of the Experiments section.",Does the review address Experiment?,TRUE,FALSE,The review suggests reorganization of experimental section.
The way in which you have collected these samples is likely to create a bias towards simple missing conditions.,Does the review address Methodology?,TRUE,FALSE,The review discusses sampling bias in methodology.
They should have comparable numbers of parameters.,Does the review address Methodology?,TRUE,FALSE,The review discusses need for comparable parameter numbers.
They provide a training that guarantees convergence to local maxima.,Does the review address Methodology?,TRUE,FALSE,The review discusses training convergence guarantee.
"####Summary:  To tackle situations where compositionality is mostly required at inference time, the paper proposes a novel data augmentation method with an RNN based generator (recombination); to make the generator generate highly compositional patterns, the paper proposes a resampling method.",Does the review address Data/Task?,TRUE,FALSE,The review summarizes data augmentation method and generator approach.
* The paper is well motivated and easy to understand and follow.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review praises paper motivation and clarity.
"If successful, the approach could be impactful because it speeds up prediction.",Does the review address Significance?,TRUE,FALSE,The review discusses potential impact of approach.
It is then not clear how each fact block (grey squares in Figure 4) functions as a whole.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out unclear explanation of fact block functionality.
"* Because BPE is such a standard baseline, why do you not include it as a baseline?",Does the review address Comparison?,TRUE,FALSE,The review questions absence of BPE baseline comparison.
1.The performance of this model is closely related to both the AST encoding frontend and the LLaMA model's performance.,Does the review address Result?,TRUE,FALSE,The review discusses model performance dependencies.
"The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",Does the review address Experiment?,TRUE,FALSE,The review praises experimental details and ablation study.
"Due to the very “flat” portions of the softmax function, there can be meaningful differences between the logits corresponding to 2 different words, but the LM probabilities for those words are extremely similar (and thus, harder for a linear model to distinguish).",Does the review address Presentation?,TRUE,FALSE,The review explains softmax function implications for word probability distinctions.
"The work introduces the Transformer-QL, a transformer-based model that aims to capture long distance dependencies in the input.",Does the review address Methodology?,TRUE,FALSE,The review introduces Transformer-QL model's approach.
Some discussion on the current design choices and why making the proposed methods features to some of the other baselines is not a way to achieve some benefits is not the right way to do it.,Does the review address Comparison?,TRUE,FALSE,The review discusses design choices in relation to baselines.
Weaknesses: There is no contribution/novelty from the modeling/methods side.,Does the review address Contribution?,TRUE,FALSE,The review explicitly mentions lack of modeling/methods novelty.
The fact that the previous study reported a 126 perplexity baseline using LSTM and the LSTM's perplexity of 106.9 provided by the author showed that the FBIS gives an advantage to computing the language model's perplexity when tested on PTB.,Does the review address Methodology?,TRUE,FALSE,The review discusses LSTM perplexity comparisons across datasets.
I understand that LMU might have limited capacity but this is not specifically discussed and it is unclear how each component contributes to the end performance.,Does the review address Result?,TRUE,FALSE,The review discusses unclear component contributions to performance.
"In sec4.1, the authors said ""A batch size of 256 is employed, "", does that mean K=256 in Algorithm 1?",Does the review address Presentation?,TRUE,FALSE,The review asks for clarification about batch size parameter.
Many of the notations look cumbersome and I suspect that there is still room for making the notations more accessible for new readers.,Does the review address Presentation?,TRUE,FALSE,The review criticizes cumbersome notation and accessibility.
* It is explained in the paper that the runtime environment ensures that the proofs are never circular.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses explanation of proof circularity prevention.
It seems to be making every previously known augmentation approach better.,Does the review address Result?,TRUE,FALSE,The review discusses improvement over known augmentation approaches.
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Ablation?,TRUE,FALSE,The review mentions sufficiency of ablation study and visualization analysis.
"Prior work has explored ""learning-to-share""  strategies for parameter sharing in multi-task learning (see Ruder et al., AAAI 2018), and using gating/masking to control computational paths in a differentiable way (see Fan et al., ICLR 2019, Sukhbaatar et al., ACL 2019); it is clear that the focus is NMT but it should be worth mentioning/discussing such studies to better situate the work and to help the reader assess the actual contributions.",Does the review address Methodology?,TRUE,FALSE,The review discusses prior work on parameter sharing and gating strategies.
"In section 3.3.3 ""THE MIX-UP OF MULTIPLE TYPES,"" the authors mention that ""it is possible to embed multiple Double-I watermarks in a model, which theoretically has the potential to enhance the robustness of our watermarking technique.""",Does the review address Result?,TRUE,FALSE,The review discusses potential of multiple Double-I watermarks.
This paper conducts comprehensive evaluations on the influence of selecting specific examples for inclusion in the prompt.,Does the review address Presentation?,TRUE,FALSE,The review discusses comprehensive evaluation of prompt example selection.
"2016 [2] A syntactic neural model for general-purpose code generation, Yin and Neubig 2017 [3] Making Neural Programming Architectures Generalize via Recursion, Cai et al. 2017  ####Authors have engaged in the discussion, clarified questions about the paper and addressed comments in its newest revision.",Does the review address Methodology?,TRUE,FALSE,The review references neural programming architectures and model discussion.
Pros: - Weakly-supervised method for video moment localization is a reasonable and important direction.,Does the review address Presentation?,TRUE,FALSE,The review notes importance of weakly-supervised method direction.
2) The presentation is very good and easy to follow.,Does the review address Presentation?,TRUE,FALSE,The review explicitly praises presentation quality.
"Finally, writing in general can be made clearer:  1.",Does the review address Presentation?,TRUE,FALSE,The review suggests writing clarity improvements.
I think I'd like to see a discussion of sufficient number D analytically or empirically.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests discussion of sufficient number D.
"## (Minor) Imprecise Claim about Poly(n) Size  In Theorem 1, the authors claim: > We consider log-precision, constant-depth, and polynomial-size Transformers: for Transformers whose input is of length n, the values at all neurons are represented with O(log n) bits, the depth is constant, and the number of neurons is O(poly (n)).",Does the review address Theory?,TRUE,FALSE,The review discusses theoretical claims about Transformer properties.
It's not really okay to put up the tables and show the perplexity and BLEU scores without some explanation.,Does the review address Result?,TRUE,FALSE,The review criticizes lack of explanation for perplexity and BLEU scores.
"Edit after seeing others reviews -- I think I gave this paper a MUCH higher score than the other reviewers, simply because it is very novel with Fon language.",Does the review address Novelty?,TRUE,FALSE,The review discusses novelty regarding Fon language.
"First, the authors are missing a great deal of related work: Neelakantan at al. 2015 (https://arxiv.org/abs/1504.06662) perform zero-shot relation extraction using RNNs over KB paths.",Does the review address Related Work?,TRUE,FALSE,The review points out missing references to related work.
"But then at the end, I saw you include Encode as step 4, so it is the machine...",Does the review address Methodology?,TRUE,FALSE,The review discusses encoding step in methodology.
The graph indicates that for MNLI and QNLI 60% seems like a better choice.,Does the review address Result?,TRUE,FALSE,The review discusses performance results for specific datasets.
The difference in the ablation results seem quite small (tables 3 and 4).,Does the review address Result?,TRUE,FALSE,The review discusses small differences in ablation results.
"Considering the actual experimental setting is significantly different from the VIP setting, the title “Answering Queries with CLIP Adversely affects VIPs explanations” and the conclusions seem a bit misleading.",Does the review address Experiment?,TRUE,FALSE,The review discusses mismatch between experimental setting and conclusions.
The difference in the ablation results seem quite small (tables 3 and 4).,Does the review address Significance?,TRUE,FALSE,The review discusses significance of ablation result differences.
Margins are very small for the Average differences across all datasets as well -- have you considered confidence intervals on those as well?,Does the review address Data/Task?,TRUE,FALSE,The review discusses margin differences across datasets.
"Consequently, there is a possibility that it could be utilized in real-world applications of in-context learning.",Does the review address Methodology?,TRUE,FALSE,The review discusses potential real-world application.
"I look forward to the author's discussion of the additional learnable parameters introduced in addition to CLIP's pre-trained model, and compare the number with other methods.",Does the review address Comparison?,TRUE,FALSE,The review requests comparison of learnable parameters with other methods.
(2) Is table 1 an average over the 17 embeddings described in section 5.1?,Does the review address Methodology?,TRUE,FALSE,The review asks about methodology of table 1 calculation.
Solid experiments demonstrating the proposed method outperforms other existing approaches.,Does the review address Experiment?,TRUE,FALSE,The review discusses experimental demonstration of method performance.
(3) The loss for answer prediction in Eq 6 is not clearly described: do you use an aggregated embedding over all nodes for prediction?,Does the review address Methodology?,TRUE,FALSE,The review questions methodology of answer prediction embedding.
The provided experiments are more like baselines for self-evaluation other than state-of-the-art performance.,Does the review address Evaluation?,TRUE,FALSE,The review criticizes experiments as self-evaluation rather than SOTA comparison.
"Consider, for a moment, that they are using only 25,000 input/output pairs for their training/validation/testing.",Does the review address Data/Task?,TRUE,FALSE,The review discusses dataset size for training/validation/testing.
"Did the author try other window widths, for example width `1' to extract unigram features, `3' to trigram, or use them together?",Does the review address Presentation?,FALSE,TRUE,The review questions methodological choice about window widths.
An ablation study is carried out to rule out the possibility that the benefits from PACT come from simply regularizing the model.,Does the review address Ablation?,TRUE,FALSE,The review discusses ablation study ruling out regularization benefits.
Another limitation is that it is unclear whether the improvement would hold when the size of the model increases; the evaluation is dealing with scaling laws after all.,Does the review address Evaluation?,TRUE,FALSE,The review discusses evaluation limitations regarding model scaling.
The optimality of deterministic inference does not hold empirically due to class imbalance or discrepancy between training and test sets.,Does the review address Methodology?,TRUE,FALSE,The review discusses limitations of deterministic inference.
Experimental evaluation shows competitive performance.,Does the review address Evaluation?,TRUE,FALSE,The review mentions competitive performance in evaluation.
I agree with the authors that extending the context is important.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review agrees with authors' motivation about context extension.
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Methodology?,TRUE,FALSE,The review discusses comparison with other annotation approaches.
"Sec 3.1 contains results on captionnet, Sec 4 also contains results on captionnet.",Does the review address Result?,TRUE,FALSE,The review notes result locations across sections.
"Some of the details for model description are missing and confusing, e.g., (1) How the representation is initialized for a supernode corresponding to a fact triplet and how does the supernode propagate information to the sub-nodes?",Does the review address Presentation?,TRUE,FALSE,The review criticizes missing and confusing model description details.
Strengths * Improving the data efficiency in language models is an important problem that so far studies have shown that can be achieved by scaling the size of the model.,Does the review address Methodology?,TRUE,FALSE,The review discusses data efficiency improvement through model scaling.
"It is important to note that while BLEU of other methods reduced on the Fr→Fon task, WB improved on it.",Does the review address Presentation?,TRUE,FALSE,The review highlights important performance comparison on Fr-Fon task.
- During the training of the decoder how do you make sure that the decoder uses the information given by the latent plan?,Does the review address Methodology?,TRUE,FALSE,The review questions decoder's use of latent plan information.
"It is also strange that the multi-cluster approach, which discards inter-cluster (word and language) semantic information performs the best with respect to the extrinsic metrics.",Does the review address Evaluation?,TRUE,FALSE,The review discusses unexpected performance of multi-cluster approach.
"For example, sentence inference tasks such as MNLI and RTE are common tasks in NLP field.",Does the review address Data/Task?,TRUE,FALSE,The review mentions common NLP tasks (MNLI and RTE).
Explicit modeling the generation order is not a very novel idea that there have been many works on this topic.,Does the review address Novelty?,TRUE,FALSE,The review criticizes lack of novelty in generation order modeling.
"It would help to clarify when what you predict is a guard, a precondition, an invariant, or something else.",Does the review address Presentation?,TRUE,FALSE,The review requests clarification of prediction types.
"I do understand that the main point is the reduction of the amount of parameters (per task), but this doesn't mean that the evaluation should paint a wrong picture.",Does the review address Evaluation?,TRUE,FALSE,The review criticizes misleading evaluation presentation.
"Second, the authors neither 1) evaluate their model on another dataset or 2) evaluate any previously published models on their dataset.",Does the review address Data/Task?,TRUE,FALSE,The review criticizes lack of cross-dataset evaluation.
Hyper-parameter balancing strategies in Section 3.1 is not a solid theoretical analysis.,Does the review address Theory?,TRUE,FALSE,The review criticizes theoretical analysis of hyperparameter strategies.
"I would suggest the following:   * To make the comparison more fair, I would suggest to train transformer models with varying size and derive a power law based on the exact same experimental configuration used for LMU models.",Does the review address Presentation?,TRUE,FALSE,The review suggests fairer comparison methodology.
- I don't see why your theory does not generalize to a _masked_ language modeling (MLM).,Does the review address Theory?,TRUE,FALSE,The review questions theory's applicability to masked language modeling.
"The paper has ""support set"" and ""support instructions"" at many places but it is unclear to me what it actually means.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review points out unclear terminology about ""support set"" and ""support instructions""."
"-----General Discussion----- This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses paper's practical model and novelty concerns.
Details / Questions: * It seems to me that the GLUE results might be within the margin of error.,Does the review address Result?,TRUE,FALSE,The review suggests GLUE results might be within margin of error.
Might be useful to define what is exactly meant by 'comprehensibility' 4.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests definition of 'comprehensibility'.
"But from Table 5., the trend of performance seems to increase with the increased prepositional phrases (with 84.7 being the max for 4 PPs).",Does the review address Methodology?,TRUE,FALSE,The review discusses performance trend with increased prepositional phrases.
"**Major concern** If I understand correctly (and please correct me if I am wrong), in Theorem B.1, the ratio between the downstream error $\ell_\mathcal{T}(\\{p_{\cdot\mid s}\\}) - \tau$ and the pre-training error $\ell_\text{xent}(\\{p_{\cdot\mid s}\\})-\ell_\text{xent}^\ast$ is _hidden_ in the $\gamma(p_{\mathcal{T}}; \\{p_{\cdot\mid s}\\})$ coefficient.",Does the review address Methodology?,TRUE,FALSE,The review discusses technical details of theorem coefficient.
- Improvement over previous state-of-the-art models.,Does the review address Methodology?,TRUE,FALSE,The review mentions improvement over previous state-of-the-art models.
"Therefore, it is necessary to compare OTTER and CLIP on the same-scaled datasets.",Does the review address Data/Task?,TRUE,FALSE,The review suggests comparison on same-scaled datasets.
"Overall, I think the paper provides an interesting view of discussion, but there are many flaws in the current version which needs to be corrected before a more serious consideration.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses paper flaws needing correction.
I suppose it would be hard to define auxiliary tasks for simpler systems.,Does the review address Methodology?,TRUE,FALSE,The review discusses difficulty of defining auxiliary tasks.
(4) How exactly is the interaction module processed?,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review asks for clarification about interaction module processing.
* Description of refl and tidy-bfs baselines appears much late in the paper.,Does the review address Comparison?,TRUE,FALSE,The review notes late appearance of baseline descriptions.
"According to the evaluation, the proposed method shows its effectiveness especially when the finetuning data is limited.",Does the review address Data/Task?,TRUE,FALSE,The review discusses method effectiveness with limited finetuning data.
Could you explain the significance of this result again?,Does the review address Significance?,TRUE,FALSE,The review requests explanation of result significance.
"But I support given a fixed set of phrase pairs at train time, the attention mechanism at the phrasal level can be pre-computed but at inference (apply the attention on new data at test time), this might be kind of problematic when the architecture is scaled to a larger dataset.",Does the review address Methodology?,TRUE,FALSE,The review discusses scalability issues with attention mechanism.
"-----General Discussion----- This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths).",Does the review address Novelty?,TRUE,FALSE,The review explicitly discusses lack of novelty in main ideas.
• It is stated that (page 7) the submission to GLUE leaderboard uses only single-task finetuning.,Does the review address Data/Task?,TRUE,FALSE,The review mentions GLUE leaderboard submission details.
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.,Does the review address Methodology?,TRUE,FALSE,The review suggests reorganization of model figure placement.
It is not clear to me what the value of OpenAQA dataset is on top of of the textual metadata available with most of these datasets.,Does the review address Significance?,TRUE,FALSE,The review questions value of OpenAQA dataset.
"‘Wang & Cho’ were not the first who used Transformers generativity (see Vaswani, 2017).",Does the review address Methodology?,TRUE,FALSE,The review corrects historical attribution of Transformer generativity.
"For this purpose, the authors introduced the definition of a ""natural"" task.",Does the review address Data/Task?,TRUE,FALSE,"The review mentions definition of ""natural"" task."
The findings from the analysis are an important addition to the understanding of the role of language specific parameters in multilingual NMT.,Does the review address Analysis?,TRUE,FALSE,The review discusses importance of findings about language-specific parameters.
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Analysis?,TRUE,FALSE,The review discusses theoretical analysis of language model performance.
"The true contribution appears to be the improvement of the overlapping strategy tokenization for DNA pretraining, which diverges from the broader theme of ""rethinking the pretraining for DNA sequence.""",Does the review address Contribution?,TRUE,FALSE,The review identifies true contribution in tokenization strategy.
"The paper made a impactful finding for practicing adversarial training, that mixture of signals at different depth of of the generator can stabilize ELECTRA-style models trained adversarially using Gumble-Softmax relaxation.",Does the review address Methodology?,TRUE,FALSE,The review discusses findings about adversarial training methodology.
"I would suggest using the phrase ""weighted SVD"" early on in the introduction (e.g., exactly when you introduce your new method).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review suggests earlier introduction of ""weighted SVD"" terminology."
Chain-of-thought prompting elicits reasoning in large language models.,Does the review address Related Work?,TRUE,FALSE,The review references chain-of-thought prompting work.
"If the experiment does not peer inside the structure of the noise and treats it as a gray box instead, it is not much different than a discrete-channel environment where random edits are made to the message.",Does the review address Experiment?,TRUE,FALSE,The review discusses experimental treatment of noise structure.
Why isn’t an asymmetric architecture more natural?,Does the review address Methodology?,TRUE,FALSE,The review questions choice of symmetric vs asymmetric architecture.
- The ablation experiments and optimized prompt analysis are insightful.,Does the review address Methodology?,TRUE,FALSE,The review mentions insightful ablation experiments and prompt analysis.
"*  What is the contribution of each specific design choice, such as the FFN/global attention and implicit self-attention, to the end performance?",Does the review address Ablation?,TRUE,FALSE,The review requests ablation of specific design choices.
"- P5, Sec 4.1: ""The result suggests that small test cross-entropy (hence test perplexity)..."" Same question as above.",Does the review address Presentation?,TRUE,FALSE,The review questions explanation of test cross-entropy results.
"Main weaknesses (for each of them, see detailed comments below): - The description of the corpus and the experimental setup frequently lacked some details; there is also no comparison to an existing Thai UD resource.",Does the review address Comparison?,TRUE,FALSE,The review notes lack of comparison to Thai UD resource.
**Experimental results** The presentation of the experimental results is clear.,Does the review address Presentation?,TRUE,FALSE,The review praises clarity of experimental results presentation.
- The analysis of compositionality given is insufficient.,Does the review address Analysis?,TRUE,FALSE,The review criticizes insufficient compositionality analysis.
The cost of training NLP models: A concise overview.,Does the review address Related Work?,TRUE,FALSE,The review references work on NLP model training costs.
"Despite very encouraging results, several important methodological questions about the source of the efficiency gains and other aspects of the paper are left unanswered.",Does the review address Result?,TRUE,FALSE,The review discusses encouraging results but unanswered methodological questions.
"To name a few:   -“Language Models as Knowledge Bases?” EMNLP 2019   -“Commonsense Knowledge Mining from Pretrained Models.” EMNLP 2019   -“Comet: Commonsense Transformers for Automatic Knowledge Graph Construction.” ACL 2019 - Although the proposed model achieves quantitative improvements over Angeli et al. (2015), it seems unclear whether these improvements are due to the factual knowledge encoded in the pre-trained LM, as claimed.",Does the review address Methodology?,TRUE,FALSE,The review questions source of improvements in pre-trained LM.
Section 3.4  does not describe clearly enough how attention maps were used for predicting contact maps.,Does the review address Presentation?,TRUE,FALSE,The review criticizes unclear description of attention map usage.
"#### Weakness - In Table 1, the WNLI task is excluded from the GLUE benchmark, I wonder what is the reason this task is removed?",Does the review address Data/Task?,TRUE,FALSE,The review questions exclusion of WNLI task from GLUE benchmark.
- The visualization section is only a minor contribution; there isn't really any innovation or findings about what works or doesn't work here.,Does the review address Result?,TRUE,FALSE,The review criticizes minor contribution of visualization section.
And there is no further explanation and ablation study on the design of the dynamic threshold.,Does the review address Ablation?,TRUE,FALSE,The review notes missing ablation study for dynamic threshold.
The algorithms were clear and the comments were useful for understanding the proposed idea.,Does the review address Methodology?,TRUE,FALSE,The review praises clarity of algorithms and comments.
"It requires more analysis about experimental results, such as Figure 1 and tables in Section D.",Does the review address Experiment?,TRUE,FALSE,The review requests more analysis of experimental results.
"In contrast, focusing on a solid target and ignoring the rest of potential targets, CLIP may still infer the generalized information provided by many-to-many relationships due to the wide range of data collection.",Does the review address Data/Task?,TRUE,FALSE,The review discusses CLIP's data collection and relationship inference.
"Discussion of D  Since RF is not the major contribution, you summarize existing results of FA in sec2.2.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses summary of FA results in section 2.2.
"It is widely acknowledged and studied that the complexity (i.e., the length or reasoning steps of the CoT annotations) significantly influences the performance of the LLMs.",Does the review address Presentation?,TRUE,FALSE,The review discusses acknowledged influence of CoT annotation complexity.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses empirical validation of theoretical assumptions.
It is also hard to navigate through all the information due to different ablation targets.,Does the review address Ablation?,TRUE,FALSE,The review mentions difficulty navigating multiple ablation targets.
"The description of the baselines is lacking and quite confusing: it's not clear why the authors have two DP-SGD baselines, and what they're exactly updating during training.",Does the review address Comparison?,TRUE,FALSE,The review criticizes unclear baseline description and comparison.
"Comparative Analysis and Benchmarking:  The comparisons presented in Tables 1 and 2 focus solely on the improvements over one reference work (Ma et al., 2023).",Does the review address Data/Task?,TRUE,FALSE,The review discusses limited comparison focus in Tables 1 and 2.
"This idea is novel and interesting to me, and the derivation and experiment results look encouraging.",Does the review address Result?,TRUE,FALSE,The review mentions encouraging derivation and experiment results.
Using Transformer attention maps for protein contact prediction is not new.,Does the review address Methodology?,TRUE,FALSE,The review discusses lack of novelty in using attention maps.
"That is, unless I’ve just missed something, it seems that all of the core components of N-Bref are lifted from prior work with perhaps some minor augmentation.",Does the review address Novelty?,TRUE,FALSE,The review suggests components are lifted from prior work.
"For a more comprehensive analysis, it would be instructive to see how the approach compares with a broader spectrum of state-of-the-art methods.",Does the review address Methodology?,TRUE,FALSE,The review suggests broader comparison with SOTA methods.
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Ablation?,TRUE,FALSE,The review discusses ablations and size variations in comparison.
This paper presents an effective way to make use of this idea.,Does the review address Methodology?,TRUE,FALSE,The review mentions effective implementation of an idea.
The proposed method improves modestly on BERT on the GLUE suite of problems.,Does the review address Result?,TRUE,FALSE,The review discusses modest improvements over BERT on GLUE.
"* It will be cool to show some results on BLEU improvement on machine translation, or user studies on language generation tasks, to demonstrate its practical impact, as the quantitative metrics right now are still kind of artificial.",Does the review address Evaluation?,TRUE,FALSE,The review suggests additional evaluation metrics and user studies.
**Empirical**:  One issue with the language modelling experiment is the choice of evaluation and train set.,Does the review address Methodology?,TRUE,FALSE,The review criticizes choice of evaluation and train set.
Ablations show the necessity of applying a 2-step intermediate training scheme with mixed training followed by joint training.,Does the review address Methodology?,TRUE,FALSE,The review discusses necessity of 2-step training scheme.
"The key ideas are: (i) training longer with bigger batches over more data, (ii) removing NSP, (iii) training over long sequences, and (iv) dynamically changing the masking pattern.",Does the review address Data/Task?,TRUE,FALSE,The review lists key training ideas including batch size and data.
"In fact, empirical evidence suggest that LMs do memorize n-grams from their training data somewhat, but not full examples (see [McCoy et al.",Does the review address Result?,TRUE,FALSE,The review discusses empirical evidence about LM memorization.
"Although the individual components are similar to previous work, they are combined in a novel way that shows a path toward longer and more efficient context lengths.",Does the review address Methodology?,TRUE,FALSE,The review discusses novel combination of existing components.
"Finally, the CALM intermediate objectives share many properties with all of the datasets tested on and are likely calibrating the model to the kind of correlations they should expect to predict in advance of finetuning.",Does the review address Methodology?,TRUE,FALSE,The review discusses CALM objectives' properties and effects.
It might be valuable to evaluate PENGI on Open ended tasks.,Does the review address Significance?,TRUE,FALSE,The review suggests value of open-ended task evaluation.
"I have no experience with these kinds of NLU models, so I can't say with confidence whether the architectural additions proposed are well-motivated, but to me it feels like there is not a strong justification for adding these particular features to the BERT architecture, and the results do not clearly demonstrate their utility except in the ""lexical_overlap"" case.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions justification for architectural additions.
"The only interesting aspect is adapting the training procedure to contrastive learning, which is trivial.",Does the review address Methodology?,TRUE,FALSE,The review discusses adaptation of training procedure.
"In sec4.1, the authors said ""A batch size of 256 is employed, "", does that mean K=256 in Algorithm 1?",Does the review address Methodology?,TRUE,FALSE,The review asks for clarification about batch size parameter.
It also substantially improves on BERT with respect to a class of examples that are designed to confound models that learn superficial heuristics based on word occurrence.,Does the review address Result?,TRUE,FALSE,The review discusses improvement over BERT on specific examples.
"About type dependency graph: 1) Comparing to previous work (e.g, Allamanis et.al, ICLR 18), it seems the construction of the task specific graph is the major contribution, where the novelty is a bit limited.",Does the review address Novelty?,TRUE,FALSE,The review discusses limited novelty in graph construction.
"This setting captures the design and the hardware restriction of realistic T-LLMs and is common in the literature on the theoretical power of T-LLMs (Hahn, 2020; Hao et al., 2022; Merrill et al., 2022; Merrill & Sabharwal, 2023).",Does the review address Presentation?,TRUE,FALSE,The review discusses common setting in theoretical literature.
"This is especially disappointing as the objectives introduced _directly_ match the task in CommonGEN, making this intermediate training a form of noisy training data rather than pretraining.",Does the review address Data/Task?,TRUE,FALSE,The review criticizes objectives matching CommonGEN task.
Both publications appeared on arXiv at least one month before the ICLR submission deadline and are not clearly discussed in the paper.,Does the review address Related Work?,TRUE,FALSE,The review points out undiscussed prior arXiv publications.
It does not follow from the theoretical results that adding similar sentences will be a good thing.,Does the review address Methodology?,TRUE,FALSE,The review questions theoretical support for methodology.
"However, the teacher networks used in the experiments are not always uni-modal.",Does the review address Experiment?,TRUE,FALSE,The review discusses experimental setup regarding teacher networks.
The methodology is explained clearly and experiments are executed with a considerable amount of detail.,Does the review address Methodology?,TRUE,FALSE,The review praises clear methodology explanation and detailed experiments.
"I think authors wanted to say that even though BROS does not rely on visual features, it does outperform LayoutLM which, in turn, uses visual features.",Does the review address Comparison?,TRUE,FALSE,The review clarifies performance comparison between BROS and LayoutLM.
"Weakness While the ablation study and visualization analysis are done, the key evaluations are missing.",Does the review address Presentation?,TRUE,FALSE,The review notes missing key evaluations despite completed analyses.
"- P6, Sec 4.3: ""In fact, $f$ almost always performs better than ..."" This part seems intriguing despite the linear relationship shown in figure 1.",Does the review address Presentation?,TRUE,FALSE,The review discusses intriguing relationship despite figure presentation.
"- P8, Table 2: The results from using Quad look worse than the above two.",Does the review address Significance?,TRUE,FALSE,The review discusses worse results from using Quad.
"In my knowledge, the previous work has not yet attempted to tackle this problem.",Does the review address Novelty?,TRUE,FALSE,The review notes problem hasn't been tackled in previous work.
- The choice in deciding how many template tokens are used is unclear.,Does the review address Presentation?,TRUE,FALSE,The review criticizes unclear template token selection.
It might be good to address the existing literature on compressing trained neural networks which also goes beyond simply trying to minimize the Frobenius norm of the difference between the weights.,Does the review address Related Work?,TRUE,FALSE,The review suggests addressing literature on neural network compression.
Since we observe that the randomly pruned models do not competitive performance ...: how uncompetitive?,Does the review address Result?,TRUE,FALSE,The review questions degree of uncompetitive performance.
"Nonetheless, the current paper leaves too many open questions regarding the validity of the experiments.",Does the review address Experiment?,TRUE,FALSE,The review mentions open questions about experiment validity.
"The proposed models -- which seem to be an application of various tree-structured recursive neural network models -- demonstrate a nice performance increase compared to a fairly convincing, broad set of baselines (if we are able to trust them; see below).",Does the review address Methodology?,TRUE,FALSE,The review discusses tree-structured models and performance comparison.
"This paper makes comparison with techniques used in active learning (AL), domain shift detection (DS), and multi-domain sampling to combine data from multiple sources.",Does the review address Methodology?,TRUE,FALSE,The review discusses comparison with various learning techniques.
"This setting captures the design and the hardware restriction of realistic T-LLMs and is common in the literature on the theoretical power of T-LLMs (Hahn, 2020; Hao et al., 2022; Merrill et al., 2022; Merrill & Sabharwal, 2023).",Does the review address Related Work?,TRUE,FALSE,The review references literature on T-LLMs theoretical power.
Performance: Concept-QA appears to perform well when evaluated along multiple axes.,Does the review address Result?,TRUE,FALSE,The review discusses Concept-QA's performance evaluation.
The results on Split H are positive and they also conducted a range of ablation and error analysis.,Does the review address Ablation?,TRUE,FALSE,The review mentions ablation and error analysis results.
"in Table 2, it's necessary to explain why the LSTM's perplexity from previous work is higher than the author's implementation.",Does the review address Result?,TRUE,FALSE,The review questions LSTM perplexity differences.
"* In the results section there is a typo: *""performances with a large margins of 2.32pp in""*.",Does the review address Result?,TRUE,FALSE,The review points out typo in results section.
"- Strengths: This paper has high originality, proposing a fundamentally different way of predicting words from a vocabulary that is more efficient than a softmax layer and has comparable performance on NMT.",Does the review address Novelty?,TRUE,FALSE,The review praises originality of word prediction approach.
"Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally.",Does the review address Analysis?,TRUE,FALSE,The review discusses analysis-based recommendations and validation.
The idea of learning which parameters to share across languages in multilingual transformer models is original and potentially useful for designing and analyzing multilingual models in the context of NMT.,Does the review address Novelty?,TRUE,FALSE,The review discusses originality of parameter sharing approach.
"Overall, I think this paper has a clear motivation and some interesting ideas on how to incorporate semantic language information into planning algorithms.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review praises clear motivation and interesting ideas.
"It is good to know that it works for 2D-coordinates for the task at hand, though it seems to be more a marginal improvement on existing work rather than a standalone contribution.",Does the review address Result?,TRUE,FALSE,The review discusses marginal improvement nature of results.
I would appreciate further elaboration on the limitations of sparse attention in DNA sequence representation.,Does the review address Methodology?,TRUE,FALSE,The review requests elaboration on sparse attention limitations.
"Specifically, having the BFS analysis of the attention weights as a function of different GreaseLM layers (as done by Yasunaga et al.)",Does the review address Analysis?,TRUE,FALSE,The review discusses BFS analysis of attention weights.
"Experiments on type predictions for TypeScript have shown better performance than the previous methods, with or without user specified types.",Does the review address Experiment?,TRUE,FALSE,The review discusses experimental performance on TypeScript type predictions.
The experimental results also look promising in compared with the exsiting models.,Does the review address Comparison?,TRUE,FALSE,The review discusses promising results compared to existing models.
"Given that there is a wealth of existing work that performs the same task and the lack of novelty of this work, the authors need to include experiments that demonstrate that their technique outperforms others on this task, or otherwise show that their dataset is superior to others (e.g. since it is much larger than previous, does it allow for better generalization?)",Does the review address Methodology?,TRUE,FALSE,The review discusses need for comparative experiments or dataset superiority demonstration.
"These are not weakness, but I think some work in this direction may help improve the paper.",Does the review address Experiment?,FALSE,TRUE,"The review makes a general comment about paper improvement, not experiments."
The authors have somewhat clarified in this in their updated version.,Does the review address Presentation?,TRUE,FALSE,The review mentions clarification in updated version.
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Theory?,TRUE,FALSE,The review discusses theoretical guarantees for language model performance.
"Some things that are worth looking into are the work on Scalable static analysis [Scaling], the inference of necessary preconditions [Logozzo], and bug detection that is based on ""belief"" [deviant, belief], which is closely related to your intuition about naturalness and human-written invariants.",Does the review address Analysis?,TRUE,FALSE,The review suggests examining various analysis works and approaches.
The cold-start problem is actually an urgent problem to several online review analysis applications.,Does the review address Significance?,TRUE,FALSE,The review discusses urgency of cold-start problem.
My another is concern is that the motivation of the experimental design is not clear.,Does the review address Experiment?,TRUE,FALSE,The review criticizes unclear experimental design motivation.
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Result?,TRUE,FALSE,The review notes limited validation and missing analyses.
"I would suggest the following:   * To make the comparison more fair, I would suggest to train transformer models with varying size and derive a power law based on the exact same experimental configuration used for LMU models.",Does the review address Experiment?,TRUE,FALSE,The review suggests specific experimental configuration for fair comparison.
"The term ""intermediate neurons"" (section 3.2) was unclear to me.",Does the review address Presentation?,TRUE,FALSE,The review notes unclear terminology.
"Discussion of D  Since RF is not the major contribution, you summarize existing results of FA in sec2.2.",Does the review address Result?,TRUE,FALSE,The review discusses summary of existing FA results.
The hypothesis are clearly stated and the experiments are well designed.,Does the review address Methodology?,TRUE,FALSE,The review praises hypothesis statement and experimental design.
**Student networks** are too weak to prove the proposed techniques are useful for the more recent (and more powerful) models.,Does the review address Presentation?,TRUE,FALSE,The review criticizes weakness of student networks for technique validation.
"For example, besides the quantative improvements, does the rapid convergence and under-training still exist after applying RandomMask?",Does the review address Result?,TRUE,FALSE,The review questions persistence of convergence properties.
"**Related work** The authors clearly describe the related prior works from both the perspectives of program synthesis, large language models, and benchmarks for program synthesis.",Does the review address Related Work?,TRUE,FALSE,The review praises clear description of prior work.
"New Outlooks for Low-Bit Quantization on Large Language Models, Zhang et al. [3] FP8 Quantization: The Power of the Exponent, Kuzmin et al.",Does the review address Related Work?,TRUE,FALSE,The review references works on quantization.
It is not clear how certain experimental designs were made.,Does the review address Presentation?,TRUE,FALSE,The review criticizes unclear experimental design choices.
- The algorithm presented here is able to be used in an unsupervised way and can work with both open-ended and more structured knowledge graph schema.,Does the review address Methodology?,TRUE,FALSE,The review discusses algorithm's unsupervised capabilities.
- The analysis which builds on these definitions/models/assumptions provides meaningful theoretical insight into why language model pre-training may be so beneficial for downstream training.,Does the review address Theory?,TRUE,FALSE,The review discusses theoretical insights about pre-training benefits.
"Having an ablation on the number of GreaseLM layers would also be quite useful to answer if performance improves with more GreaseLM layers, are there diminishing returns or do we need just a few GreaseLM layers, beyond which it is detrimental to the model's performance.",Does the review address Result?,TRUE,FALSE,The review suggests ablation study to examine performance patterns.
S: - The idea of controlling the generation of language models step-by-step in a recurred manner is interesting.,Does the review address Methodology?,TRUE,FALSE,The review discusses step-by-step generation control approach.
I felt this was quite separate from the theoretical analysis.,Does the review address Theory?,TRUE,FALSE,The review notes separation from theoretical analysis.
The paper proposes Options framework based method for using the hierarchical structure in dialog to learn the dialog policy and NLG in a hierarchical fashion.,Does the review address Methodology?,TRUE,FALSE,The review describes Options framework method for dialog policy.
"But from Table 5., the trend of performance seems to increase with the increased prepositional phrases (with 84.7 being the max for 4 PPs).",Does the review address Result?,TRUE,FALSE,The review discusses performance trend with prepositional phrases.
I would recommend include some references in semantic parsing.,Does the review address Related Work?,TRUE,FALSE,The review recommends including semantic parsing references.
Time analysis on language modeling is not presented.,Does the review address Analysis?,TRUE,FALSE,The review notes missing time analysis for language modeling.
"This is the key weakness, but this makes me find it really difficult to judge the overall technical quality and significance.",Does the review address Significance?,TRUE,FALSE,The review discusses difficulty judging technical quality and significance.
Also the pointer mechanism used for predicting user specified types is a good strategy that advances the previous method.,Does the review address Result?,TRUE,FALSE,The review discusses effectiveness of pointer mechanism strategy.
The description of how you compare your invariants to those inferred by Daikon is not clear unless all relevant cases related to (pre)conditions on method parameters.,Does the review address Comparison?,TRUE,FALSE,The review criticizes unclear comparison methodology with Daikon.
"- Secondly, this main result depends on the worst-case coefficient, which is also unclear to me.",Does the review address Result?,TRUE,FALSE,The review discusses dependency on worst-case coefficient.
"Based on the large-scale training data and the proposed visual expert module, the proposed method achieves a number of state-of-the-art results across a wide range of vision-language tasks.",Does the review address Result?,TRUE,FALSE,The review discusses achievement of state-of-the-art results.
"While I appreciate the environment introduced and believe it to be promising, the experiments presented fail to highlight the novelty of the environment.",Does the review address Novelty?,TRUE,FALSE,The review criticizes experiments' failure to highlight environment novelty.
The work successfully leverages the framing of general learners in terms of circuits to conclude that transformer LMs are not universal learners.,Does the review address Methodology?,TRUE,FALSE,The review discusses use of circuit framing for transformer LM analysis.
The submission has evaluated the proposed algorithms on four datasets and improved SOTA performances.,Does the review address Result?,TRUE,FALSE,The review mentions improved SOTA performance on four datasets.
"Typos: In Sec 5.2 Tasks (f), ""$\phi_2(x)=1$"" should be ""$\bar \mu_2=1$"".",Does the review address Presentation?,TRUE,FALSE,The review points out specific mathematical notation typo.
"On the one hand the baselines make use of a large set of training trajectories, but on the other hand these methods train policies that choose low-level actions.",Does the review address Comparison?,TRUE,FALSE,The review discusses baseline methodology differences.
"The claimed contributions include: 1) The proposed method is free from the common issue of diverging from human language, because it learns from the sentences sampled from the pre-trained LM.",Does the review address Methodology?,TRUE,FALSE,The review discusses method's advantage regarding human language.
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.,Does the review address Data/Task?,TRUE,FALSE,The review mentions evaluation on two public datasets.
"Last sentence of intro: ""without scarifying accuracy"" seems like an inaccurate description of the results presented in this paper.",Does the review address Result?,TRUE,FALSE,The review criticizes inaccurate description of results.
Here there is no direct comparison of the performance of the current system w.r.t.,Does the review address Comparison?,TRUE,FALSE,The review notes lack of direct performance comparison.
"This makes it difficult to conclusively prove that this is an ""applicable to all"" data augmentation scheme.",Does the review address Methodology?,TRUE,FALSE,The review discusses difficulty proving universal applicability.
I suppose it would be hard to define auxiliary tasks for simpler systems.,Does the review address Data/Task?,TRUE,FALSE,The review discusses difficulty of defining auxiliary tasks.
"The architecture does not look entirely novel, but I kind of like the simple and practical approach compared to prior work.",Does the review address Related Work?,TRUE,FALSE,The review compares architecture approach to prior work.
"This makes it difficult to conclusively prove that this is an ""applicable to all"" data augmentation scheme.",Does the review address Data/Task?,TRUE,FALSE,The review discusses data augmentation scheme applicability.
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Ablation?,TRUE,FALSE,The review discusses paper contributions in absence of ablation study.
"But using neural models to rank (or rerank) is a long-existing technique, regardless of the chosen parametrization of the reranking model.",Does the review address Methodology?,TRUE,FALSE,The review discusses historical context of neural ranking.
"Sometimes, sparse attention can improve generalization [1].",Does the review address Methodology?,TRUE,FALSE,The review discusses impact of sparse attention on generalization.
Please let me know if I have misunderstood something(s),Does the review address Presentation?,FALSE,TRUE,The review asks for clarification of potential misunderstandings.
- The proof technique (pre-training performance $\to$ covariance of pre-training errors $\to$ covariance of downstream errors $\to$ downstream performance) is itself interesting.,Does the review address Result?,TRUE,FALSE,The review discusses interesting proof technique for performance relationships.
"However, I am unable to grasp nuances, leaving important questions untouched such as: In what scenarios do we expect the model to perform better than GECA?",Does the review address Comparison?,TRUE,FALSE,The review discusses inability to grasp comparative performance scenarios with GECA.
"- The definitions, models, and assumptions in the paper are intuitive and clear (e.g., natural task).",Does the review address Presentation?,TRUE,FALSE,"The review praises clarity of definitions, models, and assumptions."
The authors should conduct experiments on more types of sentence pair tasks.,Does the review address Experiment?,TRUE,FALSE,The review suggests conducting more sentence pair task experiments.
One issue is that the main contribution is  mostly condensed into section 3.2 which is less than one page.,Does the review address Contribution?,TRUE,FALSE,The review criticizes brevity of main contribution section.
"For the first ablation, it just gives out the performance of intermediate models on a single task.",Does the review address Ablation?,TRUE,FALSE,The review discusses limited scope of ablation analysis.
Strengths: The paper is well-written with clear motivations and structure.,Does the review address Presentation?,TRUE,FALSE,"The review praises paper writing, motivations and structure."
"The authors experiment both with pre-training and fine-tuning of contextual models (BERT-{base,large}) and claim large reduction in training time, with reasonable loss in performance.",Does the review address Experiment?,TRUE,FALSE,The review discusses experimental results with BERT models.
Incorporating bert into neural machine translation.,Does the review address Related Work?,TRUE,FALSE,The review references work on BERT in neural machine translation.
The idea itself is not completely new as the authors readily explain in the paragraph MACHINE LEARNING WITH PROOF ARTIFACTS on page 2.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses explanation of idea's novelty.
Existing performance improvement is quite limited.,Does the review address Result?,TRUE,FALSE,The review notes limited performance improvement.
* I found the discussion in Section 4.1 pretty confusing.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review finds Section 4.1 discussion confusing.
This seems to contradict findings from Brown et al where larger models did better on essentially all tasks.,Does the review address Methodology?,TRUE,FALSE,The review notes contradiction with Brown et al.'s findings about model size.
"Minor Issues  ==== Figure 2 is a little redundant, I think figure 1 is enough to compare it against the pRNN (figure3 and 4).",Does the review address Presentation?,TRUE,FALSE,The review suggests Figure 2 is redundant.
This could be tested by ablating elements from the input or ablating the recurrent memory vectors (setting them to zero during inference).,Does the review address Experiment?,TRUE,FALSE,The review suggests specific ablation experiments.
"Strengths:  - The paper is generally well-written, with excellent motivation and empirical setup/analysis  - The overall strategy of differentiable prompt optimized to maintain fluency is reasonable and novel.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review praises motivation and empirical setup/analysis.
- Experiments are well-designed: many baselines are implemented to compare proposed method with traditional lifelong learning methods.,Does the review address Experiment?,TRUE,FALSE,The review praises experimental design and baseline comparisons.
"Detailed comments:  1) Reducing the variance of output prediction can reduce the gap on variational posterior, but how does the gap relate to the generalization error?",Does the review address Methodology?,TRUE,FALSE,The review questions relationship between variance reduction and generalization error.
This paper presents a replication study of BERT pretraining and carefully measures the impact of many key hyperparameters and training data size.,Does the review address Methodology?,TRUE,FALSE,The review describes replication study of BERT pretraining.
- The data preprocessing and training steps are complex.,Does the review address Methodology?,TRUE,FALSE,The review notes complexity of preprocessing and training steps.
The theory can be more practically useful if it can be extended to quantify the intractability level so the resulting embeddings' error can be bounded or compared.,Does the review address Theory?,TRUE,FALSE,The review suggests theoretical extension for practical utility.
"As the main contribution of this paper is the increased efficiency of the proposed approach, it must be clear how efficiency is measured.",Does the review address Contribution?,TRUE,FALSE,The review discusses need for clear efficiency measurement.
The paper is mostly clearly written and discusses server interesting ablation experiments.,Does the review address Ablation?,TRUE,FALSE,The review mentions interesting ablation experiments.
- Standard Errors: The VIMABench experiments were run over three random seeds for each meta-task but results are reported without any standard errors?,Does the review address Experiment?,TRUE,FALSE,The review questions missing standard errors in experimental results.
"Furthermore, they have clarified that on the key metric of CommonGen they achieved SoTA with only slightly more than half the parameters of the current SoTA model.",Does the review address Presentation?,TRUE,FALSE,The review discusses clarification about model parameters and SOTA achievement.
"However, two recent papers that appeared on arXiv before the ICLR submission deadlines also use Transformers for protein contact prediction.",Does the review address Methodology?,TRUE,FALSE,The review mentions similar methodology in recent papers using Transformers.
"- It's because if the largest phrase length is the sentence length, then model can be simplified into a some sort of convolution RNN where the each state of the RNN goes through some convolution layer before a final softmax and attention.",Does the review address Presentation?,TRUE,FALSE,The review explains model simplification based on phrase length.
"In addition, the explanations (query-answer chains) are shorter and more human-interpretable.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses characteristics of explanations.
"Compared to a softmax layer and hierarchical/differentiated softmax, is binary code prediction a natural way to predict words?",Does the review address Comparison?,TRUE,FALSE,The review compares different word prediction approaches.
"Intuitively, a smaller gap might lead to better performance.",Does the review address Result?,TRUE,FALSE,The review discusses relationship between gap size and performance.
"However, the way they convert the logic forms is different for each dataset and they have to manually design rules for each logic form.",Does the review address Methodology?,TRUE,FALSE,The review discusses dataset-specific logic form conversion.
More importantly the PACT methodology is more general; the idea of incorporating diverse auxiliary tasks as a language modeling task by introducing a distinct token for each task is novel.,Does the review address Methodology?,TRUE,FALSE,The review discusses novelty of PACT methodology.
"In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 257–266.",Does the review address Related Work?,TRUE,FALSE,The review references specific conference proceedings.
**Summary** This work relates a pre-training performance with a downstream performance for tasks that _can_ be reformulated as next word prediction tasks.,Does the review address Result?,TRUE,FALSE,The review discusses relationship between pre-training and downstream performance.
"(iii) Some suggested baselines that make these assumptions would be a heuristic A\* search, or modifying any of the existing algorithms to use smaller action spaces and/or apply alternative exploration strategies seen in previous works such as modular policy chaining (that MC!Q*BERT uses) or Go-Explore (Madotto et al.",Does the review address Comparison?,TRUE,FALSE,The review suggests baseline comparisons and alternatives.
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Experiment?,TRUE,FALSE,The review criticizes limited validation and missing analyses.
"I’m not sure about this, so any discussion would be appreciated.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests discussion clarification.
"For example, if you could give us one or two sentences of Fon in the beginning of the paper, that demonstrate some of the difficulties of the language, I think this would greatly strengthen the motivation.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests strengthening motivation with language examples.
Questions:  * How can we be sure that the specific power law derived from a different experimental configuration in Kaplan et al. (2020) corresponds to the empirical law that can be derived for transformers in this particular evaluation setting?,Does the review address Evaluation?,TRUE,FALSE,The review questions applicability of power law across settings.
This looks like an order of magnitude difference in dataset empirical evaluation to me.,Does the review address Data/Task?,TRUE,FALSE,The review discusses dataset size difference in empirical evaluation.
"- The definitions, models, and assumptions in the paper are intuitive and clear (e.g., natural task).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review praises clarity of definitions and assumptions.
Could you explain the significance of this result again?,Does the review address Presentation?,TRUE,FALSE,The review requests explanation of result significance.
In case of the textual prompts benchmarks its also not clear to me why no standard errors on results are reported?,Does the review address Data/Task?,TRUE,FALSE,The review questions missing standard errors in benchmarks.
"Hence, to my understanding, it may not be suitable to use the term ""global reasoning"" in this work.",Does the review address Presentation?,TRUE,FALSE,The review questions appropriateness of terminology.
The show improved performance in MultiWoz dataset.,Does the review address Result?,TRUE,FALSE,The review mentions improved performance on MultiWoz dataset.
More details should be reported to show the benefits of adopting the adaptive smoothing parameter.,Does the review address Methodology?,TRUE,FALSE,The review requests details about adaptive smoothing parameter.
"Specifically, having the BFS analysis of the attention weights as a function of different GreaseLM layers (as done by Yasunaga et al.)",Does the review address Methodology?,TRUE,#ERROR!,The review discusses BFS analysis of attention weights.
"This paper suggests a number of cheap-to-compute corruptions of the input data that, when used to reconstruct the input, enrich the underlying model.",Does the review address Methodology?,TRUE,FALSE,The review describes input corruption methodology.
"For the theoretical analysis, it was not clear to me what is the contribution of the current analysis compared to the Levine 2020 paper.",Does the review address Theory?,TRUE,FALSE,The review questions theoretical contribution compared to prior work.
"In particular, they used the option framework to represent the connection between the dialog policy and the natural language generation.",Does the review address Methodology?,TRUE,FALSE,The review discusses use of option framework for dialog policy.
Performance better than previous approaches (although minor).,Does the review address Result?,TRUE,FALSE,"The review explicitly mentions performance being ""better than previous approaches"", directly relating to results."
"It provides a nice theoretical framework for thinking about the connection between language models and downstream tasks, which future work could build on.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses language models and downstream tasks, which aligns with the Data/Task aspect."
Some experimental settings only include the baselines Random and Vote-k. More methods as mentioned in 4.3.2 can be also included.,Does the review address Methodology?,TRUE,FALSE,"The review critiques experimental settings and mentions baselines, which relates to methodology."
* The paper doesn’t explain why learning a linear model directly on the context embeddings f(s) performs better than using the contextual mean embeddings.,Does the review address Result?,TRUE,FALSE,"The review discusses performance of a linear model, which is related to results."
"The first use of the proposed definitions to make a non-trivial claim is in Section 5 with Postulate 1, but this claim is not justified.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review questions the justification of a claim, directly addressing motivation and validation."
"Thus, it seems to me that you are essentially applying past results to answer a specific question you have (which is still a valuable contribution).",Does the review address Contribution?,TRUE,FALSE,The review explicitly discusses the value of the contribution.
"*  What is the contribution of each specific design choice, such as the FFN/global attention and implicit self-attention, to the end performance?",Does the review address Analysis?,TRUE,FALSE,"The review asks about the contribution of specific design choices, which is an analytical inquiry."
- No error analysis about the generated plans and the edited text.,Does the review address Analysis?,TRUE,FALSE,"The review points out a lack of error analysis, which is an analytical observation."
"The presentation can be improved, all the definitions are hard to follow.",Does the review address Presentation?,TRUE,FALSE,"The review directly comments on the difficulty of following definitions, addressing presentation."
Summary of review:  There have been lots of interests to understand why self-supervised learning approaches such as the next word prediction task learn a useful representation for downstream tasks.,Does the review address Data/Task?,TRUE,FALSE,"The review discusses self-supervised learning approaches and downstream tasks, fitting the Data/Task aspect."
- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.,Does the review address Analysis?,TRUE,FALSE,"The review suggests more ablation analysis, which is an explicit analytical recommendation."
"Yet, it is difficult for me to trust that the effects in this paper will generalize to better performing models without further evidence: what if the CALM intermediate objectives only help with mistakes that larger models do not make in the first place?",Does the review address Result?,TRUE,FALSE,The review discusses the effects and generalizability of results.
So a very straightforward idea is that we can directly set an independently learnable parameter as the prototype of each category to calculate the cosine similarity with image embeddings.,Does the review address Methodology?,TRUE,FALSE,The review describes a straightforward methodological approach.
(2) Another weakness is that the comparison with the vanilla and LS baselines does not seem to be properly controlled in terms of parameters.,Does the review address Methodology?,TRUE,FALSE,"The review critiques the comparison of baselines in terms of parameters, which is a methodological concern."
As noted in contemporary works such assumptions dramatically reduce the difficulty and language understanding capabilities of text games (Yao et al. (ii) The second issue is that MC-LAVE assumes that the simulator is deterministic and can conduct rollouts and reset within the span of an episode - standard planning assumptions but incompatible with all other baselines (except for MC!Q\*BERT) which do not use this handicap.,Does the review address Presentation?,TRUE,FALSE,"The review discusses assumptions and baseline comparisons, which relates to presentation of the work."
The separate table on the left in Table 2 appears to be redundant.,Does the review address Presentation?,TRUE,FALSE,"The review points out a redundant table, which is a presentation-related comment."
"These prior methods do not incorporate the SFT stage, making it unclear how the model performs before this crucial phase.",Does the review address Comparison?,TRUE,FALSE,The review compares prior methods and their performance.
"- Similarly, using bold and not-bold B in Theorem 5.2 is confusing notation.",Does the review address Presentation?,TRUE,FALSE,"The review critiques notation, which is a presentation aspect."
"In experimental details, the slightly better performance in Table 2, can it be attributed to finer generation powered by the RNN generator?",Does the review address Result?,TRUE,FALSE,The review discusses performance and potential reasons for slight improvements.
"Overall, I like the idea of the paper: it is important to reduce the parameters needed for sets of tasks, to enable NLP models to be deployed in a larger variety of settings, and reducing the amount of data needed.",Does the review address Data/Task?,TRUE,FALSE,"The review discusses tasks, parameter reduction, and NLP model deployment."
"It might be good to find the best hyperparameters for each setting to truly do a fair comparison (avoiding hyperparameter tuning isn't really a fair comparison, IMO -- but this depends on how much compute you have available).",Does the review address Methodology?,TRUE,FALSE,The review suggests finding best hyperparameters for fair comparison.
- The analysis which builds on these definitions/models/assumptions provides meaningful theoretical insight into why language model pre-training may be so beneficial for downstream training.,Does the review address Methodology?,TRUE,FALSE,The review discusses theoretical models and their insights into methodology.
"With the proposed CaptionNet dataset, it is now possible to have a fairer comparison between VL models and CE models.",Does the review address Methodology?,TRUE,FALSE,The review discusses creating a dataset for fairer comparisons.
"The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",Does the review address Data/Task?,TRUE,FALSE,The review discusses a specific task (Parity/Sum) and its assumptions.
"Firstly, in the last paragraph of Section 2, the authors claim that the role matrix $R$ would be invertible such that there exists a matrix $U = R^{-1}$ such that the fillers would be recovered.",Does the review address Theory?,TRUE,FALSE,The review discusses a theoretical claim about a role matrix and its properties.
* The paper is well motivated and easy to understand and follow.,Does the review address Presentation?,TRUE,FALSE,"The review explicitly mentions the paper being ""well motivated and easy to understand and follow"", which is a presentation aspect."
The authors have created a large dataset for relation extraction as question answering which would likely be useful to the community.,Does the review address Data/Task?,TRUE,FALSE,"The review discusses creating a dataset for relation extraction, directly addressing the Data/Task aspect."
"Section 4.8: Using transformers for generating proteins with natural properties is not new (see Madani et al, 2020, ‘ProGen’ or Rives et al, 2020).",Does the review address Methodology?,TRUE,FALSE,The review compares the methodology to previous work on protein generation.
"Similarly, for pretraining, the model runs 80% of the training steps (20% reduction), which accounts much of the training time reduction reported on section 4.3.",Does the review address Methodology?,TRUE,FALSE,The review discusses training steps and methodology details.
"**Pros**  - The paper is well structured and easy to follow, the idea of modeling sentences to a Brownian bridge latent space is neat and generic enough to (1) allow for noise given its stochasticity (2) doesn't require explicit domain knowledge for planning.",Does the review address Methodology?,TRUE,FALSE,The review describes the methodology of modeling sentences in a Brownian bridge latent space.
"However, the main driving force in the choice of the language-specific computation is currently a single hyper-parameter p which is the same across languages; so, this will lead to choices that are good on average for all language pairs involved for a given *universal* budget.",Does the review address Methodology?,TRUE,FALSE,The review critiques the language-specific computation methodology.
"Unfortunately, many aspects of the models, experimentation, and evaluation are not explained very well.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"The review points out a lack of explanation in models, experimentation, and evaluation."
The method's innovative and effective feature fusion into the language model sets it apart.,Does the review address Presentation?,TRUE,FALSE,The review highlights an innovative feature of the method's presentation.
This paper is meaningful and presents a reasonable analysis.,Does the review address Analysis?,TRUE,FALSE,"The review describes the paper as presenting a ""reasonable analysis""."
"Detailed comments:  - P2, Sec 1.1: ""analyze the efficiency language model features"" -> analyze the efficiency of language model features  - P2, Sec 2: you started introducing these notations without explaining what they mean.",Does the review address Presentation?,TRUE,FALSE,"The review provides detailed comments on notation and language, which are presentation aspects."
It is not clear how certain experimental designs were made.,Does the review address Experiment?,TRUE,FALSE,The review expresses uncertainty about experimental designs.
"- I know GPT3 access is hard to get, but I wish experiments with k=8 prompts could be compared against  Post rebuttal: I think another pass for clarity over the paper would be good for the final version, but otherwise I'm happy with the paper updates and I'm happy to see the ablation numbers aren't too sensitive to token count.",Does the review address Methodology?,TRUE,FALSE,The review discusses experimental approaches and prompt comparisons.
"It is also strange that the multi-cluster approach, which discards inter-cluster (word and language) semantic information performs the best with respect to the extrinsic metrics.",Does the review address Result?,TRUE,FALSE,The review discusses the performance of a multi-cluster approach.
"- One huge benefit of perceiver IO is to train different tasks together and explore the transfer between different tasks/modalities, which is not explored in this paper.",Does the review address Methodology?,TRUE,FALSE,The review discusses potential task exploration in the methodology.
Their models achieve better quantitative results when compared to the provided baselines.,Does the review address Result?,TRUE,FALSE,The review explicitly mentions quantitative results compared to baselines.
The authors find that the main ingredients for the success of in-context learning are a combination of selective annotation with similarity-based prompt retrieval.,Does the review address Data/Task?,TRUE,FALSE,The review discusses in-context learning and its key ingredients.
"Some kind of analysis of the qualitative strengths and weaknesses of the binary code prediction would be welcome -- what kind of mistakes does the system make, and how does this compare to standard softmax and/or hierarchical and differentiated softmax?",Does the review address Analysis?,TRUE,FALSE,The review requests a qualitative analysis of the system's strengths and weaknesses.
"While previous work has examined tasks in the overall area, to my knowledge there has not been any publicly availble sentence-level annotated data for the problem -- the authors here make a contribution as well by annotating some data included with the submission; if it is released, it could be useful for future researchers in this area.",Does the review address Data/Task?,TRUE,FALSE,The review discusses the creation of a new dataset and its potential usefulness.
"(2) In this paper, similarity and alignment structures are proposed, but no ablation experiments have been carried out to prove the effectiveness of the improved model.",Does the review address Experiment?,TRUE,FALSE,The review points out a lack of ablation experiments.
* Section 4 - I think you really need to re-state that the algorithm has a human-in-the-loop for clarity.,Does the review address Methodology?,TRUE,FALSE,The review suggests clarifying the algorithm's methodology.
The provided experiments are more like baselines for self-evaluation other than state-of-the-art performance.,Does the review address Result?,TRUE,FALSE,The review critiques the experimental results as baseline-level.
"Authors could have provided more in-depth details (visualizations, analysis, examples) to show main differences between the proposed approach and baselines (specially LayoutLM).",Does the review address Presentation?,TRUE,FALSE,The review suggests providing more details and visualizations.
The analysis shows that it outperforms only all the other baselines only on 5/9 games and matches on 3.,Does the review address Comparison?,TRUE,FALSE,The review discusses the performance across different games.
The paper presents an end-to-end methods for jointly training named entity recognition (NER) and relation extraction (RE).,Does the review address Methodology?,TRUE,FALSE,The review describes an end-to-end method for joint training.
"Comparing the proposed method to earlier approaches such as PaLI, CoCa, and Flamingo may not be entirely fair.",Does the review address Comparison?,TRUE,FALSE,The review discusses comparing the proposed method to earlier approaches.
A single value of $k=150$ was chosen for experiments across all tasks.,Does the review address Data/Task?,TRUE,FALSE,"The review discusses experimental parameters across tasks, which relates to the Data/Task aspect."
"However, all the parameters/variables in the neural networks are freely designated and are not correlated to each other, thus they cannot work together to meet the requirements in the binding-unbinding mechanism.",Does the review address Theory?,TRUE,FALSE,The review discusses theoretical limitations of neural network parameters.
"In terms of strenghs - The paper has a very throughout analysis of different models and positional encodings - It proposes several contributions, including a new probing task and several positional encoding methods.",Does the review address Analysis?,TRUE,FALSE,"The review explicitly highlights a ""thorough analysis"" of models and positional encodings."
"* I think it should be discussed earlier (in intro/related work) why the paper focuses on language models which do next word prediction via linear softmax models over fixed dimensional context embeddings, and that BERT is out of scope.",Does the review address Methodology?,TRUE,FALSE,The review suggests discussing the methodological focus on specific language model types.
"By converting the logic forms to natural languages, the authors can leverage paraphrase datasets and pre-train the critic as a paraphrase model.",Does the review address Presentation?,TRUE,FALSE,"The review describes a methodology for converting logic forms, which relates to presentation."
"- The paper is well written: it gives an appropriate context, presents the main theoretical results, and verifies _some_ of the claims experimentally.",Does the review address Experiment?,TRUE,FALSE,The review comments on the paper's experimental verification of claims.
"335: consider defining GPGPU Table 3: Highlight the best BLEU scores in bold Equation 15: remind the reader that q is defined in equation 6 and b is a function of w. I was confused by this at first because w and h appear on the LHS but don't appear on the right, and I didn't know what b and q were.",Does the review address Presentation?,TRUE,FALSE,The review provides specific suggestions for improving presentation clarity.
Should also discuss related work in 2d spatial visualization of country-country relationships by Peter Hoff and Michael Ward.,Does the review address Presentation?,TRUE,FALSE,The review suggests discussing related work in visualization.
"It would be to show more experiment results for some settings, for example, performance on Sum task when training with a mixture distribution, or more Sum task samples and fewer Parity task samples ( p range from 0.5 to 1.",Does the review address Data/Task?,TRUE,FALSE,The review suggests additional experimental settings for specific tasks.
"They use the reading comprehension model of Seo et al. 2016, adding the ability to return “no relation,” as the original model must always return an answer.",Does the review address Methodology?,TRUE,FALSE,The review describes a specific methodological approach to a reading comprehension model.
It paves the way for more widespread application of VIP in scenarios where interpretable-by-design approaches are critical.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses the broader implications and interpretation of the work.
* Related work: I would also include a discussion of this Lazaridou et al paper where they compare ways of combining EC with non-EC learning signals (e.g. image caption training): https://aclanthology.org/2020.acl-main.685.pdf  * Ethics statement: I appreciate this statement and agree with the possible positive impacts.,Does the review address Methodology?,TRUE,FALSE,The review suggests including additional related work methodology.
"According to Table 6, I can hardly see a clear improvement brought by the introduced new VE modules.",Does the review address Result?,TRUE,FALSE,The review critiques the improvement shown in the results.
A uniform framework for resampling Different recombinations perform more or less favorably across different datasets.,Does the review address Methodology?,TRUE,FALSE,The review discusses a framework for resampling and recombination.
Why don't the authors of this work do this evaluation as well?,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions the motivation behind certain evaluation choices.
It is unclear why the authors only show the response generation results.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out a lack of clarity in result presentation.
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.,Does the review address Evaluation?,TRUE,FALSE,The review discusses model evaluation on publicly available datasets.
Their thorough ablation experiments and other analysis yield some interesting findings the authors could emphasize more.,Does the review address Result?,TRUE,FALSE,The review highlights interesting findings from ablation experiments.
The authors curated a large-scale dataset for first-stage pretraining and second-stage instruction tuning.,Does the review address Data/Task?,TRUE,FALSE,The review discusses dataset curation for pretraining and instruction tuning.
"(In particular, pre-training on emergent language performs on average better than synthetic hierarchical data, but not quite as well as a different natural language, and all of these pre-training methods do better than training from scratch.)",Does the review address Result?,TRUE,FALSE,The review compares performance of different pretraining methods.
"Overall, the authors show better accuracy for their tested problem set against REWARD, a baseline system (a transformer), lang2logic, and Ins2AST across two dimensions: data type recovery and abstract syntax tree (AST) generation.",Does the review address Result?,TRUE,FALSE,The review discusses accuracy improvements across different baselines.
"It would be useful if following the suggestions of [2,3] the authors could present results in settings with low data regimes and with significant distribution shift with respect to the pre-training set, which represents a more realistic application setting.",Does the review address Data/Task?,TRUE,FALSE,The review suggests exploring results in low-data and distribution-shifted settings.
Why does Recomb-2 perform less well than GECA in SCAN?,Does the review address Result?,TRUE,FALSE,The review questions the performance of a specific recombination method.
"In the 6.2.3 visualization of clusters, it would be very useful to have a visualization of clusters from some baselines on other ways of learning.",Does the review address Presentation?,TRUE,FALSE,The review suggests improving visualization of cluster comparisons.
Some theoretical and empirical evidence is shown for the learning effect.,Does the review address Result?,TRUE,FALSE,The review mentions theoretical and empirical evidence for learning effects.
"The authors propose to include related texts retrieved by the kNN method in a single training sample, which is proved effective in solving sentence similarity tasks.",Does the review address Methodology?,TRUE,FALSE,The review describes a methodology of including related texts using kNN method.
- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.,Does the review address Experiment?,TRUE,FALSE,The review critiques the experimental analysis and its dataset distribution.
But the authors didn’t compare against these agent-based system design.,Does the review address Methodology?,TRUE,FALSE,The review points out a lack of comparison with alternative system designs.
"The authors could add more content to figure 1, which may resolve this issue.",Does the review address Presentation?,TRUE,FALSE,The review suggests improving content in Figure 1.
Minor issues that did not affect score ------------------ Figure 1 has some scaling/resolution issues that make it hard to read.,Does the review address Presentation?,TRUE,FALSE,The review highlights scaling and resolution issues in Figure 1.
The paper provides an image on GCP to reproduce their partial results.,Does the review address Result?,TRUE,FALSE,The review mentions providing an image for reproducing partial results.
"> On the generative task CALM performs closer to SOTA, but it improves only slightly on T5.",Does the review address Data/Task?,TRUE,FALSE,The review discusses performance on a generative task.
"Contribution: The authors contribute a new tokenization method, code, and a dataset.",Does the review address Contribution?,TRUE,FALSE,The review explicitly lists the contributions of the paper.
The model architecture should be better justified.,Does the review address Methodology?,TRUE,FALSE,The review suggests better justification of the model architecture.
Also they could visually demonstrate the advantages of their approach.,Does the review address Presentation?,TRUE,FALSE,The review recommends visually demonstrating the approach's advantages.
Such a comparison would highlight the advantages of the multi-task model and would be helpful for the relevant audience.,Does the review address Methodology?,TRUE,FALSE,The review suggests a comparison to highlight multi-task model advantages.
There are few places (see details) that authors have assumptions in mind but do not provide those assumptions until later.,Does the review address Presentation?,TRUE,FALSE,The review critiques the delayed presentation of assumptions.
"(2) multiCCA : Extends the approach presented by Faruqui and Dyer (2014) for embedding bilingual words, to multilingual words by using English embeddings as the anchor space.",Does the review address Methodology?,TRUE,FALSE,The review describes a specific methodological approach for multilingual word embedding.
"It is not clear whether the proposed method can be applied to other hardware settings, such as other GPUs, TPUs and large scale.",Does the review address Methodology?,TRUE,FALSE,The review questions the method's applicability to different hardware settings.
"In experiments, there is no comparison with previous retrieval based methods.",Does the review address Significance?,TRUE,FALSE,The review points out a lack of comparison with previous retrieval methods.
* I found the discussion in Section 4.1 pretty confusing.,Does the review address Presentation?,TRUE,FALSE,The review finds a specific section confusing.
The visualization of OTTER’s matching illustrates its effectiveness in handling many-to-many relationships.,Does the review address Presentation?,TRUE,FALSE,The review discusses a visualization illustrating the method's effectiveness.
"Negatives --------- The experiments do not compare to many other approaches, even though those approaches are cited throughout the paper.",Does the review address Experiment?,TRUE,FALSE,The review critiques the lack of comprehensive experimental comparisons.
(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.,Does the review address Methodology?,TRUE,FALSE,The review highlights the model's performance on specific tasks.
Hyper-parameter balancing strategies in Section 3.1 is not a solid theoretical analysis.,Does the review address Analysis?,TRUE,FALSE,The review critiques the theoretical analysis of hyper-parameter balancing.
The proposed model is then experimentally verified on three logic-driven datasets which demonstrates some performance gain.,Does the review address Result?,TRUE,FALSE,The review mentions experimental verification and performance gain.
Some comments:  _ It may be interesting to include a brief explanation of the differences between the approach from Tian et al. 2014 and the current one.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests providing more detailed explanation of approach differences.
"For the second ablation, why do all the larger splits lead to similar performance?",Does the review address Ablation?,TRUE,FALSE,The review asks about performance similarities in ablation experiments.
Experimental evaluation shows competitive performance.,Does the review address Experiment?,TRUE,FALSE,The review notes competitive performance in experimental evaluation.
"(3) The proposed model in this paper uses sparse alignment matrix to aggregate token-level similarity, where each element represents the alignment of a pair of tokens, which can develop different retrieval models in a unified way and identify the shortcomings of existing models.",Does the review address Presentation?,TRUE,FALSE,The review describes the model's presentation of sparse alignment matrix.
"For example, in the visualization in Figure 2, the maximum many-to-many relationship of a sample is 3.",Does the review address Presentation?,TRUE,FALSE,The review discusses a visualization detail in Figure 2.
"However, there are many numbers in different tables.",Does the review address Presentation?,TRUE,FALSE,The review comments on the number of tables.
"what part of the performance is coming from pretraining (especially if using VAE type is novel, then quantifying that is important with and without VAE type SL), etc.",Does the review address Methodology?,TRUE,FALSE,The review suggests investigating the performance impact of pretraining.
"However, they compare to BERT models and build themselves on RoBERTa_base; how are the results meaningful if they use a stronger model to start with?",Does the review address Comparison?,TRUE,FALSE,The review questions the meaningfulness of comparisons with different model bases.
So my point 5 is important to answer and I would like to see all the details are clarified in order to make the contribution stronger.,Does the review address Contribution?,TRUE,FALSE,The review suggests clarifying details to strengthen the contribution.
"**Updates after rebuttal period**  The authors addressed some of the concerns -- showing inference time, model size and a discussion about training details and hyperparameters in the appendix.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review mentions addressing concerns with additional details.
The paper made a significant contribution to idea of using adversarial training as part of the self-supervision signal for language learning.,Does the review address Methodology?,TRUE,FALSE,The review highlights the contribution of using adversarial training in language learning.
Making these comparisons would require a heavy rewrite starting from the abstract to the analysis and so I would recommend reject right now but look forward to seeing an updated version of the paper in the future with some of these changes.,Does the review address Comparison?,TRUE,FALSE,The review suggests comprehensive comparisons requiring a major rewrite.
"However, the way they convert the logic forms is different for each dataset and they have to manually design rules for each logic form.",Does the review address Data/Task?,TRUE,FALSE,The review discusses the manual conversion of logic forms across datasets.
- Major contributions of the work should be described in the main paper.,Does the review address Contribution?,TRUE,FALSE,The review suggests describing major contributions in the main paper.
Solid experiments demonstrating the proposed method outperforms other existing approaches.,Does the review address Result?,TRUE,FALSE,The review notes solid experiments demonstrating performance.
Human evaluation is costly and could also have bias like the paper points out.,Does the review address Evaluation?,TRUE,FALSE,The review discusses potential biases in human evaluation.
"-----Strengths----- I think the main contribution of this paper is a simple way to ""flatten"" structured information to an array of vectors (the memory), which is then connected to the tagger as additional knowledge.",Does the review address Contribution?,TRUE,FALSE,The review highlights the main contribution of flattening structured information.
"If there are particular differences in the above, it would nice to clearly state them and also say why the different choices and verify if the different choices are beneficial compared to the previous ones.",Does the review address Evaluation?,TRUE,FALSE,The review suggests clearly stating and verifying different choices.
"Finally, a number of ablation studies are performed and demonstrate the effectiveness of the proposed method to some extent.",Does the review address Methodology?,TRUE,FALSE,The review mentions ablation studies demonstrating method effectiveness.
How can the authors use a pair of logic forms as negative examples (in figure-2)?,Does the review address Methodology?,TRUE,FALSE,The review questions the methodology of using logic form pairs as negative examples.
A key parameter that occurs in obtaining the above results is a worst-case coefficient that bounds the distributional shift between language model distributions of the training dataset and that of the downstream task.,Does the review address Data/Task?,TRUE,FALSE,The review discusses a parameter related to distributional shift between datasets.
"In comparison, if we look at Page 17, the actual annotations from the authors are very long and detailed.",Does the review address Comparison?,TRUE,FALSE,The review compares the length and detail of annotations.
The experiment results in Tables 1 & 2 cannot plausibly prove OTTER is more effective than CLIP.,Does the review address Experiment?,TRUE,FALSE,The review critiques the experimental results' inability to prove effectiveness.
"), yet I could not find any actual training experiments, that is training a large LLM from scratch, in the paper.",Does the review address Experiment?,TRUE,FALSE,The review notes a lack of training experiments for large language models.
"Writing:  The writing is overall clear and easy to follow, although it took me quite some time to map out the definitions of various notations.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review comments on the clarity of writing and notation difficulty.
"It would have been better to see the performance gains on more difficult text-classification tasks (non-GLUE), or underperforming models (non-BERT based).",Does the review address Result?,TRUE,FALSE,The review suggests exploring performance on more challenging tasks.
(4) Translation invariance : Uses a low rank decomposition of the word PMI matrix with an objective with includes bilingual alignment frequency components.,Does the review address Methodology?,TRUE,FALSE,The review describes a methodology involving low-rank matrix decomposition.
"Of course, it is valuable to see the great performance achieved by single-task finetuning for RoBERTa.",Does the review address Methodology?,TRUE,FALSE,The review comments on single-task fine-tuning performance.
A closer look at evaluating the phrases in a subset of the evaluation set would be necessary to support the claims.,Does the review address Evaluation?,TRUE,FALSE,The review suggests a more detailed evaluation of phrases.
I would recommend the authors to at least assume the availability of some public data that is kept out of training and evaluations and to run all the baselines fairly in this setting.,Does the review address Evaluation?,TRUE,FALSE,The review suggests improving evaluation methodology by using public out-of-training data.
"As far as I know, this is indeed the first work for handling this task using binding-unbinding mechanism.",Does the review address Novelty?,TRUE,FALSE,The review explicitly discusses the work's novelty in using a binding-unbinding mechanism.
"How would it perform if LLM is not GPT-4, but rather those open-source alternatives like Llama.",Does the review address Result?,FALSE,TRUE,"The review poses a hypothetical question about performance with different models, but does not discuss actual results."
Using meta-learning for compositional generalization is reasonable.,Does the review address Methodology?,TRUE,FALSE,The review comments on the reasonableness of using meta-learning for compositional generalization.
"In Figure 1, results with p ranges from 0.1 to 0.5 are shown.",Does the review address Result?,FALSE,TRUE,The review simply states a factual observation about Figure 1's results range without analyzing its presentation.
Authors also used a discriminator reward signal to cope with sparse reward (dialog success rate) and better representation of the human evaluation.,Does the review address Evaluation?,TRUE,FALSE,The review describes the use of a discriminator reward signal for evaluation.
(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.,Does the review address Related Work?,TRUE,FALSE,The review discusses performance in comparison to previous work.
(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.,Does the review address Result?,TRUE,FALSE,The review highlights achieving better results on MSMARCO tasks.
It also compares different subword representation strategies and finds that syllable representations perform best (when not using BERT).,Does the review address Result?,TRUE,FALSE,The review discusses findings about subword representation strategies.
"Its not that I/readers dont believe you when we are *told*, but being *shown* makes it much more interesting and give people an appreciation for Fon tokenization challenges!",Does the review address Intuition/Justification/Motivation/Validation?,FALSE,TRUE,The review makes a commentary about presentation style but does not address motivation directly.
How do the settings used in the experiments compare to those used for the analysis?,Does the review address Analysis?,FALSE,TRUE,The review asks a comparative question about experimental settings but does not discuss analysis.
N-Bref has a number of components that it relies on to perform its decompilation.,Does the review address Methodology?,TRUE,FALSE,The review describes components of a decompilation approach.
Although it turns out that additional components need to be introduced for good performance.,Does the review address Result?,TRUE,FALSE,The review suggests additional components are needed for good performance.
"The idea, at the time the paper was originally written, was indeed very novel as there were not many audio language models around back in May.",Does the review address Novelty?,TRUE,FALSE,The review discusses the novelty of the approach at the time of writing.
"To reduce the variance due to the sampling of masks, the authors propose a fully-explored masking strategy, where a text sequence is divided into a certain number of non-overlapping segments.",Does the review address Methodology?,TRUE,FALSE,The review describes a masking strategy methodology.
* One idea I had here: Could you define a natural task as one for which there exists a sparse linear model over the *logits* of p*( .,Does the review address Presentation?,FALSE,TRUE,The review suggests a hypothetical definition without critiquing presentation.
- Perhaps adding more pre-trained LMs such as GPT-2 and different sizes of T-5.,Does the review address Methodology?,TRUE,FALSE,The review suggests adding more pre-trained language models.
"5.3 L638-639: ""unions of countries"" isn't a well defined concept.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out an unclear concept definition.
"About type dependency graph: 1) Comparing to previous work (e.g, Allamanis et.al, ICLR 18), it seems the construction of the task specific graph is the major contribution, where the novelty is a bit limited.",Does the review address Contribution?,TRUE,FALSE,The review discusses the limited novelty of the contribution.
"Though the paper promises faster training speeds in the introduction, Table 3 shows only modest (less than x2) speedups for training.",Does the review address Methodology?,TRUE,FALSE,The review critiques the modest speedup claimed in the methodology.
- The visualization section is only a minor contribution; there isn't really any innovation or findings about what works or doesn't work here.,Does the review address Presentation?,TRUE,FALSE,The review criticizes the visualization section as a minor contribution.
* The paper doesn’t explain why learning a linear model directly on the context embeddings f(s) performs better than using the contextual mean embeddings.,Does the review address Methodology?,TRUE,FALSE,The review questions the explanation of model performance.
"Hence, it is hard to directly relate ""reducing the gap"" and ""improve the test-set performance"".",Does the review address Result?,FALSE,TRUE,The review discusses difficulty in relating performance metrics without addressing specific results.
"As mentioned in the paper, the authors also used some in-house data, which I guess cannot be released to the public.",Does the review address Data/Task?,TRUE,FALSE,The review mentions the use of in-house data.
"Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally.",Does the review address Methodology?,TRUE,FALSE,The review discusses proposed recommendations for multilingual NMT architectures.
"The paper here is only concerned with #1 and less concerned with #2, but certainly the previous work addresses #1.",Does the review address Related Work?,TRUE,FALSE,The review discusses the paper's focus in relation to previous work.
There are several parts to the method and there are I assume several differences in the architecture etc with baselines etc.,Does the review address Comparison?,FALSE,TRUE,The review vaguely mentions method differences without substantive comparison.
The hyperparameter search on \alpha in label smoothing is removed.,Does the review address Methodology?,TRUE,FALSE,"The review notes the removal of a hyperparameter search, which relates to methodology."
"- reasonable initial experimental results demonstrating some ways to help models better use cross-text-chunk dependencies (put them into a contiguous text chunk), providing some hope that these results could make models better.",Does the review address Experiment?,TRUE,FALSE,The review discusses initial experimental results demonstrating model dependencies.
Is any care taken to handle this in training data?,Does the review address Methodology?,FALSE,TRUE,The review poses a question about training data handling without discussing methodology.
This paper studies why language model pre-training has been such an effective technique in improving downstream performance across a wide range of NLP tasks recently.,Does the review address Methodology?,TRUE,FALSE,The review describes the study of language model pre-training methodology.
"For example, besides the quantative improvements, does the rapid convergence and under-training still exist after applying RandomMask?",Does the review address Methodology?,FALSE,TRUE,The review asks a speculative question about methodology without substantive discussion.
weaknesses 1) Approaches are straightforward and lack originality.,Does the review address Novelty?,TRUE,FALSE,The review explicitly critiques the lack of originality in the approaches.
"Of course, it is valuable to see the great performance achieved by single-task finetuning for RoBERTa.",Does the review address Result?,TRUE,FALSE,The review comments on the performance of single-task fine-tuning.
"- Figure 1: unclear why certain input sizes have their accuracy going down, even though they have reached 100% in the earlier epochs.",Does the review address Result?,TRUE,FALSE,The review points out unexpected accuracy variations in results.
"I think this paper can reasonably be rejected, but I'd like to give actionable of constructive criticism, since I do think the work on this low resource language is important for the NLP community.",Does the review address Significance?,TRUE,FALSE,The review discusses the importance of work on a low-resource language.
"The first is selecting the most uncertain examples, and the second is making the CoT annotations longer.",Does the review address Result?,FALSE,TRUE,The review lists approaches without discussing their actual results.
Did you use dynamic masking as that was previous used in RoBERTa?,Does the review address Methodology?,FALSE,TRUE,The review asks a question about masking methodology without substantive discussion.
"While it is hard to formally define meaningful comments, it would be insightful to at least calculate the document frequency of interleaved natural and programming language.",Does the review address Analysis?,TRUE,FALSE,The review suggests an analytical approach to document frequency.
Its current form doesn’t seem to give insight on how the proposed method really helps.,Does the review address Analysis?,FALSE,TRUE,The review critiques the lack of insight without providing analytical details.
"Similar numbers are true for the rest of the tasks: 60.90 vs. 87 for OBQA, 71.01 vs. 90 for PIQA, and 63.20 vs.  89.70 for aNLI.",Does the review address Result?,TRUE,FALSE,The review provides specific numerical results across different tasks.
The experimental results mainly address similar networks with similar context lengths.,Does the review address Comparison?,TRUE,FALSE,The review notes the experimental focus on similar networks.
"Absent both kinds of keyphrases) is evaluated against baselines (which contains only ""present"" type of keyphrases).",Does the review address Evaluation?,TRUE,FALSE,The review discusses evaluation approaches for different types of keyphrases.
It is unclear for readers the details of the selection.,Does the review address Presentation?,TRUE,FALSE,The review points out unclear details of selection.
About experiments: 1) I think one ablation study I’m most interested in is to simply run GNN on the AST (or simply use Allamanis et.al’s method).,Does the review address Experiment?,TRUE,FALSE,The review suggests an additional ablation study.
"On the other hand, eq 7 should be the same as eq 5.",Does the review address Comparison?,FALSE,TRUE,The review makes a brief comment about equation similarity without substantive comparison.
Look forward to the author discussing in following version.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,The review simply expresses anticipation for future discussion.
"While I think it's nice to analyze the connection between RM and DM, the math provided in the paper is simple, and the main contribution is just to add a baseline to the algorithm of Khalifa et al.",Does the review address Contribution?,TRUE,FALSE,The review critiques the contribution as simple and baseline-adding.
"- The paper also emphasizes sample efficiency, which is an essential problem in practical molecular design.",Does the review address Methodology?,TRUE,FALSE,The review highlights the emphasis on sample efficiency.
The other baselines all use the full template-based action space (except the DRRN) of size 10^8 - a auxiliary entropy loss is used there derived from the valid actions but it is not a hard constraint.,Does the review address Comparison?,TRUE,FALSE,The review discusses differences between baselines and their action spaces.
Very well written manuscript with clear non-monotonic description of details.,Does the review address Presentation?,TRUE,FALSE,The review praises the manuscript's clear presentation.
"* Theorem 2 is a restatement of past work, showing that transformers lie in logspace-uniform TC^0 * Theorem 3 assumes TC^0 \neq P / poly, and then derives that transformers cannot simulate any poly-time circuit.",Does the review address Theory?,TRUE,FALSE,The review discusses specific theoretical theorems in detail.
Also helpful to look at [loopInvariant] and the related work mentioned there.,Does the review address Related Work?,FALSE,TRUE,The review briefly mentions related work without substantive discussion.
It seems like more quantitative analysis would be needed to determine how much the LM's attention is correlating empirically to factual knowledge or if there are other factors that are affecting the downstream improvements.,Does the review address Analysis?,TRUE,FALSE,The review suggests the need for more quantitative analysis.
I think this means that some amount of claim rewriting is required in addition to the changed baselines.,Does the review address Comparison?,FALSE,TRUE,The review makes a vague comment about claim rewriting without clear comparison.
"Weaknesses, suggested improvements and requested clarifications  1.",Does the review address Result?,FALSE,TRUE,The review indicates a list of weaknesses without discussing specific results.
An additional ablation experiment trying different number of tokens to optimize could be illuminating (even for just 1 dataset).,Does the review address Experiment?,TRUE,FALSE,The review suggests an additional ablation experiment.
"As sort of an ensemble of expert models, the paper does not include any system-level ablation studies by comparing against other design choices.",Does the review address Ablation?,TRUE,FALSE,The review critiques the lack of system-level ablation studies.
The provided experiments are more like baselines for self-evaluation other than state-of-the-art performance.,Does the review address Comparison?,TRUE,FALSE,The review critiques the experimental baseline approach.
It would be good if the authors could provide some discussion around this observation.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,The review suggests additional discussion without specific details.
"If it is the extension to multilingual embeddings, a few lines explaining the novelty would help.",Does the review address Novelty?,TRUE,FALSE,The review requests explanation of novelty for multilingual embeddings.
It is a bit difficult to understand the task definitions without first understanding the various constituents of the proof.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review discusses difficulty in understanding task definitions.
"Especially because of the surprising magnitude by which this pruning degrades absolute performance, it is unfortunately necessary to try more pruning rates for a fair comparison.",Does the review address Result?,TRUE,FALSE,The review discusses performance degradation due to pruning.
"In Figure 1, results with p ranges from 0.1 to 0.5 are shown.",Does the review address Presentation?,FALSE,TRUE,The review simply states a factual observation about Figure 1.
"- Definition of meaning seems to defeat the whole purpose of this paper, as it allows for any gibberish/random sequence of tokens to still induce a meaning and possibly a set of many other gibberish sequences to be in their equivalent class.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques the definition of meaning in the paper.
Implementation details are only given for the vanilla BERT Are they similar to the EarlyBERT model as well?,Does the review address Methodology?,TRUE,FALSE,The review asks about implementation details across different models.
"####Summary:  To tackle situations where compositionality is mostly required at inference time, the paper proposes a novel data augmentation method with an RNN based generator (recombination); to make the generator generate highly compositional patterns, the paper proposes a resampling method.",Does the review address Presentation?,FALSE,TRUE,The review provides a summary without analyzing presentation.
"- In Table 1, can you explain more explicitly (in caption and text) what “subset” and “class words” means?",Does the review address Presentation?,TRUE,FALSE,The review suggests improving table caption clarity.
"What the authors can do is: you can sample some sentences from the test/development set and count how many comparative words are misused in the original model, among which how many are corrected by reranking.",Does the review address Analysis?,FALSE,TRUE,The review suggests a method for potential analysis without conducting it.
They have evaluated their architecture based on (i) the language modelling test evaluated on PTB and FBIS and (ii) Chinese-English machine translation task on NIST MT02-08 evaluation sets.,Does the review address Methodology?,TRUE,FALSE,The review describes evaluation methodology for different tasks.
"- The literature of DP in multi-modality is lacking, and therefore the work could be interesting  - There are several factually inappropriate usages of the notion of DP.",Does the review address Related Work?,TRUE,FALSE,The review comments on the literature and inappropriate usage.
I realize that PENGI's checkpoint was probably not available when this paper was submitted but it is now.,Does the review address Significance?,FALSE,TRUE,The review makes a brief comment about checkpoint availability.
An additional ablation experiment trying different number of tokens to optimize could be illuminating (even for just 1 dataset).,Does the review address Data/Task?,FALSE,TRUE,The review suggests an experiment about tokens without substantive task discussion.
*  The claims regarding the 10x better data efficiency are not well supported and I would suggest the authors to compare with transformer models on standard LM benchmarks and potentially to some downstream tasks such as MT to make a stronger case.,Does the review address Methodology?,TRUE,FALSE,The review critiques claims about data efficiency.
The error analysis might be better to be a bit more quantitative.,Does the review address Analysis?,TRUE,FALSE,The review suggests making error analysis more quantitative.
- You provide the mapped ORCHID corpus in JSON format in the Supplementary Material.,Does the review address Data/Task?,FALSE,TRUE,The review simply mentions providing a corpus in JSON format without discussing the data/task.
"Without the ablation studies on these two aspects, we cannot determine whether the performance improvement truly comes from the author's contribution or just longer CoT annotations.",Does the review address Ablation?,TRUE,FALSE,The review discusses the need for ablation studies to determine performance improvement.
The results on Split H are positive and they also conducted a range of ablation and error analysis.,Does the review address Result?,TRUE,FALSE,The review mentions positive results and ablation analysis.
"I really like the research question and goals of this work, as it draws an interesting connection between transformers' ability to execute instructions (posed as circuits) and existing results analyzing transformers via circuits and classical work on universal circuits.",Does the review address Methodology?,TRUE,FALSE,The review appreciates the research question's connection between transformers and circuits.
The simple combination of the audio model and LLM does not seem to be novel.,Does the review address Methodology?,TRUE,FALSE,The review critiques the lack of novelty in combining audio model and LLM.
"There's not much justification for it, especially given something simpler like a fixed window average could have been used.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review points out a lack of justification for the approach.
"_ There are some missing citations that could me mentioned in related work as : Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space Neelakantan, A., Shankar.",Does the review address Related Work?,TRUE,FALSE,The review suggests missing citations for related work.
Authors could have plugged their embedding strategy in LayoutLM to understand the impact of that particular component.,Does the review address Comparison?,TRUE,FALSE,The review suggests comparing the embedding strategy with existing models.
"2016 [2] A syntactic neural model for general-purpose code generation, Yin and Neubig 2017 [3] Making Neural Programming Architectures Generalize via Recursion, Cai et al. 2017  ####Authors have engaged in the discussion, clarified questions about the paper and addressed comments in its newest revision.",Does the review address Related Work?,FALSE,TRUE,The review lists some related work citations without substantive discussion.
"If not, it seems unfair to compare with PMO's best baseline REINVENT.",Does the review address Comparison?,FALSE,TRUE,The review makes a brief comment about comparison without detailed analysis.
"** Again, the performance improvement may come from two aspects.",Does the review address Result?,FALSE,TRUE,The review vaguely mentions potential performance improvements.
The authors have done further experiments and show that there are still gains on these tasks when model sized is increased significantly.,Does the review address Experiment?,TRUE,FALSE,The review describes additional experiments with model size.
A thorough proofreading could enhance the clarity of writing and word choice.,Does the review address Presentation?,TRUE,FALSE,The review suggests proofreading to improve writing clarity.
"They do pre-train their model (BROS) on a large dataset with 11M documents, and then used such models to perform downstream tasks in four smaller datasets.",Does the review address Data/Task?,TRUE,FALSE,The review describes pre-training and downstream tasks.
Can the proposed theory help explain some of the successes of one architecture over others?,Does the review address Methodology?,FALSE,TRUE,The review asks a speculative question about theoretical explanations.
"Specifically, I would expect authors provide more detailed recommendation for AL, DS, and multi-domain sampling in terms of sampling techniques, and population of different sources for certain application.",Does the review address Data/Task?,TRUE,FALSE,The review suggests more detailed recommendations for data sampling.
May I know many questions are in each data split shown in Table 5?,Does the review address Presentation?,FALSE,TRUE,The review asks a question about table details without analyzing presentation.
- Performance with relatively little finetuning data are encouraging.,Does the review address Data/Task?,FALSE,TRUE,The review briefly mentions performance with little fine-tuning data.
"However, they merely note that their data was annotated at the “relation” level rather than at the triple (relation, entity pair) level… but couldn’t Bordes et al. have done the same in their annotation?",Does the review address Related Work?,TRUE,FALSE,The review discusses annotation approaches in related work.
I see this work more as an analysis on language-specific parameters for a particular LS-model rather than a novel architecture.,Does the review address Methodology?,TRUE,FALSE,The review views the work as an analysis of language-specific parameters.
"To me, D looks to be an important efficiency tradeoff.",Does the review address Methodology?,FALSE,TRUE,The review makes a brief comment about an efficiency tradeoff.
(ii) a new way to aggregate multiple inputs (using M-BERT) and several different decoding methods.,Does the review address Significance?,TRUE,FALSE,The review mentions a new way to aggregate inputs.
I’m not saying these problems aren’t important – especially type recovery (I think this problem is deeply important) – but that it should go further to demonstrate more dimensions of decompilation.,Does the review address Significance?,TRUE,FALSE,The review discusses the importance of certain problems.
- The model uses two RNNs: a chain-based one and a knowledge guided one.,Does the review address Methodology?,TRUE,FALSE,The review describes the model's use of two RNNs.
And there is no further explanation and ablation study on the design of the dynamic threshold.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out a lack of explanation for a specific design choice.
"Their goal is to reduce the amount of parameters and data needed, while improving (or maintaining) state-of-the-art performance.",Does the review address Methodology?,TRUE,FALSE,The review describes the goal of reducing parameters and maintaining performance.
"If that is the case, that should be made more explicit.",Does the review address Presentation?,FALSE,TRUE,The review suggests making something more explicit without discussing presentation.
"[5] FP8 Formats for Deep Learning, Micikevicius et al. 1- The paper is well-written and organized.",Does the review address Related Work?,FALSE,TRUE,The review briefly mentions a citation and notes the paper is well-written.
"The experiments in the paper demonstrated the superiority of adding adversarial training to a self-supervision framework, in that significant improvements can be obtained for similar-sized networks.",Does the review address Methodology?,TRUE,FALSE,The review discusses the methodology of adding adversarial training.
"* In the results section there is a typo: *""performances with a large margins of 2.32pp in""*.",Does the review address Presentation?,TRUE,FALSE,The review points out a typo in the results section.
"In particular, using a carefully selected subset of ""prompt"" words, the authors observe that learning a linear predictor over the next word distributions of these words achieves performance close to a pre-trained GPT-2 model.",Does the review address Presentation?,TRUE,FALSE,The review describes a methodology for predicting word distributions.
"* Strength     * This paper proposes an interesting idea and interpretation to connect RM and DM paradigm     * This paper proposes a variance reduction method for DPG which demonstrates its improvement on performance, stability and sample efficiency * Weakness     * From my understanding, the baseline mostly comes from the observation in 3.3, which has limited technical novelty.",Does the review address Novelty?,TRUE,FALSE,The review discusses the paper's strengths and weaknesses in terms of novelty.
"Why are the backbone models (RoBERTa and BERT, respectively) different in Table 1 and Table 2?",Does the review address Presentation?,TRUE,FALSE,The review questions the difference in backbone models across tables.
"It will be interesting to see the impact of the RNN and Copy RNN based model on automatic extraction of local or ""present"" type of key phrases.",Does the review address Significance?,TRUE,FALSE,The review suggests exploring the impact of different models.
"Once more baselines are included, it is very possible that the performance will be surpassed.",Does the review address Comparison?,TRUE,FALSE,The review suggests the possibility of performance being surpassed by more baselines.
The authors try to interpret the design of the neural networks using the concepts in the proposed binding-unbinding theorybut are not convincible.,Does the review address Theory?,TRUE,FALSE,The review critiques the interpretation of neural network design using binding-unbinding theory.
It would be great if the authors discuss this or provide some supporting evidence about its correctness.,Does the review address Methodology?,FALSE,TRUE,The review suggests providing supporting evidence without discussing methodology.
I had to go multiple times back-and-forward in this paper to understand what was new in it.,Does the review address Presentation?,TRUE,FALSE,The review critiques the paper's clarity of presentation.
* The rationale behind the architectural choices for the self-attention component is not well explained or empirically verified.,Does the review address Methodology?,TRUE,FALSE,The review points out a lack of explanation for architectural choices.
"It is not clear how this model would compare to other models using language specific parameters (sparsely gated mixture of experts (Lepikhin et al 2020), light-weight adapters (Bapna et al 2019)  ).",Does the review address Comparison?,TRUE,FALSE,The review suggests comparing the model to other similar approaches.
"How would it perform if LLM is not GPT-4, but rather those open-source alternatives like Llama.",Does the review address Methodology?,TRUE,FALSE,The review asks about performance with different language models.
"Or if they are measuring the probability assigned to the true image and not just accuracy, the name shoudl be changed from accuracy.",Does the review address Presentation?,TRUE,FALSE,The review suggests changing the name of an accuracy metric.
"The presented method chooses action primitives such as ""PickAndPlace"" but does not need much training data (apart from the examples).",Does the review address Methodology?,TRUE,FALSE,The review describes the method of choosing action primitives.
Details of training and dataset are logical and delicate.,Does the review address Data/Task?,FALSE,TRUE,The review makes a vague comment about training details.
"Or, is the label distribution on the annotated subsets derived via vote-*k* indeed skewed for some tasks and the performance improvements are mainly coming from improvements on the labels that are well-represented?",Does the review address Result?,FALSE,TRUE,The review raises a speculative question about performance improvements.
Pros:  - A new framework for understanding why learning how to predict the next word helps the downstream task.,Does the review address Methodology?,TRUE,FALSE,The review discusses a framework for understanding next-word prediction.
"I think authors wanted to say that even though BROS does not rely on visual features, it does outperform LayoutLM which, in turn, uses visual features.",Does the review address Presentation?,TRUE,FALSE,The review clarifies the authors' intended comparison between models.
"Another problem is that there is only few qualitative results, and in both these two examples, predicted results cover the GT segments.",Does the review address Result?,TRUE,FALSE,The review critiques the limited qualitative results.
"The two datasets have some “toy flavor”, while SCAN great favors example combination (with recomb-2 performs much better than recomb-1), recomb-1 seem to perform better for morphological analysis dataset, leaving questions about how to choose the exact models in general.",Does the review address Data/Task?,TRUE,FALSE,The review discusses characteristics of different datasets.
"T-LLMs are trained with huge batches, and it can be hard to pick out all the information about one example from a batch.",Does the review address Methodology?,TRUE,FALSE,The review discusses the training methodology of large language models.
"FLOPS is a measure of computer performance, while arithmetic intensity is the ratio of total floating-point operations to total data movement.",Does the review address Result?,FALSE,TRUE,The review provides a technical definition without discussing results.
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Evaluation?,TRUE,FALSE,The review critiques the lack of human evaluation and error analysis.
In Proceedings of the 6th Workshop on Asian Translation (pp.,Does the review address Related Work?,FALSE,TRUE,The review appears to be a publication reference.
"As far as I know, this is indeed the first work for handling this task using binding-unbinding mechanism.",Does the review address Data/Task?,TRUE,FALSE,The review highlights the first work using a specific mechanism.
"Ablation studies on the varying parameter counts of these two components would be valuable, if possible.",Does the review address Ablation?,TRUE,FALSE,The review suggests performing ablation studies on parameter counts.
"I appreciate that the authors do not read too much into it and focus more on the analysis of the results, but one thing that remains unanswered in this paper is how the proposed method fairs against multilingual baselines that utilize (roughly) the same number of parameters; currently, the best models outperform the LS baseline by ~28M and ~10M parameters on OPUS-100 and WMT-14 respectively.",Does the review address Analysis?,TRUE,FALSE,The review discusses analysis of results and parameter comparisons.
The performance is impressive and could be a better baseline for the future work.,Does the review address Result?,TRUE,FALSE,The review describes the performance as impressive.
"Also, what is the meaning of the two segments of ""suppress""?",Does the review address Presentation?,FALSE,TRUE,The review asks a question about terminology without analyzing presentation.
Is there any reason to use a static attention for all words?,Does the review address Methodology?,TRUE,FALSE,The review questions the approach to attention mechanism.
"The paper in general is well-written and easy to follow, the qualitative analysis and the additional diagrams in the appendix illustrating the variations in policies are appreciated.",Does the review address Presentation?,TRUE,FALSE,The review praises the paper's writing and supplementary materials.
"The evaluation results are based on the authors' implementations, for both baseline and the proposed method.",Does the review address Comparison?,TRUE,FALSE,The review notes the evaluation is based on authors' implementations.
"The latter is typically used in two different ways in the transformer architecture, each resulting in a different computation for RF  is confusing as the RFA is now redefined.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out confusion in definition and computation.
"I think it would improve the paper if you could focus on a certain kind of invariants, and show that these invariants can in fact generalize across programs.",Does the review address Methodology?,TRUE,FALSE,The review suggests focusing on specific invariants.
"Further, [5] finetunes (and even trains from scratch) large Transformers in FP8.",Does the review address Methodology?,TRUE,FALSE,The review mentions fine-tuning transformers in FP8.
"* The current analysis doesn’t apply directly to BERT, which is trained to predict masked words in a sentence, instead of the next word.",Does the review address Analysis?,TRUE,FALSE,The review notes limitations of current analysis for different model types.
I had to read it a couple of times before I could fully follow the method.,Does the review address Methodology?,FALSE,TRUE,The review comments on difficulty understanding the method.
This could be tested by ablating elements from the input or ablating the recurrent memory vectors (setting them to zero during inference).,Does the review address Ablation?,TRUE,FALSE,The review suggests methods for ablating input elements.
And are the previous work using the same training set?,Does the review address Related Work?,FALSE,TRUE,The review asks a brief question about training sets.
This paper set an assumption that the teacher network makes a less confident prediction than that of the student and extends gradient analysis in the perspective of regularization effect in the proposed adaptive label smoothing.,Does the review address Methodology?,TRUE,FALSE,The review describes the methodology of adaptive label smoothing.
The paper proposed a weakly-supervised wMAN model for moment localization in untrimmed videos.,Does the review address Methodology?,TRUE,FALSE,The review describes a weakly-supervised moment localization model.
"Other smaller suggested fixes:  * Section 5, near the end - Little grammatical mistake.",Does the review address Presentation?,TRUE,FALSE,The review points out a grammatical mistake.
The paper sets out to formally characterize controllability of LLMs which is an important issue in preventing adversarial attacks on language models and preventing LLMs from producing undesirable content.,Does the review address Methodology?,TRUE,FALSE,The review describes the goal of characterizing LLM controllability.
"The paper proposes a new joint learning algorithm that works for two tasks, NER and RE.",Does the review address Data/Task?,TRUE,FALSE,The review describes a joint learning algorithm for two tasks.
I doubt that InfoNCE can represent the best performance of CLIP trained on CC (3M) and WIT(5M).,Does the review address Result?,FALSE,TRUE,The review expresses doubt about performance representation.
The Graph connectivity ablation states that connecting the e_int node to all entities (instead of just the input text entities) hurts performance.,Does the review address Result?,TRUE,FALSE,The review discusses graph connectivity ablation and performance.
"- (The supplied code does not seem to include the baselines, just the recursive NN models.",Does the review address Methodology?,FALSE,TRUE,The review comments on the absence of baselines in supplied code.
## Paper strengths and contributions **Motivation and intuition** The motivation for multi-turn code generation is convincing.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review finds the motivation for multi-turn code generation convincing.
"Assuming that these are two different programs, there is no reason to assume that the contract of `calculateTime()` remains the same.",Does the review address Presentation?,FALSE,TRUE,The review makes a theoretical comment about program contracts.
Other questions for the authors: (1) What is the loss in performance by fixing the word embeddings in the dependency parsing task?,Does the review address Result?,FALSE,TRUE,The review asks a speculative question about performance loss.
Do you think the conclusion would be still the same if a language-specific hyper-parameter p_l was used instead?,Does the review address Methodology?,FALSE,TRUE,The review poses a hypothetical question about methodology.
"Neither the proposed “Quad” loss function, nor the theoretically inspired “conditional mean features”, perform better than the baselines.",Does the review address Comparison?,TRUE,FALSE,The review notes that proposed methods do not outperform baselines.
The experimental results are promising for both settings.,Does the review address Result?,TRUE,FALSE,The review describes experimental results as promising.
An ablation analysis would be most appropriate for quantifying this.,Does the review address Evaluation?,TRUE,FALSE,The review suggests an ablation analysis for quantification.
"The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review praises the detailed experimental description.
LOW LEVEL COMMENTS Equation 5: what's the difference between id(w) = id(w') and w = w' ?,Does the review address Presentation?,FALSE,TRUE,The review asks about a technical notation difference.
"I know you cite the Abbott & Martinus, 2018 paper, stating that BPE is bad for analytical languages, but I still think it would prove a point to show BPE performing badly for your data.",Does the review address Result?,FALSE,TRUE,The review suggests showing performance for a specific method.
- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.,Does the review address Data/Task?,TRUE,FALSE,The review critiques the experimental dataset distribution.
"In the experiments, the authors make comparisons with traditional methods, and show the effectiveness of their model.",Does the review address Experiment?,TRUE,FALSE,The review notes comparisons with traditional methods.
"Additionally, the rationale for choosing (Ma et al., 2023) as a benchmark, along with the significance of the improvements observed, even if minute, should be clearly articulated.",Does the review address Data/Task?,TRUE,FALSE,The review suggests clarifying benchmark selection.
"The idea is similar to structured / syntax-based attention (i.e. attention over nodes from treeLSTM); related work includes Zhao et al on textual entailment, Liu et al. on natural language inference, and Eriguchi et al.",Does the review address Methodology?,TRUE,FALSE,The review discusses similar attention methodologies.
Section 3.4  does not describe clearly enough how attention maps were used for predicting contact maps.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out lack of clarity in method description.
"Conventionally the ITM loss is a binary prediction task, while the particular one used in this work is more often referred as contrastive learning loss.",Does the review address Presentation?,TRUE,FALSE,The review discusses terminology and loss function classification.
- Figure 1 is helpful in comprehending the effect of different loss functions vs robustness.,Does the review address Presentation?,TRUE,FALSE,The review praises Figure 1's helpfulness.
"There is a lack of experimental analysis supporting the source of the observed improvements, which is crucial for substantiating the paper's main claims.",Does the review address Result?,TRUE,FALSE,The review critiques lack of experimental analysis.
"Each network branch is from known structures, but the combination is not proposed before.",Does the review address Novelty?,TRUE,FALSE,The review highlights novelty in network branch combination.
It also exhibits explainability during the generation.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,The review briefly mentions explainability without detailed discussion.
"More importantly, the experiments are not convincing as it is presented now.",Does the review address Experiment?,TRUE,FALSE,The review finds the experiments unconvincing.
This paper is meaningful and presents a reasonable analysis.,Does the review address Significance?,TRUE,FALSE,The review finds the paper meaningful and presents reasonable analysis.
(3) How much does coverage affect the score in table 2?,Does the review address Presentation?,FALSE,TRUE,The review asks a question about table details.
"Then, most of the paper is spent discussing preliminaries and introducing notation and definitions.",Does the review address Presentation?,TRUE,FALSE,The review comments on paper's focus on preliminaries and definitions.
"- For the open-ended questions, this work seems to focus mainly on solely LLMs assisted question answer generation.",Does the review address Methodology?,FALSE,TRUE,The review comments on the focus of LLM-assisted question generation.
"Strengths:  - The paper is generally well-written, with excellent motivation and empirical setup/analysis  - The overall strategy of differentiable prompt optimized to maintain fluency is reasonable and novel.",Does the review address Presentation?,TRUE,FALSE,The review praises the paper's writing and motivation.
- The analysis which builds on these definitions/models/assumptions provides meaningful theoretical insight into why language model pre-training may be so beneficial for downstream training.,Does the review address Analysis?,TRUE,FALSE,The review highlights theoretical insights from the analysis.
"In the 2nd paragraph of Section 4.1, ``For each s_k in s, we try to find a matched example (tx, ty) from D what tx contains the s_k’’: (1) There should be many sentence pairs (tx,ty) that tx contains s_k.",Does the review address Presentation?,FALSE,TRUE,The review points out a technical detail in a paragraph.
"2.Through a significant number of ablation experiments, this paper extensively researched the model's hyperparameter configurations and training strategies, offering highly instructive guidance for related work.",Does the review address Methodology?,TRUE,FALSE,The review discusses extensive hyperparameter and training strategy research.
"There is a lack of experimental analysis supporting the source of the observed improvements, which is crucial for substantiating the paper's main claims.",Does the review address Analysis?,TRUE,FALSE,The review critiques the lack of experimental analysis.
There is a lot missing to actually justify this claim: 1.,Does the review address Result?,FALSE,TRUE,The review suggests more justification is needed.
Here's how I would reconstruct the proof of Theorem 3:  *Proof.,Does the review address Theory?,FALSE,TRUE,The review mentions reconstructing a proof.
"But that would also mean that the phrases are determined by token ngrams which produces a sliding window of the ""pyramid encoders"" for each sentence where there are instance where the parameter for these phrases will be set close to zero to disable the phrases and these phrases would be a good intrinsic evaluation of the pRNN in addition to evaluating it purely on perplexity and BLEU extrinsically.",Does the review address Evaluation?,FALSE,TRUE,The review suggests an intrinsic evaluation method.
"- The proposed architecture is tested on massive experiments including language understanding tasks, optical flow, video audio class autoencoding, image classification, and starcraft II and achieves superior performance.",Does the review address Result?,TRUE,FALSE,The review highlights superior performance across tasks.
or adopt the exponential-moving-average (EMA) manner [3].,Does the review address Methodology?,FALSE,TRUE,The review briefly mentions an average method.
I suggest authors to add discussion about the perfomance of DeFo for domain generalization.,Does the review address Methodology?,TRUE,FALSE,The review suggests discussing domain generalization performance.
The second uses Gaussian blurring to encourage information sharing among neighboring words.,Does the review address Methodology?,TRUE,FALSE,The review describes a methodology using Gaussian blurring.
Perhaps there is some visual representation that could help demonstrate the comparisons you make in the text?,Does the review address Comparison?,FALSE,TRUE,The review suggests adding visual representation for comparisons.
- General Discussion: The main focus of this paper is the introduction of a new model for learning multimodal word distributions formed from Gaussian mixtures for multiple word meanings.,Does the review address Methodology?,TRUE,FALSE,The review describes a model for learning multimodal word distributions.
"This paper proposes a neural network architecture that represent structural linguistic knowledge in a memory network for sequence tagging tasks (in particular, slot-filling of the natural language understanding unit in conversation systems).",Does the review address Presentation?,TRUE,FALSE,The review describes a neural network architecture for sequence tagging.
- It seems like the optimal value of $k$ in vote-*k* would depend on the number of instances in the unlabeled set that changes with the tasks.,Does the review address Data/Task?,FALSE,TRUE,The review comments on the optimal value of k in vote method.
The paper is mostly clearly written and discusses server interesting ablation experiments.,Does the review address Experiment?,TRUE,FALSE,The review praises the clarity and ablation experiments.
"Did the author try other window widths, for example width `1' to extract unigram features, `3' to trigram, or use them together?",Does the review address Experiment?,FALSE,TRUE,The review suggests trying different window widths.
2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues.,Does the review address Ablation?,TRUE,FALSE,The review suggests adding subjective evaluations to ablation experiments.
"Theoretically, they showed that synchronized updates to the low-level and high-level policy may never converge, yet asynchronized updates guarantees convergence.",Does the review address Contribution?,TRUE,FALSE,The review highlights a theoretical contribution about policy updates.
We have no empirical demonstration that this approach will work on other datasets outside of LeetCode.,Does the review address Data/Task?,FALSE,TRUE,The review questions the approach's applicability to other datasets.
"Questions:   - Previous work has tried to combine both language-specific and shared parameters (Wang et al 2018), rather than making a binary choice between these.",Does the review address Related Work?,TRUE,FALSE,The review mentions previous work on parameter combinations.
"This is relevant because, by training end to end, that work effectively generates arbitrary amounts of training data through interaction the the HOL4 ITP system (intermediate theorems which are proven give some reward in that work).",Does the review address Data/Task?,FALSE,TRUE,The review discusses data generation through interaction.
The authors first qualitatively and quantitatively analyze the cold-start problem.,Does the review address Analysis?,TRUE,FALSE,The review notes a qualitative and quantitative analysis of a problem.
"- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other ""oracle"" baselines.",Does the review address Methodology?,FALSE,TRUE,The review simply notes evaluation datasets and comparisons.
The result presented in Table 4 don't match the description in Section 4.3:  - It's not true that the pRNN outperforms both PBSMT and Enc-Dec model.,Does the review address Result?,TRUE,FALSE,The review critiques the mismatch between results and description.
"Given that one of the primary goals of this paper was to create embeddings that perform well under the word translation metric (intra-language), it is disappointing that the method that performs best (by far) is the invariance approach.",Does the review address Evaluation?,TRUE,FALSE,The review expresses disappointment about embedding performance.
"A similar analysis here could greatly demystify why these sets of examples cause instability, and whether they are indeed “informative”.",Does the review address Analysis?,TRUE,FALSE,The review suggests a deeper analysis of example sets.
(4) The dictionary extraction approach (from parallel corpora via alignments or from google translate) may not reflect the challenges of using real lexicons.,Does the review address Methodology?,TRUE,FALSE,The review critiques the dictionary extraction approach.
"Presentation: - The ""Crime Suppression Division"" example would be clearer if you showed it graphically in a figure.",Does the review address Presentation?,TRUE,FALSE,The review suggests graphical representation of an example.
The idea is straightforward and the motivation is clear.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review finds the idea straightforward and motivation clear.
The proposed beam enumeration significantly outperforms REINVENT (the strongest baseline in the existing benchmark).,Does the review address Comparison?,TRUE,FALSE,The review highlights performance compared to a baseline.
"I would recommend to put the citation around it (Andreas, 2000) although previously cited.",Does the review address Related Work?,FALSE,TRUE,The review suggests a minor citation placement.
"Good set of ablation studies to show that each component of the model is necessary, especially because the entire model already has many moving parts in addition to adversarial training.",Does the review address Methodology?,TRUE,FALSE,The review praises the ablation studies' thoroughness.
"You are clearly not trying to infer any loop invariants, and it would help clarify that upfront.",Does the review address Result?,FALSE,TRUE,The review makes a comment about not inferring loop invariants.
"In Empirical Methods in Natural Language Processing (EMNLP), 2019.",Does the review address Related Work?,FALSE,TRUE,The review appears to be a publication reference.
3) This paper shows visualization of the interaction between words and latent topics in the embedding space.,Does the review address Presentation?,TRUE,FALSE,The review mentions visualization of word and topic interactions.
"Furthermore, the authors deliberately avoid settings where DP is known to be hard due to the relatively low amount of training data per class (e.g. CIFAR-100/ImageNet).",Does the review address Data/Task?,TRUE,FALSE,The review notes deliberate avoidance of challenging data settings.
"Summary: This paper presents a method of incorporating prior knowledge into MCTS via language, using interactive fiction games as a test bed.",Does the review address Methodology?,TRUE,FALSE,The review summarizes a method of incorporating prior knowledge.
Some discussion on the current design choices and why making the proposed methods features to some of the other baselines is not a way to achieve some benefits is not the right way to do it.,Does the review address Methodology?,FALSE,TRUE,The review suggests discussion of design choices.
Novel weighting scheme for SVD for low-rank weight compression (though should double check this more thoroughly).,Does the review address Novelty?,TRUE,FALSE,The review mentions a novel weighting scheme.
"In the presence of definitive results, this might be acceptable, but in its absence, as in this paper, there needs to be quantitative analysis across multiple runs to demonstrate the robustness of the phenomenon.",Does the review address Result?,TRUE,FALSE,The review suggests need for quantitative analysis across runs.
"Experiments on type predictions for TypeScript have shown better performance than the previous methods, with or without user specified types.",Does the review address Result?,TRUE,FALSE,The review highlights experimental performance on type predictions.
"However, in its current state - the comparisons made are not meaningful which makes the claim of state of the art tenuous (state of the art does not matter so much as showing that you make progress in line with the motivation).",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review critiques the lack of meaningful comparisons.
The authors present a simple technique for in-context learning with large language models that achieves consistently good results across a variety of NLP tasks.,Does the review address Methodology?,TRUE,FALSE,The review describes a technique for in-context learning.
**Strengths** - The paper is generally quite clearly written and the claims are well-validated.,Does the review address Presentation?,TRUE,FALSE,The review praises the paper's clarity and validation.
"I look forward to the author's discussion of the additional learnable parameters introduced in addition to CLIP's pre-trained model, and compare the number with other methods.",Does the review address Methodology?,TRUE,FALSE,The review suggests discussing additional learnable parameters.
"The authors first identify redundant structures early during training, then prune these structures, which leads to faster training.",Does the review address Methodology?,TRUE,FALSE,The review describes a method of identifying and pruning redundant structures.
"I think just including two sentences that have some of these features, and that gets the point accross of ""how would we tokenize this?""",Does the review address Intuition/Justification/Motivation/Validation?,FALSE,TRUE,The review suggests a brief example to illustrate a point.
"The experments are fairly convincing, although it is not entirely surprising that this approach works, and to repeat, the basic idea of extracting additional training data in this way is not entirely new.",Does the review address Methodology?,TRUE,FALSE,The review discusses the experiments and approach's basic idea.
"In the experiments, it is not reported that the learning rate or the mini-batch size is well tuned for the baseline.",Does the review address Experiment?,TRUE,FALSE,The review points out issues with baseline experimental setup.
"In the conclusion, the paper mentions comparison with Multi-Scale approaches, but that is not present in the experiments.",Does the review address Comparison?,TRUE,FALSE,The review notes a discrepancy between conclusion and experiments.
"It may be useful to show how the performance changes when using different M. - According to [2], the CommonsenseQA IH-dev set contains 1,221 questions in total.",Does the review address Methodology?,FALSE,TRUE,The review suggests exploring performance with different parameters.
Suggested additions: * I think more specific linguistic details about Fon are missing.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests adding more linguistic details.
"The main limitations seem to be: (1) the proposed method is a bit limited in that it can only be used with a corpus in which the target head, relation, and tail spans need to be directly mentioned in a single sentence (2) it’s not clear whether the quantitative improvements are due to factual knowledge in the pretrained model or the syntactic/semantic relationships encoded in the self-attention.",Does the review address Result?,TRUE,FALSE,The review discusses limitations and potential sources of improvements.
"**Please put the verbose caption description in the main text for Figure 3, 4, 5 and Table 4** Spacing in between some of the equations can also be reduced (e.g. in latex use \vspace{-5mm} )",Does the review address Presentation?,TRUE,FALSE,The review suggests improvements to captions and spacing.
_ A question to the authors: What do you attribute the loss of performance of w2gm against w2g in the analysis of SWCS?,Does the review address Result?,FALSE,TRUE,The review asks about performance loss of a specific method.
"It'll be good to have some ablation study of the combined effect of using only one data sample in a mini-batch, and the full-explored masking.",Does the review address Data/Task?,TRUE,FALSE,The review suggests an ablation study on data sampling.
"In addition, the notation in (6) looks wrong to me.",Does the review address Presentation?,TRUE,FALSE,The review points out an issue with notation.
"Or if they are measuring the probability assigned to the true image and not just accuracy, the name shoudl be changed from accuracy.",Does the review address Result?,FALSE,TRUE,The review suggests renaming the accuracy metric.
The larger dataset may relate to more many-to-many relationships when training the model.,Does the review address Data/Task?,TRUE,FALSE,The review discusses relationships in larger datasets.
The empirical analysis section answers several interesting questions.,Does the review address Analysis?,TRUE,FALSE,The review praises the empirical analysis section.
"The fact that I flustered a bit with my understanding here, was confused, and had to spend a few minutes thinking about it, means it needs a bit of tweaking.",Does the review address Presentation?,TRUE,FALSE,The review suggests improving clarity of presentation.
"To this end, language-specific behaviour is achieved via a combination of conditional computation to decide whether to use language-specific parameters or not and statically assigning experts for each languages.",Does the review address Presentation?,TRUE,FALSE,The review describes language-specific parameter approach.
"However, there is no theoretical result about the effectiveness of assigning the self-knowledge distillation to label smoothing.",Does the review address Theory?,TRUE,FALSE,The review notes lack of theoretical results.
I would shorten it and move interesting results from the Appendix to the main paper.,Does the review address Related Work?,FALSE,TRUE,The review suggests moving results from appendix to main text.
"The comparison of some other important baseline is missing, such as Tip-adapter [1] and CoCoOp [2].",Does the review address Comparison?,TRUE,FALSE,The review suggests adding comparisons with missing baselines.
It becomes difficult to fathom if the gains are actually due to good objective function or a case of chance for choosing better examples.,Does the review address Result?,FALSE,TRUE,The review questions the source of gains.
Another limitation is that it is unclear whether the improvement would hold when the size of the model increases; the evaluation is dealing with scaling laws after all.,Does the review address Result?,TRUE,FALSE,The review discusses limitations in model scaling.
The authors clearly present their ideas and describe the technical details.,Does the review address Presentation?,TRUE,FALSE,The review praises the clear presentation of ideas.
"Despite very encouraging results, several important methodological questions about the source of the efficiency gains and other aspects of the paper are left unanswered.",Does the review address Methodology?,TRUE,FALSE,The review points out unanswered methodological questions.
"However, I feel that experiments can be strengthened, and notations can be improved.",Does the review address Experiment?,TRUE,FALSE,The review suggests strengthening experiments and improving notations.
"- I know GPT3 access is hard to get, but I wish experiments with k=8 prompts could be compared against  Post rebuttal: I think another pass for clarity over the paper would be good for the final version, but otherwise I'm happy with the paper updates and I'm happy to see the ablation numbers aren't too sensitive to token count.",Does the review address Ablation?,TRUE,FALSE,The review discusses ablation numbers and token count sensitivity.
"Compared to Pengi, the closed-ended audio task performances are lower.",Does the review address Comparison?,TRUE,FALSE,The review compares performance with another method.
"In the second phase (match), they ground facts to a knowledge graph schema by using combinations of entity linking and relation matching techniques from previous work.",Does the review address Methodology?,TRUE,FALSE,The review describes a methodology for grounding facts to a knowledge graph.
"However, \alpha could also be changed in the training process.",Does the review address Methodology?,FALSE,TRUE,The review makes a brief comment about a parameter change.
The proposed RoBERTa achieves/matches state-of-the-art performance on many standard NLU downstream tasks.,Does the review address Data/Task?,TRUE,FALSE,The review discusses performance on NLU downstream tasks.
"Questions: - According to the parameters presented in Table 8, the knowledge from LM and GNN are only fused at the last 5 layers (parameter M) when 24-layer LMs are used, and at the last 3 layers when 12-layer LMs are used.",Does the review address Methodology?,TRUE,FALSE,The review discusses knowledge fusion in different layer configurations.
(2) The use of super-sense annotations across multiple languages is a problem.,Does the review address Data/Task?,TRUE,FALSE,The review points out an issue with super-sense annotations.
It is not clear to me why we cannot use HDSA+R or LARL + NLG + language model reward.,Does the review address Methodology?,FALSE,TRUE,The review questions alternative methodology approaches.
"To really become a benchmark to measure the progress of LFLL, more tasks/datasets will be needed.",Does the review address Data/Task?,TRUE,FALSE,The review suggests adding more tasks and datasets.
Ablations show the necessity of applying a 2-step intermediate training scheme with mixed training followed by joint training.,Does the review address Ablation?,TRUE,FALSE,The review highlights ablation studies on training schemes.
"For example, a lot of BERT-style models exploit dense interactions.",Does the review address Methodology?,TRUE,FALSE,The review mentions interaction approach in BERT-style models.
"Please don't abuse figure/table captions, whenever possible, please try to keep the description of the tables and figures in-text.",Does the review address Presentation?,TRUE,FALSE,The review advises against abusing figure/table captions.
It would helpful to place it more clearly where the contribution of the paper lies in the related work.,Does the review address Related Work?,TRUE,FALSE,The review suggests clarifying contribution in related work.
"The same work, with a more carefully written paper, could be really great.",Does the review address Presentation?,TRUE,FALSE,The review suggests improving the paper's writing.
The research shows how low-level proof artifact data may be used to significantly boost performance on high-level theorem proving by co-training auxiliary tasks.,Does the review address Data/Task?,TRUE,FALSE,The review discusses using proof artifact data for theorem proving.
It’s not easy to follow what the authors try to convey quickly at first glance.,Does the review address Presentation?,TRUE,FALSE,The review finds the paper difficult to follow.
Will the attention model pays more attention to this similar sample resulting in a negative impact on the target task performance since the source task and target task are quite different?,Does the review address Methodology?,FALSE,TRUE,The review asks a speculative question about attention models.
"Prior work has explored ""learning-to-share""  strategies for parameter sharing in multi-task learning (see Ruder et al., AAAI 2018), and using gating/masking to control computational paths in a differentiable way (see Fan et al., ICLR 2019, Sukhbaatar et al., ACL 2019); it is clear that the focus is NMT but it should be worth mentioning/discussing such studies to better situate the work and to help the reader assess the actual contributions.",Does the review address Contribution?,TRUE,FALSE,The review suggests discussing prior work on multi-task learning.
"Strengths:  - The paper is generally well-written, with excellent motivation and empirical setup/analysis  - The overall strategy of differentiable prompt optimized to maintain fluency is reasonable and novel.",Does the review address Novelty?,TRUE,FALSE,The review praises the paper's novelty and strategy.
"However, there are still major gaps between the theoretical analysis, the conclusion and the empirical solution (please see the detailed comments).",Does the review address Analysis?,TRUE,FALSE,The review points out gaps between theoretical analysis and empirical solution.
"We expect that the model can not only achieve good performance on a single dataset, but also have the potential to transfer beyond a single dataset.",Does the review address Result?,FALSE,TRUE,The review discusses expectations of model performance.
"That raises the question -- Gerrish and O'Connor both conduct evaluations with an external database of country relations developed in political science (""MID"", military interstate disputes).",Does the review address Data/Task?,FALSE,TRUE,The review mentions an external database of country relations.
"- Strengths: This paper has high originality, proposing a fundamentally different way of predicting words from a vocabulary that is more efficient than a softmax layer and has comparable performance on NMT.",Does the review address Result?,TRUE,FALSE,The review highlights the paper's originality and performance.
"Instead, they turn to rely on the abundant textual and behavioral information of the existing reviewer to augment the information of a new user.",Does the review address Methodology?,TRUE,FALSE,The review describes a methodology of augmenting user information.
This would be much more useful for other researchers as it is the file format used by UD.,Does the review address Data/Task?,FALSE,TRUE,The review suggests a preferred file format.
"The selected student networks, VL-BERT, UNITER, VILLA, while they are great and highly reputable works in the community, their performance is not as competitive as for today.",Does the review address Presentation?,TRUE,FALSE,The review comments on the performance of selected networks.
How many include simple string operations and/or other simple method calls as implied by Table 2?,Does the review address Presentation?,FALSE,TRUE,The review asks about details in a table.
"Overview: This paper discusses the problems of common tokenization strategies for low resource african languages, and proposes a new tokenization method to overcome these problems.",Does the review address Methodology?,TRUE,FALSE,The review describes the paper's approach to tokenization for low-resource languages.
"The techniques used in the paper (multi-branch transformer, pointing mechanism, cross-modal attention, global positional encodings, etc) have been shown to work in the past for image-text tasks [1, 2].",Does the review address Data/Task?,FALSE,TRUE,The review lists techniques used in past image-text tasks.
Contributions of the paper don't seen particularly novel.,Does the review address Contribution?,TRUE,FALSE,The review suggests the contributions lack novelty.
"Overall, I like the idea of the paper: it is important to reduce the parameters needed for sets of tasks, to enable NLP models to be deployed in a larger variety of settings, and reducing the amount of data needed.",Does the review address Significance?,TRUE,FALSE,The review appreciates the importance of reducing parameters and data needs.
"If so, does the global node $V_g$ connect to all the sub fact nodes?",Does the review address Methodology?,FALSE,TRUE,The review asks a technical question about node connections.
"I agree with all of your points about what is lacking, but in my mind, the novelty was enough to still give a 7.",Does the review address Novelty?,TRUE,FALSE,The review suggests the novelty is sufficient.
- The data preprocessing and training steps are complex.,Does the review address Data/Task?,FALSE,TRUE,The review comments on the complexity of data preprocessing.
"The paper shows the reasonable claim that it is necessary to gradually train the model from close-ended datasets to open-ended ones because if the open-ended dataset is trained first, the model is heavily dependent on language capability so it is hard to train the audio representation.",Does the review address Methodology?,TRUE,FALSE,The review describes a gradual training approach for models.
- Slight improvements over CaP via the different prompting method.,Does the review address Result?,TRUE,FALSE,The review notes slight improvements via prompting.
"Regarding preposition phrases as a proxy for complexity: since the hypothesis is that the more the number of prepositional phrases in a question, the harder it is to answer.",Does the review address Methodology?,FALSE,TRUE,The review discusses a hypothesis about prepositional phrases.
it's very clearly presented -- I like cross-referencing the models with the diagrams in Table 2.,Does the review address Presentation?,TRUE,FALSE,The review praises the clear presentation and cross-referencing.
"Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.",Does the review address Methodology?,TRUE,FALSE,The review discusses hyperparameter tuning for inference.
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.,Does the review address Methodology?,TRUE,FALSE,The review notes model evaluation on datasets.
"The studies here show that, pre-training with Inverse Cloze Task (ICT) the two-tower Transformer models significantly outperform the widely used BM-25 algorithm for large-scale information retrieval.",Does the review address Data/Task?,TRUE,FALSE,The review discusses pre-training performance for information retrieval.
"The paper only performs some finetuning on GLUE tasks, which is significantly less interesting given that it is comparatively cheap and FP8 speedups thus not so crucial while, in many cases, even more affordable finetuning techniques like QLoRA also work well.",Does the review address Data/Task?,TRUE,FALSE,The review critiques the limited fine-tuning approach.
It is a bit hard to identify the interestingness or novelty in the approach.,Does the review address Methodology?,FALSE,TRUE,The review finds it hard to identify approach's novelty.
"Page 5, Equations (6, 7, 8): should e^{l}_{s} and e^{l}_{j} be e^{(l-1)}_{s} and e^{(l-1)}_{j} respectively ?",Does the review address Presentation?,TRUE,FALSE,The review asks about notation in equations.
* Ablation: the model vs corpus transfer comparison seems unfair to me.,Does the review address Comparison?,TRUE,FALSE,The review suggests an unfair ablation comparison.
"For instance: Roee Aharoni, Melvin Johnson, and Orhan Firat.",Does the review address Related Work?,FALSE,TRUE,The review lists an author name.
"After reading other reviews and the authors’ responses to all of the reviewers, I recommend this paper by accepted—extensive results show that the CALM objectives offer more signal from data than current pretraining methods.",Does the review address Result?,TRUE,FALSE,The review highlights extensive results showing method's signal.
"As such, in my opinion this is unquestionably an important subtopic for the field of machine programming and the authors approach also seems satisfactory to me for ICLR (described below).",Does the review address Presentation?,FALSE,TRUE,The review considers the approach satisfactory.
This is very promising to simplify the construction of highly tuned task-specific neural pipelines and improve the multimodal and multi-task problems.,Does the review address Data/Task?,TRUE,FALSE,The review discusses potential for simplifying neural pipelines.
"It is hard to tell what are the standalone contributions of the paper, and what is coming from other works.",Does the review address Novelty?,TRUE,FALSE,The review finds it difficult to identify standalone contributions.
"The authors say ""the axes in the plots are the number of training steps finished.""",Does the review address Presentation?,FALSE,TRUE,The review notes a statement about plot axes.
"The input would be the source sentence with its appropriate tokenization, no?",Does the review address Presentation?,FALSE,TRUE,The review asks about input tokenization.
- The evaluation on PTB (table 2) isn't a fair one since the model was trained on a larger corpus (FBIS) and then tested on PTB.,Does the review address Methodology?,TRUE,FALSE,The review critiques the evaluation methodology across different corpora.
I think significant presentation changes are required to clarify that the paper focuses on inference and finetuning.,Does the review address Methodology?,TRUE,FALSE,The review suggests clarifying the paper's focus on inference and fine-tuning.
"Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.",Does the review address Result?,TRUE,FALSE,The review finds the hyperparameter tuning improvements convincing.
I would like the authors to have a more extended discussion of how SCS can be used outside of their work.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review requests a more extended discussion of the method's applicability.
The methods is evaluated on 5 standard NER+RE datasets with good performances.,Does the review address Evaluation?,TRUE,FALSE,The review notes good performance on standard datasets.
"The paper is clear and detailed, and well situated in the literature.",Does the review address Related Work?,TRUE,FALSE,The review praises the paper's clarity and literature positioning.
"How does the method work if the candidate with the highest score is always picked: in the end, this is what the model is supposed to learn, correct?",Does the review address Methodology?,FALSE,TRUE,The review asks a speculative question about method selection.
Nit: I would have tried to move the (datasets per cluster/templates per dataset) ablation to the main body as well and shortened Section 3  - The 4.2 (scaling laws) ablation is perhaps the most interesting of all.,Does the review address Data/Task?,TRUE,FALSE,The review suggests moving ablation details to the main body.
"Furthermore, the authors are neglecting parameter efficient fine-tuning baselines, for instance like [1].",Does the review address Methodology?,TRUE,FALSE,The review points out neglected fine-tuning baselines.
It is not clear how the proposed method considers the correlations among the retrieved data points.,Does the review address Data/Task?,FALSE,TRUE,The review questions data point correlation consideration.
I can not understand why sample-specific rather than task-specific preference is important for prompt tuning.,Does the review address Data/Task?,FALSE,TRUE,The review questions the importance of sample-specific preferences.
"If the authors would like to compare the number of additional parameters of DeFo with CoOp and CLIP-adapter, I think it may be very helpful for us to comprehensively evaluate and compare these methods.",Does the review address Comparison?,TRUE,FALSE,The review suggests comparing additional parameters across methods.
"Finally, the CALM intermediate objectives share many properties with all of the datasets tested on and are likely calibrating the model to the kind of correlations they should expect to predict in advance of finetuning.",Does the review address Data/Task?,TRUE,FALSE,The review discusses dataset characteristics and model calibration.
* I suggest using the same x-axis scale on the two charts in Figure 3 to avoid confusion about the magnitudes of the differences.,Does the review address Presentation?,TRUE,FALSE,The review suggests standardizing x-axis scales in figures.
- The number of tasks and domains is minimal setting.,Does the review address Data/Task?,TRUE,FALSE,The review critiques the minimal number of tasks and domains.
"- unconstrained, multi-concept:     This needs a direct comparison to a traditional discrete-channel referential game.",Does the review address Comparison?,TRUE,FALSE,The review suggests a direct comparison with a traditional approach.
"For example, the sentiment lexicon is not explained for the SVM.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out a lack of explanation for a specific lexicon.
"Granted, the final effect of MTL depends on task similarities, but that's probably the same for the proposed approach.",Does the review address Methodology?,FALSE,TRUE,The review makes a general comment about multi-task learning.
The paper features extensive experiments that convincingly validate the effectiveness of the proposed method.,Does the review address Experiment?,TRUE,FALSE,The review praises the extensive and convincing experiments.
- The captions are too small to read in Figure 2 & 3.,Does the review address Presentation?,TRUE,FALSE,The review critiques figure caption readability.
"## ""General Learner"": Missing Formal Definition and Misleading Name  The ""general learner"" concept used in the title and throughout is named in a somewhat misleading way, as the results here have to do more with *expressive power* than learning.",Does the review address Presentation?,TRUE,FALSE,The review suggests the concept name is misleading.
"Existing methods for contact prediction (beyond Gremlin), however, are not described sufficiently.",Does the review address Methodology?,TRUE,FALSE,The review notes insufficient description of existing methods.
It might be better to give out the trend of training loss and validation loss.,Does the review address Methodology?,FALSE,TRUE,The review suggests showing training and validation loss trends.
"Although I understand the experiment setup, missing reference to more recent VL works prevent readers from getting a good research landscape in the multimodal pre-training.",Does the review address Related Work?,TRUE,FALSE,The review points out missing references to recent works.
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Contribution?,TRUE,FALSE,The review summarizes the paper's contributions without an ablation study.
"Once more baselines are included, it is very possible that the performance will be surpassed.",Does the review address Result?,FALSE,TRUE,The review suggests potential performance changes with more baselines.
"- Consider HellaSwag/PiQA/etc, where FLAN underperformed few-shot and even zero-shot.",Does the review address Result?,FALSE,TRUE,The review points out performance issues on specific datasets.
Comments below are ranked by decreasing importance.,Does the review address Significance?,FALSE,TRUE,The review simply notes comment ranking.
"Also, please show the performance trends based on different augmentation sizes.",Does the review address Result?,FALSE,TRUE,The review suggests showing performance trends.
"Comparing the proposed method to earlier approaches such as PaLI, CoCa, and Flamingo may not be entirely fair.",Does the review address Methodology?,TRUE,FALSE,The review suggests carefully comparing with previous approaches.
"However, the dataset with 400M may contain too many many-to-many relationships like 7 or 8 (maybe more, the data scale is about 100 times the used datasets in this paper).",Does the review address Data/Task?,TRUE,FALSE,The review discusses dataset size and relationship complexity.
"Strengths: - Thorough theoretical analysis that reveals the connection between (practically-necessary) small learning rates and inability to use dependencies across text chunks - Useful framing and discussion of the ""in-context bias"", where models are more likely to learn dependencies within text chunks seen during pre-training.",Does the review address Theory?,TRUE,FALSE,The review highlights thorough theoretical analysis.
"As pointed out by the authors in section 3.3.1 ""TRIGGER IN 'INPUT' KEY,"" decorations can utilize specific keywords or phrases that are rare in regular instructions.",Does the review address Methodology?,TRUE,FALSE,The review discusses methodology for utilizing specific keywords.
"Elaboration on Theorem 1, with an intuitive breakdown of its implications, would significantly enhance the readability and credibility of the results.",Does the review address Theory?,TRUE,FALSE,The review suggests elaborating on a theorem's implications.
"For one, it would require doing some experiments with trained LMs and finding evidence of memorization.",Does the review address Experiment?,FALSE,TRUE,The review suggests potential experimental approach.
"Since the architecture (ignoring the compression) is similar to multi-scale approaches, it would be good to compare against empirically.",Does the review address Methodology?,TRUE,FALSE,The review suggests comparing with multi-scale approaches.
"- Excellent clarity and presentation of ideas  ## Weaknesses - The experiments provided do not analyze the unique characteristics of the environment introduced; instead, the experiments are similar to the typical gamut for a discrete symbol-based referential game.",Does the review address Experiment?,TRUE,FALSE,The review critiques the lack of unique environmental characteristics in experiments.
The curriculum training is yet another aspect that makes this effort worthy as it shows that a brute force approach to just wrap in all possible audio-text paired data may not be as good overall.,Does the review address Significance?,TRUE,FALSE,The review appreciates the curriculum training approach.
"The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",Does the review address Theory?,TRUE,FALSE,The review discusses theoretical results with strong assumptions.
This paper focuses on improving the dialogue policy together with the responses by utilizing a pre-trained language model and offline RL.,Does the review address Methodology?,TRUE,FALSE,The review describes the focus on improving dialogue policy.
Experimental results show improvements over both the base T5 model and the large T5 model.,Does the review address Result?,TRUE,FALSE,The review notes improvements over T5 models.
The applicability and the novelty of the SCS representation seem limited.,Does the review address Novelty?,TRUE,FALSE,The review suggests limited applicability of the representation.
"Additionally, there's some limitations to the way the language model is being leveraged and the types of knowledge it can extract.",Does the review address Methodology?,TRUE,FALSE,The review points out limitations in language model leveraging.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Theory?,TRUE,FALSE,The review discusses theoretical analysis's realism.
"It is not the case that I find the experimental results inadequate, rather, the experiments run in the first place are generic and do not illustrate the points of interest with a continuous-channel referential game.",Does the review address Experiment?,TRUE,FALSE,The review critiques the generic nature of experiments.
The fact that the previous study reported a 126 perplexity baseline using LSTM and the LSTM's perplexity of 106.9 provided by the author showed that the FBIS gives an advantage to computing the language model's perplexity when tested on PTB.,Does the review address Evaluation?,TRUE,FALSE,The review discusses perplexity baseline advantages.
The system performs on par with recently proposed GECA for SCAN and favorably to GECA on morphological analysis.,Does the review address Analysis?,TRUE,FALSE,The review notes system performance compared to other methods.
I would recommend the authors to at least assume the availability of some public data that is kept out of training and evaluations and to run all the baselines fairly in this setting.,Does the review address Data/Task?,TRUE,FALSE,The review suggests using public data for fair evaluation.
"Furthermore, an explicit definition of the feature matrix X of the nodes would help in understanding how these features interact with the quantum-inspired positional encodings.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests defining feature matrix for better understanding.
"There is no comparison provided with any baseline for 2/5 tasks (Language grounding, Tappability) 5.",Does the review address Comparison?,TRUE,FALSE,The review points out lack of baseline comparisons for some tasks.
Strengths:   - Combining lifelong and few-shot learning is a new setting.,Does the review address Novelty?,TRUE,FALSE,The review highlights the novelty of combining lifelong and few-shot learning.
"Moreover, the authors better answer questions in 2 so I can gauge if their hyper-parameters were chosen in the principled ways.",Does the review address Presentation?,FALSE,TRUE,The review suggests clarifying hyperparameter choices.
"As pointed by one public comment, the ablation study should show how much improvement is from BERT vectors.",Does the review address Ablation?,TRUE,FALSE,The review suggests an ablation study on BERT vectors.
"While I understand this is contemporaneous work, but since the work is so relevant to this paper and seems to directly contradict the premise of this paper, it might be good to have a short discussion on this (just a suggestion).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests discussing contemporaneous work.
"The experiments in the paper demonstrated the superiority of adding adversarial training to a self-supervision framework, in that significant improvements can be obtained for similar-sized networks.",Does the review address Experiment?,TRUE,FALSE,The review highlights the superiority of adversarial training.
"The paper appraisal therefore rests on the clarity of presentation, how convincing the experiments are, and how reproducible.",Does the review address Presentation?,TRUE,FALSE,The review discusses paper appraisal criteria.
"Put in another way, using RFA in transformer is from Rawat et al., 19 so do you think your major contribution is to design such  a gated usage of RFA?",Does the review address Contribution?,TRUE,FALSE,The review questions the major contribution's novelty.
"Therefore, the dynamic \alpha by hyperparameter searching should also be added as a base.",Does the review address Methodology?,TRUE,FALSE,The review suggests adding a dynamic hyperparameter approach.
Keyphrase extraction using deep recurrent neural networks on Twitter.,Does the review address Related Work?,FALSE,TRUE,The review appears to be a brief publication reference.
"However, the designed specific neural network does not support the claimed binding-unbinding theory very well.",Does the review address Theory?,TRUE,FALSE,The review critiques the support for a binding-unbinding theory.
"For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.",Does the review address Comparison?,TRUE,FALSE,The review discusses performance differences across metrics.
The idea that combining the output of several models using the attention strategy is not novel in deep learning.,Does the review address Methodology?,TRUE,FALSE,The review suggests the method of combining models is not novel.
- The experimental results are thorough and solid.,Does the review address Experiment?,TRUE,FALSE,The review praises the thorough and solid experimental results.
"Therefore, it's not ideal that the uncertainty sampling algorithm has been moved to the appendix.",Does the review address Methodology?,TRUE,FALSE,The review comments on the placement of an uncertainty sampling algorithm.
One of the important motivations of multi-modal multi-task learning mentioned was to achieve better or on-par performance with a single model (and supposedly fewer computations) which is crucial for devices with limited computing resources.,Does the review address Result?,TRUE,FALSE,The review discusses motivation for multi-modal multi-task learning.
"However, I am unable to grasp nuances, leaving important questions untouched such as: In what scenarios do we expect the model to perform better than GECA?",Does the review address Result?,FALSE,TRUE,The review asks about potential performance scenarios.
"**Major concern** If I understand correctly (and please correct me if I am wrong), in Theorem B.1, the ratio between the downstream error $\ell_\mathcal{T}(\\{p_{\cdot\mid s}\\}) - \tau$ and the pre-training error $\ell_\text{xent}(\\{p_{\cdot\mid s}\\})-\ell_\text{xent}^\ast$ is _hidden_ in the $\gamma(p_{\mathcal{T}}; \\{p_{\cdot\mid s}\\})$ coefficient.",Does the review address Theory?,TRUE,FALSE,The review discusses a theoretical theorem's coefficient.
"While this paper provides extensive empirical results and quantitively demonstrates the effectiveness of RandomMask, there are several areas where it could be further enhanced.",Does the review address Result?,TRUE,FALSE,The review praises extensive empirical results while noting room for improvement.
"In the conclusion, the paper mentions comparison with Multi-Scale approaches, but that is not present in the experiments.",Does the review address Experiment?,TRUE,FALSE,The review notes a lack of comparison with multi-scale approaches.
"The in-depth experimental analysis of the BERT pretraining process in this paper answers many open questions (e.g., the usefulness of NSP objective) and also provide some guidance in how to effectively tweak the performance of pretrained model (e.g., large batch size).",Does the review address Experiment?,TRUE,FALSE,The review highlights in-depth experimental analysis of BERT pretraining.
"(4) In general, the results in table 3 do not tell a consistent story.",Does the review address Result?,TRUE,FALSE,The review suggests inconsistent results in a table.
"## Paper weaknesses and questions  **Code comment analysis**  Some programmers like to write comments, while some are not.",Does the review address Analysis?,FALSE,TRUE,The review briefly mentions code comment analysis.
"Mainly, for most of the intrinsic metrics, the multilingual embedding techniques do not seem to perform the best.",Does the review address Evaluation?,TRUE,FALSE,The review discusses performance of multilingual embedding techniques.
"- If not, please remove the attention layer after the encoder in figure 5.",Does the review address Methodology?,TRUE,FALSE,The review suggests removing an attention layer.
"Do we need better model design, or more data and computations?",Does the review address Methodology?,FALSE,TRUE,The review asks a speculative question about model improvement.
What is the result if we directly learn to match input and logic forms?,Does the review address Methodology?,FALSE,TRUE,The review asks a speculative question about matching input and logic forms.
"Furthermore, when there is a gap between the empirical results and the theoretical results (e.g., validation of Lemma 4.3 at the end of Section 4), the paper makes these limitations clear, which I appreciated very much as a reader (paper does not over-claim its contributions).",Does the review address Result?,TRUE,FALSE,The review appreciates the paper's clarity about limitations.
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Result?,TRUE,FALSE,The review finds the ablation and visualization analysis sufficient.
"- Strengths: Useful modeling contribution, and potentially useful annotated data, for an important problem -- event extraction for the relationships between countries as expressed in news text.",Does the review address Data/Task?,TRUE,FALSE,The review highlights the contribution of event extraction data.
"Perhaps an entropy-regularized setup is a useful comparison to show that it provides marginal benefit over the setup studied, and this might resolve the lack of clarity around the implications of the claims made from the first set of experiments.",Does the review address Presentation?,FALSE,TRUE,The review suggests an additional experimental setup.
Pros: - Weakly-supervised method for video moment localization is a reasonable and important direction.,Does the review address Significance?,TRUE,FALSE,The review appreciates the direction of weakly-supervised video localization.
Weaknesses - The writing and the paper organization can be improved.,Does the review address Presentation?,TRUE,FALSE,The review suggests improving writing and organization.
"1 ""Rule based approaches may seem outdated in contrast to statistical or neural methods.",Does the review address Methodology?,FALSE,TRUE,The review comments on rule-based approaches.
"It describes a mapping of ORCHID, a Thai-specific POS tagset, to the Universal Dependencies (UD) scheme, and evaluates various state-of-the-art POS taggers on this scheme.",Does the review address Evaluation?,TRUE,FALSE,The review describes the mapping and evaluation of POS taggers.
It also includes the recurrent memory extension from Transformer-XL from Dai et al.,Does the review address Methodology?,TRUE,FALSE,The review mentions a recurrent memory extension.
"On the other hand, the symbolic logic rules are able to express global patterns.",Does the review address Comparison?,TRUE,FALSE,The review compares symbolic logic rules with other methods.
Contributions of the paper don't seen particularly novel.,Does the review address Novelty?,TRUE,FALSE,The review suggests the contributions lack novelty.
"Thus, while concatenating the audio feature and the text feature can introduce desired performance, there could be some advancements not just combining pretrained audio model and LLM.",Does the review address Result?,TRUE,FALSE,The review discusses potential performance improvements.
It would helpful to place it more clearly where the contribution of the paper lies in the related work.,Does the review address Contribution?,TRUE,FALSE,The review suggests clarifying the paper's contribution.
"However, there is no theoretical result about the effectiveness of assigning the self-knowledge distillation to label smoothing.",Does the review address Result?,FALSE,TRUE,The review notes a lack of theoretical results.
* Can we get any information about how the annotators were trained?,Does the review address Methodology?,FALSE,TRUE,The review asks about annotator training.
"It would be great to define and identify beyond current close-ended tasks with new lower level tasks which really require using the audio, such as counting sound events, ordering of events, etc.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests defining new lower-level tasks.
"- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other ""oracle"" baselines.",Does the review address Data/Task?,TRUE,FALSE,The review notes dataset evaluation and comparisons.
The ablations cannot serve the topic of this paper well.,Does the review address Ablation?,TRUE,FALSE,The review suggests the ablations are insufficient.
But a direct head to head comparison for the computational cost of a multi-task model and individual models is not provided.,Does the review address Comparison?,TRUE,FALSE,The review points out lack of computational cost comparison.
* Authors reproduced results from their strongest baseline.,Does the review address Result?,FALSE,TRUE,The review notes reproduction of baseline results.
The paper is taking all the lessons from past works and applying it to a new domain.,Does the review address Methodology?,TRUE,FALSE,The review describes applying past lessons to a new domain.
"A significant part of the contribution was in the analysis of the results, obtained by this learning-based parameter sharing approach, which was quite informative and revealed some interesting insights about where and when a language-specific computation is required.",Does the review address Analysis?,TRUE,FALSE,The review praises the analysis revealing insights about computation.
"2. the FlexGen proposed in (Sheng et al., 2023) have showed -> has shown 3.",Does the review address Presentation?,FALSE,TRUE,The review notes a grammatical correction.
The proposed distillation loss is standard and by itself is not technically new.,Does the review address Novelty?,TRUE,FALSE,The review suggests the distillation loss is not technically new.
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Methodology?,TRUE,FALSE,The review describes an interesting methodology for Multiple-Choice Question-Answering.
"3.The model excels in various audio-related tasks and open-ended question answering, demonstrating its outstanding performance.",Does the review address Methodology?,TRUE,FALSE,The review highlights the model's performance across audio tasks.
"Additionally, the rationale for choosing (Ma et al., 2023) as a benchmark, along with the significance of the improvements observed, even if minute, should be clearly articulated.",Does the review address Presentation?,TRUE,FALSE,The review suggests clarifying benchmark and improvement rationale.
- Discussion in Section 4.1 - I think Figure 4 should be explained in more detail (in caption and/or text).,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests more detailed explanation of a figure.
Such choice and associated thresholds seem arbitrary: how were they actually found out?,Does the review address Experiment?,FALSE,TRUE,The review questions the arbitrariness of choice and thresholds.
The same comment is applicable to oracle database (DB) results.,Does the review address Presentation?,FALSE,TRUE,The review makes a brief comment about database results.
It will be good to rewrite highlighting the contributions.,Does the review address Presentation?,TRUE,FALSE,The review suggests rewriting to highlight contributions.
"Experiments show that the induced ""best-first"" order outperforms fixed orders, which verifies the motivation of the paper` 4.",Does the review address Result?,TRUE,FALSE,The review notes the performance of an induced order.
Theoretical analysis is provided to demonstrate the effectiveness of the proposed method under a greedy search algorithm.,Does the review address Presentation?,TRUE,FALSE,The review mentions theoretical analysis presentation.
"In its current form, the two arguments (input query and output sequence translated from a logic form) are interchangeable.",Does the review address Methodology?,FALSE,TRUE,The review notes interchangeability of arguments.
The findings from the analysis are an important addition to the understanding of the role of language specific parameters in multilingual NMT.,Does the review address Methodology?,TRUE,FALSE,The review highlights findings about language-specific parameters.
"I recommend this paper for acceptance, though I encourage the authors to revise their paper to make this the focus of the story, rather than the vaguely defined notion of “concept”.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests focusing the paper's narrative.
The main weakness of the paper is that it is mainly based on further tuning the existing BERT model and lacks novel contribution in model architecture.,Does the review address Novelty?,TRUE,FALSE,The review critiques the lack of novel model architecture.
"Therefore, the training is stable and guarantee to converge.",Does the review address Methodology?,TRUE,FALSE,The review notes training stability and convergence.
Strengths: The paper is well-written with clear motivations and structure.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review praises the paper's clear motivation and structure.
"- The authors have evaluated their models on multiple settings, proving that their models trained on Wikipedia can potentially generalize to multiple downstream tasks.",Does the review address Data/Task?,TRUE,FALSE,The review discusses model evaluation across multiple settings.
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Contribution?,TRUE,FALSE,The review suggests insufficient experiments to prove novelty.
I also encourage the authors to simplify the experiment described in section 3.1 to make it more clear.,Does the review address Presentation?,TRUE,FALSE,The review suggests simplifying experimental description.
"The motivation is to leverage unimodal data, which are assumed easier to obtain than image-text pairs.",Does the review address Data/Task?,TRUE,FALSE,The review discusses motivation for leveraging unimodal data.
"One novel finding of this paper is that the distribution of the next word, conditional on the context, can provide a strong discriminative signal for the downstream task.",Does the review address Data/Task?,FALSE,TRUE,The review discusses a novel finding about word distribution.
"A lot of attention/space is dedicated to locality and symmetry properties of positional encodings, which from my understanding, isn’t very novel and has been explored in previous work.",Does the review address Novelty?,TRUE,FALSE,The review suggests limited novelty in positional encoding analysis.
The empirical study that compares the prediction ensemble with the prompt ensemble is quite interesting and can inspire many related fields.,Does the review address Methodology?,TRUE,FALSE,The review finds the ensemble comparison interesting.
About experiments: 1) I think one ablation study I’m most interested in is to simply run GNN on the AST (or simply use Allamanis et.al’s method).,Does the review address Ablation?,TRUE,FALSE,The review suggests an additional ablation study.
"I appreciate that the authors do not read too much into it and focus more on the analysis of the results, but one thing that remains unanswered in this paper is how the proposed method fairs against multilingual baselines that utilize (roughly) the same number of parameters; currently, the best models outperform the LS baseline by ~28M and ~10M parameters on OPUS-100 and WMT-14 respectively.",Does the review address Methodology?,TRUE,FALSE,The review discusses comparing multilingual baselines.
W: - Human evaluation is missing and could add more insights to the interactive process.,Does the review address Evaluation?,TRUE,FALSE,The review suggests adding human evaluation.
Could you explain more precisely what exactly is new?,Does the review address Novelty?,FALSE,TRUE,The review asks a direct question about novelty without substantive discussion.
"Theoretically, they showed that synchronized updates to the low-level and high-level policy may never converge, yet asynchronized updates guarantees convergence.",Does the review address Theory?,TRUE,FALSE,The review describes theoretical findings about policy updates.
This paper is an interesting application of a data augmentation or self-supervised learning type of approach for tactic based theorem proving.,Does the review address Data/Task?,TRUE,FALSE,The review describes the paper as an application of data augmentation.
Authors also used a discriminator reward signal to cope with sparse reward (dialog success rate) and better representation of the human evaluation.,Does the review address Methodology?,TRUE,FALSE,The review describes using a discriminator reward signal.
"I also appreciate that due care has been taken to present the work as understanding a phenomenon, to avoid any misconceptions about a new method being proposed.",Does the review address Presentation?,TRUE,FALSE,The review appreciates the careful presentation of work.
- The experimental results are thorough and solid.,Does the review address Result?,TRUE,FALSE,The review praises thorough and solid experimental results.
"Therefore, it is necessary to compare OTTER and CLIP on the same-scaled datasets.",Does the review address Comparison?,TRUE,FALSE,The review suggests comparing models on same-scaled datasets.
"For the transferability coefficient proposed in Section 5.1, is it possible to measure it in experiments?",Does the review address Experiment?,FALSE,TRUE,The review asks about measuring a theoretical coefficient.
"The annotations from [1] are very simple and short, only including some easy examples as in-context examples.",Does the review address Data/Task?,FALSE,TRUE,The review comments on annotation simplicity.
"The main limitation to me is that, the two novel pre-training tasks proposed in this paper are specific for Wikipedia and they are less effective than the ICT strategy (as shown in Table 5).",Does the review address Methodology?,TRUE,FALSE,The review discusses limitations of pre-training tasks.
It shows that BERT was significantly undertrained and propose an improved training recipe called RoBERTa.,Does the review address Methodology?,TRUE,FALSE,The review describes improving BERT training.
"There are several follow-up results built on these two results, such as a new loss objective for predicting the downstream task, but to the best of my understanding, these two results are the main claims of this paper.",Does the review address Data/Task?,FALSE,TRUE,The review discusses follow-up results.
This seems to contradict findings from Brown et al where larger models did better on essentially all tasks.,Does the review address Result?,FALSE,TRUE,The review points out a contradiction in model performance.
"2) The proposed method outperforms other SOTA models in offline and interactive online settings, MultiWOZ and ConvLab respectively.",Does the review address Result?,TRUE,FALSE,The review notes performance improvements across settings.
"Also, I think putting the english translation in a different font or color would be greatly helpful to our eyes.",Does the review address Presentation?,TRUE,FALSE,The review suggests improving translation presentation.
I understand that LMU might have limited capacity but this is not specifically discussed and it is unclear how each component contributes to the end performance.,Does the review address Contribution?,TRUE,FALSE,The review questions the contribution of model components.
This work has the potential to set a precedent in the fusion of quantum computing with graph transformers.,Does the review address Methodology?,TRUE,FALSE,The review discusses potential for quantum computing fusion.
"Reasons for Score ----------------- The idea proposed in the paper is novel and exciting, but I have some concerns about whether the gains promised by the theoretical analysis can be realized while maintaining modeling quality.",Does the review address Theory?,TRUE,FALSE,The review discusses theoretical analysis and potential gains.
- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.,Does the review address Methodology?,TRUE,FALSE,The review critiques experimental dataset distribution.
"* ""By achieving the best, these results prove that BROS"" this sentence can be improved.",Does the review address Result?,FALSE,TRUE,The review suggests improving a results-related sentence.
"2) The proposed method outperforms other SOTA models in offline and interactive online settings, MultiWOZ and ConvLab respectively.",Does the review address Presentation?,FALSE,TRUE,The review repeats a performance statement.
"However, only one member (alpha=0.5) from the family has been evaluated in the experiments, and it does not achieve the best performance in most experiments.",Does the review address Result?,TRUE,FALSE,The review notes limitations in model family evaluation.
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Analysis?,TRUE,FALSE,The review finds the ablation and visualization analysis sufficient.
"According to my understanding, at least there should be some direct connections between the parameters in the encoder and decoder.",Does the review address Methodology?,FALSE,TRUE,The review suggests connections between encoder and decoder.
However in experiment only 300 projects are involved.,Does the review address Experiment?,FALSE,TRUE,The review notes the limited number of projects in experiments.
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Methodology?,TRUE,FALSE,The review discusses theoretical analysis of hyperparameter selection.
"They show improved total performance in MultiWoz dataset compared to recent, relevant baselines.",Does the review address Comparison?,TRUE,FALSE,The review notes improved performance compared to baselines.
"The experments are fairly convincing, although it is not entirely surprising that this approach works, and to repeat, the basic idea of extracting additional training data in this way is not entirely new.",Does the review address Experiment?,TRUE,FALSE,The review finds the experiments convincing while noting lack of novelty.
What is the result if we directly learn to match input and logic forms?,Does the review address Result?,FALSE,TRUE,The review asks a speculative question about matching input and logic forms.
"Based on the large-scale training data and the proposed visual expert module, the proposed method achieves a number of state-of-the-art results across a wide range of vision-language tasks.",Does the review address Methodology?,TRUE,FALSE,The review describes achieving state-of-the-art results using a visual expert module.
"The main limitation to me is that, the two novel pre-training tasks proposed in this paper are specific for Wikipedia and they are less effective than the ICT strategy (as shown in Table 5).",Does the review address Data/Task?,TRUE,FALSE,The review critiques pre-training tasks specific to Wikipedia.
This is very promising to simplify the construction of highly tuned task-specific neural pipelines and improve the multimodal and multi-task problems.,Does the review address Result?,TRUE,FALSE,The review discusses promise for simplifying neural pipelines.
Clarification on the task setting: Is it the case that the agent's current utterance does not decide what the next user utterance is?,Does the review address Methodology?,FALSE,TRUE,The review asks a clarifying question about task setting.
"- Well Structured Experiments sections with 4 RQs and results that confirm each of the hypotheses  - Reproducibility and Transparency in reporting of experiments in terms of available source code, dataset information, details about human evaluation, generation examples.",Does the review address Experiment?,TRUE,FALSE,The review praises well-structured experiments and reproducibility.
"(3) In the experiment about linguistic similarity, it appears that the capacity schedule is the same across languages and the authors conclude from this that the schedule has little to do with linguistic characteristics.",Does the review address Experiment?,TRUE,FALSE,The review discusses an experiment about linguistic similarity.
"(In particular, pre-training on emergent language performs on average better than synthetic hierarchical data, but not quite as well as a different natural language, and all of these pre-training methods do better than training from scratch.)",Does the review address Methodology?,TRUE,FALSE,The review compares different pre-training approaches.
"(2) Specifically, in the encoder side, the M-BERT model is leveraged to jointly encode the $x,tx,ty$.",Does the review address Presentation?,FALSE,TRUE,The review notes specific encoding details.
**Limited technical novelty and incremental empirical gains**.,Does the review address Novelty?,TRUE,FALSE,The review suggests limited technical novelty.
Do you learn a vector of each tag of BIOES and then take a weighted sum of these vectors with predicted probabilities as weights?,Does the review address Presentation?,FALSE,TRUE,The review asks a technical question about tag vector processing.
"Altogether, I think this paper makes an interesting contribution to the question of: How can we get the most pretraining signal from unstructured data using off-the-shelf tools?",Does the review address Methodology?,TRUE,FALSE,The review discusses extracting pretraining signal from unstructured data.
"In practice, the authors use nouns and verbs as their concepts, which is fine in terms of pretraining objectives, but surely does not capture the generality of concepts.",Does the review address Methodology?,TRUE,FALSE,The review critiques the concept definition used in the study.
Could you explain the significance of this result again?,Does the review address Result?,FALSE,TRUE,The review asks about result significance.
"For checking the generalization of the method and better comparison w/ InDIGO (though InDIGO also conducted on MSCOCO, Django and the current comparison is sufficiently fair), I would like to increase my rating if seeing more experiments on large scale machine translation benchmarks as those in InDIGO.",Does the review address Methodology?,TRUE,FALSE,The review suggests additional experiments for generalization.
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Evaluation?,TRUE,FALSE,The review critiques the evaluation approach.
CALM shows better results with less data than the base model.,Does the review address Result?,TRUE,FALSE,The review notes CALM's performance with less data.
"It provided me with a much more thoughtful explanation for why language model pre-training improves downstream task performance, beyond simply “it helps learn good general representations of language using large amounts of unlabeled text data” (my previous reasoning).",Does the review address Methodology?,TRUE,FALSE,The review discusses understanding of language model pre-training.
The paper is well-written and the idea is well-motivated.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review praises the paper's writing and motivation.
Strengths: - The algorithms presented here are relatively straightforward but surprisingly effective.,Does the review address Methodology?,TRUE,FALSE,The review highlights surprisingly effective algorithms.
"Although the authors identify three potential challenges -- rapid convergence, the risk of under-training, and the potential for sparse attention -- they do not adequately explain how RandomMask addresses or mitigates these issues.",Does the review address Methodology?,TRUE,FALSE,The review critiques inadequate explanation of methodology challenges.
"If so, does the global node $V_g$ connect to all the sub fact nodes?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,The review asks a technical question about node connections.
"Overall this paper tackles a nice application of GNN, which is the type prediction problem that utilizes structural information of the code.",Does the review address Methodology?,TRUE,FALSE,The review describes a GNN application for type prediction.
"- Strengths: This paper has high originality, proposing a fundamentally different way of predicting words from a vocabulary that is more efficient than a softmax layer and has comparable performance on NMT.",Does the review address Methodology?,TRUE,FALSE,The review highlights a novel approach to predicting words.
"They show improved total performance in MultiWoz dataset compared to recent, relevant baselines.",Does the review address Data/Task?,TRUE,FALSE,The review notes performance improvement on MultiWoz dataset.
"Your work is so similar to much of this work that you should really cite and establish novelty wrt at least some of them as early as the introduction -- that's how early I was wondering how your work differed, and it was not made clear.",Does the review address Novelty?,TRUE,FALSE,The review suggests need for clarifying work's novelty.
The experiments are conducted on datasets from questions answering and sentiment analysis.,Does the review address Experiment?,TRUE,FALSE,The review notes experiments on question answering and sentiment analysis datasets.
"The paper claims that Balance Beam is ""an workflow to optimize the trade-off between latency and throughput performance of LLMs"".",Does the review address Presentation?,TRUE,FALSE,The review quotes the paper's claim about Balance Beam.
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Presentation?,TRUE,FALSE,The review finds ablation and visualization analysis sufficient.
"**Weaknesses**:   (1) Even though it is the first time such a method is applied in the context of NMT, the idea is not as much novel in the broader context of deep learning.",Does the review address Novelty?,TRUE,FALSE,The review suggests limited novelty in broader deep learning context.
The current paper only indicates that a small gap gives more consistency between the true objective and the optimized objective defined on the training set: they can be still far away from the expected posterior over data distribution.,Does the review address Data/Task?,TRUE,FALSE,The review discusses objective optimization challenges.
"However, only one member (alpha=0.5) from the family has been evaluated in the experiments, and it does not achieve the best performance in most experiments.",Does the review address Experiment?,TRUE,FALSE,The review notes limited evaluation of model family.
The experiments are conducted on datasets from questions answering and sentiment analysis.,Does the review address Analysis?,TRUE,FALSE,The review reiterates experiments on datasets.
It is better to compare with more demonstration selection methods such as similarity-based and diversity-based methods which are widely used in practice.,Does the review address Comparison?,TRUE,FALSE,The review suggests comparing with more demonstration selection methods.
"- The experiments contain two setups, one is offline response evaluation via MultiWOZ, and another is interactive simulation via ConvLab.",Does the review address Experiment?,TRUE,FALSE,The review describes experimental setups.
"Related Work: Contrastive learning - Under an unsupervised setting, ontrastive -> contrastive  Overall:  This work highlights the importance of incorporating contrastive training for data augmentation.",Does the review address Data/Task?,TRUE,FALSE,The review highlights contrastive training for data augmentation.
Presumably this is because much of the training iteration time is consumed by other parts of the network.,Does the review address Methodology?,FALSE,TRUE,The review speculates about training iteration time.
One of the important motivations of multi-modal multi-task learning mentioned was to achieve better or on-par performance with a single model (and supposedly fewer computations) which is crucial for devices with limited computing resources.,Does the review address Data/Task?,TRUE,FALSE,The review discusses motivation for multi-modal multi-task learning.
This is to verify and support the usage of proposed type dependency graph.,Does the review address Experiment?,FALSE,TRUE,The review mentions verifying a type dependency graph.
"The two datasets have some “toy flavor”, while SCAN great favors example combination (with recomb-2 performs much better than recomb-1), recomb-1 seem to perform better for morphological analysis dataset, leaving questions about how to choose the exact models in general.",Does the review address Methodology?,TRUE,FALSE,The review discusses dataset characteristics and model performance.
"For instance, they ask how different amounts of data influence model behavior or if their data sampling method can react to task difficulty.",Does the review address Evaluation?,TRUE,FALSE,The review discusses data influence on model behavior.
"In experiments, mainly accuracy is shown, but since the major motivation to reduce gradient variance, why not show some comparison of gradient variance of MLM and MLM-FE?",Does the review address Comparison?,TRUE,FALSE,The review suggests comparing gradient variance.
"For example, by selecting the most complex examples, the performance of ChatGPT (i.e., gpt-3.5-turbo) can easily achieve more than 80% accuracy (without self-consistency) compared to the number 77.1% in Table 1.",Does the review address Result?,FALSE,TRUE,The review discusses potential performance improvements.
"Without the experimental results using the same training settings, I do not think the authors are able to prove the superiority of OTTER over CLIP fully.",Does the review address Methodology?,TRUE,FALSE,The review questions experimental settings for model comparison.
Questions:  * How can we be sure that the specific power law derived from a different experimental configuration in Kaplan et al. (2020) corresponds to the empirical law that can be derived for transformers in this particular evaluation setting?,Does the review address Methodology?,TRUE,FALSE,The review questions power law derivation.
"They show that, especially in small-data regimes, pre-training on an emergent language can yield significant performance boosts in both tasks.",Does the review address Data/Task?,TRUE,FALSE,The review discusses performance in small-data regimes.
Cons: Some of the claims are not quite accurate even when compared to the works already cited here - 1.,Does the review address Result?,FALSE,TRUE,The review suggests inaccuracies in claims.
"It is hard to tell what are the standalone contributions of the paper, and what is coming from other works.",Does the review address Contribution?,TRUE,FALSE,The review finds it difficult to identify standalone contributions.
"Furthermore, when there is a gap between the empirical results and the theoretical results (e.g., validation of Lemma 4.3 at the end of Section 4), the paper makes these limitations clear, which I appreciated very much as a reader (paper does not over-claim its contributions).",Does the review address Theory?,TRUE,FALSE,The review appreciates the paper's clarity about theoretical limitations.
"The authors should make it clear that on different evaluation sets, the scores differs.",Does the review address Evaluation?,TRUE,FALSE,The review suggests clarifying score differences across evaluation sets.
"Terms such as θ, t, δ, and especially the adjacency matrix A, which are crucial for understanding the method, require clear definitions and contextual usage within the proposed quantum framework.",Does the review address Methodology?,TRUE,FALSE,The review suggests clarifying key methodological terms.
"Therefore, I think it is very necessary to supplement this experiment.",Does the review address Experiment?,FALSE,TRUE,The review suggests supplementing an experiment.
And they show this technique improves accuracy in downstream tasks.,Does the review address Result?,TRUE,FALSE,The review notes technique's improvement in downstream task accuracy.
The problem is a terrific one and the application of the recursive models seems like a contribution to this problem.,Does the review address Presentation?,FALSE,TRUE,The review comments on the problem's significance.
Enhancing the paper with the aforementioned suggestions could substantially improve its impact and reception by the research community.,Does the review address Significance?,TRUE,FALSE,The review suggests improvements could enhance paper's impact.
* I think there should be more discussion about the implications of Proposition 2.2.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests more discussion of a proposition.
- The proof technique (pre-training performance $\to$ covariance of pre-training errors $\to$ covariance of downstream errors $\to$ downstream performance) is itself interesting.,Does the review address Methodology?,TRUE,FALSE,The review highlights an interesting proof technique.
"Of course, it is valuable to see the great performance achieved by single-task finetuning for RoBERTa.",Does the review address Data/Task?,FALSE,TRUE,The review notes performance of single-task fine-tuning.
"The authors use objectives which capture both generative and discriminative information, which some have suggested contain mutually beneficial signal but have not been unified in a single training method.",Does the review address Methodology?,TRUE,FALSE,The review describes objectives capturing generative and discriminative information.
- The original option framework assumes given options.,Does the review address Methodology?,FALSE,TRUE,The review notes limitations of an option framework.
"335: consider defining GPGPU Table 3: Highlight the best BLEU scores in bold Equation 15: remind the reader that q is defined in equation 6 and b is a function of w. I was confused by this at first because w and h appear on the LHS but don't appear on the right, and I didn't know what b and q were.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests clarifying equation and notation.
The authors take time to implement and evaluate several prominent baselines.,Does the review address Evaluation?,TRUE,FALSE,The review notes implementation of baseline evaluations.
"> However, in every task except CommonGEN the authors do not discuss any methods that are even close to the state of the art.",Does the review address Presentation?,FALSE,TRUE,The review comments on baseline discussions.
This paper suggestsan intermediate training regime that can be used between pretraining and the end-task finetuning.,Does the review address Methodology?,TRUE,FALSE,The review describes an intermediate training regime.
"* Why does the EC pre-training use |V| = 4035, as opposed to 50 that's used in the other tasks and the fine-tuning corpora?",Does the review address Methodology?,FALSE,TRUE,The review asks about a specific parameter choice.
"The in-depth experimental analysis of the BERT pretraining process in this paper answers many open questions (e.g., the usefulness of NSP objective) and also provide some guidance in how to effectively tweak the performance of pretrained model (e.g., large batch size).",Does the review address Result?,TRUE,FALSE,The review highlights experimental analysis of BERT pretraining.
"While the authors say that they use vocabulary permutation, it is not clear what the size of the vocabulary is.",Does the review address Presentation?,FALSE,TRUE,The review asks about vocabulary permutation.
Were there perhaps some poor datasets that happened to be in the held-in split (since the held-out tasks don't seem to have the same trend)?,Does the review address Data/Task?,FALSE,TRUE,The review questions dataset characteristics.
"In this way, the conclusion is only supported by the empirical observations but not the presented theoretical analysis.",Does the review address Analysis?,TRUE,FALSE,The review notes empirical observations lacking theoretical support.
"To alleviate the difficulty of optimizing discrete latent variables, the authors propose to cast it as a one-step Markov Decision problem and optimize it using the policy gradient.",Does the review address Methodology?,TRUE,FALSE,The review describes methodology for optimizing discrete latent variables.
(2) Equation 2 and 3 use the same graph encoder $F_{G}$.,Does the review address Methodology?,FALSE,TRUE,The review notes use of the same graph encoder.
Weaknesses:   - The empirical study is not convincing by only evaluating BERT-Tiny.,Does the review address Methodology?,TRUE,FALSE,The review critiques empirical study's limited evaluation.
* The rationale behind the architectural choices for the self-attention component is not well explained or empirically verified.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques lack of explanation for architectural choices.
The result presented in Table 4 don't match the description in Section 4.3:  - It's not true that the pRNN outperforms both PBSMT and Enc-Dec model.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out discrepancies between results and description.
It will be good to rewrite highlighting the contributions.,Does the review address Contribution?,TRUE,FALSE,The review suggests rewriting to highlight contributions.
"Since the selective annotation is based entirely on similarities derived from sentence embeddings, there is nothing explicit ensuring that the label distribution over the selected subset is not skewed.",Does the review address Presentation?,FALSE,TRUE,The review discusses potential bias in annotation selection.
The authors suggest that their method captures more commonsense knowledge by being focused on capturing knowledge about “concepts”.,Does the review address Methodology?,TRUE,FALSE,The review discusses method's approach to capturing commonsense knowledge.
"The result section cannot be simply presenting a table without explanation:  - Still on the result sections, although it's clear that BLEU and perplexity are objective automatic measure to evaluate the new architecture.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques lack of explanation in results section.
"Without the ablation studies on these two aspects, we cannot determine whether the performance improvement truly comes from the author's contribution or just longer CoT annotations.",Does the review address Data/Task?,TRUE,FALSE,The review suggests need for ablation studies.
Summary: + Appealing theoretical contributions + Empirical results are encouraging + The use of discriminator for reward shaping in addition to task success rate is interesting  - Writing and explanation can be improved.,Does the review address Contribution?,TRUE,FALSE,The review summarizes theoretical and empirical contributions.
"In particular, you are comparing a small GRU LM to a larger transformer LM, where the latter is, as you mention, a much more powerful model.",Does the review address Comparison?,TRUE,FALSE,The review notes comparison between different model sizes.
"Other concerns along these lines: all of this paper's results are averaged over 3 runs while the other baselines are over 5 runs - an indication of variance would be useful to assess whether the differences are significant, especially since some of the margins quite small (23 on MC-LAVE-RL vs 22.8 for the next best on Ludicorp) added to the fact that hyperparameters are different for each game - does that imply that the authors tuned the hyperparameters for each game?",Does the review address Significance?,TRUE,FALSE,The review discusses experimental run variations and significance.
"The result section cannot be simply presenting a table without explanation:  - Still on the result sections, although it's clear that BLEU and perplexity are objective automatic measure to evaluate the new architecture.",Does the review address Result?,TRUE,FALSE,The review discusses results presentation and metrics.
"Rules may be ""outdated"" because they are inefficient for certain languages with reams of available data and scads of phenomena that don't fit.",Does the review address Methodology?,FALSE,TRUE,The review comments on rules becoming outdated.
The methodology is explained clearly and experiments are executed with a considerable amount of detail.,Does the review address Presentation?,TRUE,FALSE,The review praises methodology explanation and experimental detail.
"Does the definition of ""event word""s here come from any particular previous work that motivates it?",Does the review address Related Work?,FALSE,TRUE,"The review asks about the definition of an ""event word""."
"Then, taking inspiration from recent work that shows that many downstream tasks can be reframed as sentence completion tasks, it defines a “natural task” as one on which a sparse linear model over the output of the “true” language model (next word probability distribution, conditioned on context) attains strong performance.",Does the review address Data/Task?,TRUE,FALSE,The review discusses task definition inspired by recent work.
Are these rather the ppl resulting from training an LM on the full dataset?,Does the review address Methodology?,FALSE,TRUE,The review asks about perplexity calculation.
"To me saying ""BLUE reduced for the other methods"" means that you have some other baseline you are comparing to.",Does the review address Comparison?,FALSE,TRUE,The review questions baseline comparison.
"However, they compare to BERT models and build themselves on RoBERTa_base; how are the results meaningful if they use a stronger model to start with?",Does the review address Methodology?,TRUE,FALSE,The review questions model comparison methodology.
"**Related work** The authors clearly describe the related prior works from both the perspectives of program synthesis, large language models, and benchmarks for program synthesis.",Does the review address Data/Task?,FALSE,TRUE,The review praises description of related work.
"It is hard to infer the test gains, given the possibly significant hyperparameter optimization on the dev set.",Does the review address Presentation?,FALSE,TRUE,The review discusses hyperparameter optimization challenges.
It is great to have a theoretical analysis of the property of the influence function.,Does the review address Analysis?,TRUE,FALSE,The review appreciates theoretical analysis.
"However, there are still major gaps between the theoretical analysis, the conclusion and the empirical solution (please see the detailed comments).",Does the review address Theory?,TRUE,FALSE,The review notes gaps between theoretical analysis and empirical solution.
- It is unclear why the zero-shot prediction of CLIP is not used as a baseline (as it would be equivalent to epsilon = 0).,Does the review address Comparison?,TRUE,FALSE,The review suggests using zero-shot prediction as a baseline.
"Compared to the related work, the novel part of this work is: (i) a new retrieval way, which is not quite clear and convincing to me.",Does the review address Novelty?,TRUE,FALSE,The review finds the novel retrieval approach unconvincing.
This is an interesting topic that can spur further research and help predictability and understand the LLM's behaviours in general.,Does the review address Methodology?,TRUE,FALSE,The review finds the topic interesting for understanding LLM behaviors.
The proposed model explored to utilize better context information and captured the relation between video and sentence/word via graph neural networks.,Does the review address Methodology?,TRUE,FALSE,The review describes utilizing context information via graph neural networks.
The annotations in baseline [1] are much shorter compared to the annotations by the authors.,Does the review address Data/Task?,TRUE,FALSE,The review compares annotation lengths across baseline and current work.
#### Strength - The idea of perceiver IO is novel and solid -- a general architecture capable of handling general-purpose inputs and outputs across different tasks and modalities.,Does the review address Methodology?,TRUE,FALSE,The review highlights the novel architecture of Perceiver IO.
It handles the hallucination problem of LLM by training close-ended dataset and then non-answerable question-answer pairs.,Does the review address Data/Task?,TRUE,FALSE,The review describes approach to handling LLM hallucination.
(2) Another weakness is that the comparison with the vanilla and LS baselines does not seem to be properly controlled in terms of parameters.,Does the review address Comparison?,TRUE,FALSE,The review critiques baseline comparison control.
Their thorough ablation experiments and other analysis yield some interesting findings the authors could emphasize more.,Does the review address Analysis?,TRUE,FALSE,The review suggests emphasizing findings from ablation experiments.
"On the other hand, one could argue that N-Bref is novel because it combines a number of existing components in a unique way to achieve better performance that prior work.",Does the review address Novelty?,TRUE,FALSE,The review discusses novelty in combining existing components.
The margin of change seems even larger than some results which are discussed in the paper as significant.,Does the review address Significance?,TRUE,FALSE,The review notes margin of change in results.
"It is also strange that the multi-cluster approach, which discards inter-cluster (word and language) semantic information performs the best with respect to the extrinsic metrics.",Does the review address Methodology?,TRUE,FALSE,The review discusses performance of multi-cluster approach.
"you explained this in page 6, in Task Description.",Does the review address Presentation?,FALSE,TRUE,The review refers to a specific page explanation.
Is this strategy guaranteed optimal theoretically?,Does the review address Theory?,FALSE,TRUE,The review asks about strategy's theoretical optimality.
"It is not the case that I find the experimental results inadequate, rather, the experiments run in the first place are generic and do not illustrate the points of interest with a continuous-channel referential game.",Does the review address Result?,TRUE,FALSE,The review critiques the generic nature of experiments.
"The authors cite Bordes et al. (https://arxiv.org/pdf/1506.02075.pdf), who collect a similar dataset and perform relation extraction using memory networks (which are commonly used for reading comprehension).",Does the review address Data/Task?,TRUE,FALSE,The review discusses a similar dataset and relation extraction.
Impact: The labeling requirement was a huge bottleneck.,Does the review address Significance?,TRUE,FALSE,The review notes impact of labeling requirements.
"On the one hand the baselines make use of a large set of training trajectories, but on the other hand these methods train policies that choose low-level actions.",Does the review address Methodology?,TRUE,FALSE,The review discusses baseline training approaches.
Or an experiment could address if using the phonotactics from a natural language results is more effective than using a randomly selected phonemes due to necessity for natural languages to have acoustically distinct words.,Does the review address Experiment?,FALSE,TRUE,The review suggests a potential experimental approach.
My understanding is that contribution of the paper is in exploring using options framework to goal-oriented dialog to handle the issue in question.,Does the review address Methodology?,TRUE,FALSE,The review describes contribution of using options framework.
"Are there any overheads/disadvantages because of multi-task learning (Like a larger model size, inference time for individual tasks etc)?",Does the review address Data/Task?,FALSE,TRUE,The review asks about multi-task learning overheads.
More of an issue is that the fact that the definition of general learner in Section 2.2 is not clearly structured.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review critiques unclear definition structure.
"The main contribution are the following innovations: a special attention mechanism called block-diagonal conditional attention, a set of modules for adaptation of a pretrained model, and an uncertainty-based multi-task data sampling method.",Does the review address Contribution?,TRUE,FALSE,The review lists main contributions and innovations.
"If this secondary goal is valid, the paper requires sufficient reasoning for why the presented approach is superior.",Does the review address Methodology?,TRUE,FALSE,The review suggests need for reasoning about approach.
"It provided me with a much more thoughtful explanation for why language model pre-training improves downstream task performance, beyond simply “it helps learn good general representations of language using large amounts of unlabeled text data” (my previous reasoning).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review provides a more thoughtful explanation of language model pre-training.
Strength: - A novel architecture to enable deeper interaction between LM and GCN.,Does the review address Methodology?,TRUE,FALSE,The review highlights novel architecture for LM and GCN interaction.
**Strengths** - The paper is generally quite clearly written and the claims are well-validated.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review praises clear writing and well-validated claims.
The research shows how low-level proof artifact data may be used to significantly boost performance on high-level theorem proving by co-training auxiliary tasks.,Does the review address Result?,TRUE,FALSE,The review discusses boosting performance through co-training.
Clarity on Quantum Enhancements:  Section 3.2.2 seems to lack depth in the explanation of how the quantum correlations are calculated and utilized within the graph transformers.,Does the review address Presentation?,FALSE,TRUE,The review suggests lack of depth in quantum correlation explanation.
"Mainly, Table 4 provides understandable results showing that multi-turn specifications achieve better performance compared to single-turn specifications.",Does the review address Result?,TRUE,FALSE,The review notes performance improvement of multi-turn specifications.
"Yet it seems inconsistent at times whether this is a formal definition of the concept or a necessary condition obtained from some other (unprovided) definition, as Proposition 1 suggests.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review points out inconsistency in concept definition.
The new established benchmark is another good contribution.,Does the review address Contribution?,TRUE,FALSE,The review highlights the new benchmark as a contribution.
More discussion is required on a) what are the reasons of loss in comprehensibility in this case (it is briefly mentioned in the intro) b) why their individual design choices and how they handles the different reasons c) some evaluation to verify this 2.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests more discussion on comprehensibility.
"Moreover, the authors better answer questions in 2 so I can gauge if their hyper-parameters were chosen in the principled ways.",Does the review address Experiment?,FALSE,TRUE,The review suggests clarifying hyperparameter choices.
Perhaps the authors can consider adding them to setup a more comprehensive benchmark.,Does the review address Data/Task?,FALSE,TRUE,The review suggests adding more to the benchmark.
The same applies to Table 3: it is unclear to me why or how the baseline T5 model has been chosen.,Does the review address Presentation?,FALSE,TRUE,The review questions baseline model selection.
The description of how you compare your invariants to those inferred by Daikon is not clear unless all relevant cases related to (pre)conditions on method parameters.,Does the review address Presentation?,FALSE,TRUE,The review suggests unclear comparison description.
Can PACT be applied to simpler theorem provers like MetaMath where there are no tactics?,Does the review address Methodology?,FALSE,TRUE,The review asks about applicability to different theorem provers.
"This work tries a single pruning rate and finds it significantly degrades, rather than improves results: for both active learning and random selection.",Does the review address Result?,TRUE,FALSE,The review discusses results of pruning rate.
"According to the description, the fact units are constructed using the dependency parser.",Does the review address Methodology?,TRUE,FALSE,The review describes fact unit construction methodology.
"For a fair comparison, I think the baseline should add those methods as claimed in the introduction (Lee et al., 2019; Child et al., 2019; Sukhbaatar et al., 2019; Beltagy et al., 2020, inter alia), (Kitaev et al., 2020; Wang et al., 2020; Roy et al., 2020, inter alia) and let us know how badly they performed under the short sequence.",Does the review address Methodology?,TRUE,FALSE,The review suggests including additional baseline methods.
"- Extensive ablation studies that showcase specific abilities of the model (types of OOD generalization), investigate the role of the foundation models and study the importance of the components of the prompt.",Does the review address Presentation?,TRUE,FALSE,The review highlights extensive ablation studies.
The proposed method is reasonable and moderately novel.,Does the review address Methodology?,TRUE,FALSE,The review finds the method reasonable and moderately novel.
It seems like more quantitative analysis would be needed to determine how much the LM's attention is correlating empirically to factual knowledge or if there are other factors that are affecting the downstream improvements.,Does the review address Methodology?,TRUE,FALSE,The review suggests more quantitative analysis of attention.
"* Even though this paper proposes a new efficient transformer, the evaluation does not focus on computational efficiency aspects and comes across as incomplete.",Does the review address Methodology?,TRUE,FALSE,The review critiques incomplete evaluation of efficiency.
I would encourage the authors to do this comparison to show how LTU could be a more generic model which can be super useful for users to interact with an audio language model through natural text.,Does the review address Significance?,TRUE,FALSE,The review suggests comparison to show model genericity.
"The only advantage of using two is an increase of model capacity, i.e. Furthermore, what are the hyper-parameters / size of the baseline neural networks?",Does the review address Methodology?,FALSE,TRUE,The review asks about model capacity and baseline parameters.
"Compared with commonsense and entity-relation knowledge, the fact units are more informative to each specific question.",Does the review address Comparison?,TRUE,FALSE,The review compares fact units to other knowledge types.
"-----Weaknesses----- I'm not very convinced by the empirical results, mostly due to the lack of details of the baselines.",Does the review address Result?,TRUE,FALSE,The review expresses lack of conviction in empirical results.
It paves the way for more widespread application of VIP in scenarios where interpretable-by-design approaches are critical.,Does the review address Significance?,TRUE,FALSE,The review discusses potential widespread application.
"Footnote 2 -- ""the tensor version"" - needs citation to explain what's being referred to.",Does the review address Related Work?,FALSE,TRUE,The review suggests a citation for a tensor version.
My main problem with this paper at the moment is that it could be much better written: The overall narrative of the paper is unpolished and it’s hard at first to understand the contributions of the paper.,Does the review address Contribution?,TRUE,FALSE,The review critiques the unpolished narrative of contributions.
"There is no comparison with other public masking methods in Table 2, such as whole-word-masking, span masking, etc.",Does the review address Methodology?,TRUE,FALSE,The review notes lack of comparison with other masking methods.
"It requires more analysis about experimental results, such as Figure 1 and tables in Section D.",Does the review address Presentation?,FALSE,TRUE,The review suggests more analysis of experimental results.
"I look forward to seeing the authors discuss a comprehensive comparison of DeFo's training time and other methods, such as CoOp and CLIP-adapter.",Does the review address Comparison?,TRUE,FALSE,The review suggests comprehensive comparison of training times.
"Second, the authors neither 1) evaluate their model on another dataset or 2) evaluate any previously published models on their dataset.",Does the review address Methodology?,TRUE,FALSE,The review critiques lack of model and dataset evaluation.
"Strengths: * Novel method of using emergent language for pre-training (as opposed to transferring an entire artificial agent) * Some good ablations to identify what contributes to successful transfer * A new evaluation metric (emergent --> NL translation performance) that best correlates with fine-tuning performance  Weaknesses: * Some parameter choices and the design of some ablations are not completely justified * Some additional related works could be included   # Minor comments / questions  * ""However, this metric is too rigid in its definition of compositionality, ignoring aspects like argument structure, context or morphology which play a key role in determining the combination of word semantics (Goldberg, 2015).""",Does the review address Evaluation?,TRUE,FALSE,The review discusses strengths and weaknesses of the method.
"The paper proposes a novel task, text-to-audio storytelling.",Does the review address Data/Task?,TRUE,FALSE,The review notes a novel text-to-audio storytelling task.
"Given a sentence $x$ to be translated, they first retrieve a $(tx, ty)$ sentence pair from the training set through ``SEGMENT-BASED TM RETRIEVAL’’ defined in Section 4.1, where $tx$ and $ty$ are from source and target languages respectively.",Does the review address Methodology?,TRUE,FALSE,The review describes sentence pair retrieval methodology.
"The authors provide OTTER using hard labels (InfoNCE) as a baseline, but ZSL methods are sensitive to hyper-parameters and training sets.",Does the review address Comparison?,TRUE,FALSE,The review discusses baseline method sensitivity.
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Data/Task?,TRUE,FALSE,The review discusses natural tasks for language models.
It is not clear how the proposed method considers the correlations among the retrieved data points.,Does the review address Methodology?,FALSE,TRUE,The review questions correlation consideration in retrieved data.
"Generally speaking, this paper puts forward a universal retrieval scheme, and achieves good results, the specific advantages are as follows:  (1) The sparse alignment of multi-vector retrieval is a good solution to solve the retrieval effect and efficiency.",Does the review address Presentation?,FALSE,TRUE,The review highlights retrieval scheme advantages.
* There are some points in the paper that could be made clearer.,Does the review address Presentation?,FALSE,TRUE,The review suggests points needing clarification.
"Regarding the proof, the notations in Section 3 are quite loose, especially for Section 3.1.",Does the review address Presentation?,FALSE,TRUE,The review critiques notation looseness in proof section.
"Unfortunately, as the paper overall does not seem to contain significant novelty, neither in methodology nor in results, I cannot recommend acceptance at this point.",Does the review address Result?,TRUE,FALSE,The review suggests lack of novelty in methodology and results.
"## Logical Flow of Main Results and Relation to Prior Work Should be Clarified  The paper defines T-LLMs as general learners if ""the expressive power of realistic T-LLM model class can cover universal circuits for all circuits of polynomial size"" and says that:  > It is unknown whether the realistic Transformers are expressive enough to be general learners   In fact, it seems that Theorem 3 essentially follows from the TC0 upper bound in previous work.",Does the review address Related Work?,TRUE,FALSE,The review discusses relationship to prior work and theorems.
"Given that there is a wealth of existing work that performs the same task and the lack of novelty of this work, the authors need to include experiments that demonstrate that their technique outperforms others on this task, or otherwise show that their dataset is superior to others (e.g. since it is much larger than previous, does it allow for better generalization?)",Does the review address Experiment?,TRUE,FALSE,The review suggests demonstrating technique's superiority.
Reducing it to 80% seems to be a sweet point with the best balance between performance and efficiency.,Does the review address Result?,FALSE,TRUE,"The review notes a ""sweet point"" for performance and efficiency."
"They show that, especially in small-data regimes, pre-training on an emergent language can yield significant performance boosts in both tasks.",Does the review address Methodology?,TRUE,FALSE,The review highlights performance in small-data regimes.
"- The authors have evaluated their models on multiple settings, proving that their models trained on Wikipedia can potentially generalize to multiple downstream tasks.",Does the review address Evaluation?,TRUE,FALSE,The review notes model evaluation across multiple settings.
"**Technical contribution** Codegen for program synthesis seems effective, especially when the user wants to generate pieces of code from input/output examples or natural language descriptions.",Does the review address Contribution?,TRUE,FALSE,The review highlights technical contribution of code generation.
The related work section does not connect this paper to specific prior work (only citing two survey papers).,Does the review address Related Work?,TRUE,FALSE,The review critiques limited connection to prior work.
One may also refer to https://opencompass.org.cn/leaderboard-llm for the performance of LLMs (I acknowledge that the performance of ChatGPT on GSM8K from that website is possibly still underestimated).,Does the review address Related Work?,FALSE,TRUE,The review suggests a performance leaderboard reference.
"With these two elements, the approach performs on par with recently proposed GECA (where the data is not augmented via a neural generator) on two datasets.",Does the review address Result?,TRUE,FALSE,The review notes performance comparable to recent approaches.
This paper focuses on improving the dialogue policy together with the responses by utilizing a pre-trained language model and offline RL.,Does the review address Result?,FALSE,TRUE,The review describes dialogue policy improvement approach.
See section-2.6 of this tutorial for more details about using neural models to rank: https://www.microsoft.com/en-us/research/uploads/prod/2017/06/INR-061-Mitra-neuralir-intro.pdf.,Does the review address Methodology?,FALSE,TRUE,The review suggests a tutorial reference for neural ranking.
The authors also seem to have carefully designed their experiments.,Does the review address Experiment?,FALSE,TRUE,The review notes careful experiment design.
Questions & Comments: • It is stated that the performance is sensitive to epsilon in AdamW.,Does the review address Result?,FALSE,TRUE,The review notes performance sensitivity to a parameter.
"Also, can you add a column where a dense linear model over p_f(s) is used?",Does the review address Methodology?,FALSE,TRUE,The review suggests adding a column for linear model.
"It considers the training direction to be ""first to perceive, and then comprehend the sound"" so that the training starts from using close-ended datasets to open-ended datasets.",Does the review address Data/Task?,TRUE,FALSE,The review describes training approach across datasets.
"Intuitively, this parameter arises from translating the ""natural"" task assumption, which only guarantees transfer on average to the downstream task.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses parameter motivation.
"-----Post-rebuttal----- The authors did not address my main concern, which is whether the baselines (e.g. TreeRNN) are used to compute substructure embeddings independent of the sentence embedding and the joint tagger.",Does the review address Methodology?,TRUE,FALSE,The review questions baseline methodology.
"As, deep recurrent neural networks are already used in keyphrase extraction (shows very good performance also), so, it will be interesting to have a proper motivation to justify the use of  RNN and Copy RNN over deep recurrent neural networks.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests justification for method selection.
"However, there is no discussion on the latency in the proposed method and experiments.",Does the review address Experiment?,FALSE,TRUE,The review notes lack of latency discussion.
(Current experiments only include the results of models that are free from this issue.),Does the review address Methodology?,FALSE,TRUE,The review comments on experiment model selection.
An additional experimental results with multi-task finetuning should also be added.,Does the review address Experiment?,TRUE,FALSE,The review suggests additional multi-task fine-tuning experiments.
"Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",Does the review address Result?,TRUE,FALSE,The review describes extensive testing and robustness checks.
The second major concern I have with this paper is the small dataset they are using.,Does the review address Data/Task?,FALSE,TRUE,The review critiques the small dataset.
- Extensive results show improvements over a base model and a larger model across a range of tasks.,Does the review address Data/Task?,TRUE,FALSE,The review notes improvements across tasks.
Perhaps the biggest reason is I can’t seem to understand what is novel about the system.,Does the review address Novelty?,TRUE,FALSE,The review questions the system's novelty.
"I thought that this paper was very thought-provoking, and I appreciated the attempts to better understand what is going on with pre-trained language models, why they work well, and what might we be able to improve from theses insights.",Does the review address Result?,FALSE,TRUE,The review appreciates insights into pre-trained models.
The paper then does a good job of showing how using one-hot encodings compared to SCS change the problem definition leading to a difference in performance on the same task.,Does the review address Result?,TRUE,FALSE,The review discusses performance differences.
The idea of analyzing the gap to variational posterior lower bound for different dropout inference model is interesting.,Does the review address Methodology?,TRUE,FALSE,The review finds the analysis of variational posterior interesting.
"We observe empirically that if pruned globally, the attention heads in some layers may be completely removed, making the network un-trainable.",Does the review address Presentation?,FALSE,TRUE,The review notes observation about attention head pruning.
It is therefore not surprising that multi-task learning should help these tasks.,Does the review address Result?,FALSE,TRUE,The review comments on multi-task learning.
"Specifically, is there any feed-forward computation involved and how many layers of the models used in comparison.",Does the review address Methodology?,FALSE,TRUE,The review asks about model computation details.
"From what I can tell, Appendix C on prompt tuning (which is very interesting) is maybe the primary evidence the instructions are important.",Does the review address Methodology?,FALSE,TRUE,The review comments on prompt tuning evidence.
"While it is also true that corpus transfer _enables_ this divergence in model types, to really test whether transferring the whole model versus using the corpus works or not, I would think you would want to compare fine-tuning the sender GRU on the LM data vs. starting from scratch _with a GRU of the same type_ and pre-training on the EC corpus before fine-tuning.",Does the review address Methodology?,TRUE,FALSE,The review suggests alternative comparison methodology.
"They train low resource NMTs using 4 different tokenization strategies, to show that their proposed tokenization method leads to the best NMT results by several metrics.",Does the review address Result?,TRUE,FALSE,The review describes NMT results across tokenization strategies.
- Many interesting robustness capabilities of VL models only emerge when trained with hundreds of millions of samples.,Does the review address Result?,FALSE,TRUE,The review notes robustness capabilities of models.
An ablation analysis would be most appropriate for quantifying this.,Does the review address Comparison?,FALSE,TRUE,The review suggests ablation analysis.
"I.e., Figure 1 should be your results table, and figure 2 should be the examples for us to see.",Does the review address Result?,FALSE,TRUE,The review suggests figure presentation changes.
The show improved performance in MultiWoz dataset.,Does the review address Data/Task?,TRUE,FALSE,The review notes performance improvement on MultiWoz dataset.
"As shown in Figure 6, when more than 12 facts are constructed, the performance becomes worse.",Does the review address Result?,TRUE,FALSE,The review discusses performance change with fact construction.
"For example, you explained why ADJ is not used in your mapping, but ADJ does appear in this UD treebank.",Does the review address Comparison?,TRUE,FALSE,The review points out a specific mapping discrepancy.
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Significance?,TRUE,FALSE,The review suggests insufficient experiments and novelty.
This paper is an interesting application of a data augmentation or self-supervised learning type of approach for tactic based theorem proving.,Does the review address Methodology?,TRUE,FALSE,The review describes the approach as data augmentation for theorem proving.
The method can select appropriate batch sizes by assessing the working memory requirements per token during benchmarking.,Does the review address Data/Task?,TRUE,FALSE,The review describes method for batch size selection.
The question about whether realistic transformers can represent any polynomial-time-computable function is interesting.,Does the review address Methodology?,TRUE,FALSE,The review finds the question about transformer representation interesting.
"For fine-tuning, the authors run their model for 2.2 epochs, while their baseline model runs for 3 epochs, roughly 30% more which accounts for much of the reduction observed in Table 2.",Does the review address Comparison?,TRUE,FALSE,The review discusses differences in model training epochs.
"The authors start with some good motivation for building more intimate interaction between vision and language, but it finally becomes the emphasis of the benefit of scaling up.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review discusses motivation for vision-language interaction.
"* page 3: s/""It has also been previous observed""/""It has also been previously observed""",Does the review address Presentation?,FALSE,TRUE,The review suggests a minor grammatical correction.
Another major concern is the use of two separate RNNs which gives the proposed model more parameters than the baselines.,Does the review address Methodology?,TRUE,FALSE,The review critiques the use of multiple RNNs.
Detailed comments: - There already is a small UD treebank for Thai: <https://github.com/UniversalDependencies/UD_Thai-PUD/>   How does your mapped tagset compare to the annotation scheme chosen there?,Does the review address Comparison?,TRUE,FALSE,The review suggests comparing to existing treebank.
"There is a lack of experimental analysis supporting the source of the observed improvements, which is crucial for substantiating the paper's main claims.",Does the review address Experiment?,TRUE,FALSE,The review suggests lack of experimental analysis.
"The paper only performs some finetuning on GLUE tasks, which is significantly less interesting given that it is comparatively cheap and FP8 speedups thus not so crucial while, in many cases, even more affordable finetuning techniques like QLoRA also work well.",Does the review address Methodology?,TRUE,FALSE,The review critiques limited fine-tuning approach.
"The closest baseline is simply a comparison against a CLIP(image, concept) similarity score.",Does the review address Comparison?,TRUE,FALSE,The review notes the baseline comparison method.
"Where the paper does get technical is in a discussion of the differing difficulties of speech recognition for different languages, providing a useful case study to demonstrate that one-size technology approaches are not necessarily universal stand-alone solutions.",Does the review address Presentation?,TRUE,FALSE,The review discusses technical discussion of language differences.
"The experments are fairly convincing, although it is not entirely surprising that this approach works, and to repeat, the basic idea of extracting additional training data in this way is not entirely new.",Does the review address Novelty?,TRUE,FALSE,The review finds the experiments convincing but not entirely novel.
"It would be useful if following the suggestions of [2,3] the authors could present results in settings with low data regimes and with significant distribution shift with respect to the pre-training set, which represents a more realistic application setting.",Does the review address Result?,FALSE,TRUE,The review suggests exploring results in low-data regimes.
The results demonstrated in the experiments show an improvement over previous models.,Does the review address Result?,TRUE,FALSE,The review notes improvement over previous models.
"See Rives et al, 2020, ‘Biological structures and functions emerge…’, section 5.2, and Vig et al, 2020, ‘Bertology’ section 4.2.",Does the review address Related Work?,FALSE,TRUE,The review suggests references to related work.
"Thus, the experiment could answer questions such as:     - Does compositionality emerge at the same rate in continuous- and discrete-channel games?",Does the review address Experiment?,FALSE,TRUE,The review suggests potential experimental questions.
Is it possible to import a public SOTA implementation and conduct comparisons based on that?,Does the review address Methodology?,FALSE,TRUE,The review asks about importing SOTA implementation.
The proposed method also extends this to multilingual evaluations.,Does the review address Evaluation?,TRUE,FALSE,The review notes extension to multilingual evaluations.
Ablation studies show that the model achieves good performance on more complex questions.,Does the review address Ablation?,TRUE,FALSE,The review highlights ablation studies' performance findings.
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Result?,TRUE,FALSE,The review discusses theoretical performance guarantee.
"In general, the paper is well written and describes the work clearly.",Does the review address Presentation?,FALSE,TRUE,The review praises the paper's clear writing.
L680-683: This needs more examples or explanation of what it means to judge the polarity of a peak.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests more explanation of a specific concept.
"So, In this case, it will be interesting to see the results (or will be helpful in evaluating ""absent type"" keyphrases): if we identify all the topical phrases of the entire corpus by using tf-idf and relate the document to the high-ranked extracted topical phrases (by using Normalized Google Distance, PMI, etc.).",Does the review address Evaluation?,TRUE,FALSE,The review suggests an alternative evaluation approach.
"For example, Figure 4 validates Assumption 4.1 (log-partition function is roughly quadratic in theta), and Table 1 shows many real tasks are approximately “natural”.",Does the review address Methodology?,TRUE,FALSE,The review discusses validation of assumptions and tasks.
"I would like to have seen qualitative examples of model predictions, and more examples from the dataset.",Does the review address Data/Task?,FALSE,TRUE,The review requests more qualitative examples.
"For example, if for the baseline model, we also only use one data sample and apply different masks, will there be improvement?",Does the review address Methodology?,FALSE,TRUE,The review suggests alternative masking approach.
- Performance with relatively little finetuning data are encouraging.,Does the review address Result?,FALSE,TRUE,The review notes encouraging performance with little fine-tuning.
"It's important to discuss why these improvements are non-trivial and how they advance the field, considering the rapidly evolving landscape of both quantum computing and graph analysis.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review suggests discussing improvement significance.
It seems completely unnecessary to me to have separate weights for the two RNNs.,Does the review address Methodology?,TRUE,FALSE,The review questions the necessity of separate RNN weights.
The authors should conduct experiments beyond English-to-French.,Does the review address Experiment?,FALSE,TRUE,The review suggests expanding language experiments.
Is Theorem 2 a stronger version in some sense because it applies for polylog input size?,Does the review address Theory?,FALSE,TRUE,The review asks about a theorem's strength.
Theorem 2 is presented with no intuition and the proof in the appendix is only for a special case.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review critiques lack of theorem intuition.
- The ablation study would be better if specific numbers were provided.,Does the review address Ablation?,TRUE,FALSE,The review suggests providing specific numbers in ablation study.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Analysis?,TRUE,FALSE,The review discusses empirical results' realism.
"By converting the logic forms to natural languages, the authors can leverage paraphrase datasets and pre-train the critic as a paraphrase model.",Does the review address Data/Task?,TRUE,FALSE,The review describes approach to leveraging paraphrase datasets.
"Nonetheless, the current paper leaves too many open questions regarding the validity of the experiments.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review questions experiment validity.
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Data/Task?,TRUE,FALSE,The review suggests discussing data weaknesses.
"While it is also true that corpus transfer _enables_ this divergence in model types, to really test whether transferring the whole model versus using the corpus works or not, I would think you would want to compare fine-tuning the sender GRU on the LM data vs. starting from scratch _with a GRU of the same type_ and pre-training on the EC corpus before fine-tuning.",Does the review address Comparison?,TRUE,FALSE,The review suggests alternative model comparison approach.
"This is not new (see Rives 2020 and Vig 2020) and does not fit well to the rest of the paper, which is about contact prediction.",Does the review address Novelty?,TRUE,FALSE,The review suggests lack of novelty in some aspects.
I find the analysis presented in the paper very interesting and insightful - and distinguishes it from previous work in this area.,Does the review address Analysis?,TRUE,FALSE,The review finds the analysis interesting and insightful.
"It is reported that current system uses 527,830 documents for training, while 40,000 publications are held out for training baselines.",Does the review address Data/Task?,TRUE,FALSE,The review notes details about training documents.
Audio Instruction Generation (AIG) is also quite nice and interesting.,Does the review address Novelty?,FALSE,TRUE,The review finds Audio Instruction Generation interesting.
There are several such insights in the experiments section that will be helpful to the community.,Does the review address Experiment?,FALSE,TRUE,The review notes helpful insights in experiments.
"Questions:   - Previous work has tried to combine both language-specific and shared parameters (Wang et al 2018), rather than making a binary choice between these.",Does the review address Methodology?,TRUE,FALSE,The review discusses parameter sharing approaches.
"- Table 5 the VAE(32) method performs the best overall in ""Wiki section"" although the TC (16) method has been highlighted as the best.",Does the review address Presentation?,FALSE,TRUE,The review points out a discrepancy in table highlighting.
