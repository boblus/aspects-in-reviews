review,question,yes,no,explanation
* The authors have included ablation tests to demonstrate the robustness of their approach.,Does the review address Result?,FALSE,TRUE,"It discusses ablation tests, not findings or improvements related to Result."
3) The authors compared the robustness of the NVIB-regularized model with that of a regular transformer and found the former more robust to noisy input.,Does the review address Comparison?,TRUE,FALSE,It mentions comparing the NVIB-regularized model with a regular transformer.
Proposes a novel approach by combining ideas from active learning and human-AI collaboration.,Does the review address Methodology?,TRUE,FALSE,It describes the approach and techniques used in the study.
"Buf if that's the case, then there's a controllable parameter that implicitly controls an entropy constraint and it's no longer clear to me that low-entropy is emerging.",Does the review address Methodology?,TRUE,FALSE,"discusses a controllable parameter and its effect, which relates to the study's approach."
Provide additional feedback with the aim to improve the paper.,Does the review address Result?,FALSE,TRUE,requests additional feedback but does not mention findings or improvements
3) The authors compared the robustness of the NVIB-regularized model with that of a regular transformer and found the former more robust to noisy input.,Does the review address Result?,TRUE,FALSE,It mentions findings about robustness to noisy input.
"To pick just one recent example [1], the results reported (such as F1) appear to be way higher than anything in Table 2 (and that is also true for the baselines reported in [1]).",Does the review address Result?,TRUE,FALSE,mentions results and metrics like F1 scores.
This combined with the baseline I proposed above could lead to a general-purpose pattern-based classifier.,Does the review address Comparison?,TRUE,FALSE,refers to a comparison with a proposed baseline.
I am also somewhat confused by the second set of experiments.,Does the review address Experiment?,TRUE,FALSE,mentions experiments.
Comprehensive empirical analysis on multiple datasets and CIR tasks demonstrates the effectiveness over baselines.,Does the review address Analysis?,TRUE,FALSE,mentions empirical analysis across datasets and tasks.
* The approach is straightforward and seems to improve over the pattern-verbalizer approach.,Does the review address Result?,TRUE,FALSE,"mentions improvement, which relates to Result"
1) The specific design choices made in adapting the original NVIB to self-attention could benefit from more justification and discussion.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"calls for more justification and discussion, which relates to explanation."
Among the biggest issues I consider the following:   * Weak baselines: Given the chosen dataset contains much more information than the textual content I would want to see the results of this work compared to the state of the art reported in the literature that looks at the same dataset.,Does the review address Data/Task?,TRUE,FALSE,mentions the chosen dataset and its use.
"In addition, the proposed approach could include more labels, e.g., from Wikipedia, which may or may not contain the labels of the downstream tasks, and create a larger dataset.",Does the review address Data/Task?,TRUE,FALSE,"discusses labels and creating a larger dataset, which relates to Data/Task."
* The randomized and mismatched ablations are not very well designed.,Does the review address Ablation?,TRUE,FALSE,critiques the design of ablations.
3) The ablation study in table 5 seemed more like good baselines which is good to have as it shows GBT is more effective when applied to only hard examples.,Does the review address Ablation?,TRUE,FALSE,mentions and evaluates the ablation study.
Thus the model may require more steps to adapt.,Does the review address Methodology?,TRUE,FALSE,"refers to the model's adaptation process, which relates to methodology."
I would expect however to compare these results with the other methods on the same set of samples.,Does the review address Result?,FALSE,TRUE,"discusses a comparison request, not findings or outcomes."
"Given the closeness with this proposed work of using paraphrases (both negative and positive), some of baselines are necessary for comparison with GBT, especially counterfactual data-augmentation techniques as GBT uses (negative paraphrases in DA i.e., IBH0) Feng et.al., A Survey of Data Augmentation Approaches for NLP  Li  et.al., Data Augmentation Approaches in Natural Language Processing: A Survey 2) Some other, even more simpler baselines could be lower learning rate and training for more number of epochs.",Does the review address Comparison?,TRUE,FALSE,discusses baselines necessary for comparison.
The proposed method shows consistent performance improvement on the three benchmark datasets for referring expression comprehension.,Does the review address Presentation?,FALSE,TRUE,"discusses performance improvement, not clarity or structure."
Claim verification is an important topic with practical significance.,Does the review address Significance?,TRUE,FALSE,highlights the practical significance of the topic.
The approach could inspire more work on human-machine collaboration for efficient system evaluation.,Does the review address Evaluation?,TRUE,FALSE,It mentions system evaluation.
A human study on how well the verification process leveraging only the top-1 search result is required.,Does the review address Result?,FALSE,TRUE,"It requests a study, not findings or outcomes."
After reading the paper a few times I am a bit confused about how the experimental setup supports the claims & conclusions.,Does the review address Experiment?,TRUE,FALSE,mentions the experimental setup
2) The authors presented interesting results from intrinsic evaluation of the attention distributions of such a model pretrained on Wikitext-2 and from evaluating the quality of the representation in linguistic probing and text classification.,Does the review address Evaluation?,TRUE,FALSE,discusses intrinsic and quality evaluations.
Comprehensive empirical analysis on multiple datasets and CIR tasks demonstrates the effectiveness over baselines.,Does the review address Data/Task?,TRUE,FALSE,mentions multiple datasets and CIR tasks
Please provide a justification for this.,Does the review address Result?,FALSE,TRUE,It requests justification but does not mention findings or outcomes.
"A lot of emphasis in the paper has been on generating explanations; however, only 30 examples have been evaluated which may not provide enough evidence to support the claims of the paper.",Does the review address Evaluation?,TRUE,FALSE,critiques the evaluation of explanations
1) There are potentially numerous baselines as data augmentation for hard examples has several work.,Does the review address Comparison?,TRUE,FALSE,"mentions baselines, which implies comparison."
"It is understandable that the authors were able to only evaluate 1,000 samples to reduce the cost.",Does the review address Evaluation?,TRUE,FALSE,"discusses the evaluation of 1,000 samples"
1) The specific design choices made in adapting the original NVIB to self-attention could benefit from more justification and discussion.,Does the review address Methodology?,TRUE,FALSE,"refers to design choices and adaptations, which relate to methodology."
"As reported in the ProgramFC paper, it achieves 60.63 on HoVER 3-hop (as compared to 54.80 of FOLK) and similarly for the FEVEROUS dataset.",Does the review address Result?,TRUE,FALSE,mentions specific performance metrics and outcomes.
I would expect however to compare these results with the other methods on the same set of samples.,Does the review address Methodology?,FALSE,TRUE,"discusses comparison, not the approach or techniques used."
5) The text in line 293-295 makes the above point a little bit more unclear.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"critiques clarity, which relates to explanation."
* The results are neither surprising nor exciting.,Does the review address Result?,TRUE,FALSE,comments on the results' impact.
"To pick just one recent example [1], the results reported (such as F1) appear to be way higher than anything in Table 2 (and that is also true for the baselines reported in [1]).",Does the review address Comparison?,TRUE,FALSE,compares reported results with baselines.
The authors use the same setting found during hyper-parameter tuning.,Does the review address Methodology?,TRUE,FALSE,"mentions the setting used, which relates to methodology."
"For Chain-of-Thought and Self-Ask baselines, do you provide the retrieved knowledge to verify the sub-claims as done with FOLK?",Does the review address Comparison?,TRUE,FALSE,compares baselines with FOLK
Discrepancies in the presented results of ProgramFC approach.,Does the review address Methodology?,FALSE,TRUE,"mentions discrepancies in results, not the approach or techniques used."
I don’t see a justification for doing this.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,explicitly asks for justification
I think the paper does an interesting analysis and makes an interesting point about the problem being studied.,Does the review address Analysis?,TRUE,FALSE,mentions the analysis conducted in the paper
The experiments show that it leads to some performance improvements.,Does the review address Experiment?,TRUE,FALSE,mentions experiments leading to improvements.
A better ablation study could be giving just positive paraphrases (IBH1) and just negative paraphrases (IBH0) 4) Some of the important technical details are unclear.,Does the review address Ablation?,TRUE,FALSE,suggests improvements to the ablation study.
The proposed method shows consistent performance improvement on the three benchmark datasets for referring expression comprehension.,Does the review address Data/Task?,TRUE,FALSE,"mentions benchmark datasets, which relate to the task."
Proposes a novel approach by combining ideas from active learning and human-AI collaboration.,Does the review address Novelty?,TRUE,FALSE,highlights the originality of the proposed approach
Comprehensive empirical analysis on multiple datasets and CIR tasks demonstrates the effectiveness over baselines.,Does the review address Comparison?,TRUE,FALSE,mentions effectiveness compared to baselines.
"Is the approach well motivated, including being well-placed in the literature?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,explicitly asks about motivation and placement in literature
Please provide a justification for this.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"requests justification, which relates to intuition or validation"
* Conducting an ablation study is a strong aspect of the experimental work as it offers more nuanced insights into what components of the architecture contribute how much  to the overall performance.,Does the review address Presentation?,FALSE,TRUE,"discusses the value of an ablation study, not the clarity or structure of the paper."
"* I believe the authors should have included one more baseline, i.e., the model trained on the 20NG dataset.",Does the review address Comparison?,TRUE,FALSE,suggests adding a baseline for comparison
The weaknesses are minor compared to the contributions.,Does the review address Contribution?,TRUE,FALSE,"compares weaknesses to contributions, indicating a focus on contributions."
* The approach is straightforward and seems to improve over the pattern-verbalizer approach.,Does the review address Methodology?,TRUE,FALSE,"discusses the approach used, which relates to methodology"
2) The authors presented interesting results from intrinsic evaluation of the attention distributions of such a model pretrained on Wikitext-2 and from evaluating the quality of the representation in linguistic probing and text classification.,Does the review address Result?,TRUE,FALSE,mentions results from intrinsic evaluation and quality of representation
Analyzing the relation between correct claim verification decision and the correct generated explanation can be added in the analysis section.,Does the review address Analysis?,TRUE,FALSE,"suggests adding an analysis, which relates to the analysis section."
Addresses the important challenge of designing labor-efficient evaluation methods for conversational systems.,Does the review address Evaluation?,TRUE,FALSE,discusses the challenge of designing evaluation methods.
I am a bit confused by how the experimental setup supports the claims and their consequences.,Does the review address Experiment?,TRUE,FALSE,"questions the experimental setup, which relates to the experiment."
"* There are no statistical significance tests (and terms such as ""outperform"" should therefore not be used)      [1] Donabauer ""Exploring Fake News Detection with Heterogeneous Social Media Context Graphs"".",Does the review address Presentation?,TRUE,FALSE,"critiques the use of terms like ""outperform"" and mentions statistical significance, which relate to the clarity and accuracy of the paper's presentation."
Analyzing the relation between correct claim verification decision and the correct generated explanation can be added in the analysis section.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"suggests adding analysis, which involves discussion and interpretation."
* Conducting an ablation study is a strong aspect of the experimental work as it offers more nuanced insights into what components of the architecture contribute how much  to the overall performance.,Does the review address Methodology?,TRUE,FALSE,"discusses an ablation study, which relates to the methodology of the study"
"However, the ablated versions have a more difficult task to solve.",Does the review address Data/Task?,TRUE,FALSE,"implies that the ablated versions face a more difficult task, which relates to the task being studied"
"Given the closeness with this proposed work of using paraphrases (both negative and positive), some of baselines are necessary for comparison with GBT, especially counterfactual data-augmentation techniques as GBT uses (negative paraphrases in DA i.e., IBH0) Feng et.al., A Survey of Data Augmentation Approaches for NLP  Li  et.al., Data Augmentation Approaches in Natural Language Processing: A Survey 2) Some other, even more simpler baselines could be lower learning rate and training for more number of epochs.",Does the review address Data/Task?,FALSE,TRUE,"focuses on baselines and comparison, not on the dataset or task itself."
"In no, then verifying each sub-claim (decomposed by existing methods) leveraging the retrieved knowledge should be a fair baseline in comparison to the proposed approach that uses the retrieved knowledge.",Does the review address Comparison?,TRUE,FALSE,suggests a baseline for comparison with the proposed approach.
* The results with InstructGPT (text-davinci-003) cannot be compared with the other results.,Does the review address Comparison?,TRUE,FALSE,Mentions a comparison.
What is needed is a comparison against what the current state of the art is as reported in the literature (ideally reproduced to conduct significance tests where appropriate).,Does the review address Result?,FALSE,TRUE,Does not mention findings or performance.
"A lot of emphasis in the paper has been on generating explanations; however, only 30 examples have been evaluated which may not provide enough evidence to support the claims of the paper.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"discusses the evaluation of explanations, which relates to the explanation and interpretation of the claims."
* The work is conducted on a well-known benchmark dataset and is therefore easily contextualisable with other work in the field.,Does the review address Data/Task?,TRUE,FALSE,"mentions the use of a well-known benchmark dataset, which relates to Data/Task"
"As reported in the ProgramFC paper, it achieves 60.63 on HoVER 3-hop (as compared to 54.80 of FOLK) and similarly for the FEVEROUS dataset.",Does the review address Data/Task?,TRUE,FALSE,"mentions specific datasets (HoVER 3-hop and FEVEROUS), which relate to Data/Task."
Addresses the important challenge of designing labor-efficient evaluation methods for conversational systems.,Does the review address Methodology?,FALSE,TRUE,"discusses the challenge of designing evaluation methods, not the approach or techniques used."
* There are many missing details (and no supplementary material such as code) making it impossible to replicate the work.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,It points out missing details.
"- Although SGEPG is model-agnostic, this paper conduct experiments using a specific model, VLTVG, to validate the proposed method.",Does the review address Methodology?,TRUE,FALSE,discusses the experimental approach and model used
3 make it unclear whether the temperature parameter is implicitly controlling entropy.,Does the review address Result?,FALSE,TRUE,"discusses clarity around a parameter, not the results."
Reducing human annotation effort would have significant practical impact.,Does the review address Significance?,TRUE,FALSE,"highlights the practical impact, relating to significance."
"Instead, directly instructing the LLMs with a prompt as simple as “Generate questions verifying the sub-claims of the above claim” does very well in directly generating sub-questions that can be used for verifying the claims.",Does the review address Methodology?,TRUE,FALSE,"discusses the approach used, which relates to methodology."
"For example, which datasets and how was the paraphraser trained to generate candidate sentences for selecting IBH0 and IBH1.",Does the review address Data/Task?,TRUE,FALSE,"asks about datasets and training, which relate to Data/Task"
The additional experiments using the other VLM would be helpful to emphasize the effectiveness of the scene graph-enhanced pseudo-labeling approach.,Does the review address Experiment?,TRUE,FALSE,"discusses additional experiments, which relate to Experiment"
* Conducting an ablation study is a strong aspect of the experimental work as it offers more nuanced insights into what components of the architecture contribute how much  to the overall performance.,Does the review address Result?,FALSE,TRUE,"discusses the value of an ablation study, not the results themselves."
"The claim is that agents that try to solve a prediction task subject to a communication bottleneck will exchange low entropy messages, even if these messages are not explicitly encouraged to have low entropy.",Does the review address Data/Task?,FALSE,TRUE,"discusses the claim regarding prediction tasks, not the dataset or task itself"
I would be interested to see how the ablated versions would perform if the authors tuned the hyper-parameters on 20NG for each of these settings.,Does the review address Result?,FALSE,TRUE,"discusses a request for additional experiments, not the actual results."
The problem is timely and the solution is novel.,Does the review address Novelty?,TRUE,FALSE,mentions the novelty of the solution.
I would be interested to see how the ablated versions would perform if the authors tuned the hyper-parameters on 20NG for each of these settings.,Does the review address Methodology?,TRUE,FALSE,"suggests tuning hyper-parameters, which relates to the methodology"
"The authors fine-tune an MLM using patterns, which can be seen as instructions, and synthetic data.",Does the review address Data/Task?,TRUE,FALSE,"mentions fine-tuning using synthetic data, which relates to Data/Task"
I would expect however to compare these results with the other methods on the same set of samples.,Does the review address Comparison?,TRUE,FALSE,comparing the results with other methods on the same samples.
"In effect, the model has learned to use these patterns and is therefore able to use this knowledge for classification.",Does the review address Methodology?,TRUE,FALSE,"how the model uses patterns for classification, which relates to methodology."
"On the other hand, InstructGPT [1] was much better than GPT-3 and the main reason was that it was trained to follow instructions (prompts).",Does the review address Methodology?,TRUE,FALSE,"compares the training approaches, which relates to methodology."
"This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.",Does the review address Result?,TRUE,FALSE,discusses the correctness and rigor of results.
"In line 268-277, more details would be needed as to how and where the 50K examples were selected from.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"requests more details, which relates to description and explanation."
The negative and positive paraphrase augmentation seems like a good mix of balanced data augmentation (though we don’t know how much just adding IBH1 and just adding IBH0 independently contribute to improvement).,Does the review address Data/Task?,TRUE,FALSE,"discusses the use of data augmentation, which relates to the task."
"If yes, then how would you justify the better performance of your approach since both these approaches also result in accurate questions for verifying the subclaims.",Does the review address Comparison?,TRUE,FALSE,compares the proposed approach with others regarding performance.
The experiments show that it leads to some performance improvements.,Does the review address Result?,TRUE,FALSE,"mentions performance improvements, which relates to results."
"2) The propose technique seems like a good choice for the PI task and some of the analyses (Figure 2 for boosting interval and ratio, table 5 for why to use GBT for hard examples) highlight interesting takeaways about GBT.",Does the review address Data/Task?,TRUE,FALSE,"mentions the PI task, which relates to Data/Task"
The discussion seems to suggest that setting higher temperature in GS creates pressure for lower-entropy messages.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"discusses the effect of setting higher temperature, which relates to explanation and interpretation."
* The authors have included ablation tests to demonstrate the robustness of their approach.,Does the review address Ablation?,TRUE,FALSE,"ablation tests, which relate to Ablation"
2) The authors presented interesting results from intrinsic evaluation of the attention distributions of such a model pretrained on Wikitext-2 and from evaluating the quality of the representation in linguistic probing and text classification.,Does the review address Methodology?,TRUE,FALSE,"discusses the methods used for intrinsic evaluation and quality assessment, which relates to methodology."
Zero-shot and few-shot learning with GPT-3 using prompting had still a large gap with supervised SotA models.,Does the review address Methodology?,TRUE,FALSE,"compares the approach of zero-shot and few-shot learning with supervised models, relating to methodology."
What is needed is a comparison against what the current state of the art is as reported in the literature (ideally reproduced to conduct significance tests where appropriate).,Does the review address Comparison?,TRUE,FALSE,"requests a comparison with the current state of the art, which relates to comparison."
The negative and positive paraphrase augmentation seems like a good mix of balanced data augmentation (though we don’t know how much just adding IBH1 and just adding IBH0 independently contribute to improvement).,Does the review address Result?,FALSE,TRUE,discusses data augmentation but does not focus on specific results or improvements.
The motivation and design choice of the proposed method is simple and intuitive.,Does the review address Presentation?,TRUE,FALSE,"discusses the clarity and simplicity of the design choice, which relates to presentation."
"In addition, the proposed approach could include more labels, e.g., from Wikipedia, which may or may not contain the labels of the downstream tasks, and create a larger dataset.",Does the review address Methodology?,TRUE,FALSE,"suggests expanding the dataset and methodology by adding more labels, which relates to methodology."
The proposed approach is very similar to the basic idea of InstructGPT.,Does the review address Methodology?,TRUE,FALSE,"draws a parallel between the proposed approach and InstructGPT, which pertains to methodology."
Reducing human annotation effort would have significant practical impact.,Does the review address Data/Task?,FALSE,TRUE,"highlights the practical impact, but does not focus on the dataset or task itself"
Among the biggest issues I consider the following:   * Weak baselines: Given the chosen dataset contains much more information than the textual content I would want to see the results of this work compared to the state of the art reported in the literature that looks at the same dataset.,Does the review address Comparison?,TRUE,FALSE,"suggests comparing the results to the state of the art, which relates to comparison."
"On the other hand, directly generating the decomposed sub-claims has been shown to work really well in prior works.",Does the review address Methodology?,TRUE,FALSE,"refers to the method of directly generating decomposed sub-claims, which relates to methodology."
1) The GBT technique shows improvement (as per the result tables 3 and 4) and could be applied generally to other tasks as well.,Does the review address Result?,TRUE,FALSE,"refers to the improvements shown in result tables, which relate to results"
"2) The propose technique seems like a good choice for the PI task and some of the analyses (Figure 2 for boosting interval and ratio, table 5 for why to use GBT for hard examples) highlight interesting takeaways about GBT.",Does the review address Methodology?,TRUE,FALSE,discusses the proposed technique and analyses
Comprehensive empirical analysis on multiple datasets and CIR tasks demonstrates the effectiveness over baselines.,Does the review address Methodology?,FALSE,TRUE,"focuses on the effectiveness of the method, not the methodology itself"
* I am not entirely convinced by the choice of the authors to use only 4 labels from the 20NG dataset.,Does the review address Data/Task?,TRUE,FALSE,"critiques the choice of labels from the dataset, which relates to Data/Task"
A better ablation study could be giving just positive paraphrases (IBH1) and just negative paraphrases (IBH0) 4) Some of the important technical details are unclear.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"suggests improvements to the ablation study and points out unclear technical details, which relate to explanation and description."
* The paper is well-written and easy to understand.,Does the review address Presentation?,TRUE,FALSE,"comments on the clarity and readability of the paper, which relates to presentation"
"Is the approach well motivated, including being well-placed in the literature?",Does the review address Related Work?,TRUE,FALSE,"asks if the approach is well-placed in the literature, which relates to related work."
"2) The propose technique seems like a good choice for the PI task and some of the analyses (Figure 2 for boosting interval and ratio, table 5 for why to use GBT for hard examples) highlight interesting takeaways about GBT.",Does the review address Analysis?,TRUE,FALSE,mentions analyses and takeaways
"* I believe the authors should have included one more baseline, i.e., the model trained on the 20NG dataset.",Does the review address Data/Task?,TRUE,FALSE,suggests using the 20NG dataset
"Furthermore, the paper is well written and provides a good background for the problem statement.",Does the review address Presentation?,TRUE,FALSE,comments on the clarity and background
The method consistently approximates full human evaluation with minimal labor.,Does the review address Methodology?,TRUE,FALSE,method and its effectiveness
The entropy of the messages was only analyzed for the runs where agents have successfully learned to communicate in order to solve the task.,Does the review address Analysis?,TRUE,FALSE,mentions analyzing entropy
The method consistently approximates full human evaluation with minimal labor.,Does the review address Evaluation?,TRUE,FALSE,method's ability to approximate human evaluation
The entropy of the messages was only analyzed for the runs where agents have successfully learned to communicate in order to solve the task.,Does the review address Data/Task?,FALSE,TRUE,focuses on entropy analysis
* The results with InstructGPT (text-davinci-003) cannot be compared with the other results.,Does the review address Result?,TRUE,FALSE,discusses the results and their comparability
"The paper is well motivated, though I am not an expert in the area.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,talks about the motivation behind the paper
"The authors fine-tune an MLM using patterns, which can be seen as instructions, and synthetic data.",Does the review address Methodology?,TRUE,FALSE,describes the approach used
After reading the paper a few times I am a bit confused about how the experimental setup supports the claims & conclusions.,Does the review address Presentation?,TRUE,FALSE,questions the clarity of the experimental setup
I think the paper does an interesting analysis and makes an interesting point about the problem being studied.,Does the review address Contribution?,TRUE,FALSE,highlights the interesting analysis and points made
The approach could inspire more work on human-machine collaboration for efficient system evaluation.,Does the review address Methodology?,FALSE,TRUE,discusses the potential for future work only
1) The GBT technique shows improvement (as per the result tables 3 and 4) and could be applied generally to other tasks as well.,Does the review address Methodology?,FALSE,TRUE,the improvement and application of the technique
It would be difficult for readers to understand and evaluate – “we manually observed the generated examples and find the results acceptable.”  6) A very minute point – it may be interesting to compare with openLLM methods like LLaMa (after some instruction tuning for PI  task).,Does the review address Comparison?,TRUE,FALSE,suggests a comparison with openLLM methods
"If yes, then how would you justify the better performance of your approach since both these approaches also result in accurate questions for verifying the subclaims.",Does the review address Result?,TRUE,FALSE,questions the justification for better performance
"- Although SGEPG is model-agnostic, this paper conduct experiments using a specific model, VLTVG, to validate the proposed method.",Does the review address Experiment?,TRUE,FALSE,experiments using a specific model to validate the method
"Make it clear that these points are here to help, and not necessarily part of your decision assessment.",Does the review address Presentation?,TRUE,FALSE,clarifying the intention behind the points
The additional experiments using the other VLM would be helpful to emphasize the effectiveness of the scene graph-enhanced pseudo-labeling approach.,Does the review address Presentation?,FALSE,TRUE,additional experiments but does not address the clarity or structure of the paper
One limitation is the need for a differentiable evaluation metric to estimate sample hardness (relevance scores addressed via ChatGPT).,Does the review address Evaluation?,TRUE,FALSE,need for a differentiable evaluation metric
There are many more benchmark datasets for text classification (including fake news detection) that could be included to provide more confidence in the findings.,Does the review address Result?,FALSE,TRUE,additional datasets for further validation
3) The authors compared the robustness of the NVIB-regularized model with that of a regular transformer and found the former more robust to noisy input.,Does the review address Methodology?,FALSE,TRUE,compares the models' robustness only not methodology
"On the other hand, directly generating the decomposed sub-claims has been shown to work really well in prior works.",Does the review address Related Work?,TRUE,FALSE,references prior works
3) The ablation study in table 5 seemed more like good baselines which is good to have as it shows GBT is more effective when applied to only hard examples.,Does the review address Comparison?,TRUE,FALSE,compares the effectiveness of GBT with other baselines
"For example, which datasets and how was the paraphraser trained to generate candidate sentences for selecting IBH0 and IBH1.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,asks for more details about the datasets and paraphraser training
"* Only a single dataset is used to explore the problem (well, it is two different parts but in the end it is one fairly specific dataset).",Does the review address Data/Task?,TRUE,FALSE,critiques the use of a single dataset
"The proposed approach is intuitive, easy to implement, and effective.",Does the review address Methodology?,TRUE,FALSE,describes the approach used
This would even strengthen the claims of GBT if improvements are significant.,Does the review address Result?,TRUE,FALSE,strengthening the claims through significant improvements
"Is the approach well motivated, including being well-placed in the literature?",Does the review address Methodology?,FALSE,TRUE,"asks about the motivation and placement in literature, not the approach or techniques used"
The entropy of the messages was only analyzed for the runs where agents have successfully learned to communicate in order to solve the task.,Does the review address Result?,FALSE,TRUE,discusses the analysis of entropy
The randomized version has to learn new embeddings from scratch and the mismatched version has to learn a new meaning for each label.,Does the review address Methodology?,TRUE,FALSE,how the versions learn embeddings and meanings
- This paper is well-written and easy to follow.,Does the review address Presentation?,TRUE,FALSE,comments on the clarity and readability
1) There are potentially numerous baselines as data augmentation for hard examples has several work.,Does the review address Data/Task?,FALSE,TRUE,discusses baselines related to data augmentation
"A lot of emphasis in the paper has been on generating explanations; however, only 30 examples have been evaluated which may not provide enough evidence to support the claims of the paper.",Does the review address Result?,FALSE,TRUE,critiques the evaluation sample size
There are many more benchmark datasets for text classification (including fake news detection) that could be included to provide more confidence in the findings.,Does the review address Data/Task?,TRUE,FALSE,suggests including more benchmark datasets
"Also, why not 5 or maybe more search results are used as the knowledge because the first result may not always contain sufficient information to verify the sub-claim.",Does the review address Result?,FALSE,TRUE,the use of multiple search results
* The idea to construct synthetic data using only the labels is interesting.,Does the review address Data/Task?,TRUE,FALSE,constructing synthetic data
I am also somewhat confused by the second set of experiments.,Does the review address Related Work?,FALSE,TRUE,expresses confusion about the experiments
"- Although SGEPG is model-agnostic, this paper conduct experiments using a specific model, VLTVG, to validate the proposed method.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,discusses the use of a specific model to validate the method
"* There are no statistical significance tests (and terms such as ""outperform"" should therefore not be used)      [1] Donabauer ""Exploring Fake News Detection with Heterogeneous Social Media Context Graphs"".",Does the review address Result?,TRUE,FALSE,"the use of terms like ""outperform"""
It would be difficult for readers to understand and evaluate – “we manually observed the generated examples and find the results acceptable.”  6) A very minute point – it may be interesting to compare with openLLM methods like LLaMa (after some instruction tuning for PI  task).,Does the review address Evaluation?,TRUE,FALSE,evaluation process and suggests comparing with other methods
These could possibly be answered with ablation studies.,Does the review address Ablation?,TRUE,FALSE,suggests using ablation studies to answer the questions
1) The authors propose adaptations of NVIB to self-attention and to use it for learning increasingly abstract representations at higher layers of a transformer encoder.,Does the review address Methodology?,TRUE,FALSE,proposed adaptations and how they relate to the methodology.
1) The specific design choices made in adapting the original NVIB to self-attention could benefit from more justification and discussion.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,asks for more justification and discussion
* Conducting an ablation study is a strong aspect of the experimental work as it offers more nuanced insights into what components of the architecture contribute how much  to the overall performance.,Does the review address Ablation?,TRUE,FALSE,discusses the value of conducting an ablation study.
The authors could do more error analysis and discuss scenarios where the approach may not work as well.,Does the review address Methodology?,TRUE,FALSE,Mentions methods or techniques.
The authors could do more error analysis and discuss scenarios where the approach may not work as well.,Does the review address Analysis?,TRUE,FALSE,Mentions analysis.
3) The ablation study in table 5 seemed more like good baselines which is good to have as it shows GBT is more effective when applied to only hard examples.,Does the review address Methodology?,FALSE,TRUE,Does not mention methods or techniques.
"These type of questions might already exist in the proposed dataset, it would provide more insights to dive deeper into those.",Does the review address Data/Task?,TRUE,FALSE,Refers to questions in a dataset.
"2.Through a significant number of ablation experiments, this paper extensively researched the model's hyperparameter configurations and training strategies, offering highly instructive guidance for related work.",Does the review address Experiment?,TRUE,FALSE,Discusses ablation experiments
The key contribution of the paper appears to be the formulation of the Concept-QA model based on query information and answers from GPT + CLIP.,Does the review address Methodology?,TRUE,FALSE,Describes the Concept-QA model formulation
- Ablation study shown in table 5 provides good insights for choices of LoRA params and the benefit of curriculum in staged training.,Does the review address Ablation?,TRUE,FALSE,points to the study in Table 5
The main concern to me about this paper is its limited novelty and scientific merit.,Does the review address Novelty?,TRUE,FALSE,Expresses concern about limited novelty.
"Having an ablation on the number of GreaseLM layers would also be quite useful to answer if performance improves with more GreaseLM layers, are there diminishing returns or do we need just a few GreaseLM layers, beyond which it is detrimental to the model's performance.",Does the review address Ablation?,TRUE,FALSE,Suggests an ablation on GreaseLM layers
"In experiments, mainly accuracy is shown, but since the major motivation to reduce gradient variance, why not show some comparison of gradient variance of MLM and MLM-FE?",Does the review address Result?,TRUE,FALSE,Refers to accuracy and gradient variance comparison
This looks like an order of magnitude difference in dataset empirical evaluation to me.,Does the review address Comparison?,TRUE,FALSE,Highlights a difference in dataset evaluation
"This is in sharp contrast to computer vision where techniques like rotation, modification of hue, saturation as well as umpteen other techniques exist.",Does the review address Comparison?,TRUE,FALSE,Contrasts techniques with those in computer vision
* The proposed RandomMask is effective but simple.,Does the review address Methodology?,TRUE,FALSE,Refers to the effectiveness of RandomMask
"The authors empirically evaluate their N-Bref’s accuracy on a number of problems from the open source LeetCode problem set and generate 25,000 pairs of high-level source and low-level source which are broken into training (60%), validation (20%), and testing (20%).",Does the review address Data/Task?,TRUE,FALSE,Describes the LeetCode problem set and dataset division
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Result?,TRUE,FALSE,Discusses concerns about result comparability and validity
"As the main contribution of this paper is the increased efficiency of the proposed approach, it must be clear how efficiency is measured.",Does the review address Methodology?,TRUE,FALSE,Refers to measuring the efficiency of the approach
"**Areas of Enhancement & Questions to authors**  - The information about each of the ablations (ID, BM) could be explained better.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests better explanation of ablations.
"The paper then proposes two practical solutions for better inference: 1) tuning dropout rate, softmax temperature, and the power mean parameter; and 2) deterministic inference with tuned softmax temperature.",Does the review address Methodology?,TRUE,FALSE,Describes proposed solutions for inference.
"Specifically, for Table 1, the inference time of each algorithm should be reported (retrieval time included).",Does the review address Significance?,FALSE,TRUE,"Focuses on reporting inference time, not impact or importance."
"- The paper is well written: it gives an appropriate context, presents the main theoretical results, and verifies _some_ of the claims experimentally.",Does the review address Result?,TRUE,FALSE,Refers to verifying claims experimentally
"Without comparison with SOTA's performance, I will try my best to reject this paper.",Does the review address Result?,TRUE,FALSE,Criticizes the lack of comparison with SOTA performance
"- Because the policy learning procedure utilizes the additionally generated dialogue acts and corresponding responses, it is easy to think that naively fine-tuning the GPT-2 model on the additional generated data may also improve the dialogue model performance in terms of its policy and responses (similar to a data augmentation method).",Does the review address Data/Task?,TRUE,FALSE,Refers to generated dialogue acts and data augmentation
"For example, Figure 4 validates Assumption 4.1 (log-partition function is roughly quadratic in theta), and Table 1 shows many real tasks are approximately “natural”.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Validates assumptions with Figure 4 and Table 1.
It wasn't intuitive for me that it'd be useful for NQ.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Expresses lack of intuition for usefulness in NQ
**Weaknesses** * Unclear if there are real practical applications to the insights from this paper.,Does the review address Methodology?,FALSE,TRUE,"Focuses on the practical applications of insights, not approaches or techniques"
"It's also not explained how Theorem 2 justifies the main conclusion: that ""a prompt engineer aided by enough time and memory can force an LLM to output an arbitrary sequence of ℓ tokens.""",Does the review address Theory?,TRUE,FALSE,Discusses Theorem 2 and its justification of the conclusion.
"), yet I could not find any actual training experiments, that is training a large LLM from scratch, in the paper.",Does the review address Methodology?,TRUE,FALSE,Criticizes the absence of training experiments for a large LLM
2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues.,Does the review address Methodology?,TRUE,FALSE,Suggests subjective evaluations for the LoRA fine-tuning strategy
Why are all publications not used in training the baselines?,Does the review address Data/Task?,TRUE,FALSE,Questions the use of publications in training baselines
"Why are the backbone models (RoBERTa and BERT, respectively) different in Table 1 and Table 2?",Does the review address Methodology?,TRUE,FALSE,Questions the difference in backbone models used in the tables
The paper also presents a manual evaluation of the inferred time series from a news corpus which is nice to see.,Does the review address Evaluation?,TRUE,FALSE,Refers to the manual evaluation of inferred time series.
The authors curated a large-scale dataset for first-stage pretraining and second-stage instruction tuning.,Does the review address Presentation?,FALSE,TRUE,"Focuses on the dataset curation, not the paper's structure or clarity."
Hyper-parameter balancing strategies in Section 3.1 is not a solid theoretical analysis.,Does the review address Methodology?,TRUE,FALSE,Criticizes the theoretical analysis of hyper-parameter balancing strategies
"The paper proposes a new joint learning algorithm that works for two tasks, NER and RE.",Does the review address Methodology?,TRUE,FALSE,Refers to the proposed joint learning algorithm for NER and RE tasks.
"Since one of the main contributions of this paper is the analysis of the BERT pretraining process, more experimental analysis on the optimizer should also be included.",Does the review address Methodology?,TRUE,FALSE,Suggests more experimental analysis on the optimizer.
"These objectives certainly improve over the original T5 base _and_ larges models that are used as initializations, and especially outperform the base model in the low-data regime.",Does the review address Result?,TRUE,FALSE,Compares performance improvements over T5 base and large models
Pros:  - A new framework for understanding why learning how to predict the next word helps the downstream task.,Does the review address Data/Task?,FALSE,TRUE,"Focuses on the framework for understanding predictions, not a specific dataset or task"
2017 (https://arxiv.org/abs/1606.05804) perform relation extraction on unseen entities.,Does the review address Related Work?,TRUE,FALSE,Refers to previous work on relation extraction.
- It would have been interesting to see a comparison of POS tagging performance with UD-style tags versus ORCHID tags.,Does the review address Comparison?,TRUE,FALSE,Suggests comparing POS tagging performance with different tag types.
"However, it is unclear how well they perform to the CASP state-of-the art (see also Rives et al, 2020).",Does the review address Result?,TRUE,FALSE,Questions performance in comparison to the CASP state-of-the-art.
"Last sentence of intro: ""without scarifying accuracy"" seems like an inaccurate description of the results presented in this paper.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques the description of the results as inaccurate.
"In general, it may help to reorder some of these results, add forward references to the proofs, and indicate how different results depend on one another.",Does the review address Result?,TRUE,FALSE,Suggests reordering and referencing results more clearly.
I am not sure on this---my intuition is based on your Lemma D.2 and the fact that for a $p_{\cdot\mid s}$ with full support a non-precise reverse version of [Pinsker's inequality](https://en.wikipedia.org/wiki/Pinsker%27s_inequality#Inverse_problem) holds.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Expresses uncertainty based on the intuition from Lemma D.2.
"The first use of the proposed definitions to make a non-trivial claim is in Section 5 with Postulate 1, but this claim is not justified.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Highlights the lack of justification for a claim made using the proposed definitions.
"Also, some additional experiments need to be added in order to better justify its claims.",Does the review address Experiment?,TRUE,FALSE,Suggests adding more experiments to justify the claims.
I therefore believe that these results show merit.,Does the review address Result?,TRUE,FALSE,Expresses belief in the merit of the results.
"- Table 5 the VAE(32) method performs the best overall in ""Wiki section"" although the TC (16) method has been highlighted as the best.",Does the review address Result?,TRUE,FALSE,Compares the performance of methods in Table 5.
"The main contribution are the following innovations: a special attention mechanism called block-diagonal conditional attention, a set of modules for adaptation of a pretrained model, and an uncertainty-based multi-task data sampling method.",Does the review address Novelty?,TRUE,FALSE,Describes the innovative contributions of the paper.
It would be really useful to have an ablation study to disentangle which piece of the training or method is contributing to what and how in the performance measure.,Does the review address Result?,FALSE,TRUE,"Focuses on suggesting an ablation study, not discussing the results directly."
What would happen to the network if compression is removed?,Does the review address Experiment?,TRUE,FALSE,Suggests testing the effect of removing compression from the network.
The phrasal RNN (pRNN) architecture is achieved by generating subnetworks of phrases.,Does the review address Methodology?,TRUE,FALSE,Describes the pRNN architecture and its generation of subnetworks.
In particular we don't know if the sacrifice of short sequence time would benefit a lot in long sequences for existing methods.,Does the review address Methodology?,FALSE,TRUE,"Focuses on the trade-off in sequence length, not the methodology itself."
"Additionally, showing this for negations and / or examples which GreaseLM gets correct but QA-GNN does not (and vice-versa) can shed some light on what the model improves on (and what are the limitations).",Does the review address Comparison?,TRUE,FALSE,Suggests comparing GreaseLM and QA-GNN on specific examples.
"For experiments, Table 1 shows the FOCAL Reasoner (DeBERTa) brings much performance gain, compared to FOCAL Reasoner (RoBERTa) (the performance seems comparable with DAGN and LReasoner using RoBERTa).",Does the review address Experiment?,TRUE,FALSE,Compares performance in Table 1 across different models.
"The authors provide several reasonable insights that might be relevant to the user interface modeling community — using object detection as part of multi-task learning instead of standalone pre-training task, design choices to create a single unified architecture for all the tasks, multi-task learning outperforming single-task learning etc.",Does the review address Data/Task?,FALSE,TRUE,"Focuses on insights related to modeling choices, not a specific dataset or task."
"What is the impact of a good OCR for training and testing (prediction of new, unseen documents)?",Does the review address Presentation?,FALSE,TRUE,"Focuses on the impact of OCR on training and testing, not the paper's structure or clarity."
"Strengths: * Novel method of using emergent language for pre-training (as opposed to transferring an entire artificial agent) * Some good ablations to identify what contributes to successful transfer * A new evaluation metric (emergent --> NL translation performance) that best correlates with fine-tuning performance  Weaknesses: * Some parameter choices and the design of some ablations are not completely justified * Some additional related works could be included   # Minor comments / questions  * ""However, this metric is too rigid in its definition of compositionality, ignoring aspects like argument structure, context or morphology which play a key role in determining the combination of word semantics (Goldberg, 2015).""",Does the review address Methodology?,TRUE,FALSE,Critiques the design of ablations and parameter choices.
"- When building the relation between the word and the frame, is there any emphasis on verb, some particular word, or self-learned attention?",Does the review address Methodology?,TRUE,FALSE,Asks about the approach used to build the relation between the word and the frame.
"It's particularly surprising to me that this works so well on NQ, and I wish the authors had dug a bit deeper into this, but I also recognize that page limits exist.",Does the review address Analysis?,TRUE,FALSE,Expresses surprise and suggests further analysis on the NQ performance.
Comparison with GECA: I can read from the paper that the performance is on par with GECA.,Does the review address Result?,TRUE,FALSE,Compares performance with GECA.
"They train low resource NMTs using 4 different tokenization strategies, to show that their proposed tokenization method leads to the best NMT results by several metrics.",Does the review address Methodology?,TRUE,FALSE,Describes the tokenization strategies and their impact on NMT results.
It would be really useful to have an ablation study to disentangle which piece of the training or method is contributing to what and how in the performance measure.,Does the review address Presentation?,FALSE,TRUE,"Focuses on suggesting an ablation study, not on the clarity or structure of the paper."
"PE seems to be important for wMAN, and the authors provides few sentences analysis about this, but I don't think I fully understand this part.",Does the review address Significance?,FALSE,TRUE,It discusses understanding and analysis but does not focus on the impact or importance.
The graph indicates that for MNLI and QNLI 60% seems like a better choice.,Does the review address Methodology?,TRUE,FALSE,"Refers to choosing a better option based on the graph, likely related to a method or approach."
The analysis shows that it outperforms only all the other baselines only on 5/9 games and matches on 3.,Does the review address Analysis?,TRUE,FALSE,Discusses the performance analysis across games and matches.
The margin of change seems even larger than some results which are discussed in the paper as significant.,Does the review address Result?,TRUE,FALSE,Discusses the margin of change in relation to significant results.
"With the proposed CaptionNet dataset, it is now possible to have a fairer comparison between VL models and CE models.",Does the review address Data/Task?,TRUE,FALSE,Refers to the CaptionNet dataset and its role in comparisons between VL and CE models.
The authors have done further experiments and show that there are still gains on these tasks when model sized is increased significantly.,Does the review address Result?,TRUE,FALSE,Discusses performance gains with increased model size.
"Informally , a task is defined as natural if, just by using the next word distributions as features, the downstream task can be solved with a small loss.",Does the review address Data/Task?,TRUE,FALSE,Defines a task as natural based on the use of next-word distributions as features.
It appears that a single example was analyzed qualitatively.,Does the review address Analysis?,TRUE,FALSE,Refers to the qualitative analysis of a single example.
"The experiments cover loss functions, label noise, caption length, caption quality, VL vs CE etc.",Does the review address Experiment?,TRUE,FALSE,Refers to the different aspects covered in the experiments.
"However, the presented theory suffers from various core issues.",Does the review address Theory?,TRUE,FALSE,Critiques the presented theory for core issues.
"Decompilation can mean many things, but the general idea as I understand it, is to take a representation of a software program from one level (e.g., program binary) and then “lift it” to a level that is higher in abstraction (e.g., from binary to assembly, from assembly to C, from C to a lambda calculus, etc.).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Refers to the definition and explanation of decompilation.
I believe such an experiment will definitely make the submission stronger.,Does the review address Experiment?,TRUE,FALSE,Refers to the suggestion of conducting an experiment to strengthen the submission.
"**Baselines are too weak, leading to a misunderstanding of the effectiveness of the proposed method.",Does the review address Comparison?,TRUE,FALSE,Refers to the evaluation of the proposed method against weak baselines.
"One might hypothesize that if using a (subotimal) template that is less natural for language modeling, that zero-shot performance would suffer, but that FLAN performance wouldn't - One might hypothesize that the ""turn the task around"" templates help more than the other more straightforward templates that don't swap information between the prompt and response.",Does the review address Result?,FALSE,TRUE,It refers to a hypothesis rather than reporting specific findings or outcomes.
It is hard to know here which one of these actually made the adversarial setup useful.,Does the review address Methodology?,TRUE,FALSE,Refers to the uncertainty about what aspect of the adversarial setup contributed to its usefulness.
"* Fundamentally, beyond simple invariants (array bounds, nullness checks) it is not clear why program invariants would generalize well across different programs.",Does the review address Methodology?,TRUE,FALSE,Refers to a question about the generalizability of program invariants across different programs.
"In fact, empirical evidence suggest that LMs do memorize n-grams from their training data somewhat, but not full examples (see [McCoy et al.",Does the review address Methodology?,FALSE,TRUE,"It discusses empirical evidence about language models, not the methods or approaches used in the study."
"In the presence of definitive results, this might be acceptable, but in its absence, as in this paper, there needs to be quantitative analysis across multiple runs to demonstrate the robustness of the phenomenon.",Does the review address Analysis?,TRUE,FALSE,Refers to the need for quantitative analysis to demonstrate the robustness of the phenomenon.
"Liu Y., Liu Z., Chua T.,Sun M. AAAI 2015 _ Also, the inclusion of the result from those approaches in tables 3 and 4 could be interesting.",Does the review address Result?,TRUE,FALSE,Refers to the inclusion of results from other approaches in the tables.
This method should be included in the experiments in order to justify the proposed RL approach is necessary.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Refers to the need to include the method to justify the necessity of the proposed RL approach
Another major concern is the use of two separate RNNs which gives the proposed model more parameters than the baselines.,Does the review address Comparison?,TRUE,FALSE,Refers to comparing the proposed model’s parameters with those of the baselines.
**Summary** This work relates a pre-training performance with a downstream performance for tasks that _can_ be reformulated as next word prediction tasks.,Does the review address Presentation?,FALSE,TRUE,"It provides a summary of the work, but does not discuss clarity, structure, or organization."
"Therefore, the obtained task performance is far from state-of-the-art.",Does the review address Result?,TRUE,FALSE,Refers to the obtained task performance being far from state-of-the-art.
"Because if too many parameters are introduced, the performance improvement may come from overfitting of too many parameters.",Does the review address Result?,FALSE,TRUE,"It discusses a potential issue related to overfitting, but does not report specific results or performance outcomes."
Complexity-based prompting for multi-step reasoning.,Does the review address Related Work?,TRUE,FALSE,"Refers to complexity-based prompting, which could be discussing previous approaches or research in the field."
The training procedure mentioned in section 5.2.2 talks about joint training but the procedure followed for training for individual tasks or a subset of tasks is not described in detail.,Does the review address Methodology?,TRUE,FALSE,Refers to the training procedure and the lack of detail about training for individual tasks or subsets of tasks.
Pros:  - the paper is well written and very clear - the proposed model has two main advantages: (1) it is very fast to train due to the use of pre-trained BERT representations and (2) it does not depends on any external NLP tool (such as dependency parser)  Cons:   - I think the main source of improvement comes from the BERT representations used as input.,Does the review address Presentation?,TRUE,FALSE,Refers to the paper being well written and clear.
Move to E2E system can be motivated a bit more (allows end-user feedback to be passed through all modules easily and don't have to worry about how a change in one module affects all other modules explicitly etc) 3.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"Refers to motivating the move to an E2E system by explaining its benefits, such as allowing end-user feedback to flow through all modules easily."
"In order to train reading comprehension models to perform relation extraction, they create a large dataset of 30m “querified” (converted to natural language) relations by asking mechanical turk annotators to write natural language queries for relations from a schema.",Does the review address Methodology?,TRUE,FALSE,"Refers to the process of creating a large dataset and using mechanical turk annotators to generate queries, describing the approach used in the study."
I see this work more as an analysis on language-specific parameters for a particular LS-model rather than a novel architecture.,Does the review address Analysis?,TRUE,FALSE,Refers to the work being viewed as an analysis of language-specific parameters for a particular model.
This paper is well-written and the idea is interesting.,Does the review address Presentation?,TRUE,FALSE,Refers to the paper being well-written.
The annotations in baseline [1] are much shorter compared to the annotations by the authors.,Does the review address Comparison?,TRUE,FALSE,Refers to comparing the length of annotations in the baseline to those provided by the authors.
"- Additionally, in my opinion, the authors are misrepresenting prior work when saying in line 163 that the ""MTL approach has not yet been successful in NLP"".",Does the review address Presentation?,FALSE,TRUE,"It discusses a potential misrepresentation of prior work, but does not address the clarity, structure, or organization of the paper."
"The model is based on a pre-trained BERT model, which provides the word vectors of the input word sequence.",Does the review address Methodology?,TRUE,FALSE,"Refers to the use of a pre-trained BERT model to provide word vectors for the input sequence, describing the approach used in the study."
"In particular, you are comparing a small GRU LM to a larger transformer LM, where the latter is, as you mention, a much more powerful model.",Does the review address Methodology?,FALSE,TRUE,"It discusses a comparison between two models (GRU and transformer), but does not describe the methods or techniques used in the study."
"Please report the total training and total inference time, and make a comparison with standard Transformer model.",Does the review address Significance?,FALSE,TRUE,"It asks for reporting and comparison of training and inference times, but does not discuss the impact or importance of the study."
"For example, what is the experiment environment and training receipts.",Does the review address Experiment?,TRUE,FALSE,Refers to asking for details about the experiment environment and training setup.
"The methods have been tested on two benchmarks focusing on the issue, SCAN and morphological analysis.",Does the review address Presentation?,FALSE,TRUE,"It discusses the benchmarks used for testing the methods but does not address the clarity, structure, or organization of the paper."
"The motivation is very clear, MCTS is generally action agnostic and using language to provide additional semantic information to it can prove to be very effective.",Does the review address Methodology?,FALSE,TRUE,It discusses the motivation for using language with MCTS but does not describe the methods or techniques used in the study.
"(2) In this paper, similarity and alignment structures are proposed, but no ablation experiments have been carried out to prove the effectiveness of the improved model.",Does the review address Methodology?,TRUE,FALSE,Refers to the absence of ablation experiments to validate the effectiveness of the proposed similarity and alignment structures.
"In particular, using a carefully selected subset of ""prompt"" words, the authors observe that learning a linear predictor over the next word distributions of these words achieves performance close to a pre-trained GPT-2 model.",Does the review address Result?,TRUE,FALSE,Refers to the observation that using a subset of “prompt” words achieves performance close to a pre-trained GPT-2 model.
"Without the ablation studies on these two aspects, we cannot determine whether the performance improvement truly comes from the author's contribution or just longer CoT annotations.",Does the review address Result?,TRUE,FALSE,Refers to the inability to determine whether the performance improvement is due to the author’s contribution or just longer CoT annotations without the ablation studies.
"It is naturally expected that vision-language models can benefit from stronger unimodal encoders, for which the best strategies are not very well explored by the community.",Does the review address Methodology?,FALSE,TRUE,It discusses the expectation that vision-language models can benefit from stronger unimodal encoders but does not describe the methods or techniques used.
I would appreciate the explanation and further evidence to address these concerns.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Refers to the request for further explanation and evidence to address the concerns
"- P24, Figure 2: What are the x and y axis, and what does each dot mean in this figure?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Refers to asking for clarification on the x and y axes and the meaning of each dot in the figure.
The Ablation Study of the paper also provides useful insights about the impact of different pre-training schemas on large-scale information retrieval tasks.,Does the review address Presentation?,FALSE,TRUE,"It refers to the ablation study providing useful insights but does not address the clarity, structure, or organization of the paper."
"Intuitively, this parameter arises from translating the ""natural"" task assumption, which only guarantees transfer on average to the downstream task.",Does the review address Data/Task?,TRUE,FALSE,"Refers to the task assumption and its relation to the downstream task, indicating a focus on how the data or task is structured."
"- The proposed architecture is tested on massive experiments including language understanding tasks, optical flow, video audio class autoencoding, image classification, and starcraft II and achieves superior performance.",Does the review address Methodology?,TRUE,FALSE,"Refers to the proposed architecture being tested on various tasks, describing the methods used in the study."
"- `s4.3 Findings p4`: ""the channel ... influences generalisation"" -- Without further explication, this potentially interesting point does not gain any traction.",Does the review address Result?,TRUE,FALSE,"Refers to the finding that the channel influences generalization, but it points out the lack of further explanation to support the result."
"The approach, extend the model introduced by Vilnis and McCallum (2014) which represented word as unimodal Gaussian distribution.",Does the review address Methodology?,TRUE,FALSE,"Refers to extending the model introduced by Vilnis and McCallum (2014), describing the approach used in the study."
Can PACT be applied to simpler theorem provers like MetaMath where there are no tactics?,Does the review address Theory?,TRUE,FALSE,"Refers to questioning the applicability of PACT to simpler theorem provers like MetaMath, which relates to the theoretical foundations of the method."
Pros:  - the paper is well written and very clear - the proposed model has two main advantages: (1) it is very fast to train due to the use of pre-trained BERT representations and (2) it does not depends on any external NLP tool (such as dependency parser)  Cons:   - I think the main source of improvement comes from the BERT representations used as input.,Does the review address Methodology?,TRUE,FALSE,"Refers to the proposed model’s use of pre-trained BERT representations and the absence of dependency on external NLP tools, which relates to the methodology of the study."
"* It will be cool to show some results on BLEU improvement on machine translation, or user studies on language generation tasks, to demonstrate its practical impact, as the quantitative metrics right now are still kind of artificial.",Does the review address Significance?,TRUE,FALSE,"Refers to demonstrating the practical impact of the approach through results on BLEU improvement or user studies, suggesting the importance of validating the method’s real-world relevance."
* There has been so much work on static inference of invariants that it is impossible to list even all the closely related work.,Does the review address Related Work?,TRUE,FALSE,Refers to the extensive amount of work on static inference of invariants and the challenge of listing all the closely related studies.
The cold-start problem is actually an urgent problem to several online review analysis applications.,Does the review address Presentation?,TRUE,FALSE,"Refers to presenting the cold-start problem as an urgent issue in online review analysis applications, which is part of the paper's explanation or context."
A comparison and discussion of this would be really useful.,Does the review address Comparison?,TRUE,FALSE,Refers to the need for comparison and discussion to enhance the understanding of the topic.
"Further, the performance improvements are nice, though not impressive.",Does the review address Result?,TRUE,FALSE,Refers to the performance improvements discussed in the review.
It's unclear what the contribution of the paper is.,Does the review address Contribution?,TRUE,FALSE,Refers to the clarity of the paper's contribution.
"It also further demonstrates that the BERT model, once fully tuned, could achieve SOTA/competitive performance compared to the recent new models (e.g., XLNet).",Does the review address Methodology?,TRUE,FALSE,Refers to the tuning and performance comparison of the BERT model.
"For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.",Does the review address Experiment?,TRUE,FALSE,"Refers to the comparison of model performance metrics (R@1, R@5, R@10)."
_ A question to the authors: What do you attribute the loss of performance of w2gm against w2g in the analysis of SWCS?,Does the review address Analysis?,TRUE,FALSE,Refers to the performance comparison and analysis between w2gm and w2g.
"Since one of the main contributions of this paper is the analysis of the BERT pretraining process, more experimental analysis on the optimizer should also be included.",Does the review address Contribution?,TRUE,FALSE,The analysis of the BERT pretraining process is highlighted as one of the main contributions of the paper.
I encourage the authors to try out ideas they mentioned as future work to have a substantial contribution for a conference publication.,Does the review address Contribution?,TRUE,FALSE,The reviewer encourages the authors to explore future work ideas to make a substantial contribution for a conference publication.
Energy and policy considerations for deep learning in NLP.,Does the review address Related Work?,TRUE,FALSE,Refers to energy and policy considerations in deep learning for NLP.
"It is not fully clarified what is the difference between the so-called ""ITM"" (image-text matching) and the contrastive losses used in other  VL pretrained models, such as ALIGN, ALBEF.",Does the review address Methodology?,TRUE,FALSE,Refers to the clarification of differences between ITM and contrastive losses in VL pretrained models.
It especially corroborates that certain tasks are innately more challenging for active learning than others.,Does the review address Data/Task?,TRUE,FALSE,Refers to tasks that are more challenging for active learning.
"**Experiment setup** In Table 3, the paper only compares the proposed method against GPT-Neo and GPT-J, which is not sufficient.",Does the review address Comparison?,TRUE,FALSE,Refers to comparing the proposed method against GPT-Neo and GPT-J.
"Weakness: - paper title is misleading, not directly related to LM - no citation and description for the baseline method T5+KB (Table 4) - As shown in Table 7, the proposed method is very sensitive to many factors.",Does the review address Related Work?,TRUE,FALSE,Refers to the lack of citation and description for the baseline method T5+KB.
"2.Through a significant number of ablation experiments, this paper extensively researched the model's hyperparameter configurations and training strategies, offering highly instructive guidance for related work.",Does the review address Ablation?,TRUE,FALSE,Refers to the significant number of ablation experiments conducted.
I think the setting of checkpoint depends on the hardware specifications and model architectures.,Does the review address Methodology?,TRUE,FALSE,Refers to the setting of the checkpoint based on hardware and model architectures.
"You forgot to bold the best performer in line 3 of Table 2 (in this case, the original compact model).",Does the review address Presentation?,TRUE,FALSE,Refers to the formatting of results in a table.
"The authors experiment both with pre-training and fine-tuning of contextual models (BERT-{base,large}) and claim large reduction in training time, with reasonable loss in performance.",Does the review address Result?,TRUE,FALSE,Refers to the outcome of the authors' experiments on training time and performance loss.
"The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",Does the review address Result?,FALSE,TRUE,"It mentions experimental details and ablation study, but focuses more on methodology and validation."
"(3) multiSkip : Extends the approach presented by Luong et al. (2015b) for embedding using source and target context (via alignment), to the multilingual case by extending the objective function to include components for all available parallel corpora.",Does the review address Methodology?,TRUE,FALSE,Describes the approach and extension of the objective function.
"Do we need better model design, or more data and computations?",Does the review address Data/Task?,TRUE,FALSE,Refers to the need for better model design or more data and computations.
"Alongside with qualitative analysis, some quantitative analysis would be good to show what the model learns.",Does the review address Methodology?,TRUE,FALSE,Refers to the need for quantitative analysis to support the model's learning.
"Elaboration on Theorem 1, with an intuitive breakdown of its implications, would significantly enhance the readability and credibility of the results.",Does the review address Presentation?,TRUE,FALSE,Refers to enhancing the clarity and credibility of the results through an intuitive breakdown.
How effective is the method to capture farther long-term dependencies compared to previous methods?,Does the review address Presentation?,FALSE,TRUE,It focuses on the effectiveness of the method in capturing long-term dependencies.
Their method MC-LAVE used word embeddings on the language action space to help induce a non-uniform distribution over the action space.,Does the review address Methodology?,TRUE,FALSE,Refers to the approach of using word embeddings on the language action space.
"The proposed method has achieved SOTA performance on a range of Vision-Language benchmarks, spanning image captioning, Visual Question Answering, and visual grounding tasks.",Does the review address Data/Task?,TRUE,FALSE,"Refers to the tasks the model is evaluated on, including image captioning, Visual Question Answering, and visual grounding."
"This paper proposes a new understanding of dropout on top of variational dropout, which shows that training with dropout equals to maximizing an empirical variational lower bound on the log-likelihood.",Does the review address Methodology?,TRUE,FALSE,"Refers to the new understanding of dropout and its connection to variational dropout, explaining the method used in the paper."
"Also, the citation to Universal Dependencies is completely broken.",Does the review address Presentation?,TRUE,FALSE,Refers to a broken citation in the paper.
My understanding is that contribution of the paper is in exploring using options framework to goal-oriented dialog to handle the issue in question.,Does the review address Contribution?,TRUE,FALSE,Refers to exploring the use of the options framework in goal-oriented dialog.
So this contribution seems not practically useful according to the empirical result.,Does the review address Result?,TRUE,FALSE,Refers to the empirical result showing limited practical usefulness of the contribution.
"Perhaps an entropy-regularized setup is a useful comparison to show that it provides marginal benefit over the setup studied, and this might resolve the lack of clarity around the implications of the claims made from the first set of experiments.",Does the review address Comparison?,TRUE,FALSE,Suggests comparing with an entropy-regularized setup to clarify the implications of the claims.
"Also, the lack of attention mechanism provides a disadvantage to the baseline enc-dec system and it's unclear whether the pRNN can outperform or be an additive feature to the enc-dec system with an attention mechanism.",Does the review address Result?,TRUE,FALSE,Discusses the potential disadvantage of the baseline enc-dec system and questions whether pRNN can outperform or complement an attention-based system.
This approach is simple combination of  Doc2Vec and STE.,Does the review address Presentation?,TRUE,FALSE,Describes the approach as a simple combination of Doc2Vec and STE.
Why authors consider questions answering and sentiment analysis as the applications?,Does the review address Analysis?,TRUE,FALSE,Questions why the authors consider specific applications like question answering and sentiment analysis.
It's not really okay to put up the tables and show the perplexity and BLEU scores without some explanation.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out the need for explanation of the tables showing perplexity and BLEU scores.
"However, I feel that experiments can be strengthened, and notations can be improved.",Does the review address Presentation?,TRUE,FALSE,Suggests improving notations and strengthening the experiments.
"I would have thought this was training an LM on progressively larger portions of the relevant data (being used for fine-tuning the others), in which case I'd also expect a downward trend in perplexity.",Does the review address Presentation?,FALSE,TRUE,"It discusses expectations regarding training and perplexity, not the paper's structure, clarity, or organization."
"- In the experiments in MultiWOZ, this paper only evaluates the response generation results.",Does the review address Experiment?,TRUE,FALSE,Refers to evaluating response generation results in the MultiWOZ dataset.
"For example, a lot of BERT-style models exploit dense interactions.",Does the review address Related Work?,TRUE,FALSE,"Refers to BERT-style models and their use of dense interactions, likely comparing to previous work."
"- Weaknesses: Though it may not be possible in the time remaining, it would be good to see a comparison (i.e. BLEU scores) with previous related work like hierarchical softmax and differentiated softmax.",Does the review address Comparison?,TRUE,FALSE,"Refers to a comparison with previous related work, such as hierarchical softmax and differentiated softmax."
PUCT-RL is the only directly comparable baseline given action space and other handicap differences.,Does the review address Comparison?,TRUE,FALSE,Refers to the comparison with PUCT-RL as the only directly comparable baseline.
"- After definition 5.1, what does Omega[w] = Omega[w’] mean?",Does the review address Presentation?,TRUE,FALSE,"Refers to the clarification needed for the notation ""Omega[w] = Omega[w’]"" after Definition 5.1."
The authors claim that “There are a number of benefits of adopting the adaptive smoothing parameter”.,Does the review address Methodology?,TRUE,FALSE,"Refers to the adoption of an adaptive smoothing parameter, which is part of the methodology being discussed."
"Publication venues are often missing; e.g., where was Boonkwan & Supnithi (2018) published?",Does the review address Presentation?,TRUE,FALSE,Refers to the absence of publication venues for cited works.
"Details ========= Abstract: In o gur work => In our work P5: ""oracle dialogue state"": What is the oracle dialog state and how is it calculated?",Does the review address Presentation?,TRUE,FALSE,"Critiques the clarity and detail of the term ""oracle dialogue state"" and its explanation."
3) One main contribution of this paper is the power-mean family of dropout.,Does the review address Contribution?,TRUE,FALSE,Refers to the power-mean family of dropout as a main contribution.
"The billions that have been pumped into languages like English have in fact resulted in technologies that can be applied at much lower cost to languages like Kanyen’kéha, but there are still costs.",Does the review address Methodology?,FALSE,TRUE,"It discusses the impact of investment in languages and related costs, not the techniques or processes used in the study."
"Publication venues are often missing; e.g., where was Boonkwan & Supnithi (2018) published?",Does the review address Related Work?,TRUE,FALSE,"Refers to the missing publication venue for a cited work, pointing to a potential issue in referencing related research."
In particular the part that argued why B = O(1/alpha).,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Refers to a specific argument or claim in the paper.
"But that would also mean that the phrases are determined by token ngrams which produces a sliding window of the ""pyramid encoders"" for each sentence where there are instance where the parameter for these phrases will be set close to zero to disable the phrases and these phrases would be a good intrinsic evaluation of the pRNN in addition to evaluating it purely on perplexity and BLEU extrinsically.",Does the review address Presentation?,FALSE,TRUE,"Focuses on the evaluation of pRNN, not the paper's clarity or structure."
Theorem 1 in Section 5 seems to follow directly from the proposed definition of controllability.,Does the review address Theory?,TRUE,FALSE,Refers to Theorem 1 and its relationship with the definition of controllability.
"The design of triggers, in this context, warrants a more nuanced discussion by the authors.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests a more detailed discussion on the design of triggers.
The larger dataset may relate to more many-to-many relationships when training the model.,Does the review address Methodology?,TRUE,FALSE,Refers to how the dataset's size may impact the model's training process.
"The method shows some performance gains over BERT on some GLUE tasks, but these are fairly small for the most part, and BERT outperforms the proposed method by a similar amount on a similar number of tasks.",Does the review address Comparison?,TRUE,FALSE,Compares the proposed method's performance with BERT on GLUE tasks.
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Evaluation?,TRUE,FALSE,Critiques the evaluation approach and calls for justification.
Weaknesses * Something that stands out is the lack of discussion and comparison to related works that employ recurrent formulations of attention.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out the lack of discussion and comparison to related works.
"However, Section 3.1 cannot demonstrate effective theoretical information.",Does the review address Methodology?,TRUE,FALSE,Critiques Section 3.1 for not demonstrating effective theoretical information related to the methodology.
"Even with the results that already exist, it is claimed (for example in section 5.1) that MC-LAVE-RL is the only algorithm to pass bottlenecks such as getting the action ""take lantern"" right.",Does the review address Result?,TRUE,FALSE,Refers to the claim about MC-LAVE-RL passing specific bottlenecks and achieving correct actions.
"Although I understand the experiment setup, missing reference to more recent VL works prevent readers from getting a good research landscape in the multimodal pre-training.",Does the review address Experiment?,FALSE,TRUE,"Focuses on the lack of references to recent VL works, not on the experiment itself."
- Experiments contain 3 different tasks and each has datasets from different domains.,Does the review address Experiment?,TRUE,FALSE,Describes the experiments involving three tasks with datasets from different domains.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Presentation?,FALSE,TRUE,"Focuses on the results and theoretical analysis, not on the clarity or structure of the paper."
- Improvement over previous state-of-the-art models.,Does the review address Result?,TRUE,FALSE,Refers to improvement over previous state-of-the-art models.
"The proposed system outperforms or achieves on-par  performance against previous SOTA methods, i.e., AudioGen and AudioLDM, in both objective and subjective metrics.",Does the review address Result?,TRUE,FALSE,Compares the system's performance with previous SOTA methods using both objective and subjective metrics.
"What the authors can do is: you can sample some sentences from the test/development set and count how many comparative words are misused in the original model, among which how many are corrected by reranking.",Does the review address Methodology?,TRUE,FALSE,Suggests a method for evaluating comparative word misuse and correction through reranking.
Introducing the layer and networks in a simple way would help clarify the implementation and other notation.,Does the review address Methodology?,TRUE,FALSE,Suggests simplifying the introduction of layers and networks to clarify the implementation and notation.
"In the experiment section, the authors only include the CoT annotations from [1] as the most important baseline.",Does the review address Comparison?,TRUE,FALSE,Refers to comparing CoT annotations with the baseline.
Simply adding related sentences in the pre training input context helps end performance.,Does the review address Methodology?,TRUE,FALSE,Refers to adding related sentences in the pre-training input context as part of the method.
The experimental results mainly address similar networks with similar context lengths.,Does the review address Result?,TRUE,FALSE,Refers to experimental results comparing networks with similar context lengths.
"For example, the $p^{\star}$ notation is also defined in Sec 2.1.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Refers to the explanation of notation and its definition in the paper.
Empirical results on MultiWoz 2 and 2.1 shows improvement over other state-of-the-art techniques.,Does the review address Data/Task?,TRUE,FALSE,Refers to the MultiWOZ 2 and 2.1 datasets used in the experiments.
This is a crucial scientific finding: money works!,Does the review address Significance?,TRUE,FALSE,Highlights the importance of the scientific finding that money works.
"With this definition, a linear model of the logits is also a linear model over the context embeddings f(s) directly.",Does the review address Presentation?,FALSE,TRUE,"It discusses the relationship between the model and the context embeddings, not the clarity or structure of the paper."
"The model leverage pre-trained BERT language models, making it very fast to train.",Does the review address Methodology?,TRUE,FALSE,Refers to leveraging pre-trained BERT models as part of the training process.
Each task is supported with a detailed ablation study to shed light on future research.,Does the review address Data/Task?,TRUE,FALSE,Refers to tasks being supported by detailed ablation studies.
Making these comparisons would require a heavy rewrite starting from the abstract to the analysis and so I would recommend reject right now but look forward to seeing an updated version of the paper in the future with some of these changes.,Does the review address Analysis?,TRUE,FALSE,Suggests that comparisons would require a rewrite of the analysis section.
"Also, possibly figure 3 can be combined into the pyramid part of figure 4.",Does the review address Presentation?,TRUE,FALSE,Suggests combining figures 3 and 4 for better clarity or organization.
"Especially, in terms novelty, the paper is relatively limited as the RF is explored in Rawat et al., 19.",Does the review address Novelty?,TRUE,FALSE,"Critiques the paper's novelty due to prior exploration of RF in Rawat et al., 19."
"Considering this is the combined benefit of multiple techniques, e.g. distillation, text token selection, contrastive learning, I am not fully convinced by the empirical value of the proposed method.",Does the review address Methodology?,TRUE,FALSE,"Questions the empirical value of the method, which involves multiple techniques like distillation, text token selection, and contrastive learning."
"It is not clear how this model would compare to other models using language specific parameters (sparsely gated mixture of experts (Lepikhin et al 2020), light-weight adapters (Bapna et al 2019)  ).",Does the review address Methodology?,TRUE,FALSE,Compares the proposed model with others using language-specific parameters and techniques.
2) TDE follows the previous work and aims to learn three different level embeddings.,Does the review address Methodology?,TRUE,FALSE,Describes TDE's approach of learning three different level embeddings.
"In comparison, if we look at Page 17, the actual annotations from the authors are very long and detailed.",Does the review address Data/Task?,FALSE,TRUE,"The focus is on the length and detail of the authors' annotations, not the dataset or task itself."
This paper studies why language model pre-training has been such an effective technique in improving downstream performance across a wide range of NLP tasks recently.,Does the review address Result?,FALSE,TRUE,It discusses the focus of the study but does not present specific results or findings.
I felt this was quite separate from the theoretical analysis.,Does the review address Analysis?,TRUE,FALSE,Expresses a feeling that the discussed point is separate from the theoretical analysis.
* Related work: I would also include a discussion of this Lazaridou et al paper where they compare ways of combining EC with non-EC learning signals (e.g. image caption training): https://aclanthology.org/2020.acl-main.685.pdf  * Ethics statement: I appreciate this statement and agree with the possible positive impacts.,Does the review address Related Work?,TRUE,FALSE,Suggests including a discussion of a specific paper related to combining EC with non-EC learning signals.
"Reducing these costs could have a very high impact on the field, allowing many more researchers to participate in state-of-the-art research [3].",Does the review address Significance?,TRUE,FALSE,"Highlights the potential high impact of reducing costs on the field.






"
There is also a NAACL 2016 paper (https://www.aclweb.org/anthology/N/N16/N16-2016.pdf) which performs relation extraction using a new model based on memory networks… and I’m sure there are more.,Does the review address Related Work?,TRUE,FALSE,Refers to a specific NAACL 2016 paper on relation extraction using memory networks.
### Notes on text and style  There are parts of the manuscript that felt somewhat informal and confusing to me.,Does the review address Presentation?,TRUE,FALSE,"The review comments on parts of the manuscript feeling informal and confusing, which relates to the clarity and style of the paper."
"The authors cite Bordes et al. (https://arxiv.org/pdf/1506.02075.pdf), who collect a similar dataset and perform relation extraction using memory networks (which are commonly used for reading comprehension).",Does the review address Related Work?,TRUE,FALSE,"The review references the citation of Bordes et al. and discusses their dataset and method, which relates to the review and discussion of relevant literature."
"- P24, Figure 2: What are the x and y axis, and what does each dot mean in this figure?",Does the review address Presentation?,TRUE,FALSE,"Questions the clarity of Figure 2, specifically the x and y axes and the meaning of the dots."
Why don't the authors of this work do this evaluation as well?,Does the review address Data/Task?,FALSE,TRUE,It questions why the authors didn't perform a specific evaluation but does not discuss a dataset or task.
"I would have liked to see these results (also, please fix grammar in this sentence) 9.",Does the review address Result?,TRUE,FALSE,"Expresses a desire to see specific results and asks for grammar correction.






"
The findings of (2)(3)(4)(5) mentioned in the summary section above are especially interesting and can be helpful to the community when comparing new VL methods with existing methods.,Does the review address Methodology?,FALSE,TRUE,It discusses findings and their relevance to the community but not the methods used.
The introduction of the motivation (the concept of in-context bias) is not easy to understand at the very beginning.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"Critiques the clarity of the introduction of the motivation, specifically the concept of in-context bias."
It would be good if the authors could provide some intuition / insight as to why that might be the case.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Suggests providing intuition or insight to explain a particular outcome.
Towards making the most of bert in neural machine translation.,Does the review address Related Work?,TRUE,FALSE,"The review title refers to the work involving BERT in neural machine translation, indicating a connection to existing research in the field."
"However, there is no discussion on the latency in the proposed method and experiments.",Does the review address Methodology?,TRUE,FALSE,Points out the lack of discussion on latency in the proposed method and experiments.
- The ablation experiments and optimized prompt analysis are insightful.,Does the review address Analysis?,TRUE,FALSE,Refers to the insightful analysis of ablation experiments and optimized prompt.
The paper features extensive experiments that convincingly validate the effectiveness of the proposed method.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review highlights that the experiments convincingly validate the effectiveness of the proposed method.
A qualitative analysis might be more revealing here.,Does the review address Analysis?,TRUE,FALSE,Suggests that a qualitative analysis would provide more insight.
This along with a regularization reward using language model the paper aims to improve comprehensibility.,Does the review address Methodology?,TRUE,FALSE,Refers to using a regularization reward with a language model to improve comprehensibility.
Otherwise for example it is not clear to me if the improvement in Blue compared to LaRL comes from the extra reward using the language model or from the options framework.,Does the review address Result?,TRUE,FALSE,Questions whether the improvement in BLEU score is due to the extra reward from the language model or the options framework.
"**Strengths** - To the best of my knowledge, this is the first work that _mathematically_ justifies the connection between the pre-training objective and the downstream performance.",Does the review address Methodology?,TRUE,FALSE,Refers to the mathematical justification of the connection between the pre-training objective and downstream performance.
Please feel free to highlight other major contributions.,Does the review address Contribution?,TRUE,FALSE,Invites the highlighting of other major contributions.
"- Less technical comments: The paper writing is fine to me, but I don't like the typesetting.",Does the review address Presentation?,TRUE,FALSE,Critiques the typesetting of the paper.
"Contribution: The authors contribute a new tokenization method, code, and a dataset.",Does the review address Data/Task?,TRUE,FALSE,Refers to the dataset contributed by the authors.
This is the newest of a small but growing body of literature that seeks to connect emergent communication with genuine NLP tasks.,Does the review address Related Work?,TRUE,FALSE,The review refers to the paper as part of a growing body of literature on emergent communication in NLP tasks.
"The authors argued that most of the previous multimodal LLMs used shallow connections between vision and models, and thus proposed a new module called visual expert.",Does the review address Related Work?,TRUE,FALSE,Discusses previous multimodal LLMs and contrasts them with the proposed visual expert module.
"In this case, the authors are using LeetCode coded solutions in MP to compiled the source code into a lower level form (assembly I believe) and then see if N-Bref can return the assembly back to the original form or some semantically equivalent form.",Does the review address Presentation?,FALSE,TRUE,It discusses the method used by the authors without addressing the clarity or structure of the paper.
"- For the classification tasks, what do the label distributions look like over the labeled subset $\mathcal L$?",Does the review address Data/Task?,TRUE,FALSE,Asks about the label distributions over the labeled subset in the classification tasks.
* Could the authors provide more details about the evaluation settings and number of parameters of each model for the per-token loss comparison?,Does the review address Methodology?,TRUE,FALSE,Requests more details about the evaluation settings and model parameters for the comparison.
The paper has explained and empirically showed that this learned generator needs a resampler.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Describes the explanation and empirical evidence supporting the need for a resampler in the learned generator.






"
Hon downstream tasks with smaller learning rate -> Do you mean smaller datasets?,Does the review address Data/Task?,TRUE,FALSE,"Questions whether ""smaller learning rate"" refers to smaller datasets."
"The proposed method has achieved SOTA performance on a range of Vision-Language benchmarks, spanning image captioning, Visual Question Answering, and visual grounding tasks.",Does the review address Methodology?,FALSE,TRUE,"It discusses the performance achieved by the proposed method across various tasks, but does not focus on the methods or techniques used."
"The studies here show that, pre-training with Inverse Cloze Task (ICT) the two-tower Transformer models significantly outperform the widely used BM-25 algorithm for large-scale information retrieval.",Does the review address Presentation?,FALSE,TRUE,"The review focuses on the studies and results of the model performance but does not address the clarity, structure, or organization of the paper."
### Overall  Authors used BERT alongside to a 2D-position embedding based on a sinusoidal function and a graph-based decoder to improve performance on document information extraction tasks.,Does the review address Result?,TRUE,FALSE,"Summarizes the use of BERT, a 2D-position embedding, and a graph-based decoder to improve performance on document information extraction tasks."
"According to the evaluation, the proposed method shows its effectiveness especially when the finetuning data is limited.",Does the review address Evaluation?,TRUE,FALSE,"Refers to the evaluation showing the effectiveness of the proposed method, particularly with limited fine-tuning data."
I found the result that the LSTM-based model successfully reconstructs the stimuli but fails on the main game to be interesting.,Does the review address Methodology?,FALSE,TRUE,It discusses an interesting result about the LSTM-based model's performance but does not focus on the methodology or techniques used.
It is based on the state-of-the-art language model--augmented memory.,Does the review address Methodology?,TRUE,FALSE,"Refers to the use of a state-of-the-art language model with augmented memory, which is part of the methodology or approach used in the study."
"Authors could have provided more in-depth details (visualizations, analysis, examples) to show main differences between the proposed approach and baselines (specially LayoutLM).",Does the review address Comparison?,TRUE,FALSE,"Refers to the differences between the proposed approach and baselines, specifically LayoutLM."
"For example, the model hyper-parameters are quite different for different tasks.",Does the review address Data/Task?,TRUE,FALSE,Refers to the different tasks requiring different model hyper-parameters.
The use of RNN and Copy RNN in the current context is a new idea.,Does the review address Methodology?,TRUE,FALSE,Highlights the use of RNN and Copy RNN as a new idea in the context of the study.
- There is some missing prior work in creating knowledge graphs from pre-trained language models.,Does the review address Related Work?,TRUE,FALSE,Refers to missing prior work on creating knowledge graphs from pre-trained language models.
"The motivation is very clear, MCTS is generally action agnostic and using language to provide additional semantic information to it can prove to be very effective.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Highlights the clear motivation for using language to enhance MCTS by providing additional semantic information.
"If there is some significant difference here, it is not made clear in the paper.",Does the review address Presentation?,TRUE,FALSE,Indicates that a significant difference is not clearly communicated in the paper.
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Result?,TRUE,FALSE,The technique is compared against other approaches and shows consistent performance improvement.
The authors should discuss the relationship with other in-context example selection methods and compare the performance.,Does the review address Result?,FALSE,TRUE,"It suggests discussing and comparing the relationship with other methods, but does not present specific results or findings."
It does not only require the optimization ability but also the oracle efficiency.,Does the review address Methodology?,TRUE,FALSE,Refers to the need for optimization ability and oracle efficiency as part of the methodology.
This paper proposed a new phrasal RNN architecture for sequence to sequence generation.,Does the review address Presentation?,FALSE,TRUE,It describes the proposed phrasal RNN architecture but does not focus on the clarity or structure of the paper.
- Removing the dependence of engineered perceptual models from the CaP method by using foundation models.,Does the review address Methodology?,TRUE,FALSE,Refers to the change in methodology by removing engineered perceptual models and using foundation models instead.
"Additionally, there are some minor things I would add or improve: - I would add references to multi-task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE).",Does the review address Methodology?,TRUE,FALSE,Suggests adding references to multi-task training for translation between different languages.
"- Additionally, why isn't the the GRU version of pRNNv reported in the FBIS evaluation in Table 3?",Does the review address Presentation?,TRUE,FALSE,Questions the omission of the GRU version of pRNNv in the FBIS evaluation in Table 3.
"- Weaknesses: In experiments, the author set the window width of the filters in the CNN module to 2.",Does the review address Experiment?,TRUE,FALSE,"Refers to the specific experimental setup, including the window width of the filters in the CNN module."
Use the text data that comes with each dataset as is and compare this with :   a) Using OpenAQA (current setting)   b) Augmenting the original audio text pairs with OpenAQA  2.,Does the review address Significance?,FALSE,TRUE,"It suggests a comparison of different settings, but does not discuss the impact or importance of the results."
The methods is evaluated on 5 standard NER+RE datasets with good performances.,Does the review address Data/Task?,TRUE,FALSE,Refers to the evaluation of the method on 5 standard NER+RE datasets.
"3.The model excels in various audio-related tasks and open-ended question answering, demonstrating its outstanding performance.",Does the review address Data/Task?,TRUE,FALSE,Refers to the model's performance on audio-related tasks and open-ended question answering.
"However, it seems like there's still some open questions about the types of improvements being made and what this implies about the LM's attention mechanism.",Does the review address Methodology?,TRUE,FALSE,Discusses open questions regarding the improvements and their implications on the language model's attention mechanism.
The authors take time to implement and evaluate several prominent baselines.,Does the review address Presentation?,FALSE,TRUE,"It focuses on the implementation and evaluation of baselines, not the clarity or structure of the paper."
"Kernel-based variants of self-attention have a recurrent formulation and lead to linear complexity (see [1,2,3,4]).",Does the review address Methodology?,TRUE,FALSE,"Refers to kernel-based variants of self-attention with a recurrent formulation, which is part of the methodology discussed."
Statistical comparisons of classifiers over multiple data sets.,Does the review address Related Work?,FALSE,TRUE,"It refers to statistical comparisons of classifiers, but does not discuss or compare relevant literature."
"High-level view:  I don’t think this is necessarily a bad paper, but I think it’s unacceptable for ICLR in its current form.",Does the review address Evaluation?,TRUE,FALSE,Provides an assessment of the paper's suitability for ICLR in its current form.
This is very likely a confounding factor in the efficacy of active learning and pruning techniques.,Does the review address Methodology?,TRUE,FALSE,"Refers to active learning and pruning techniques, which are part of the methodology being discussed."
The LSTM classifier is left highly unspecified (L407-409) -- there are multiple different architectures to use an LSTM for classification.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out the lack of specification for the LSTM classifier and the need for further explanation or discussion.
"If the authors can adequately address the following issues around presentation and the interpretation of Theorem 5, I would be satisfied raising my score, as I value the research question raised by the paper and believe the conclusions are valid.",Does the review address Theory?,TRUE,FALSE,"Refers to the interpretation of Theorem 5, which is related to the theoretical foundations of the paper."
The findings from the analysis are an important addition to the understanding of the role of language specific parameters in multilingual NMT.,Does the review address Result?,TRUE,FALSE,Refers to the findings from the analysis and their importance in understanding language-specific parameters in multilingual NMT.
- The objectives suggested are cheap to compute and seem to increase the signal available in the data.,Does the review address Data/Task?,TRUE,FALSE,Refers to the signal available in the data and how the objectives impact it.
"Considering the BERT is leveraged, you should discuss the relation with BERT + NMT [R1,R2].",Does the review address Methodology?,TRUE,FALSE,"Suggests discussing the relationship between BERT and NMT, which pertains to the methodology."
The results presented in the paper show strong gains against baseline methods on 3 different datasets.,Does the review address Result?,TRUE,FALSE,Discusses the strong gains presented in the paper against baseline methods on different datasets.
This paper claims that it is the first time designing a reasoning comprehension-capable model.,Does the review address Methodology?,FALSE,TRUE,It discusses the claim about the novelty of the model but does not focus on the methods or techniques used.
"Can the theory extend to cross-language clone detection, e.g., one language is tractable, but the other language is not?",Does the review address Theory?,TRUE,FALSE,"Questions whether the theory can extend to cross-language clone detection, which involves theoretical considerations."
This method should be included in the experiments in order to justify the proposed RL approach is necessary.,Does the review address Methodology?,TRUE,FALSE,Suggests including a method in the experiments to justify the necessity of the proposed RL approach.
Can the proposed theory help explain if the same code modeling task for some languages is strictly easier than the others?,Does the review address Theory?,TRUE,FALSE,Questions whether the proposed theory can explain differences in the difficulty of the same code modeling task across languages.
"In terms of strenghs - The paper has a very throughout analysis of different models and positional encodings - It proposes several contributions, including a new probing task and several positional encoding methods.",Does the review address Presentation?,FALSE,TRUE,"It discusses the strengths of the paper and the contributions, but not the clarity or structure of the paper itself."
"- P6, Sec 4.3: ""In fact, $f$ almost always performs better than ..."" This part seems intriguing despite the linear relationship shown in figure 1.",Does the review address Result?,TRUE,FALSE,Refers to the performance comparison mentioned in Section 4.3 and Figure 1.
The results on a mixture of the Parity/Sum task are interesting   2.,Does the review address Result?,TRUE,FALSE,Refers to the results on a mixture of the Parity/Sum task.
"Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally.",Does the review address Experiment?,TRUE,FALSE,Refers to the validation of the proposed recommendations through experiments.
"Also, can you add a column where a dense linear model over p_f(s) is used?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Suggests adding a column where a dense linear model over 𝑝_𝑓(𝑠) is used, which involves clarifying the details or description."
"* It will be cool to show some results on BLEU improvement on machine translation, or user studies on language generation tasks, to demonstrate its practical impact, as the quantitative metrics right now are still kind of artificial.",Does the review address Data/Task?,TRUE,FALSE,"Suggests showing results on BLEU for machine translation or user studies for language generation tasks, which relate to specific tasks being evaluated."
"Your work is so similar to much of this work that you should really cite and establish novelty wrt at least some of them as early as the introduction -- that's how early I was wondering how your work differed, and it was not made clear.",Does the review address Related Work?,TRUE,FALSE,Suggests citing and establishing novelty with respect to existing work early in the introduction.
"The article is well-structured, starting with a thorough discussion on the shortcomings of naive backdoor-type watermarking methods before delving into their novel DOUBLE-I WATERMARKING FRAMEWORK.",Does the review address Methodology?,TRUE,FALSE,"Describes the novel DOUBLE-I watermarking framework, which is part of the methodology discussed in the paper."
"For CSQA, the best number in this paper is 63.32 vs. 79.5 on the current leaderboard.",Does the review address Result?,TRUE,FALSE,Compares the performance on CSQA with the current leaderboard results.
The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).,Does the review address Presentation?,FALSE,TRUE,"It discusses the experimental results and their applicability to the downstream task, but does not focus on the clarity or structure of the paper."
"So I suggest that the authors give a technical introduction of the framework and more precisely discuss how it can solve the problem of interest, possibly with visual illustrations.",Does the review address Methodology?,TRUE,FALSE,"Suggests giving a technical introduction to the framework and discussing how it solves the problem, which pertains to the methodology."
"For example, if you could give us one or two sentences of Fon in the beginning of the paper, that demonstrate some of the difficulties of the language, I think this would greatly strengthen the motivation.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests providing examples to better explain and strengthen the motivation.
"- The paper is well-written, well-organized, and easy to follow.",Does the review address Presentation?,TRUE,FALSE,"Compliments the paper's clarity, organization, and readability."
"For instance, they ask how different amounts of data influence model behavior or if their data sampling method can react to task difficulty.",Does the review address Methodology?,TRUE,FALSE,"Refers to how different amounts of data influence model behavior and the data sampling method, which are related to the methodology."
"However, the paper does not include detailed descriptions about the proposed method, making readers not easy to understand.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Points out the lack of detailed descriptions about the proposed method, making it harder to understand."
"The study sheds light on the amount of language specific parameter sharing, their distribution in the network, impact of language, etc.",Does the review address Methodology?,TRUE,FALSE,"Discusses the study's exploration of language-specific parameter sharing, their distribution, and the impact of language, which relates to the methodology."
"In a similar vein, I would have appreciated more details about the model architecture and the training regimes used (possibly in the appendix).",Does the review address Presentation?,TRUE,FALSE,"Suggests adding more details about the model architecture and training regimes, likely to improve clarity and organization."
"However, there is a lack of unified experimental standards and ablation experiments in this paper.",Does the review address Experiment?,TRUE,FALSE,Critiques the lack of unified experimental standards and ablation experiments in the paper.
"These objectives certainly improve over the original T5 base _and_ larges models that are used as initializations, and especially outperform the base model in the low-data regime.",Does the review address Data/Task?,TRUE,FALSE,"Refers to the performance improvement of T5 base and large models in the low-data regime, which involves tasks related to data usage."
The authors only conduct the evaluation on sentence similarity tasks and open domain QA tasks.,Does the review address Data/Task?,TRUE,FALSE,Refers to the evaluation being conducted on sentence similarity tasks and open domain QA tasks.
I found the result that the LSTM-based model successfully reconstructs the stimuli but fails on the main game to be interesting.,Does the review address Result?,TRUE,FALSE,Discusses the interesting result of the LSTM-based model's performance in reconstructing stimuli and failing on the main game.
(3) The loss for answer prediction in Eq 6 is not clearly described: do you use an aggregated embedding over all nodes for prediction?,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Questions the clarity of the loss description in Eq 6, specifically regarding the use of an aggregated embedding for prediction."
"In this way, the conclusion is only supported by the empirical observations but not the presented theoretical analysis.",Does the review address Theory?,TRUE,FALSE,Critiques the conclusion for being supported by empirical observations rather than the presented theoretical analysis.
The usage of attention mechanism without some sort of pruning might be problematic at the phrasal level.,Does the review address Methodology?,TRUE,FALSE,"Discusses the potential issue of using the attention mechanism without pruning at the phrasal level, which relates to the methodology."
This paper describes four methods of obtaining multilingual word embeddings and a modified QVEC metric for evaluating the efficacy of these embeddings.,Does the review address Evaluation?,TRUE,FALSE,Refers to the modified QVEC metric used for evaluating the efficacy of multilingual word embeddings.
"Detailed comments:  Training (especially pretraining) costs have been going wild in AI and NLP more particularly, which leads to large costs ([1]) as well as potential environmental problems ([2]).",Does the review address Methodology?,FALSE,TRUE,"It discusses the costs and potential environmental impact of training and pretraining, but not the methods or techniques used in the study."
"I would have thought this was training an LM on progressively larger portions of the relevant data (being used for fine-tuning the others), in which case I'd also expect a downward trend in perplexity.",Does the review address Data/Task?,TRUE,FALSE,Discusses the expectation of a downward trend in perplexity based on progressively larger portions of the relevant data.
"Also, different programmers write comments very differently.",Does the review address Analysis?,FALSE,TRUE,"It comments on the variability in how programmers write comments, but does not involve an analysis of data, methods, or results."
"3) Continue with 2), as the experiment results shown in Table 2, TS compiler performs poorly.",Does the review address Result?,TRUE,FALSE,"Refers to the experiment results shown in Table 2, specifically the poor performance of the TS compiler."
The wide range of datasets and active learning techniques they use (including BALD which prior works shows is very competitive) lends credence to the conclusions.,Does the review address Methodology?,TRUE,FALSE,"Refers to the use of various datasets and active learning techniques, including BALD, as part of the methodology."
"In Table 1, the baseline models are TreeRNN and DCNN, they are originally used for sentence embedding but one can easily take the node/substructure embedding from them too.",Does the review address Methodology?,TRUE,FALSE,"Discusses baseline models like TreeRNN and DCNN and how their embeddings can be adapted, which relates to the methodology."
"## Justification As my primary critique concerns the experiments, I will address each individually mentioning any deficiencies and potential improvements.",Does the review address Experiment?,TRUE,FALSE,Focuses on addressing critiques related to the experiments and suggesting improvements.
"Result 1: Under the above assumption over the downstream task, this paper provides a bound on the empirical loss of the downstream prediction task.",Does the review address Result?,TRUE,FALSE,Refers to the bound on the empirical loss of the downstream prediction task as a result presented in the paper.
"It is unclear to me how the authors are going to justify this ""assumption"".",Does the review address Presentation?,FALSE,TRUE,It questions the justification of an assumption but does not focus on the clarity or structure of the paper.
"By using a multimodal, the current approach attain the problem of polysemy.",Does the review address Methodology?,TRUE,FALSE,"Refers to the use of a multimodal approach to address the issue of polysemy, which is part of the methodology."
"- Figure 1: unclear why certain input sizes have their accuracy going down, even though they have reached 100% in the earlier epochs.",Does the review address Presentation?,TRUE,FALSE,"Questions the clarity of Figure 1, specifically regarding the accuracy behavior and its explanation."
Concerns around novelty and the multi-task setup was also raised by another reviewer (e7Hg).,Does the review address Novelty?,TRUE,FALSE,Refers to concerns raised about the novelty of the multi-task setup.
"However, there is no theoretical result about the effectiveness of assigning the self-knowledge distillation to label smoothing.",Does the review address Methodology?,TRUE,FALSE,"Points out the lack of a theoretical result regarding the effectiveness of assigning self-knowledge distillation to label smoothing, which pertains to the methodology."
The proposed method achieves SoTA results on CommonGen with slightly more than half the parameters of the current SoTA model.,Does the review address Result?,TRUE,FALSE,"Refers to the SoTA results achieved by the proposed method on CommonGen, with a comparison to the current SoTA model."
"- P6, Sec 4.3: ""In fact, $f$ almost always performs better than ..."" This part seems intriguing despite the linear relationship shown in figure 1.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Finds the statement intriguing and suggests further explanation despite the linear relationship shown in Figure 1.
"- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other ""oracle"" baselines.",Does the review address Evaluation?,TRUE,FALSE,Refers to the evaluation of wMAN on publicly available datasets and its comparison with state-of-the-art methods and baselines.
It is hard for other users to apply this technique.,Does the review address Methodology?,TRUE,FALSE,"Suggests that the technique is difficult for other users to apply, which relates to the methodology being discussed."
"Other concerns along these lines: all of this paper's results are averaged over 3 runs while the other baselines are over 5 runs - an indication of variance would be useful to assess whether the differences are significant, especially since some of the margins quite small (23 on MC-LAVE-RL vs 22.8 for the next best on Ludicorp) added to the fact that hyperparameters are different for each game - does that imply that the authors tuned the hyperparameters for each game?",Does the review address Result?,TRUE,FALSE,"Discusses the averaging of results over 3 runs, the need for variance analysis, and the significance of small margins, which are related to the results presented in the paper."
One very simple way could be to analyze the occurrence frequency of interleaved natural and programming patterns in the dataset.,Does the review address Analysis?,TRUE,FALSE,Suggests analyzing the occurrence frequency of interleaved natural and programming patterns in the dataset.
First theoretical definition of equivalence-preserving program embedding problem.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Refers to the theoretical definition of the equivalence-preserving program embedding problem, which involves explaining or describing a concept."
"The first is selecting the most uncertain examples, and the second is making the CoT annotations longer.",Does the review address Data/Task?,TRUE,FALSE,"Refers to selecting uncertain examples and making CoT annotations longer, which relates to the task or data being used."
"The evaluation results are based on the authors' implementations, for both baseline and the proposed method.",Does the review address Methodology?,TRUE,FALSE,Refers to the evaluation being based on the authors' implementations of both the baseline and proposed method.
The main weakness of the paper is that it is mainly based on further tuning the existing BERT model and lacks novel contribution in model architecture.,Does the review address Methodology?,TRUE,FALSE,Critiques the methodology for focusing on further tuning the existing BERT model without introducing novel contributions in the model architecture.
"... bunch of those errors has should be ""errors have"".",Does the review address Presentation?,TRUE,FALSE,"The review points out a grammatical error (""has"" should be ""have""), which relates to the clarity and language quality in the paper."
The paper provides a comprehensive study on the two-tower Transformer models in terms of the impact of its pre-training tasks on large-scale retrieval applications.,Does the review address Methodology?,TRUE,FALSE,"Refers to the study of two-tower Transformer models and the impact of pre-training tasks, which relates to the methodology used in the research."
The method relies much upon manual designs that seem hard to generalize.,Does the review address Presentation?,FALSE,TRUE,"It critiques the method for relying on manual designs, but does not address the clarity or structure of the paper."
"So how would it be possible to train with poor annotations, while generalize much better?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Asks for an explanation or discussion on how training with poor annotations could lead to better generalization.
What if a similar sample exists in a quite different source task?,Does the review address Data/Task?,TRUE,FALSE,Refers to the existence of a similar sample in a different source task.
"In experiments, there is no comparison with previous retrieval based methods.",Does the review address Experiment?,TRUE,FALSE,Points out the lack of comparison with previous retrieval-based methods in the experiments.
The need for short sequence acceleration needs to be justified IMO.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Calls for justification of the need for short sequence acceleration.
"Indeed, the proposed graph model seems to only implicitly convey knowledge across facts in terms of local reasoning.",Does the review address Methodology?,TRUE,FALSE,"Discusses how the proposed graph model conveys knowledge through local reasoning, which relates to the methodology used."
The idea was (reasonably) well-positioned with respect to prior work and clearly presented.,Does the review address Related Work?,TRUE,FALSE,Refers to how the idea is positioned with respect to prior work.
Ablation studies show that the model achieves good performance on more complex questions.,Does the review address Result?,TRUE,FALSE,Refers to the good performance achieved by the model on more complex questions as shown by ablation studies.
Hon downstream tasks with smaller learning rate -> Do you mean smaller datasets?,Does the review address Presentation?,FALSE,TRUE,"It asks for clarification regarding the learning rate, but it does not discuss the clarity or structure of the paper."
"The paper has ""support set"" and ""support instructions"" at many places but it is unclear to me what it actually means.",Does the review address Presentation?,TRUE,FALSE,"Points out the lack of clarity in the use of terms like ""support set"" and ""support instructions."""
### Summary ### The paper presents a technique for inference of certain kinds of program invariants directly from the program’s source code.,Does the review address Methodology?,TRUE,FALSE,"Describes a technique for inferring program invariants from source code, which is part of the methodology."
"However, the BERT analysis results provided in this paper should also be valuable to the community.",Does the review address Methodology?,FALSE,TRUE,It discusses the value of the BERT analysis results but does not focus on the methods or techniques used.
Strength: + Describes an important property of program embeddings: they should remain invariant to semantic-preserving transformations.,Does the review address Methodology?,TRUE,FALSE,"Describes an important property of program embeddings, which relates to the methodology of how they are used and evaluated."
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Presentation?,FALSE,TRUE,It discusses the theoretical aspects of language models but does not focus on the clarity or structure of the paper.
"The authors only put a sentence at the end of the Appendix saying that “we still found PEER to generate false statements or claims not backed up by the provided documents in many cases“, but in the main paper there is no discussion or statistics on this weakness.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Points out the lack of discussion or statistics on the weakness of PEER in the main paper, which requires more explanation or detail."
"- Weaknesses: In experiments, the author set the window width of the filters in the CNN module to 2.",Does the review address Methodology?,TRUE,FALSE,"Refers to the specific experimental setup, including the window width of the filters in the CNN module, which relates to the methodology."
"### Cons and aspects to improve  My main concern is that the overall contribution is seems to be limited.In fact, the original paper of the Transformer approach, already proposed such kind of embedding.",Does the review address Contribution?,TRUE,FALSE,"Critiques the paper's contribution, suggesting that it is limited and similar to the original Transformer approach."
"These are not weakness, but I think some work in this direction may help improve the paper.",Does the review address Presentation?,FALSE,TRUE,It suggests improvements in a specific direction but does not address the clarity or structure of the paper itself.
"By associating nodes across different fact units based on coreferences and mentions, a supergraph is built that connects all related information and conducts graph reasoning for answer predictions.",Does the review address Methodology?,TRUE,FALSE,"Describes the process of building a supergraph and using graph reasoning for answer predictions, which is part of the methodology."
A three-line explanation at the end of Section 4.1 seems a bit scarce to me.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques the explanation in Section 4.1 for being too brief and lacking sufficient detail.
"## Justification As my primary critique concerns the experiments, I will address each individually mentioning any deficiencies and potential improvements.",Does the review address Result?,FALSE,TRUE,"It focuses on the critique of experiments, not on the results themselves."
"It provides a nice theoretical framework for thinking about the connection between language models and downstream tasks, which future work could build on.",Does the review address Methodology?,TRUE,FALSE,"Describes the theoretical framework for understanding the connection between language models and downstream tasks, which relates to the methodology."
"Figure from LayoutLM is a good example of that, it comprises the entire process and makes it easier to understand the whole architecture.",Does the review address Methodology?,TRUE,FALSE,"Refers to the use of a figure from LayoutLM to help understand the architecture, which is part of explaining the methodology."
The experimentation is correct and the qualitative analysis made in table 1 shows results as expected from the approach.,Does the review address Analysis?,TRUE,FALSE,Refers to the qualitative analysis shown in Table 1 and the results expected from the approach.
"It's ok for the proposed method to be one particular way, but that discussion would be useful.",Does the review address Methodology?,TRUE,FALSE,"Suggests that a discussion of the proposed method would be useful, which pertains to the methodology."
The difference in the ablation results seem quite small (tables 3 and 4).,Does the review address Ablation?,TRUE,FALSE,"Refers to the ablation results in Tables 3 and 4, discussing the small differences observed."
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Experiment?,TRUE,FALSE,Refers to the ablation study and visualization analysis of the experimental results.
I can not understand why sample-specific rather than task-specific preference is important for prompt tuning.,Does the review address Methodology?,TRUE,FALSE,"Questions the importance of sample-specific preference over task-specific preference in the context of prompt tuning, which relates to the methodology."
"HRL in general has been used previously for goal-oriented dialog, using language models to regularize RL models has been used and pertaining using SL is widely used.",Does the review address Methodology?,TRUE,FALSE,"Discusses the use of HRL for goal-oriented dialogue and the integration of language models with RL and SL, which pertains to the methodology."
The paper does a systematic analysis on the role of language specific parameters using the proposed architecture.,Does the review address Methodology?,TRUE,FALSE,"Refers to the systematic analysis of language-specific parameters using the proposed architecture, which is part of the methodology."
"It would have been better to see the performance gains on more difficult text-classification tasks (non-GLUE), or underperforming models (non-BERT based).",Does the review address Methodology?,TRUE,FALSE,"Suggests testing the proposed method on more difficult text-classification tasks and underperforming models, which relates to the methodology of the study."
"For table 4, please also include the significance of the BLEU improvement made by the pRNN with respect to the the baseline, see https://github.com/jhclark/multeval General Discussion ==== As the main contribution of this work is on the phrasal effect of the new RNN architecture, it's rather important to show that the phrases are more coherent than the vanilla LSTM / RNN model.",Does the review address Comparison?,TRUE,FALSE,Suggests including the significance of the BLEU improvement made by the pRNN compared to the baseline and discusses the comparison of phrase coherence with the vanilla LSTM/RNN model.
"In the experiment section, the authors only include the CoT annotations from [1] as the most important baseline.",Does the review address Experiment?,TRUE,FALSE,Refers to the inclusion of CoT annotations from [1] as the most important baseline in the experiment section.
This would probably highlight LTU significantly as the two approaches are contemporary in many ways and are very similar in the overarching goal.,Does the review address Significance?,TRUE,FALSE,Suggests that highlighting LTU could significantly demonstrate its relevance due to its similarities with the two approaches in terms of goals.
"Numerous neural architectures have been used to model programs, e.g., large language models, graph neural networks, etc.",Does the review address Presentation?,FALSE,TRUE,"It discusses various neural architectures used to model programs but does not address the clarity, structure, or organization of the paper."
**Limitations** - The authors admit that their work is limited to a particular type of downstream tasks.,Does the review address Data/Task?,TRUE,FALSE,Refers to the limitation of the work being applicable to a particular type of downstream tasks.
"1.The paper introduces for the first time a large language model that combines both general audio perception capabilities and language reasoning abilities, along with the datasets used for training.",Does the review address Data/Task?,TRUE,FALSE,"Refers to the datasets used for training the large language model, which is part of the data/task discussed."
"There are many confounding factors such as the number and type of pretraining data, the instruction-tuning data, different architecture designs, and finetuning strategies.",Does the review address Methodology?,TRUE,FALSE,"Discusses confounding factors such as pretraining data, instruction-tuning data, architecture designs, and finetuning strategies, which are related to the methodology."
- It would be great if authors could incorporate more baseline methods.,Does the review address Methodology?,TRUE,FALSE,"Suggests incorporating more baseline methods, which is related to the methodology used in the study."
"Comments on the model: - After computing the substructure embeddings, it seems very natural to compute an attention over them at each word.",Does the review address Methodology?,TRUE,FALSE,"Discusses the process of computing substructure embeddings and using attention over them, which relates to the methodology of the model."
"It considers the training direction to be ""first to perceive, and then comprehend the sound"" so that the training starts from using close-ended datasets to open-ended datasets.",Does the review address Methodology?,TRUE,FALSE,"Refers to the training direction and the use of close-ended to open-ended datasets, which are part of the methodology."
Details of training and dataset are logical and delicate.,Does the review address Methodology?,TRUE,FALSE,"Refers to the logical and delicate details of training and the dataset, which are part of the methodology."
Would be great to state them upfront to avoid confusion.,Does the review address Presentation?,TRUE,FALSE,"Suggests stating the details upfront to avoid confusion, which relates to the clarity and structure of the paper."
I suspect the size plays an important role in such setups and this hasn't been discussed much in the paper.,Does the review address Significance?,TRUE,FALSE,"Suggests that the size plays an important role and should be discussed, highlighting its significance in the context of the setup."
"It provided me with a much more thoughtful explanation for why language model pre-training improves downstream task performance, beyond simply “it helps learn good general representations of language using large amounts of unlabeled text data” (my previous reasoning).",Does the review address Data/Task?,FALSE,TRUE,"It discusses the explanation for why language model pre-training improves downstream task performance, but does not focus on the data or task itself."
"It requires more analysis about experimental results, such as Figure 1 and tables in Section D.",Does the review address Result?,TRUE,FALSE,"Suggests more analysis of the experimental results, such as Figure 1 and tables in Section D."
All of the results in this work seem to be previously known: * Theorem 1 is general to any polynomial-size circuit -- there is nothing special about Transformers.,Does the review address Result?,TRUE,FALSE,Refers to the results being previously known and discusses Theorem 1 in relation to polynomial-size circuits.
"But I support given a fixed set of phrase pairs at train time, the attention mechanism at the phrasal level can be pre-computed but at inference (apply the attention on new data at test time), this might be kind of problematic when the architecture is scaled to a larger dataset.",Does the review address Data/Task?,TRUE,FALSE,"Discusses the application of the attention mechanism on new data at test time, which relates to how the model interacts with the dataset or task."
"Furthermore, when there is a gap between the empirical results and the theoretical results (e.g., validation of Lemma 4.3 at the end of Section 4), the paper makes these limitations clear, which I appreciated very much as a reader (paper does not over-claim its contributions).",Does the review address Contribution?,TRUE,FALSE,"Appreciates how the paper clearly addresses the limitations of its empirical and theoretical results, avoiding over-claiming its contributions."
"Are there any overheads/disadvantages because of multi-task learning (Like a larger model size, inference time for individual tasks etc)?",Does the review address Methodology?,TRUE,FALSE,"Questions potential overheads or disadvantages of multi-task learning, such as model size and inference time, which relate to the methodology used."
"in Table 2, it's necessary to explain why the LSTM's perplexity from previous work is higher than the author's implementation.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Points out the need to explain the difference in perplexity between the LSTM from previous work and the author's implementation, which requires further discussion or clarification."
One of the important motivations of multi-modal multi-task learning mentioned was to achieve better or on-par performance with a single model (and supposedly fewer computations) which is crucial for devices with limited computing resources.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"Discusses the motivation behind multi-modal multi-task learning to achieve better or on-par performance with fewer computations, especially for devices with limited computing resources."
"Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Refers to the validation of the proposed recommendations on multilingual NMT architectures through experimentation.
"The authors say ""we focus on larger datasets from GLUE (MNLI, QNLI, QQP and SST-2), as it is less meaningful to discuss efficient training"", but then report and analyze results from other GLUE datasets as well.",Does the review address Result?,TRUE,FALSE,"Points out the reporting and analysis of results from other GLUE datasets, even though the focus was on larger datasets."
I think the story starts with pointing out the importance for long-sequence but turns to the topic on short sequence which is confusing.,Does the review address Presentation?,TRUE,FALSE,"Points out that the shift in focus from long-sequence to short-sequence is confusing, which relates to the clarity and structure of the paper."
"The computation of RFA requires outer product, which is O(D^2d) so overall it's O(M D^2 d), if M is around 64 or 128 (common usage) and D is 64, I actually don't see why RFA could improve 2x.",Does the review address Result?,TRUE,FALSE,"Discusses the computation of RFA and questions why it would lead to a 2x improvement, relating to the expected result."
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Comparison?,FALSE,TRUE,"It discusses the lack of improvements over baselines and the realism of the assumptions, but does not directly compare the proposed method to other methods."
"DP is not ""incorporated"" in a model or multimodality (as the authors mention in different ways a few times throughout the paper), DP is a property of a randomised algorithm (in this context, the training algorithm that produces the distribution of models, not the model).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Clarifies the concept of DP and its distinction from being incorporated in a model or multimodality, which involves providing a more accurate description or interpretation."
I felt this was quite separate from the theoretical analysis.,Does the review address Result?,FALSE,TRUE,It discusses the separation of the point from the theoretical analysis but does not refer to any specific results or findings.
"Furthermore, they have clarified that on the key metric of CommonGen they achieved SoTA with only slightly more than half the parameters of the current SoTA model.",Does the review address Methodology?,FALSE,TRUE,"It discusses the performance achievement on the key metric of CommonGen, but does not focus on the methods or techniques used."
"So I also have a few doubts about this article:  (1) This paper uses 6B T5-V1.1, but the previous baseline work only GTRxxl has the same size, while ColBERTv2 using multi-vector retrieval model has only 110m model size.",Does the review address Methodology?,TRUE,FALSE,"Compares the model sizes used in the paper (6B T5-V1.1) with the previous baseline (GTRxxl and ColBERTv2), which relates to the methodology."
"Your work obviously is different enough to stand on its own, but it might be good to make a mention of this work and others (e.g. do more of a lit search / related work on low rank compression).",Does the review address Related Work?,TRUE,FALSE,Suggests doing a literature search and mentioning related work on low-rank compression.
Strengths: - Unifying generative and contrastive training is an important and interesting goal.,Does the review address Presentation?,FALSE,TRUE,"It discusses the strength of unifying generative and contrastive training, but does not address the clarity, structure, or organization of the paper."
The PACT methodology: The paper proposes a methodology for extracting auxiliary tasks that can be trained jointly along with the main task (tactic prediction task).,Does the review address Methodology?,TRUE,FALSE,Refers to the proposed methodology for extracting auxiliary tasks to be trained jointly with the main task.
"However, it seems like there's still some open questions about the types of improvements being made and what this implies about the LM's attention mechanism.",Does the review address Result?,FALSE,TRUE,"It discusses open questions regarding improvements and the implications for the LM's attention mechanism, but does not focus on specific results."
"The main contribution are the following innovations: a special attention mechanism called block-diagonal conditional attention, a set of modules for adaptation of a pretrained model, and an uncertainty-based multi-task data sampling method.",Does the review address Methodology?,TRUE,FALSE,"Describes the innovations in the attention mechanism, model adaptation modules, and multi-task data sampling method, which are all related to the methodology."
The evaluation method uses CCA to maximize the correlation between the word embeddings and possibly hand crafted linguistic data.,Does the review address Evaluation?,TRUE,FALSE,Refers to the use of CCA in the evaluation method to maximize the correlation between word embeddings and linguistic data.
The findings illustrate the substantial impact this choice can have on the final model's behavior.,Does the review address Methodology?,TRUE,FALSE,"Refers to the impact of a specific choice on the final model's behavior, which relates to the methodology used in the study."
Both settings show the better performance of the proposed method.,Does the review address Result?,TRUE,FALSE,Refers to the better performance of the proposed method in both settings.
"Secondly, the design of the specific neural network cannot describe the theory behind proposed binding-unbinding mechanism properly.",Does the review address Theory?,TRUE,FALSE,Critiques the design of the neural network for not properly describing the theory behind the proposed binding-unbinding mechanism.
"* In the abstract, authors say ""BROS utilizes a powerful graph-based decoder that can capture the relation between text segment""* Though in the text such a component (that is from other work) is only mentioned twice without further detail.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out the lack of detail or further discussion on the graph-based decoder mentioned in the abstract.
The findings of (2)(3)(4)(5) mentioned in the summary section above are especially interesting and can be helpful to the community when comparing new VL methods with existing methods.,Does the review address Result?,TRUE,FALSE,Refers to the findings discussed in the summary section and their potential to help the community in comparing new VL methods with existing ones.
"This paper makes comparison with techniques used in active learning (AL), domain shift detection (DS), and multi-domain sampling to combine data from multiple sources.",Does the review address Comparison?,TRUE,FALSE,"Discusses the comparison with techniques in active learning, domain shift detection, and multi-domain sampling."
"Unfortunately, as the paper overall does not seem to contain significant novelty, neither in methodology nor in results, I cannot recommend acceptance at this point.",Does the review address Methodology?,TRUE,FALSE,Critiques the paper for lacking significant novelty in both methodology and results.
"First of all, the dense interaction between vision and language tokens has been heavily studied prior to the so-called multimodal LLM era.",Does the review address Methodology?,TRUE,FALSE,"Discusses the dense interaction between vision and language tokens, which pertains to the methodology used in prior studies."
"However, in its current state - the comparisons made are not meaningful which makes the claim of state of the art tenuous (state of the art does not matter so much as showing that you make progress in line with the motivation).",Does the review address Comparison?,TRUE,FALSE,"Critiques the comparisons made in the paper, stating that they are not meaningful, which weakens the claim of state-of-the-art performance."
"Additionally, there are some minor things I would add or improve: - I would add references to multi-task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE).",Does the review address Data/Task?,TRUE,FALSE,"Suggests adding references to multi-task training for translation between different languages, which relates to specific tasks."
Is it possible to import a public SOTA implementation and conduct comparisons based on that?,Does the review address Comparison?,TRUE,FALSE,"Suggests importing a public SOTA implementation to conduct comparisons, which directly relates to comparing the proposed method with existing methods."
- I don't see why your theory does not generalize to a _masked_ language modeling (MLM).,Does the review address Methodology?,TRUE,FALSE,"Questions why the theory does not generalize to masked language modeling (MLM), which relates to the methodology being discussed."
The paper provides a comprehensive study on the two-tower Transformer models in terms of the impact of its pre-training tasks on large-scale retrieval applications.,Does the review address Data/Task?,TRUE,FALSE,"Refers to the impact of pre-training tasks on large-scale retrieval applications, which is related to the task being evaluated."
"- OpenAQA-5M is a good contribution to provide open-ended question answering in audio domain, especially it is verified with human evaluation.",Does the review address Data/Task?,TRUE,FALSE,"Refers to OpenAQA-5M as a contribution for open-ended question answering in the audio domain, which is related to the task being evaluated."
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Comparison?,TRUE,FALSE,Discusses comparing the proposed technique with other existing selective annotation approaches and showing that it consistently outperforms them.
"How does Theorem 2 come into play when proving Theorem 3, if Theorem 3 can be proved independently?",Does the review address Theory?,TRUE,FALSE,"Questions the role of Theorem 2 in proving Theorem 3, which involves a discussion of the theoretical foundations."
An additional ablation experiment trying different number of tokens to optimize could be illuminating (even for just 1 dataset).,Does the review address Ablation?,TRUE,FALSE,"Suggests an additional ablation experiment to try different numbers of tokens to optimize, which relates to ablation studies."
"That is, by ""general learner"" the authors mean a model that can *express* a universal circuit.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Clarifies what is meant by ""general learner"" and its relationship to expressing a universal circuit."
Could the authors list some possible approaches to automatically choose this hyper-parameter please?,Does the review address Methodology?,TRUE,FALSE,"Suggests listing possible approaches for automatically choosing the hyper-parameter, which pertains to the methodology."
"- From the diversity and representativeness measures shown in Table 10 in Appendix F, the difference between Random and vote-*k* does not appear to be very large.",Does the review address Presentation?,TRUE,FALSE,"Refers to the presentation of the diversity and representativeness measures in Table 10, highlighting the small difference between Random and vote-k."
Such a comparison would highlight the advantages of the multi-task model and would be helpful for the relevant audience.,Does the review address Comparison?,TRUE,FALSE,"Suggests that a comparison would highlight the advantages of the multi-task model, which relates to comparing it with other models."
"This line of work could be much stronger if the models comprised the whole process (detection, text extraction, recognition) in an end-to-end manner.",Does the review address Methodology?,TRUE,FALSE,"Suggests that the models would be stronger if they comprised the entire process (detection, text extraction, recognition) in an end-to-end manner, which relates to the methodology."
"While the exact choice depends on the dataset characteristics, a framework will be more attractive if it can perform well on different scenarios.",Does the review address Presentation?,FALSE,TRUE,"It discusses the attractiveness of a framework based on its performance across different scenarios, but does not focus on the clarity or structure of the paper."
## Strengths - The environment is novel and provides a good basis for studying certain traits of continuous-channel referential games.,Does the review address Novelty?,TRUE,FALSE,"Highlights the novelty of the environment, providing a good basis for studying certain traits of continuous-channel referential games."
"The proposed method has achieved SOTA performance on a range of Vision-Language benchmarks, spanning image captioning, Visual Question Answering, and visual grounding tasks.",Does the review address Result?,TRUE,FALSE,Refers to the achieved SOTA performance on a range of Vision-Language benchmarks.
The use of RNN and Copy RNN in the current context is a new idea.,Does the review address Novelty?,TRUE,FALSE,Highlights the use of RNN and Copy RNN as a new idea in the current context.
"Running a baseline model that runs *for the same amount of time* is essential to appreciate the contribution of this work (e.g., repeat the same analysis in Figure 3 for the vanilla BERT).",Does the review address Contribution?,TRUE,FALSE,Suggests running a baseline model for the same amount of time to properly appreciate the contribution of the work.
"This is immediate from Theorem 2, and this kind of separation appears to have been the implicit the point of Merrill and Sabharwal 2023  * This statement seems overly strong and minimizes prior work: ""This work takes the first step towards rigorously answering the fundamental question by considering a theoretical boundary of model capacity to be general learner""      * e.g., ""Saturated Transformers are Constant-Depth Threshold Circuits"" shows that transformers lie in TC^0 under a saturation condition     * e.g., ""The Parallelism Tradeoff: Limitations of Log-Precision Transformers"" shows that log-precision transformers lie in log-space-uniform TC^0",Does the review address Related Work?,TRUE,FALSE,"Critiques the paper for minimizing prior work and references specific studies that show transformers lie in TC^0 under certain conditions, indicating a discussion of related work."
"This is mentioned several times, but there are no initial results or anything suggesting that it might be a promising direction to pursue.",Does the review address Result?,FALSE,TRUE,"It discusses the lack of initial results or evidence suggesting the direction is promising, but does not present any specific results or findings."
"The dialog needs to be polite, follow natural language, short, etc which are hard to automatically measure.",Does the review address Evaluation?,TRUE,FALSE,"Refers to the difficulty in automatically measuring aspects of the dialogue such as politeness, natural language, and brevity, which are part of the evaluation criteria."
"In sec3.1, you used S_t for minibatch, but in sec3.4, you use S_i for ""a text sequence"", which is confusing.",Does the review address Presentation?,TRUE,FALSE,"Points out the confusion caused by inconsistent notation (S_t vs. S_i) in different sections, which relates to the clarity of the paper."
"The authors switch between using BERT_base and RoBERTa_base without being very clear about when and why, e.g., in Table 2 they have both models, but only in different sections.",Does the review address Comparison?,TRUE,FALSE,"Points out the switch between using BERT_base and RoBERTa_base without clear justification, highlighting the need for a more explicit comparison between the models."
The evaluation method uses CCA to maximize the correlation between the word embeddings and possibly hand crafted linguistic data.,Does the review address Methodology?,TRUE,FALSE,"Refers to the use of CCA in the evaluation method to maximize the correlation between word embeddings and linguistic data, which is part of the methodology."
- The title of the paper is a bit strongly worded and may be over-claiming what is shown quantitatively in this paper.,Does the review address Result?,TRUE,FALSE,Critiques the title for potentially over-claiming the quantitative results shown in the paper.
"The unfair disadvantage is even more prevalent when the pRNN uses multiple phrasal attention layers within a single sentence while a simple enc-dec system without attention is used as a benchmark =( Question: Wouldn't a simpler way to get phrasal RNN is to put the ""pyramid"" RNNs of a phrase into some soft of a average pooling layer?",Does the review address Methodology?,TRUE,FALSE,"Discusses the use of multiple phrasal attention layers in pRNN and suggests an alternative approach of using average pooling for the ""pyramid"" RNNs, which pertains to the methodology."
How much does the system rely on the capabilities of LLMs?,Does the review address Methodology?,TRUE,FALSE,"Questions the reliance of the system on the capabilities of LLMs, which pertains to the methodology being used."
TacticZero by Wu et al 2021 is missing from the related work.,Does the review address Related Work?,TRUE,FALSE,Points out that TacticZero by Wu et al. (2021) is missing from the related work section.
"If the authors can adequately address the following issues around presentation and the interpretation of Theorem 5, I would be satisfied raising my score, as I value the research question raised by the paper and believe the conclusions are valid.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Refers to the interpretation of Theorem 5 and suggests addressing issues related to its presentation, which involves further explanation or clarification."
I felt similar conclusions can be drawn from the results of that paper as well.,Does the review address Comparison?,TRUE,FALSE,"Suggests that similar conclusions can be drawn from the results of another paper, indicating a comparison between the two studies."
"However, this was already proposed and implemented by an earlier paper (Oikarinen et al.).",Does the review address Contribution?,TRUE,FALSE,"Points out that the idea was already proposed and implemented by an earlier paper, critiquing the originality of the contribution."
"This is immediate from Theorem 2, and this kind of separation appears to have been the implicit the point of Merrill and Sabharwal 2023  * This statement seems overly strong and minimizes prior work: ""This work takes the first step towards rigorously answering the fundamental question by considering a theoretical boundary of model capacity to be general learner""      * e.g., ""Saturated Transformers are Constant-Depth Threshold Circuits"" shows that transformers lie in TC^0 under a saturation condition     * e.g., ""The Parallelism Tradeoff: Limitations of Log-Precision Transformers"" shows that log-precision transformers lie in log-space-uniform TC^0",Does the review address Theory?,TRUE,FALSE,"Critiques the strength of the statement and references prior theoretical work that addresses similar concepts, relating to the theoretical foundations discussed in the paper."
The community will be interested how the model type / scale affect the LFLL capability.,Does the review address Methodology?,TRUE,FALSE,"Discusses how the model type/scale affects the LFLL capability, which is related to the methodology used in the study."
"With the strengths being said, I hope to also point out that the paper's application of adversarial training is one attempt in many possibilities, and in many cases it is not clear where the improvements come from.",Does the review address Presentation?,FALSE,TRUE,"It critiques the application of adversarial training and the unclear source of improvements, but does not focus on the clarity or structure of the paper."
Comparison with GECA: I can read from the paper that the performance is on par with GECA.,Does the review address Comparison?,TRUE,FALSE,"Refers to the comparison of performance between the proposed method and GECA, indicating they are on par."
"Clarification of contribution  Eq 6,7 reads like RNN style update but the intuition is lacking.",Does the review address Contribution?,TRUE,FALSE,"Points out the lack of intuition in the RNN-style update described in Eq 6 and 7, which relates to the contribution of the paper."
"For table 4, please also include the significance of the BLEU improvement made by the pRNN with respect to the the baseline, see https://github.com/jhclark/multeval General Discussion ==== As the main contribution of this work is on the phrasal effect of the new RNN architecture, it's rather important to show that the phrases are more coherent than the vanilla LSTM / RNN model.",Does the review address Result?,TRUE,FALSE,"Requests the inclusion of the significance of the BLEU improvement made by the pRNN, which relates to the results of the study."
"The organization is not perfect and readers might find it hard to follow here and there, but the main idea is understandable.",Does the review address Presentation?,TRUE,FALSE,"Critiques the organization of the paper, noting that it may be hard to follow in places, but the main idea is understandable."
"It is unclear to me how the authors are going to justify this ""assumption"".",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"Questions how the authors will justify a specific assumption, which relates to the justification or motivation behind the claim."
5.2 visualizations: this seems pretty ad-hoc without much justification for the choices.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Critiques the visualizations in Section 5.2 for being ad-hoc and lacking justification for the choices made.
The latter ratio seems proportional to the ratio $\frac{\ell_\mathcal{T}(\\{p_{\cdot\mid s}\\}) - \tau}{\ell_\text{xent}(\\{p_{\cdot\mid s}\\})-\ell_\text{xent}^\ast}$.,Does the review address Methodology?,TRUE,FALSE,"Refers to a specific ratio involving loss functions, which is part of the methodology being discussed in the paper."
I suspect that a statistical analysis [1] might conclude that BERT and the proposed method are indistinguishable on the GLUE suite.,Does the review address Analysis?,TRUE,FALSE,Suggests that a statistical analysis might conclude that BERT and the proposed method are indistinguishable on the GLUE suite.
"More importantly, the experiments are not convincing as it is presented now.",Does the review address Presentation?,TRUE,FALSE,"Critiques the presentation of the experiments, stating they are not convincing in their current form."
"The experimental settings in Section 3 lack detailed descriptions, potentially making reproduction difficult and potentially misleading.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Points out the lack of detailed descriptions in the experimental settings, which could make reproduction difficult and potentially misleading."
"The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",Does the review address Methodology?,TRUE,FALSE,"Discusses the theoretical results on the Parity/Sum task and the assumptions made, which relate to the methodology used in the study."
Having additional ways to improve data efficiency by changing the model design is definitely of interest.,Does the review address Data/Task?,TRUE,FALSE,"Refers to improving data efficiency through changes in model design, which relates to how the model interacts with the task or data."
The paper describes the idea of multiple temporal scales.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Describes the idea of multiple temporal scales, which involves explaining or defining a concept."
"- P8, Table 2: The results from using Quad look worse than the above two.",Does the review address Presentation?,TRUE,FALSE,"Points out the presentation of results in Table 2, specifically that the results from using Quad appear worse than the previous two."
This is the first such dataset for the Lean Theorem prover.,Does the review address Theory?,TRUE,FALSE,"Refers to the dataset being the first for the Lean Theorem prover, which could relate to the theoretical foundations of the work."
"Since one of the main contributions of this paper is the analysis of the BERT pretraining process, more experimental analysis on the optimizer should also be included.",Does the review address Experiment?,TRUE,FALSE,Suggests including more experimental analysis on the optimizer as part of the evaluation.
This could be another area to investigate  ---- Misc:  ----  - UnifiedQA seems potentially worth citing as prior work,Does the review address Related Work?,TRUE,FALSE,"Suggests citing UnifiedQA as prior work, which relates to the literature review and comparison."
I believe RFA should only refer one thing and I don't think eq(6) and eq(5) leads to the same result.,Does the review address Result?,FALSE,TRUE,It questions the consistency between equations (6) and (5) but does not directly address the results or findings.
"Then, most of the paper is spent discussing preliminaries and introducing notation and definitions.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Refers to the discussion of preliminaries, notation, and definitions, which involves providing descriptions and explanations."
"It describes a mapping of ORCHID, a Thai-specific POS tagset, to the Universal Dependencies (UD) scheme, and evaluates various state-of-the-art POS taggers on this scheme.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Describes the mapping of ORCHID to the UD scheme and evaluates POS taggers, which involves providing explanations and details about the process."
An ablation analysis would be most appropriate for quantifying this.,Does the review address Methodology?,TRUE,FALSE,"Suggests using an ablation analysis to quantify the impact, which relates to the methodology of the study."
Why do the authors use the Quora dataset in particular?,Does the review address Data/Task?,TRUE,FALSE,"Questions the choice of using the Quora dataset, which relates to the task being evaluated in the paper."
"So, In this case, it will be interesting to see the results (or will be helpful in evaluating ""absent type"" keyphrases): if we identify all the topical phrases of the entire corpus by using tf-idf and relate the document to the high-ranked extracted topical phrases (by using Normalized Google Distance, PMI, etc.).",Does the review address Presentation?,FALSE,TRUE,It talks about evaluating keyphrases
Another limitation is that it is unclear whether the improvement would hold when the size of the model increases; the evaluation is dealing with scaling laws after all.,Does the review address Methodology?,TRUE,FALSE,"Discusses the uncertainty about improvements when model size increases, related to scaling laws."
- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.,Does the review address Experiment?,TRUE,FALSE,Suggests adding more ablation analysis to the experiment section.
Some experimental settings only include the baselines Random and Vote-k. More methods as mentioned in 4.3.2 can be also included.,Does the review address Comparison?,TRUE,FALSE,"Suggests including more methods for comparison, as mentioned in Section 4.3.2."
"Maybe I've missed this in the paper, if there is, please be more explicit about it because it affects the model quite drastically if for every sentence the largest phrase length is the sentence length.",Does the review address Methodology?,TRUE,FALSE,Asks for clarity on phrase length in the model's behavior.
3) The usage of graph is somewhat straightforward to me.,Does the review address Methodology?,TRUE,FALSE,"Refers to the usage of a graph in the methodology, describing it as straightforward."
It does not follow from the theoretical results that adding similar sentences will be a good thing.,Does the review address Theory?,TRUE,FALSE,Points out that the theoretical results do not support the idea that adding similar sentences will be beneficial.
"Moreover, I have some comments on the model and experiments.",Does the review address Methodology?,TRUE,FALSE,"Refers to comments on the model and experiments, which are related to the methodology."
"The paper can be better if adding the real-user interactions, because the performance may be different between the simulation environment and the real-user interactions reported by prior results (DSTC in ConvLab).",Does the review address Result?,TRUE,FALSE,Suggests real-user interactions could affect performance compared to simulation results.
*  The claims regarding the 10x better data efficiency are not well supported and I would suggest the authors to compare with transformer models on standard LM benchmarks and potentially to some downstream tasks such as MT to make a stronger case.,Does the review address Comparison?,TRUE,FALSE,Suggests comparing with transformer models and downstream tasks.
"Specific criteria: - Correctness: 4     - The claims are supported, but I do not think the claims go far enough (e.g., ""noise has an effect on generalization"" is claimed when instead what that effect is needs to be characterized).",Does the review address Methodology?,TRUE,FALSE,"Points out that the effect of noise on generalization needs to be characterized, which relates to the methodology."
**Novelty** The idea of utilizing weak supervision of interleaved patterns is intuitive and convincing.,Does the review address Novelty?,TRUE,FALSE,Refers to the idea of utilizing weak supervision of interleaved patterns as intuitive and convincing.
"This paper suggests a number of cheap-to-compute corruptions of the input data that, when used to reconstruct the input, enrich the underlying model.",Does the review address Data/Task?,TRUE,FALSE,"Refers to corruptions of the input data, which are related to the task being performed."
"However, it should be straightforward to extend the results from these papers to the poly(n) case, at least in the nonuniform setting considered here.",Does the review address Result?,TRUE,FALSE,Suggests that the results from these papers can be extended to the poly(n) case.
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Experiment?,TRUE,FALSE,Discusses concerns about the comparability of results from different experimental configurations.
"In algorithm 1, in each iteration, only data sample (S_i) is used, how is this choice motivated?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Questions the choice of using one data sample (S_i) per iteration.
"If not, the presentation requires to change and reflect only the controllability analysis.",Does the review address Analysis?,TRUE,FALSE,Refers to the need for a change in presentation to reflect only the controllability analysis.
I will be more convinced if evaluation is done on a wider range of tasks.,Does the review address Evaluation?,TRUE,FALSE,Suggests that evaluation on a wider range of tasks would be more convincing.
"- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other ""oracle"" baselines.",Does the review address Comparison?,TRUE,FALSE,"Refers to the comparison of wMAN with state-of-the-art methods and other ""oracle"" baselines."
The authors experiment their method on three datasets and get the state of the art results.,Does the review address Data/Task?,TRUE,FALSE,Refers to the three datasets used for experimenting and achieving state-of-the-art results.
How many include simple string operations and/or other simple method calls as implied by Table 2?,Does the review address Methodology?,TRUE,FALSE,Questions the inclusion of simple string operations and method calls.
The paper presents a novel way of combining information from text and a KB in a bidirectional way.,Does the review address Novelty?,TRUE,FALSE,Describes a novel bidirectional approach for combining text and KB information.
"(2) What’is more, if tx contains s_k, can we say that the selected $tx$ is similar to $x$?",Does the review address Presentation?,FALSE,TRUE,It questions similarity but doesn’t address clarity or structure
"Why do you choose case-insensitive BLEU score for En->Fr, which is not commonly used in previous baselines.",Does the review address Significance?,TRUE,FALSE,"Questions the choice of case-insensitive BLEU score, which could affect the significance of the results."
The idea was (reasonably) well-positioned with respect to prior work and clearly presented.,Does the review address Presentation?,TRUE,FALSE,Refers to the clarity and positioning of the idea in relation to prior work.
"- How to find a discriminant for meaning is left out as the authors explicitly assume that “the mechanism is provided by human annotators and other providers of training data.” While the authors emphasize in the introduction that such information can be used in the LLM training without external reward model: “This observation shows that sentence-level annotations can be incorporated directly into the trained model without the need for any external reward model nor external policy model, simply by sentence-level feedback,” I do not see the advantage of this approach over using the very same data to train a reward model and use that either during the training (as in RLHF) or as an augmentation (as in Rectification method), the latter indeed provides quite strong theoretical guarantees.",Does the review address Theory?,TRUE,FALSE,"Compares the approach with using a reward model, discussing theoretical advantages."
"While the exact choice depends on the dataset characteristics, a framework will be more attractive if it can perform well on different scenarios.",Does the review address Result?,FALSE,TRUE,It discusses the framework's performance in different scenarios but does not mention specific results.
I think as an ACL paper there should be more takeaways.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,"It comments on the lack of takeaways but does not focus on definitions, descriptions, or explanations."
"Informally , a task is defined as natural if, just by using the next word distributions as features, the downstream task can be solved with a small loss.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Provides a definition of a ""natural"" task in terms of downstream task performance using next word distributions."
The authors try to interpret the design of the neural networks using the concepts in the proposed binding-unbinding theorybut are not convincible.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques the interpretation of the neural network design using the proposed binding-unbinding theory.
"I would suggest the following:   * To make the comparison more fair, I would suggest to train transformer models with varying size and derive a power law based on the exact same experimental configuration used for LMU models.",Does the review address Comparison?,TRUE,FALSE,Proposes a fairer approach to comparing transformer and LMU models.
"While this paper provides extensive empirical results and quantitively demonstrates the effectiveness of RandomMask, there are several areas where it could be further enhanced.",Does the review address Methodology?,TRUE,FALSE,Refers to methodological improvements and enhancements.
"The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",Does the review address Ablation?,TRUE,FALSE,Highlights how ablation studies validate design elements.
Weaknesses: Some of the design choices need to be elaborated on further and additional analysis-based experiments would also be useful.,Does the review address Experiment?,TRUE,FALSE,Suggests additional experiments for deeper analysis.
There is a lot missing to actually justify this claim: 1.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Questions the adequacy of justification for a claim.
"Before describing your algorithm, humans are only mentioned once in the algorithm.",Does the review address Presentation?,TRUE,FALSE,Highlights a structural aspect of the algorithm's presentation.
I appreciate the additional figures and other results that you have provided.,Does the review address Result?,TRUE,FALSE,Acknowledges additional results and figures contributing to the findings.
"* Strength     * This paper proposes an interesting idea and interpretation to connect RM and DM paradigm     * This paper proposes a variance reduction method for DPG which demonstrates its improvement on performance, stability and sample efficiency * Weakness     * From my understanding, the baseline mostly comes from the observation in 3.3, which has limited technical novelty.",Does the review address Presentation?,TRUE,FALSE,Notes the presentation of ideas and baselines.
"Main strengths: - Mapping existing Thai corpora to the UD scheme is a useful contribution for Thai NLP, as the UD scheme has become popular for multilingual work, and this will allow Thai NLP to profit better from advances in this area.",Does the review address Contribution?,TRUE,FALSE,Recognizes a contribution related to mapping Thai corpora.
The new established benchmark is another good contribution.,Does the review address Data/Task?,TRUE,FALSE,Refers to a newly introduced benchmark related to data or tasks.
"Previous work [2] has already shown that by selecting the most complex examples from the training dataset, the performance can be largely improved compared to the original annotations from [1].",Does the review address Result?,TRUE,FALSE,Refers to performance improvements based on data selection.
"There is no comparison with other public masking methods in Table 2, such as whole-word-masking, span masking, etc.",Does the review address Comparison?,TRUE,FALSE,Critiques the lack of comparisons with masking methods.
"Though the paper promises faster training speeds in the introduction, Table 3 shows only modest (less than x2) speedups for training.",Does the review address Result?,TRUE,FALSE,Discusses the speedup results presented in Table 3.
- Using “concept” to stand in for verbs and nouns is somewhat confusing.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Notes confusion in the description of terms like ""concept."""
"For the first ablation, it just gives out the performance of intermediate models on a single task.",Does the review address Data/Task?,TRUE,FALSE,Mentions performance analysis on specific tasks in the ablation study.
"Overall, the authors show better accuracy for their tested problem set against REWARD, a baseline system (a transformer), lang2logic, and Ins2AST across two dimensions: data type recovery and abstract syntax tree (AST) generation.",Does the review address Comparison?,TRUE,FALSE,Compares the proposed method's accuracy against multiple baselines.
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Novelty?,TRUE,FALSE,Questions the originality and impact of the contributions.
I had to read it a couple of times before I could fully follow the method.,Does the review address Presentation?,TRUE,FALSE,Highlights a difficulty in following the presented method.
The proposed method achieves SoTA results on CommonGen with slightly more than half the parameters of the current SoTA model.,Does the review address Methodology?,TRUE,FALSE,Refers to the efficiency of the proposed methodology in achieving results.
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Comparison?,TRUE,FALSE,Critiques the lack of sufficient comparisons to prior work.
Weaknesses:  - The notation/description of section 4 is not immediately intuitive.,Does the review address Presentation?,TRUE,FALSE,Critiques the clarity of the notation and description in Section 4.
- Each component in perceiver IO is necessary and well defined for the proposed tasks.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Highlights the clear definition and necessity of components for tasks.
"In addition, the authors empirically demonstrate that the token-level masked-LM model used by BERT is not a good choice as pre-training task for the two-tower Transformer when deployed for large-scale information retrieval applications.",Does the review address Methodology?,TRUE,FALSE,Discusses the methodological choice for pre-training tasks.
"- The paper mentioned that the standard RL methods easily fail and generate responses diverging from human language, even when fine-tuning a pre-trained LM.",Does the review address Methodology?,TRUE,FALSE,Refers to the challenges of standard RL methods in fine-tuning LMs.
"With these two elements, the approach performs on par with recently proposed GECA (where the data is not augmented via a neural generator) on two datasets.",Does the review address Data/Task?,TRUE,FALSE,Mentions the datasets used to evaluate the approach.
"Last sentence of intro: ""without scarifying accuracy"" seems like an inaccurate description of the results presented in this paper.",Does the review address Presentation?,TRUE,FALSE,Critiques the clarity or accuracy of the paper's claims.
Which script did you choose to evaluate BLEU score?,Does the review address Presentation?,TRUE,FALSE,Refers to the tools or methods used for presenting evaluation results.
"Strengths: - Thorough theoretical analysis that reveals the connection between (practically-necessary) small learning rates and inability to use dependencies across text chunks - Useful framing and discussion of the ""in-context bias"", where models are more likely to learn dependencies within text chunks seen during pre-training.",Does the review address Analysis?,TRUE,FALSE,Highlights a theoretical analysis revealing key insights.
"* Why are the lines for ""from scratch"" flat in Figure 2?",Does the review address Methodology?,TRUE,FALSE,Questions aspects of the methodology related to results presentation.
"Although the complexity analysis is thorough, I'd like to see empirical results of memory/compute requirements as a function of the context length.",Does the review address Result?,TRUE,FALSE,Suggests additional results to complement the complexity analysis.
"## ""General Learner"": Missing Formal Definition and Misleading Name  The ""general learner"" concept used in the title and throughout is named in a somewhat misleading way, as the results here have to do more with *expressive power* than learning.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Discusses the need for a formal definition and clarity of the concept.
"The motivation is to reduce the undesirable large variance of MLM objective, based on the hypothesis that randomly sampled masks in MLM would lead to undesirably large gradient variance, which as a result typically hurts the training efficiency with stochastic gradient optimization algorithms.",Does the review address Methodology?,TRUE,FALSE,Addresses a methodological hypothesis and its impact on training.
"Empirically, it demonstrates that several NLP tasks are “natural”.",Does the review address Data/Task?,TRUE,FALSE,Highlights the focus on NLP tasks and their characteristics.
"After reading other reviews and the authors’ responses to all of the reviewers, I recommend this paper by accepted—extensive results show that the CALM objectives offer more signal from data than current pretraining methods.",Does the review address Data/Task?,TRUE,FALSE,Notes the value of the objectives in extracting signal from data.
"- Strengths: Useful modeling contribution, and potentially useful annotated data, for an important problem -- event extraction for the relationships between countries as expressed in news text.",Does the review address Methodology?,TRUE,FALSE,Refers to a modeling contribution and its methodological significance.
"After thinking over the concepts in the paper more, I might lean more strongly toward rejection or toward acceptance (if the authors can address the issues I raise below).",Does the review address Evaluation?,TRUE,FALSE,Discusses conditions for acceptance or rejection based on evaluation.
"- Table 5 the VAE(32) method performs the best overall in ""Wiki section"" although the TC (16) method has been highlighted as the best.",Does the review address Methodology?,TRUE,FALSE,Refers to the comparison and setup of methods in the table.
Are these rather the ppl resulting from training an LM on the full dataset?,Does the review address Data/Task?,TRUE,FALSE,Questions dataset use in the training process.
"There are numerous works and existing methods working on connecting LLM to perform various tasks, e.g., AutoGPT.",Does the review address Methodology?,TRUE,FALSE,Refers to the connection of methods and tasks within the methodology.
"Other concerns along these lines: all of this paper's results are averaged over 3 runs while the other baselines are over 5 runs - an indication of variance would be useful to assess whether the differences are significant, especially since some of the margins quite small (23 on MC-LAVE-RL vs 22.8 for the next best on Ludicorp) added to the fact that hyperparameters are different for each game - does that imply that the authors tuned the hyperparameters for each game?",Does the review address Presentation?,TRUE,FALSE,"Discusses presentation of results, including averages and variances."
#### Strength - The idea of perceiver IO is novel and solid -- a general architecture capable of handling general-purpose inputs and outputs across different tasks and modalities.,Does the review address Novelty?,TRUE,FALSE,Highlights the novelty of perceiver IO as a general architecture.
Their thorough ablation experiments and other analysis yield some interesting findings the authors could emphasize more.,Does the review address Experiment?,TRUE,FALSE,Mentions ablation experiments and analysis conducted.
There is limited contribution in terms of machine learning algorithms.,Does the review address Contribution?,TRUE,FALSE,Points out limited contribution in the paper's approach.
"Similar idea also exists in [R3], which is missing from this paper.",Does the review address Related Work?,TRUE,FALSE,Refers to missing related work (R3).
"-----General Discussion----- This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths).",Does the review address Data/Task?,TRUE,FALSE,Mentions the dataset used in evaluating the model.
It also includes the recurrent memory extension from Transformer-XL from Dai et al.,Does the review address Related Work?,TRUE,FALSE,Mentions related work by referencing Transformer-XL from Dai et al.
"This is relevant because, by training end to end, that work effectively generates arbitrary amounts of training data through interaction the the HOL4 ITP system (intermediate theorems which are proven give some reward in that work).",Does the review address Theory?,TRUE,FALSE,Refers to theoretical aspects involving reward mechanisms in the HOL4 ITP system.
This is an interesting work on the investigation of learning effects with a mix of tasks.,Does the review address Data/Task?,TRUE,FALSE,Highlights the use of tasks in investigating learning effects.
"While I appreciate the environment introduced and believe it to be promising, the experiments presented fail to highlight the novelty of the environment.",Does the review address Experiment?,TRUE,FALSE,Discusses experiments related to the introduced environment.
The authors present a new approach called: neural-based binary reverse engineering framework (N-Bref).,Does the review address Methodology?,TRUE,FALSE,Describes the methodology of the proposed N-Bref approach.
"As a result, this paper has a great potential, and its results seem very promising.",Does the review address Result?,TRUE,FALSE,Highlights the promising results of the paper.
"There is no comparison with other public masking methods in Table 2, such as whole-word-masking, span masking, etc.",Does the review address Presentation?,FALSE,TRUE,"It discusses the lack of comparison with other masking methods, which relates more to Comparison."
"Specifically, for Table 1, the inference time of each algorithm should be reported (retrieval time included).",Does the review address Presentation?,TRUE,FALSE,Suggests reporting inference time for clarity.
Summary: + Appealing theoretical contributions + Empirical results are encouraging + The use of discriminator for reward shaping in addition to task success rate is interesting  - Writing and explanation can be improved.,Does the review address Result?,TRUE,FALSE,Refers to encouraging empirical results.
"If I understand correctly, the sub-linear results depend on particular settings of the memory length and compression rate.",Does the review address Methodology?,TRUE,FALSE,Discusses the dependency of sub-linear results on memory length and compression rate.
"* Were the proposed architectural additions conceived with the HANS ""counterexamples"" in mind (i.e. is there a specific reason to think that these types of methods would avoid the ""superficial"" reasoning that these examples are supposed to reveal)?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"Questions if the additions avoid superficial reasoning, relating to the motivation."
"The methods have been tested on two benchmarks focusing on the issue, SCAN and morphological analysis.",Does the review address Analysis?,TRUE,FALSE,"Refers to testing the methods on two benchmarks, focusing on SCAN and morphological analysis."
"At the least, it would be worth proposing that the languages in this study can offer a test of rule-based vs. inference-based processes, and propose performing such comparisons when the data for the study languages is sufficiently mature.",Does the review address Data/Task?,TRUE,FALSE,Suggests testing rule-based vs. inference-based processes when data is mature.
"For example, on VQA, more recent works (BEiT-3) achieve 84+, while the best reported result in the manuscript is ~76.",Does the review address Result?,TRUE,FALSE,"Compares the reported result with more recent works, highlighting the performance difference."
*  The claims regarding the 10x better data efficiency are not well supported and I would suggest the authors to compare with transformer models on standard LM benchmarks and potentially to some downstream tasks such as MT to make a stronger case.,Does the review address Data/Task?,TRUE,FALSE,Suggests comparing with transformer models on LM benchmarks and downstream tasks like MT.
"I do not believe that SoTA results are necessary to write a good paper, and indeed the obsession our field has with SoTA is unhealthy.",Does the review address Result?,TRUE,FALSE,"Critiques the focus on SoTA results, implying it’s not necessary for a good paper."
"Secondly, the design of the specific neural network cannot describe the theory behind proposed binding-unbinding mechanism properly.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques the neural network design for not properly describing the theory behind the binding-unbinding mechanism.
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Analysis?,TRUE,FALSE,Points out the lack of human evaluation and error analysis in the reported experimental results.
"That raises the question -- Gerrish and O'Connor both conduct evaluations with an external database of country relations developed in political science (""MID"", military interstate disputes).",Does the review address Evaluation?,TRUE,FALSE,Refers to the evaluation conducted with an external database of country relations.
"This paper makes comparison with techniques used in active learning (AL), domain shift detection (DS), and multi-domain sampling to combine data from multiple sources.",Does the review address Data/Task?,TRUE,FALSE,"Discusses combining data from multiple sources, which relates to the task being evaluated."
The simple combination of the audio model and LLM does not seem to be novel.,Does the review address Novelty?,TRUE,FALSE,Critiques the combination of the audio model and LLM as not being novel.
-  Consistent performance improvement over the baseline models on all of the three QA benchmarks.,Does the review address Methodology?,TRUE,FALSE,"Refers to consistent performance improvements over baseline models, which relates to the methodology used."
"- The paper is well written: it gives an appropriate context, presents the main theoretical results, and verifies _some_ of the claims experimentally.",Does the review address Theory?,TRUE,FALSE,Refers to the presentation of the main theoretical results in the paper.
"Additionally, the rationale for choosing (Ma et al., 2023) as a benchmark, along with the significance of the improvements observed, even if minute, should be clearly articulated.",Does the review address Significance?,TRUE,FALSE,Discusses the significance of improvements observed and the rationale for choosing a benchmark.
Experimental evaluation shows competitive performance.,Does the review address Result?,TRUE,FALSE,Refers to competitive performance shown in the experimental evaluation.
"The authors analyze the in-context bias of the self-attention model, which could inspire some research works on designing training examples.",Does the review address Analysis?,TRUE,FALSE,Refers to the analysis of in-context bias in the self-attention model.
"For example, if for the baseline model, we also only use one data sample and apply different masks, will there be improvement?",Does the review address Result?,TRUE,FALSE,Considers the potential improvement in performance by altering the baseline model's approach.
"This bound consists of two parts: - The first part measures how ""natural"" the task is, that is, how well can the task be solved using the next word distributions as features.",Does the review address Data/Task?,TRUE,FALSE,"Describes how ""natural"" the task is using next word distributions."
"However, with most Indigenous languages, existing corpora are not large enough to produce accurate statistical models.""",Does the review address Methodology?,TRUE,FALSE,Discusses the limitation of corpora for accurate models.
"3.2.2 presents the observation that choosing a set of queries from the dataset a-priori (agnostic to the image), does not result in either an optimal or interpretable query set.",Does the review address Data/Task?,TRUE,FALSE,Discusses the process of selecting queries from the dataset and its implications.
This paper provides a mathematical framework to understand this question.,Does the review address Methodology?,TRUE,FALSE,Refers to the mathematical framework used to understand the question.
What happens when the extra reward for using the language model is added to LaRL (that might be tough if you have to modify others code).,Does the review address Methodology?,TRUE,FALSE,Discusses the impact of modifying the reward system in the method.
"In Sec2, you said ""yet is outperformed by the proposed fully-explored masking (see Table 2).",Does the review address Related Work?,FALSE,TRUE,"It discusses method performance, not literature review."
"The main issue of the paper is in the experiments and results reporting, it needs quite a bit of reworking.",Does the review address Experiment?,TRUE,FALSE,"Critiques the experiments and results reporting, suggesting they require significant reworking."
"Contribution: The authors contribute a new tokenization method, code, and a dataset.",Does the review address Methodology?,FALSE,TRUE,No process detail given
# Summary  The authors propose to use corpora generated from _emergent communication_ as a fine-tuning signal for NLP tasks (language modeling and image captioning in particular).,Does the review address Methodology?,FALSE,TRUE,Refers to techniques and processes.
"- Excellent clarity and presentation of ideas  ## Weaknesses - The experiments provided do not analyze the unique characteristics of the environment introduced; instead, the experiments are similar to the typical gamut for a discrete symbol-based referential game.",Does the review address Presentation?,TRUE,FALSE,"Yes, it mentions Presentation: Excellent clarity and presentation."
"I also wanted to mention that I appreciate the addition of the suggested related work, but I would still suggest that the authors consider looking into more detailed means of comparison in the future (especially to the Petroni work), since this seemed to be a concern in multiple reviews.",Does the review address Comparison?,TRUE,FALSE,Suggests detailed means of comparison.
Weaknesses * Something that stands out is the lack of discussion and comparison to related works that employ recurrent formulations of attention.,Does the review address Related Work?,TRUE,FALSE,Discusses comparison to related works.
Other questions for the authors: (1) What is the loss in performance by fixing the word embeddings in the dependency parsing task?,Does the review address Data/Task?,TRUE,FALSE,Relates to the dependency parsing task.
"So how would it be possible to train with poor annotations, while generalize much better?",Does the review address Methodology?,TRUE,FALSE,Focuses on training methods.
"If you remove the RE component, does the NER performance suffer?",Does the review address Ablation?,TRUE,FALSE,Discusses the removal of components.
"It also further demonstrates that the BERT model, once fully tuned, could achieve SOTA/competitive performance compared to the recent new models (e.g., XLNet).",Does the review address Result?,TRUE,FALSE,Achieves SOTA performance.
"**The method is simple with limited contribution, while performance improvement is not significant.",Does the review address Methodology?,TRUE,FALSE,Discusses method simplicity and contribution.
The theory is a bit complicated and not easy to follow.,Does the review address Theory?,TRUE,FALSE,Notes complexity and clarity issues.
Having additional ways to improve data efficiency by changing the model design is definitely of interest.,Does the review address Methodology?,TRUE,FALSE,Discusses model design changes.
"**Baselines are too weak, leading to a misunderstanding of the effectiveness of the proposed method.",Does the review address Methodology?,TRUE,FALSE,Discusses baselines and effectiveness.
"A discussion on how to add new tasks to the same framework might help, or a discussion on why the current framework is enough.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Talks about adding tasks.
The authors introduce a BACKDOOR DATA PARADIGM that aptly fulfills the requirements for Uniqueness and Imperceptibility in watermark embedding.,Does the review address Presentation?,FALSE,TRUE,Relates to unique watermark embedding.
I highly recommend bringing this assumption earlier to avoid readers confusion.,Does the review address Presentation?,TRUE,FALSE,Suggests improving clarity.
"The result will stand out to compare against Codex, the state-of-the-art program synthesis model.",Does the review address Comparison?,TRUE,FALSE,Compares results to Codex.
Theoretical discussion proves that the gradients derived from the new masking schema have a smaller variance and can lead to more efficient self-supervised training.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Discusses gradient variance.
(Current experiments only include the results of models that are free from this issue.),Does the review address Experiment?,TRUE,FALSE,Discusses model results.
"This isn't clear from the current structure if so, since it's stated as a corollary of Theorem 3.",Does the review address Theory?,TRUE,FALSE,Relates to Theorem 3.
lead to performance decrease for individual tasks.,Does the review address Result?,TRUE,FALSE,Notes performance decrease.
"Moerover, there seem to be some errors about the correctness of the theory (See the first point below).",Does the review address Theory?,TRUE,FALSE,Notes errors in correctness.
The source for generating the data is a big contribution to the theorem prover and machine learning community.,Does the review address Contribution?,TRUE,FALSE,Acknowledges the source for data generation.
- Not accounting for the privacy loss incurred in tuning the hyperparameters is a problem.,Does the review address Methodology?,TRUE,FALSE,Discusses privacy loss in hyperparameter tuning
Would be great to state them upfront to avoid confusion.,Does the review address Methodology?,TRUE,FALSE,Suggests improving clarity.
"In section 3.3.3 ""THE MIX-UP OF MULTIPLE TYPES,"" the authors mention that ""it is possible to embed multiple Double-I watermarks in a model, which theoretically has the potential to enhance the robustness of our watermarking technique.""",Does the review address Methodology?,TRUE,FALSE,Discusses embedding multiple watermarks to enhance robustness.
The authors experiment their method on three datasets and get the state of the art results.,Does the review address Result?,TRUE,FALSE,Achieves state-of-the-art results on three datasets.
"For a fair comparison, I think the baseline should add those methods as claimed in the introduction (Lee et al., 2019; Child et al., 2019; Sukhbaatar et al., 2019; Beltagy et al., 2020, inter alia), (Kitaev et al., 2020; Wang et al., 2020; Roy et al., 2020, inter alia) and let us know how badly they performed under the short sequence.",Does the review address Comparison?,TRUE,FALSE,Discusses adding methods for fair comparison.
"There is no time complexity in the proposed method, which is very crucial if it needs to run for every inference.",Does the review address Methodology?,TRUE,FALSE,Lacks time complexity analysis.
"The paper demonstrates that naively using CLIP-score between (query-concept, image) does not work well out-of-the-box, and proposes learning a new light-weight network based on pseudo-labels.",Does the review address Contribution?,TRUE,FALSE,Proposes a new network
"I'm concerned whether these improvements will hold after optimizing BERT carefully like RoBERTa, or using more advanced backbone methods like ALBERT.",Does the review address Result?,TRUE,FALSE,Discusses potential improvements
"The experments are fairly convincing, although it is not entirely surprising that this approach works, and to repeat, the basic idea of extracting additional training data in this way is not entirely new.",Does the review address Data/Task?,FALSE,TRUE,"Focused on approach, not data"
Contrastive training (negative sampling) is one of the crucial contributions of this work.,Does the review address Contribution?,TRUE,FALSE,Highlights negative sampling as crucial.
"Maybe I've missed this in the paper, if there is, please be more explicit about it because it affects the model quite drastically if for every sentence the largest phrase length is the sentence length.",Does the review address Significance?,FALSE,TRUE,Focuses on clarity rather than impact.
The first is based on integrating information from all layers of the encoder via a method called Squeeze and Excitation.,Does the review address Methodology?,TRUE,FALSE,Describes an approach for integrating information from all layers of the encoder.
i. e. representing a word by a set of many Gaussian distributions.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Explains how a word is represented by multiple Gaussian distributions.
I would argue that this is not a fair comparison: did the authors intentionally choose weak baselines?,Does the review address Comparison?,TRUE,FALSE,Questions the fairness of the baseline comparison.
"First of all, the dense interaction between vision and language tokens has been heavily studied prior to the so-called multimodal LLM era.",Does the review address Related Work?,TRUE,FALSE,Refers to prior studies on vision and language token interaction.
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Experiment?,TRUE,FALSE,Refers to experimental validation in Section 5.1.
The graph visualization shown does not seem to illustrate much.,Does the review address Presentation?,TRUE,FALSE,Refers to the graph visualization.
The paper's presentation could be improved in several ways:     1.,Does the review address Presentation?,TRUE,FALSE,Refers to improving the paper's presentation.
**Strengths**:  The paper is well-written and easy to follow.,Does the review address Presentation?,TRUE,FALSE,Refers to the clarity and ease of following the paper.
"The paper shows the reasonable claim that it is necessary to gradually train the model from close-ended datasets to open-ended ones because if the open-ended dataset is trained first, the model is heavily dependent on language capability so it is hard to train the audio representation.",Does the review address Data/Task?,TRUE,FALSE,Refers to the dataset and task used in training the model.
It seems to be making every previously known augmentation approach better.,Does the review address Methodology?,TRUE,FALSE,Refers to an approach improving existing augmentation techniques.
"Conventionally the ITM loss is a binary prediction task, while the particular one used in this work is more often referred as contrastive learning loss.",Does the review address Data/Task?,TRUE,FALSE,Refers to a specific task (binary prediction vs. contrastive learning loss).
"A discussion on how to add new tasks to the same framework might help, or a discussion on why the current framework is enough.",Does the review address Data/Task?,TRUE,FALSE,Refers to adding new tasks or discussing the adequacy of the current framework for the tasks.
"Only the video-level annotation is available for training, and the goal is retrieving the video segment described by the sentence.",Does the review address Data/Task?,TRUE,FALSE,Refers to video-level annotation and segment retrieval.
"It might be interesting to see some examples, especially when the annotation budget is 18, of the kinds of instances that get selected depending on the task.",Does the review address Data/Task?,TRUE,FALSE,Discusses instance selection based on task and annotation budget.
"Paper is mostly clearly written, and easy to read.",Does the review address Presentation?,TRUE,FALSE,Describes the paper as clear and easy to read.
Questions for the authors: - How the parameter study was conducted?,Does the review address Presentation?,FALSE,TRUE,it doesn't mention Presentation in relation to the parameter study.
Just trying to say that automatic evaluation of dialog systems is a hard problem.,Does the review address Evaluation?,TRUE,FALSE,Notes the difficulty of automatically evaluating dialog systems.
"They show that, especially in small-data regimes, pre-training on an emergent language can yield significant performance boosts in both tasks.",Does the review address Result?,TRUE,FALSE,Describes the performance boosts in small-data regimes.
"Further, how does the network perform when a longer context is obtained *maintaining the same number of parameters* as a network with less temporal scales?",Does the review address Result?,TRUE,FALSE,It asks about the performance of the network with longer context while maintaining the same number of parameters.
"For example, the model hyper-parameters are quite different for different tasks.",Does the review address Methodology?,TRUE,FALSE,Notes that model hyper-parameters differ for various tasks.
The experimentation is correct and the qualitative analysis made in table 1 shows results as expected from the approach.,Does the review address Experiment?,TRUE,FALSE,Confirms that the experimentation is correct and the qualitative analysis shows expected results.
Could you explain more precisely what exactly is new?,Does the review address Presentation?,FALSE,TRUE,it doesn't mention Presentation in relation to explaining what exactly is new.
"# Typographic comments  * p 1, ""the input out of detractors"" --> ""the input out of distractors""   * p 2: ""transferable benefits for downstream natural language tasks"" the single hyphens surrounding the subsequent list should be em dashes (three hyphens in TeX)  * p 3: ""uses another GRU layer to decode the message m into a hidden vector hl"" I would use ""encode"" instead of ""decode"" here, since text-->representation is usually what an encoder does  * p 3: ""The most straightforward metric is the accuracy of playing the referential game p(guess = Ii).""",Does the review address Presentation?,TRUE,FALSE,Highlights typographic comments for clarity and correctness.
- Any comments / results on the model's sensitivity to parser errors?,Does the review address Methodology?,FALSE,TRUE,it doesn't mention Methodology in relation to the model's sensitivity to parser errors.
"Also, some additional experiments need to be added in order to better justify its claims.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Suggests adding additional experiments to better justify the claims.
"Thus, it seems to me that you are essentially applying past results to answer a specific question you have (which is still a valuable contribution).",Does the review address Result?,TRUE,FALSE,"Acknowledges the application of past results to address a specific question, recognizing it as a valuable contribution."
More theoretical proofs or appropriate literature citations are needed to validate this assertion.,Does the review address Related Work?,FALSE,TRUE,it doesn't mention Related Work in relation to needing more theoretical proofs or literature citations.
- The ablation experiments and optimized prompt analysis are insightful.,Does the review address Ablation?,TRUE,FALSE,Highlights the insightfulness of ablation experiments and optimized prompt analysis.
"References Yining Wang, Jiajun Zhang, Feifei Zhai, Jingfang Xu, and Chengqing Zong.",Does the review address Related Work?,TRUE,FALSE,"It references the authors Yining Wang, Jiajun Zhang, Feifei Zhai, Jingfang Xu, and Chengqing Zong."
Authors could have plugged their embedding strategy in LayoutLM to understand the impact of that particular component.,Does the review address Significance?,FALSE,TRUE,it does not mention Significance.
"Rules may be ""outdated"" because they are inefficient for certain languages with reams of available data and scads of phenomena that don't fit.",Does the review address Data/Task?,TRUE,FALSE,Refers to the inefficiency for certain languages with available data.
The theory can be more practically useful if it can be extended to quantify the intractability level so the resulting embeddings' error can be bounded or compared.,Does the review address Methodology?,TRUE,FALSE,"Yes, it mentions Methodology: Refers to extending the theory to quantify intractability."
"- Table 5 on the right for the training curriculum, it would be great to also include the language instruction following rate.",Does the review address Methodology?,FALSE,TRUE,it does not mention Methodology.
"Hence, the model relies on whether the parser accurately discovers the crucial information.",Does the review address Methodology?,TRUE,FALSE,Refers to the model's reliance on the parser's accuracy.
The empirical part of the paper shows improved performance of adding similar sentences to the context of LM training.,Does the review address Result?,TRUE,FALSE,Refers to improved performance with added similar sentences.
It would be beneficial to further explore whether sparse attention is indeed a problem for DNA sequence representation.,Does the review address Methodology?,TRUE,FALSE,Refers to exploring sparse attention in DNA sequence representation.
Does the baseline system (groundhog) contains the attention mechanism?,Does the review address Methodology?,TRUE,FALSE,Refers to the baseline system's attention mechanism.
Weaknesses: - Somewhat weaker results on some CommonGen metrics are disappointing.,Does the review address Result?,TRUE,FALSE,Refers to weaker results on some CommonGen metrics.
"You hypothesize that more templates doesn't help because ""models at such scale do not easily overfit to a finetuning single task"" - but my intuition is for an opposite explanation -- that the models at such scale easily memorize a small number of templates!",Does the review address Presentation?,FALSE,TRUE,it does not mention Presentation.
"-----Post-rebuttal----- The authors did not address my main concern, which is whether the baselines (e.g. TreeRNN) are used to compute substructure embeddings independent of the sentence embedding and the joint tagger.",Does the review address Comparison?,TRUE,FALSE,"Questions if baselines like TreeRNN are used to compute substructure embeddings, comparing it to the joint tagger."
But the diagrams in the appendix for the policy the MC!Q*BERT agent learns as well as the original paper for that agent show otherwise?,Does the review address Methodology?,TRUE,FALSE,"Refers to the diagrams and policy learned by the MC!Q*BERT agent, questioning the methodology used."
I also read the original gSCAN paper but they didn't use this term at all.,Does the review address Comparison?,TRUE,FALSE,I also read the original gSCAN paper but they didn't use this term at all.
"**Related work** The authors clearly describe the related prior works from both the perspectives of program synthesis, large language models, and benchmarks for program synthesis.",Does the review address Methodology?,FALSE,TRUE,"It discusses related work, not the methodology or approach used in the study."
* Ablation: the model vs corpus transfer comparison seems unfair to me.,Does the review address Methodology?,FALSE,TRUE,it does not mention Methodology.
The proposed method is reasonable and moderately novel.,Does the review address Novelty?,TRUE,FALSE,Refers to the method being moderately novel.
"The authors say in the introduction that the approach (Andreas, 2020) is task specific which seems not correct.",Does the review address Data/Task?,FALSE,TRUE,it does not mention Data/Task.
Their findings on learning complex tasks contribute to the understanding of large language model learning and provide valuable insights for future related work on efficient training.,Does the review address Data/Task?,FALSE,TRUE,"It discusses the contribution to understanding large language model learning, but not the specific data or task used."
The experiment results in Tables 1 & 2 cannot plausibly prove OTTER is more effective than CLIP.,Does the review address Methodology?,FALSE,TRUE,it does not mention Methodology.
"* The paper repeatedly emphasizes ""training"" in FP8 (e.g., in the title, in the abstract, etc.",Does the review address Methodology?,FALSE,TRUE,it does not mention Methodology.
The motivation behind the study is somewhat unclear.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Refers to the unclear motivation behind the study.
"The motivation is to reduce the undesirable large variance of MLM objective, based on the hypothesis that randomly sampled masks in MLM would lead to undesirably large gradient variance, which as a result typically hurts the training efficiency with stochastic gradient optimization algorithms.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Refers to the motivation behind reducing variance in MLM objective.
"However, GTR is a single vector retrieval model, so there is no unified standard to show that the effect of the proposed model in this paper is better than the previous model.",Does the review address Methodology?,TRUE,FALSE,Refers to the evaluation standard of the proposed model.
"The proposed models -- which seem to be an application of various tree-structured recursive neural network models -- demonstrate a nice performance increase compared to a fairly convincing, broad set of baselines (if we are able to trust them; see below).",Does the review address Result?,TRUE,FALSE,Refers to the performance increase compared to baselines.
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Data/Task?,TRUE,FALSE,Refers to validation on a single dataset.
"The layers are described in a textual fashion, barely any math (and extended in the pseudo-code).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Refers to the layers being described in a textual fashion with pseudo-code.
"However, there are many other tasks that involve sentence pairs.",Does the review address Data/Task?,TRUE,FALSE,Refers to tasks involving sentence pairs.
The problem is a terrific one and the application of the recursive models seems like a contribution to this problem.,Does the review address Contribution?,TRUE,FALSE,Refers to the application of recursive models contributing to the problem.
I also read the original gSCAN paper but they didn't use this term at all.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,it does not mention elucidation
"Indeed, it is not clear how one can reformulate e.g. linguistic tasks (like POS-tagging or dependency parsing) as a next word prediction task.",Does the review address Data/Task?,TRUE,FALSE,Refers to the challenges in reformulating linguistic tasks like POS-tagging or dependency parsing as a next word prediction task.
"Granted, the final effect of MTL depends on task similarities, but that's probably the same for the proposed approach.",Does the review address Data/Task?,TRUE,FALSE,Refers to the dependency of MTL on task similarities.
"It is good to know that it works for 2D-coordinates for the task at hand, though it seems to be more a marginal improvement on existing work rather than a standalone contribution.",Does the review address Contribution?,TRUE,FALSE,Refers to the work as a marginal improvement rather than a standalone contribution.
"Similar numbers are true for the rest of the tasks: 60.90 vs. 87 for OBQA, 71.01 vs. 90 for PIQA, and 63.20 vs.  89.70 for aNLI.",Does the review address Data/Task?,TRUE,FALSE,"Refers to the performance numbers for OBQA, PIQA, and aNLI tasks."
"The key ideas are: (i) training longer with bigger batches over more data, (ii) removing NSP, (iii) training over long sequences, and (iv) dynamically changing the masking pattern.",Does the review address Methodology?,TRUE,FALSE,"Refers to training with bigger batches, removing NSP, training over long sequences, and changing the masking pattern."
"Compared to the related work, the novel part of this work is: (i) a new retrieval way, which is not quite clear and convincing to me.",Does the review address Methodology?,TRUE,FALSE,Refers to the introduction of a new retrieval way.
"### Cons and aspects to improve  My main concern is that the overall contribution is seems to be limited.In fact, the original paper of the Transformer approach, already proposed such kind of embedding.",Does the review address Result?,FALSE,TRUE,it does not mention Result.
"Moreover, I have some comments on the model and experiments.",Does the review address Experiment?,TRUE,FALSE,Refers to comments on the model and experiments.
"It provided me with a much more thoughtful explanation for why language model pre-training improves downstream task performance, beyond simply “it helps learn good general representations of language using large amounts of unlabeled text data” (my previous reasoning).",Does the review address Result?,FALSE,TRUE,it does not mention Result.
"* Authors perform experimentally sound experiments, following closely LayoutLM.",Does the review address Experiment?,TRUE,FALSE,"Refers to the authors performing experimentally sound experiments, following LayoutLM."
"Theoretical Advantages and Theorem Justification:  While you mention that quantum features are theoretically more expressive, the paper falls short of explaining the underlying intuition and proof for this assertion.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Refers to the explanation of quantum features being theoretically more expressive but lacks the underlying intuition and proof.
- General Discussion: The authors perform relation extraction as reading comprehension.,Does the review address Methodology?,TRUE,FALSE,Refers to the approach of performing relation extraction as reading comprehension.
And are the previous work using the same training set?,Does the review address Methodology?,TRUE,FALSE,Refers to the inquiry about whether previous work used the same training set.
"2) As the authors claimed in Introduction, ‘plenty of training data is available’.",Does the review address Data/Task?,TRUE,FALSE,Refers to the availability of plenty of training data as claimed by the authors.
More discussions on comparing with symbolic logic reasoner model LReasoner are needed.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Refers to the need for more discussions comparing with the symbolic logic reasoner model LReasoner.
"Also, can you add a column where a dense linear model over p_f(s) is used?",Does the review address Presentation?,TRUE,FALSE,Refers to adding a column for a dense linear model over p_f(s).
The notations in equation 2 and 3 are also inconsistent with equation 5.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Refers to the inconsistencies in the notations of equations 2, 3, and 5."
"Altogether, I think this paper makes an interesting contribution to the question of: How can we get the most pretraining signal from unstructured data using off-the-shelf tools?",Does the review address Contribution?,TRUE,FALSE,Refers to the paper's contribution to maximizing pretraining signal from unstructured data using off-the-shelf tools.
"Since the selective annotation is based entirely on similarities derived from sentence embeddings, there is nothing explicit ensuring that the label distribution over the selected subset is not skewed.",Does the review address Data/Task?,TRUE,FALSE,Refers to the reliance on sentence embeddings and concerns about label distribution skewness.
"The only two tasks examined are sentence similarity tasks (which seem a bit more like a sanity check), and NaturalQuestions.",Does the review address Data/Task?,TRUE,FALSE,Refers to the examination of sentence similarity tasks and NaturalQuestions.
"- I think it makes sense in the comparison with CaP to compare using an oracle object detector, but one of the main novelties of the work is replacing the perceptual modules of CaP with foundation models.",Does the review address Comparison?,TRUE,FALSE,"Compares the work with CaP, focusing on the novelty of replacing perceptual modules with foundation models."
"The authors provide OTTER using hard labels (InfoNCE) as a baseline, but ZSL methods are sensitive to hyper-parameters and training sets.",Does the review address Methodology?,TRUE,FALSE,Discusses OTTER with hard labels and its sensitivity to hyper-parameters.
"The billions that have been pumped into languages like English have in fact resulted in technologies that can be applied at much lower cost to languages like Kanyen’kéha, but there are still costs.",Does the review address Significance?,TRUE,FALSE,Highlights the impact on costs for other languages.
"Result 1: Under the above assumption over the downstream task, this paper provides a bound on the empirical loss of the downstream prediction task.",Does the review address Presentation?,FALSE,TRUE,it does not mention Presentation.
- The ablation experiments and optimized prompt analysis are insightful.,Does the review address Experiment?,TRUE,FALSE,Refers to the insights from ablation experiments and optimized prompt analysis.
"And it's the averaged test scores that pRNN performs better - Please also make it clear whether the ""Test Avg.""",Does the review address Result?,TRUE,FALSE,Refers to the averaged test scores where pRNN performs better
"- Additionally, why isn't the the GRU version of pRNNv reported in the FBIS evaluation in Table 3?",Does the review address Evaluation?,TRUE,FALSE,Refers to the absence of the GRU version of pRNNv in the FBIS evaluation in Table 3.
"The result will stand out to compare against Codex, the state-of-the-art program synthesis model.",Does the review address Experiment?,FALSE,TRUE,it does not mention Experiment.
"Given the issued pointed out in 1 and 2, I am not sure if the results are really sound as the authors claimed.",Does the review address Methodology?,TRUE,FALSE,"Questions the soundness of the results, which relates to the methodology used in the study."
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Result?,TRUE,FALSE,Discusses the performance improvements and training speed as results of using BERT representations.
The introduction of two different positional encoding methods in different sections is confusing (even if one only serves the purpose of understanding the role of positional encodings).,Does the review address Presentation?,TRUE,FALSE,Refers to confusion from different positional encoding methods introduced in separate sections.
"Unfortunately, as the paper overall does not seem to contain significant novelty, neither in methodology nor in results, I cannot recommend acceptance at this point.",Does the review address Novelty?,TRUE,FALSE,Critiques the lack of significant novelty in both methodology and results.
"* Section 6.3 - Please change ""The results from Table 2 and Table 1"" to say ""Table 1 and Table 2"".",Does the review address Presentation?,TRUE,FALSE,Suggests a change in the presentation for clarity.
"Given the way p(guess=Ii) is used above, I think this should be more like E[argmax(p(guess=Ii)) = i].",Does the review address Presentation?,TRUE,FALSE,Suggests a change in the presentation for clarity in notation.
"Once those are answered, a significant test had better be done since the improvement seems small.",Does the review address Result?,TRUE,FALSE,Refers to conducting a significant test due to the perceived small improvement.
### Positive aspects   * Positional encoder based on sinusoidal function seems to be effective.,Does the review address Methodology?,TRUE,FALSE,Discusses the positional encoder as part of the methodology.
"Without comparison with SOTA's performance, I will try my best to reject this paper.",Does the review address Comparison?,TRUE,FALSE,Critiques the lack of comparison with SOTA's performance.
"Furthermore, the authors are neglecting parameter efficient fine-tuning baselines, for instance like [1].",Does the review address Comparison?,TRUE,FALSE,Mentions comparing to parameter-efficient baselines.
"Weakness: - paper title is misleading, not directly related to LM - no citation and description for the baseline method T5+KB (Table 4) - As shown in Table 7, the proposed method is very sensitive to many factors.",Does the review address Methodology?,FALSE,TRUE,"Critiques the title, missing citation, and sensitivity but not the method."
** The method is quite intuitive and can be regarded as an in-context example selection method (followed by annotations).,Does the review address Methodology?,TRUE,FALSE,Describes the paper’s approach as a method.
The hypothesis are clearly stated and the experiments are well designed.,Does the review address Experiment?,TRUE,FALSE,Praises how experiments are designed.
"In Sec2, you said ""yet is outperformed by the proposed fully-explored masking (see Table 2).",Does the review address Result?,TRUE,FALSE,Mentions performance from Table 2.
"* The current analysis doesn’t apply directly to BERT, which is trained to predict masked words in a sentence, instead of the next word.",Does the review address Methodology?,TRUE,FALSE,Talks about training approach (method).
(4) How exactly is the interaction module processed?,Does the review address Methodology?,TRUE,FALSE,Asks about the approach’s detail.
There are also neural architectures that particularly target to ensure some symbolic famous properties such as [3].,Does the review address Methodology?,TRUE,FALSE,Refers to particular neural architecture approaches.
Reducing it to 80% seems to be a sweet point with the best balance between performance and efficiency.,Does the review address Methodology?,TRUE,FALSE,Discusses a methodological choice (80% threshold).
Therefore the novelty of these components of the paper is negligible.,Does the review address Novelty?,TRUE,FALSE,Criticizes the paper’s lack of novelty.
"The architecture does not look entirely novel, but I kind of like the simple and practical approach compared to prior work.",Does the review address Novelty?,TRUE,FALSE,Comments on the architecture’s novelty.
I believe that this contribution isn't enough for me to recommend acceptance.,Does the review address Contribution?,TRUE,FALSE,Mentions “contribution” as insufficient.
"This paper shows that the log posterior have the same lower bound when the inference model p(y|x) is defined by different methods, i.e., the arithmetic mean of predictions with different dropout masks, the geometric mean, and a power-mean family as an interpolation between these two cases.",Does the review address Presentation?,FALSE,TRUE,"Focuses on a theoretical statement, not clarity/structure."
I think it will be helpful for authors to have a complete graph of the computational model used instead of only figure 1 concept graph.,Does the review address Methodology?,TRUE,FALSE,Suggests additional detail on the model/approach.
- There is some missing prior work in creating knowledge graphs from pre-trained language models.,Does the review address Methodology?,TRUE,FALSE,Refers to approaches for creating knowledge graphs.
"Also it seems that these are not fully annotated, and the ‘forward type inference functionality from TypeScript’ is required to obtain labels.",Does the review address Data/Task?,TRUE,FALSE,Discusses data annotation/labeling process.
So this contribution seems not practically useful according to the empirical result.,Does the review address Contribution?,TRUE,FALSE,Mentions contribution in practical terms.
"Alongside with qualitative analysis, some quantitative analysis would be good to show what the model learns.",Does the review address Analysis?,TRUE,FALSE,Requests more analysis of the model.
It is a bit hard to identify the interestingness or novelty in the approach.,Does the review address Novelty?,TRUE,FALSE,Questions the approach’s novelty.
2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues.,Does the review address Evaluation?,TRUE,FALSE,Refers to adding subjective evaluations.
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.,Does the review address Result?,TRUE,FALSE,Points out reported results.
"They show improved total performance in MultiWoz dataset compared to recent, relevant baselines.",Does the review address Result?,TRUE,FALSE,Mentions improved performance as a result.
The key contribution of the paper is the approach to overcome the limitation of annotating  query sets and labels.,Does the review address Methodology?,TRUE,FALSE,States the approach as a key contribution (method).
"For fine-tuning, the authors run their model for 2.2 epochs, while their baseline model runs for 3 epochs, roughly 30% more which accounts for much of the reduction observed in Table 2.",Does the review address Methodology?,TRUE,FALSE,Discusses fine-tuning approach details.
"Particularly because the reported accuracy margins are so slim, either of these variables could modify the empirical conclusions.",Does the review address Result?,TRUE,FALSE,References reported accuracy margins (results).
It is hard to know here which one of these actually made the adversarial setup useful.,Does the review address Presentation?,FALSE,TRUE,"Focuses on what made the adversarial setup work, not clarity/structure."
"DP is not ""incorporated"" in a model or multimodality (as the authors mention in different ways a few times throughout the paper), DP is a property of a randomised algorithm (in this context, the training algorithm that produces the distribution of models, not the model).",Does the review address Methodology?,TRUE,FALSE,Explains how DP is part of the training approach.
The method can select appropriate batch sizes by assessing the working memory requirements per token during benchmarking.,Does the review address Methodology?,TRUE,FALSE,Describes a technique for choosing batch sizes (the method).
"Given the nature of the problem statement (with multiple tasks, inputs and outputs), the authors have done a good job in explaining each of them properly.",Does the review address Data/Task?,TRUE,FALSE,Talks about multiple tasks in the paper.
May I know many questions are in each data split shown in Table 5?,Does the review address Data/Task?,TRUE,FALSE,Asks about data splits (number of questions).
"A significant part of the contribution was in the analysis of the results, obtained by this learning-based parameter sharing approach, which was quite informative and revealed some interesting insights about where and when a language-specific computation is required.",Does the review address Contribution?,TRUE,FALSE,Explicitly references the paper’s contribution.
Maybe add a comment saying Step 2 is the human-in-the-loop step of the algorithm?,Does the review address Methodology?,TRUE,FALSE,Suggests clarifying a step in the approach.
They also empirically show that it is easier and faster for the learner if the signals from easily inferred labels to learn target are provided.,Does the review address Result?,TRUE,FALSE,Describes an empirical finding (result).
The authors only conduct the evaluation on sentence similarity tasks and open domain QA tasks.,Does the review address Evaluation?,TRUE,FALSE,Mentions the scope of the evaluation.
"In a nutshell, aren't you showing that $$\text{downstream error}=\mathcal{O}\left(\sqrt{\text{pre-training error}\cdot\frac{\text{downstream error}}{\text{pre-training error}}}\right)\qquad ?$$  **Issues** - Why don't you verify the main claim---$\epsilon$-optimality in pre-training propagates as $\mathcal{O}(\sqrt{\epsilon})$-optimality on downstream---empirically?For this, you may want to vary the language modeling performance (e.g. by pruning the language model) and then verifying that the downstream loss increase is indeed $\mathcal{O}(\sqrt{\text{pre-training loss increase}})$.",Does the review address Presentation?,FALSE,TRUE,"Focuses on verifying a theoretical claim, not clarity/structure."
It is highly innovative and holds significant importance for the development of general artificial intelligence.,Does the review address Significance?,TRUE,FALSE,Emphasizes the paper’s importance/significance.
"You are clearly not trying to infer any loop invariants, and it would help clarify that upfront.",Does the review address Presentation?,TRUE,FALSE,Requests clarity regarding loop invariants.
"Also in Table 2, they claim that they outperform other approaches.",Does the review address Comparison?,TRUE,FALSE,Indicates comparison with other approaches.
"The latter is typically used in two different ways in the transformer architecture, each resulting in a different computation for RF  is confusing as the RFA is now redefined.",Does the review address Presentation?,TRUE,FALSE,Mentions confusion about definitions/usage (clarity issue).
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Questions the validity of the conclusions (validation).
"Given the barrier of reproducing the reported results and also the limited insights delivered by this work, I am sharing a huge concern regarding the current trend of building multimodal LLMs manifested by this work or other related ones.",Does the review address Methodology?,TRUE,FALSE,Critiques the approach (multimodal LLMs).
The authors take time to implement and evaluate several prominent baselines.,Does the review address Comparison?,TRUE,FALSE,Refers to evaluating multiple baselines for comparison.
"This is misleading as usually it is used to refer to world / external knowledge such as a knowledge base of entities, whereas here it is really just syntax, or arguably semantics if AMR parsing is used.",Does the review address Presentation?,TRUE,FALSE,Highlights a potentially misleading usage (clarity issue).
"For checking the generalization of the method and better comparison w/ InDIGO (though InDIGO also conducted on MSCOCO, Django and the current comparison is sufficiently fair), I would like to increase my rating if seeing more experiments on large scale machine translation benchmarks as those in InDIGO.",Does the review address Experiment?,TRUE,FALSE,Requests additional experiments for comparison.
I'd like some confirmation that larger batch size won't get much improvement for the baseline model.,Does the review address Methodology?,TRUE,FALSE,Inquires about a methodological choice (batch size).
It is unclear which sequences were used for training the Transformer models and how similar they are to test sequences.,Does the review address Methodology?,TRUE,FALSE,Questions the approach to training (method).
"Also, the citation to Universal Dependencies is completely broken.",Does the review address Related Work?,TRUE,FALSE,Mentions a broken reference to prior work.
"in CVPR, 2020  [2] J. Lu, V. Goswami, M. Rohrbach, D. Parikh, S. Lee, 12-in-1: Multi-Task Vision and Language Representation Learning.",Does the review address Related Work?,TRUE,FALSE,Cites prior publication in the same domain.
"Liu Y., Liu Z., Chua T.,Sun M. AAAI 2015 _ Also, the inclusion of the result from those approaches in tables 3 and 4 could be interesting.",Does the review address Presentation?,TRUE,FALSE,Suggests how to present additional results (tables).
"Since the data is generated by T-5, couldn't we generate as much as we want?",Does the review address Data/Task?,TRUE,FALSE,Refers to data generation and its quantity.
"Since it's a efficiency paper, I think it should be complete.",Does the review address Methodology?,FALSE,TRUE,"Criticizes completeness, but does not focus on the approach or technique."
The paper mentions that the entity extraction was done following Yasunaga et al.,Does the review address Methodology?,TRUE,FALSE,Refers to how entity extraction (a method) was performed.
"- Additionally, in my opinion, the authors are misrepresenting prior work when saying in line 163 that the ""MTL approach has not yet been successful in NLP"".",Does the review address Related Work?,TRUE,FALSE,Discusses prior work and possible misrepresentation of it.
Why authors consider questions answering and sentiment analysis as the applications?,Does the review address Methodology?,FALSE,TRUE,"Asks about application choice, but not how the method is designed/implemented."
Such gaps make the main contribution questionable and make it as a pure empirical paper on its value.,Does the review address Contribution?,TRUE,FALSE,Doubts the paper’s main contribution.
"In the 6.2.3 visualization of clusters, it would be very useful to have a visualization of clusters from some baselines on other ways of learning.",Does the review address Comparison?,TRUE,FALSE,Suggests comparing visualizations with baselines.
As the current system captures the semantics through RNN based models.,Does the review address Methodology?,TRUE,FALSE,Notes the use of RNN-based models (the approach).
"- I know GPT3 access is hard to get, but I wish experiments with k=8 prompts could be compared against  Post rebuttal: I think another pass for clarity over the paper would be good for the final version, but otherwise I'm happy with the paper updates and I'm happy to see the ablation numbers aren't too sensitive to token count.",Does the review address Presentation?,TRUE,FALSE,"Mentions clarity/presentation (e.g., ablation numbers placement)."
"- The experiments contain two setups, one is offline response evaluation via MultiWOZ, and another is interactive simulation via ConvLab.",Does the review address Evaluation?,TRUE,FALSE,Describes how the model was evaluated (offline vs. interactive).
"And further discuss the correlation between the classification performance and the instruction following rate, if there is any insights that can be drawn.",Does the review address Result?,TRUE,FALSE,Mentions performance correlations (results).
Cons: - wMAN model the relation for all possible pairs of the word and the video frame.,Does the review address Methodology?,TRUE,FALSE,Talks about how wMAN models relations (approach detail).
"If these method can also achieve very good results, then I feel that the novelty and effectiveness of DeFo may be challenged.",Does the review address Novelty?,TRUE,FALSE,Questions novelty and effectiveness.
"In experimental details, the slightly better performance in Table 2, can it be attributed to finer generation powered by the RNN generator?",Does the review address Experiment?,TRUE,FALSE,Specifically refers to experimental details/performance.
This paper proposes a reranking architecture with a LogicForm-to-NaturalLanguage preprocessing step for semantic parsing.,Does the review address Methodology?,TRUE,FALSE,Describes the proposed (re)ranking/semantic parsing approach.
The motivation behind Transformer-QL is to increase the context length processed beyond what other methods can.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,States the motivation for Transformer-QL.
"By using the first inference solution, the performance on PTB and Wikitext2 LM can be improved by 2-3 on perplexity but is still slightly worse than the SOTA achieved by the mixture of softmaxes.",Does the review address Result?,TRUE,FALSE,Mentions improved perplexity (results).
Nit: I would have tried to move the (datasets per cluster/templates per dataset) ablation to the main body as well and shortened Section 3  - The 4.2 (scaling laws) ablation is perhaps the most interesting of all.,Does the review address Ablation?,TRUE,FALSE,Explicitly references an ablation experiment.
"It would be useful if following the suggestions of [2,3] the authors could present results in settings with low data regimes and with significant distribution shift with respect to the pre-training set, which represents a more realistic application setting.",Does the review address Presentation?,FALSE,TRUE,"Suggests different experimental settings, not clarity/structure per se."
A uniform framework for resampling Different recombinations perform more or less favorably across different datasets.,Does the review address Data/Task?,TRUE,FALSE,Discusses dataset variations (resampling).
Casting the optimization of discrete latent variables as a one-step MDP is interesting 3.,Does the review address Methodology?,TRUE,FALSE,Describes an approach for optimizing discrete variables.
"Overall, I thought the paper was easy to read and understand.",Does the review address Presentation?,TRUE,FALSE,Comments on the paper’s clarity/readability.
"In terms of strenghs - The paper has a very throughout analysis of different models and positional encodings - It proposes several contributions, including a new probing task and several positional encoding methods.",Does the review address Contribution?,TRUE,FALSE,Mentions multiple contributions introduced by the paper.
Time analysis on language modeling is not presented.,Does the review address Methodology?,TRUE,FALSE,Criticizes missing methodological detail (time analysis).
"For a more comprehensive analysis, it would be instructive to see how the approach compares with a broader spectrum of state-of-the-art methods.",Does the review address Comparison?,TRUE,FALSE,Suggests comparing with more SOTA methods.
"The proposed system outperforms or achieves on-par  performance against previous SOTA methods, i.e., AudioGen and AudioLDM, in both objective and subjective metrics.",Does the review address Comparison?,TRUE,FALSE,States comparison with previous SOTA methods.
"However, this does not hold theoretically due to the extra bias on expectation.",Does the review address Analysis?,TRUE,FALSE,Mentions a theoretical issue (analysis) regarding bias on expectation.
- The evaluation on PTB (table 2) isn't a fair one since the model was trained on a larger corpus (FBIS) and then tested on PTB.,Does the review address Evaluation?,TRUE,FALSE,"Criticizes the evaluation setup (training on FBIS, testing on PTB)."
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Analysis?,TRUE,FALSE,Explicitly states a “thorough analysis” of the approach.
"As the paper points out, the success rate alone is not enough.",Does the review address Evaluation?,TRUE,FALSE,Refers to success rate (an evaluation metric).
"- In figure 6A, why was performance not increasing for untuned models w.r.t model size?",Does the review address Result?,TRUE,FALSE,Addresses model performance (a result).
"Since the architecture (ignoring the compression) is similar to multi-scale approaches, it would be good to compare against empirically.",Does the review address Comparison?,TRUE,FALSE,Suggests an empirical comparison with multi-scale approaches.
Their thorough ablation experiments and other analysis yield some interesting findings the authors could emphasize more.,Does the review address Ablation?,TRUE,FALSE,Points to ablation experiments.
"For example, a Figure to define what are $n_s, n_c, n_m$ would help to understand the paper with a nice visual benefit.",Does the review address Presentation?,TRUE,FALSE,Requests a clearer figure/definition (presentation/clarity).
"Given the ending of the paper, I interpreted that the set of dialog acts (i.e. options) are learnt automatically but I could not find this to be communicated explicitly.",Does the review address Methodology?,TRUE,FALSE,Raises a question about how the approach handles dialog acts (method detail).
"With the strengths being said, I hope to also point out that the paper's application of adversarial training is one attempt in many possibilities, and in many cases it is not clear where the improvements come from.",Does the review address Methodology?,TRUE,FALSE,Critiques the adversarial training approach (method).
"The in-depth experimental analysis of the BERT pretraining process in this paper answers many open questions (e.g., the usefulness of NSP objective) and also provide some guidance in how to effectively tweak the performance of pretrained model (e.g., large batch size).",Does the review address Methodology?,TRUE,FALSE,Describes insights for improving performance (method-related).
"Since they both use $m$ nodes, does it mean the supergraph also operates on each sub fact node?",Does the review address Methodology?,TRUE,FALSE,Inquires about the architecture’s design/approach.
The authors also introduce the recent developed Gumbel-matching techniques to derive the close-form of the posterior distribution.,Does the review address Methodology?,TRUE,FALSE,References the newly introduced technique (method).
"After reading it several times, I get the idea that the authors view a model as a general learner if it can simulate a universal circuit for all poly-size circuits.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Addresses how the authors define/describe a “general learner.”
"For the theoretical analysis, it was not clear to me what is the contribution of the current analysis compared to the Levine 2020 paper.",Does the review address Contribution?,TRUE,FALSE,Questions the added/concrete contribution of this analysis.
Experiments on both continual pre-training and general pre-training from scratch show the effectiveness of the proposed method.,Does the review address Experiment?,TRUE,FALSE,Mentions experiments on different pre-training setups.
"Setting and Main Result:  This paper focuses on classification tasks, and the bulk of the work goes into how to model the next word distributions as features or representations.",Does the review address Data/Task?,TRUE,FALSE,States it focuses on classification tasks (data/task).
Questions:  * How can we be sure that the specific power law derived from a different experimental configuration in Kaplan et al. (2020) corresponds to the empirical law that can be derived for transformers in this particular evaluation setting?,Does the review address Experiment?,TRUE,FALSE,Proposes verifying results experimentally.
"While I think it's nice to analyze the connection between RM and DM, the math provided in the paper is simple, and the main contribution is just to add a baseline to the algorithm of Khalifa et al.",Does the review address Analysis?,TRUE,FALSE,Refers to a mathematical/analytical connection (analysis).
- The empirical validation is thoughtful and relatively thorough.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Praises the thoroughness of the validation.
"However, there is no discussion on the latency in the proposed method and experiments.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes lack of discussion/explanation about latency.
The optimality of deterministic inference does not hold empirically due to class imbalance or discrepancy between training and test sets.,Does the review address Analysis?,TRUE,FALSE,Addresses an empirical/theoretical analysis point.
"### Weaknesses ###  * The paper falls short on the framing of the invariant inference problem, and on the technical details of what does it mean to infer a meaningful local invariant.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Calls for clearer definition/explanation of invariants.
"Regarding that CLIP does not release the 400M dataset (mentioned in this paper by the authors), the authors may not be able to train OTTER on the 400M dataset.",Does the review address Data/Task?,TRUE,FALSE,Discusses a dataset availability issue (data/task).
---------------------------------------------- Original: This paper is aimed at using pre-trained language models to create open-ended knowledge graphs.,Does the review address Methodology?,TRUE,FALSE,Describes the paper’s overarching approach (method).
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Addresses needing more discussion/justification (explanation/interpretation).
"other state-of-the-arts/benchmark systems on only ""present"" type of key phrases.",Does the review address Comparison?,TRUE,FALSE,Mentions comparing to other state-of-the-art systems.
"Important research can make great strides regarding languages that are usually neglected, if and only if funding is available for people to take the time to do the work.",Does the review address Significance?,TRUE,FALSE,Highlights the importance/impact (significance) for underrepresented languages.
The notations in equation 2 and 3 are also inconsistent with equation 5.,Does the review address Methodology?,FALSE,TRUE,Points to inconsistent notation (more a presentation issue than a methodological approach).
"In Sec 5.5 Gradient Variance, $\pi$ is missing in ""$G_\theta(x)=A(x)\nabla_\theta \log_{\theta}(x)$""",Does the review address Presentation?,TRUE,FALSE,Notes a missing symbol in the paper (presentation/typo).
"Overall, a very strong paper, well structured and clear.",Does the review address Presentation?,TRUE,FALSE,Praises clarity and structure of the paper.
"I have no experience with these kinds of NLU models, so I can't say with confidence whether the architectural additions proposed are well-motivated, but to me it feels like there is not a strong justification for adding these particular features to the BERT architecture, and the results do not clearly demonstrate their utility except in the ""lexical_overlap"" case.",Does the review address Result?,TRUE,FALSE,Points out unclear utility in reported results.
This paper tackles a very important and under-studied problem: reducing the cost of training NLP models.,Does the review address Presentation?,FALSE,TRUE,"Emphasizes problem importance, not clarity."
"**Update (after the author's response)**: During the rebuttal, the authors clarified my major concern, as well as provided additional experiments that verify the main claim of the paper.",Does the review address Experiment?,TRUE,FALSE,Mentions extra experiments verifying claim.
"Intuitively, this parameter arises from translating the ""natural"" task assumption, which only guarantees transfer on average to the downstream task.",Does the review address Methodology?,TRUE,FALSE,Discusses a parameter in the approach.
"For instance, the greater instability of larger Transformers to active learning bodes poorly for practitioners leveraging ever increasing model sizes for low-resource datasets.",Does the review address Data/Task?,TRUE,FALSE,Refers to low-resource datasets (data/task).
"Second, the authors neither 1) evaluate their model on another dataset or 2) evaluate any previously published models on their dataset.",Does the review address Evaluation?,TRUE,FALSE,Critiques the evaluation scope.
"I understand that a single model is helpful for multiple UI tasks, but I wonder if this approach is scalable beyond the 5 tasks and 5 modalities mentioned.",Does the review address Data/Task?,TRUE,FALSE,Questions scalability for multiple tasks.
"Compared to the related work, the novel part of this work is: (i) a new retrieval way, which is not quite clear and convincing to me.",Does the review address Significance?,FALSE,TRUE,"Questions novelty/clarity, not impact."
"The in-depth experimental analysis of the BERT pretraining process in this paper answers many open questions (e.g., the usefulness of NSP objective) and also provide some guidance in how to effectively tweak the performance of pretrained model (e.g., large batch size).",Does the review address Analysis?,TRUE,FALSE,Refers to detailed analysis of pretraining.
"As pointed by one public comment, the ablation study should show how much improvement is from BERT vectors.",Does the review address Methodology?,FALSE,TRUE,Specifically requests more ablation details.
"Prior work has explored ""learning-to-share""  strategies for parameter sharing in multi-task learning (see Ruder et al., AAAI 2018), and using gating/masking to control computational paths in a differentiable way (see Fan et al., ICLR 2019, Sukhbaatar et al., ACL 2019); it is clear that the focus is NMT but it should be worth mentioning/discussing such studies to better situate the work and to help the reader assess the actual contributions.",Does the review address Data/Task?,FALSE,TRUE,"Talks about prior methods, not data/task."
"A lot of attention/space is dedicated to locality and symmetry properties of positional encodings, which from my understanding, isn’t very novel and has been explored in previous work.",Does the review address Related Work?,TRUE,FALSE,Points to previous studies on this topic.
The paper pointed out that ELECTRA framework [1] explored the idea of using REINFORCE [2] as the the way of adding adversarial training signals to the model but observed degenerated results.,Does the review address Comparison?,TRUE,FALSE,References comparison with ELECTRA.
It is unclear which sequences were used for training the Transformer models and how similar they are to test sequences.,Does the review address Data/Task?,TRUE,FALSE,Mentions uncertainty about training/test data.
"* Theorem 2 is a restatement of past work, showing that transformers lie in logspace-uniform TC^0 * Theorem 3 assumes TC^0 \neq P / poly, and then derives that transformers cannot simulate any poly-time circuit.",Does the review address Methodology?,FALSE,TRUE,"Talks about theoretical results, not approach."
"Please report the total training and total inference time, and make a comparison with standard Transformer model.",Does the review address Comparison?,TRUE,FALSE,Requests comparison to a standard baseline.
Can the theory guide how to develop new models to learn program representations?,Does the review address Methodology?,TRUE,FALSE,Inquires about using theory to guide approach.
- Using “concept” to stand in for verbs and nouns is somewhat confusing.,Does the review address Presentation?,TRUE,FALSE,Notes confusion in terminology/clarity.
The authors may add more details about the previous work in the related work section.,Does the review address Related Work?,TRUE,FALSE,Suggests expanding discussion of prior work.
"In Section 2, the basics of binding-unbinding are introduced and many mathematical properties are required to make the binding-unbinding work.",Does the review address Theory?,TRUE,FALSE,Addresses the mathematical/theoretical basis.
This might depend on different sub-sequences and the various functions of different layers when modeling cross-attention.,Does the review address Methodology?,TRUE,FALSE,Discusses how layers function (method).
"- Since a major part of the model contains shared parameters, was there a need for new set of shared parameters along with the language-specific parameters.",Does the review address Methodology?,TRUE,FALSE,Questions approach’s parameter sharing.
"This paper shows that the log posterior have the same lower bound when the inference model p(y|x) is defined by different methods, i.e., the arithmetic mean of predictions with different dropout masks, the geometric mean, and a power-mean family as an interpolation between these two cases.",Does the review address Evaluation?,FALSE,TRUE,Focuses on theoretical/log posterior aspect.
"The authors switch between using BERT_base and RoBERTa_base without being very clear about when and why, e.g., in Table 2 they have both models, but only in different sections.",Does the review address Methodology?,TRUE,FALSE,Points out unclear approach usage.
There's also some missing related work in extracting knowledge from pretrained models that should probably be discussed.,Does the review address Related Work?,TRUE,FALSE,Mentions a need to discuss prior literature.
"Although I understand the experiment setup, missing reference to more recent VL works prevent readers from getting a good research landscape in the multimodal pre-training.",Does the review address Methodology?,FALSE,TRUE,"Points to missing references, not the approach itself."
"Hence, it will be better to additionally include the results of other standard RL algorithms for better justifying this claim.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Suggests extra RL baselines to justify the claim.
"In the experiments, the authors make comparisons with traditional methods, and show the effectiveness of their model.",Does the review address Methodology?,TRUE,FALSE,Indicates how they compare methods (approach).
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Result?,FALSE,TRUE,"Praises idea, analysis, not explicit results."
5.2 visualizations: this seems pretty ad-hoc without much justification for the choices.,Does the review address Presentation?,TRUE,FALSE,Notes unclear rationale in visualization choices.
"In Sec2, you said ""yet is outperformed by the proposed fully-explored masking (see Table 2).",Does the review address Presentation?,TRUE,FALSE,Refers to clarity of how results are shown (Table 2).
It is then not clear how each fact block (grey squares in Figure 4) functions as a whole.,Does the review address Presentation?,TRUE,FALSE,Mentions unclear figure explanation.
How about the benefits compared with the proposed one?,Does the review address Methodology?,TRUE,FALSE,Asks about comparing approaches (method detail).
"You *tell* us that Fon is ""a language with special tokenization needs"" and that ""standard tokenization methods do not alwaysadequately deal with the grammatical, diacritical, and tonal properties of some African language"", and you cite the relevant papers.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requires detailing Fon’s tokenization specifics.
How do the settings used in the experiments compare to those used for the analysis?,Does the review address Experiment?,TRUE,FALSE,Compares experimental settings with the analysis.
"- Followed by previous question, in the qualitative results, it seems the boundary parts of the predicted video segments are less accurate.",Does the review address Result?,TRUE,FALSE,Points to accuracy findings (results).
"- unconstrained, multi-concept:     This needs a direct comparison to a traditional discrete-channel referential game.",Does the review address Experiment?,TRUE,FALSE,Suggests an experimental setup for comparison.
Introducing the layer and networks in a simple way would help clarify the implementation and other notation.,Does the review address Presentation?,TRUE,FALSE,Calls for clearer implementation explanation.
The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).,Does the review address Significance?,TRUE,FALSE,States importance of data augmentation for classification.
"First, much of the improvement (I think) comes from reducing the number of epochs and/or the number of steps.",Does the review address Methodology?,TRUE,FALSE,Discusses how training steps/epochs affect the method.
In general the writing does not make the mechanisms by which proof artifacts may be extracted from Lean clear enough.,Does the review address Presentation?,TRUE,FALSE,Criticizes clarity of explanation.
- `Table 2`: Are these values computed over a single or multiple runs (in which case include stddev/confidence intervals).,Does the review address Presentation?,TRUE,FALSE,Mentions how results are presented in Table 2.
"Does the definition of ""event word""s here come from any particular previous work that motivates it?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Seeks reasoning behind defining “event word.”
"- If there is a limit set on the phrase length of pRNN, then it makes the system more tractable.",Does the review address Presentation?,TRUE,FALSE,Comments on clarity/structure of approach.
The proposed beam enumeration significantly outperforms REINVENT (the strongest baseline in the existing benchmark).,Does the review address Result?,TRUE,FALSE,Notes better performance than a baseline.
-  Consistent performance improvement over the baseline models on all of the three QA benchmarks.,Does the review address Data/Task?,TRUE,FALSE,Mentions performance on QA tasks (data/task).
The paper contributes LEANSTEP dataset and the Learning environment.,Does the review address Data/Task?,TRUE,FALSE,Introduces a new dataset/environment.
This method should be included in the experiments in order to justify the proposed RL approach is necessary.,Does the review address Experiment?,TRUE,FALSE,Suggests including a method in experiments.
"It would be to show more experiment results for some settings, for example, performance on Sum task when training with a mixture distribution, or more Sum task samples and fewer Parity task samples ( p range from 0.5 to 1.",Does the review address Result?,TRUE,FALSE,Calls for more results in specific tasks.
This logical progression effectively addresses the challenges initially posed.,Does the review address Methodology?,TRUE,FALSE,Talks about how the approach addresses challenges (method).
The model architecture should be better justified.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Requests stronger justification for the design.
This paper describes four methods of obtaining multilingual word embeddings and a modified QVEC metric for evaluating the efficacy of these embeddings.,Does the review address Presentation?,TRUE,FALSE,Refers to how methods are described and explained.
"The authors comment that the model architecture is designed to remain stable for a growing set of tasks, but this seems to be under the assumption that the input and output modalities would remain constant.",Does the review address Methodology?,TRUE,FALSE,Talks about the design approach and scalability.
Experiments on LEGO and code interpretation task are done.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Indicates details about tasks performed.
Possibly a dataset like common crawl or enwiki8 would be more appropriate for language modelling experiments.,Does the review address Methodology?,TRUE,FALSE,Suggests a different dataset for the approach.
"- P2, Sec 2: ""where $p^{\star}_{\cdot | s}$ is used as a vector on the left and distribution on the right"".",Does the review address Presentation?,TRUE,FALSE,relates to the clarity of the paper
"Is there a perplexity/efficiency tradeoff, and can you characterize that experimentally?",Does the review address Experiment?,TRUE,FALSE,Asks about evaluating perplexity vs. efficiency in experiments.
Is it possible to run an ablation study using the combination of REINFORCE and mixture-of-signals to verify whether Gumble-Softmax relaxation is the reason for it to work?,Does the review address Ablation?,TRUE,FALSE,Specifically requests an ablation study.
"It's important to discuss why these improvements are non-trivial and how they advance the field, considering the rapidly evolving landscape of both quantum computing and graph analysis.",Does the review address Result?,FALSE,TRUE,"Suggests discussing significance, not explicit results."
"Additionally, showing this for negations and / or examples which GreaseLM gets correct but QA-GNN does not (and vice-versa) can shed some light on what the model improves on (and what are the limitations).",Does the review address Methodology?,FALSE,TRUE,"Focuses on comparing model behaviors, not describing the approach."
- The methods and results are presented in an understandable manner.,Does the review address Methodology?,FALSE,TRUE,"Refers to clarity of presentation, not the method’s details."
"LeetCode problems tend to be fairly simple, self-contained, and, to my knowledge, are coding problems that are meant to help train new programmers or prepare software developers for coding interviews, amongst other things.",Does the review address Data/Task?,TRUE,FALSE,Discusses the nature of the LeetCode dataset (task).
* Ablation: the model vs corpus transfer comparison seems unfair to me.,Does the review address Ablation?,TRUE,FALSE,Explicitly refers to an ablation-related issue.
"* ""Moreover, it should be noted that BROS achieves higher f1 score than 79.27 of LayoutLM using visual features"".",Does the review address Comparison?,TRUE,FALSE,Compares BROS and LayoutLM.
"I compared their numbers explicitly to Liu et al. (2019), and RoBERTa_base outperforms their approach on nearly all tasks (and on average).",Does the review address Comparison?,TRUE,FALSE,Compares performance with Liu et al. (2019).
"This paper finds that the next word distributions of a subset of ""prompt"" words contain discriminative signals and are good features.",Does the review address Methodology?,TRUE,FALSE,Describes how the approach uses next-word distributions.
Strengths * Improving the data efficiency in language models is an important problem that so far studies have shown that can be achieved by scaling the size of the model.,Does the review address Data/Task?,TRUE,FALSE,Addresses data efficiency for language models (data/task).
The authors used RNN based generative models (discussed as RNN and Copy RNN) for keyphrase prediction and copy mechanism in RNN to predict the already occurred phrases.,Does the review address Methodology?,TRUE,FALSE,Describes specific generative modeling approach.
Theoretical analysis is provided to demonstrate the effectiveness of the proposed method under a greedy search algorithm.,Does the review address Theory?,TRUE,FALSE,Mentions a theoretical analysis.
"- Easy but probably not great thing to try:  held-out tasks with wrong/useless templates  A final thought:  It's not obvious that using as many training examples per dataset as possible is optimal, given that the model could overfit to dataset-specific spurious correlations.",Does the review address Data/Task?,TRUE,FALSE,Talks about how many training examples to use (data/task).
"Given that one of the primary goals of this paper was to create embeddings that perform well under the word translation metric (intra-language), it is disappointing that the method that performs best (by far) is the invariance approach.",Does the review address Methodology?,TRUE,FALSE,Discusses the chosen embedding method (approach).
The framework of Variational Information Pursuit is quite similar to the Concept Bottleneck Models.,Does the review address Methodology?,TRUE,FALSE,Compares one methodological framework to another.
"I think it would improve the paper if you could focus on a certain kind of invariants, and show that these invariants can in fact generalize across programs.",Does the review address Result?,TRUE,FALSE,Talks about demonstrating generalization (result).
But there should be no reason that it is restricted to be so.,Does the review address Data/Task?,FALSE,TRUE,Does not refer to data or tasks directly.
The proposed model is then experimentally verified on three logic-driven datasets which demonstrates some performance gain.,Does the review address Experiment?,TRUE,FALSE,Notes experimental verification on datasets.
"Below are my major concerns:  If the major motivation is to reduce gradient variance, can we just use larger mini-batch size?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Questions the motivation (reducing gradient variance).
* Assume T-LLMs are general learners by contradiction.,Does the review address Methodology?,TRUE,FALSE,States an assumption regarding T-LLMs (approach).
"However, it is unclear how well they perform to the CASP state-of-the art (see also Rives et al, 2020).",Does the review address Related Work?,TRUE,FALSE,References other state-of-the-art (prior work).
- Weaknesses: The comparison against similar approaches could be extended.,Does the review address Comparison?,TRUE,FALSE,Suggests more comparison with similar methods.
How effective is the method to capture farther long-term dependencies compared to previous methods?,Does the review address Comparison?,TRUE,FALSE,Directly asks about comparing with previous methods.
"For example, what if the authors don’t use a LogicForm-to-NaturalLanguage conversion?",Does the review address Methodology?,TRUE,FALSE,Questions a step in the approach.
### Overall  Authors used BERT alongside to a 2D-position embedding based on a sinusoidal function and a graph-based decoder to improve performance on document information extraction tasks.,Does the review address Methodology?,TRUE,FALSE,Describes the model’s approach (BERT + graph decoder).
"you explained this in page 6, in Task Description.",Does the review address Presentation?,TRUE,FALSE,Refers to explaining something in the text (presentation).
"Strengths:  - The paper is generally well-written, with excellent motivation and empirical setup/analysis  - The overall strategy of differentiable prompt optimized to maintain fluency is reasonable and novel.",Does the review address Analysis?,TRUE,FALSE,Notes the paper’s strong empirical analysis.
"## (Minor) Imprecise Claim about Poly(n) Size  In Theorem 1, the authors claim: > We consider log-precision, constant-depth, and polynomial-size Transformers: for Transformers whose input is of length n, the values at all neurons are represented with O(log n) bits, the depth is constant, and the number of neurons is O(poly (n)).",Does the review address Methodology?,FALSE,TRUE,"Focuses on theoretical/model size claim, not the approach itself."
"* Authors perform experimentally sound experiments, following closely LayoutLM.",Does the review address Comparison?,TRUE,FALSE,Refers to comparing with LayoutLM.
"This paper proposes to model the generation order as latent variables for sequence generation tasks, by optimizing the ELBO involving a proposed process of Variational Order Inference (VOI).",Does the review address Presentation?,FALSE,TRUE,"Describes the proposed approach, not clarity/organization."
- Figure 1 is helpful in comprehending the effect of different loss functions vs robustness.,Does the review address Result?,TRUE,FALSE,Mentions understanding results from Figure 1.
The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).,Does the review address Experiment?,TRUE,FALSE,Cites experimental results with RoBERTa.
"Detailed comments:  - P2, Sec 1.1: ""analyze the efficiency language model features"" -> analyze the efficiency of language model features  - P2, Sec 2: you started introducing these notations without explaining what they mean.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out missing explanation of terms/notations.
Weaknesses: - I felt like the empirical validation could have been stronger.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Criticizes the strength of validation.
Solid experiments demonstrating the proposed method outperforms other existing approaches.,Does the review address Methodology?,FALSE,TRUE,"Mentions strong experimental results, not the approach details."
The authors experiment their method on three datasets and get the state of the art results.,Does the review address Experiment?,TRUE,FALSE,Notes experiments on three datasets.
"The latter aims at avoiding catastrophic forgetting, while the former avoid having to share all (or no) parameters.",Does the review address Methodology?,TRUE,FALSE,Describes method for avoiding forgetting.
There is limited contribution in terms of machine learning algorithms.,Does the review address Methodology?,TRUE,FALSE,Addresses the study’s approach/algorithmic contribution.
The source for generating the data is a big contribution to the theorem prover and machine learning community.,Does the review address Theory?,TRUE,FALSE,Discusses a contribution relevant to theoretical aspects.
"However, the baseline may be much weaker than the current SOTA solution.",Does the review address Comparison?,TRUE,FALSE,Criticizes baseline vs. stronger SOTA.
Both settings show the better performance of the proposed method.,Does the review address Methodology?,FALSE,TRUE,"Mentions performance, not the approach."
"However, this does not hold theoretically due to the extra bias on expectation.",Does the review address Theory?,TRUE,FALSE,Talks about a theoretical limitation/bias.
"Overall the paper presentation is okay, although the clarity could be improved.",Does the review address Presentation?,TRUE,FALSE,Mentions clarity/presentation quality.
"You can then argue informally for why you think this definition makes sense, akin to, e.g., the Church-Turing thesis.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Discusses rationale/definition.
It should be stated more clearly in the text what this means.,Does the review address Presentation?,TRUE,FALSE,Calls for clearer statement in the text.
"**Experiment setup** In Table 3, the paper only compares the proposed method against GPT-Neo and GPT-J, which is not sufficient.",Does the review address Experiment?,TRUE,FALSE,Notes comparison limitations in the experiment.
"- I did not learn much from the evaluation; monolingual BERT achieves the highest accuracy, which by itself is not very surprising nor insightful.",Does the review address Evaluation?,TRUE,FALSE,Criticizes the evaluation insights.
"Weakness While the ablation study and visualization analysis are done, the key evaluations are missing.",Does the review address Evaluation?,TRUE,FALSE,Mentions evaluations not being thorough.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Result?,TRUE,FALSE,Refers to empirical findings.
"It'll be good to have some ablation study of the combined effect of using only one data sample in a mini-batch, and the full-explored masking.",Does the review address Ablation?,TRUE,FALSE,Requests additional ablation study.
The authors investigate how to use multi-task training on top of a pretrained model for a variety of unrelated tasks from the GLUE benchmark.,Does the review address Methodology?,TRUE,FALSE,Addresses the approach (multi-task training).
"It is clear that Shaw et al. (2019) didn't experiment on OVERNIGHT dataset, but setting up the baseline on a dataset should not be classified as ``our method’’.",Does the review address Related Work?,TRUE,FALSE,Discusses prior work usage/dataset context.
The model is tested in a long range language modeling task.,Does the review address Data/Task?,TRUE,FALSE,Mentions a specific language modeling task.
"Hence, it will be better to additionally include the results of other standard RL algorithms for better justifying this claim.",Does the review address Methodology?,TRUE,FALSE,Suggests adding more RL baselines (approach).
My hunch is LTU would be far better than Pengi in open ended tasks although Pengi might be better on Close-ended tasks.,Does the review address Significance?,TRUE,FALSE,Mentions significance for certain approach.
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.,Does the review address Result?,FALSE,TRUE,Suggests reordering figures; not about results.
5.1 aggregations: this seems fine though fairly ad-hoc.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Comments on a somewhat ad-hoc approach (motivation/validation).
Weaknesses:  - The notation/description of section 4 is not immediately intuitive.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques clarity of the notation/description.
- Too much detail in related work: I think the related work section is too long and just a list of papers rather than helping to place the work in the research area.,Does the review address Related Work?,TRUE,FALSE,Addresses the length/structure of related work.
"In terms of the experiments, there are only dev results reported on GLUE (Table 2).",Does the review address Experiment?,TRUE,FALSE,Notes that only dev results are shown (experiment).
"In the experiments, the authors make comparisons with traditional methods, and show the effectiveness of their model.",Does the review address Comparison?,TRUE,FALSE,Indicates direct comparison with other methods.
(2) Is table 1 an average over the 17 embeddings described in section 5.1?,Does the review address Presentation?,TRUE,FALSE,Asks about clarity of Table 1.
"**Weakness/Suggestions/Questions**  * Although The paper is well written overall, I think section 3.2 Proof Artifact Training can be improved by adding an example explaining the Lean terminology proof term, proof type, tactic, tactic state, etc.",Does the review address Presentation?,TRUE,FALSE,Calls for more clarity/examples in that section.
"However, evaluating dialogue policy is also important to justify the learned policy is suitable.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Highlights need for justification/validation.
"This is immediate from Theorem 2, and this kind of separation appears to have been the implicit the point of Merrill and Sabharwal 2023  * This statement seems overly strong and minimizes prior work: ""This work takes the first step towards rigorously answering the fundamental question by considering a theoretical boundary of model capacity to be general learner""      * e.g., ""Saturated Transformers are Constant-Depth Threshold Circuits"" shows that transformers lie in TC^0 under a saturation condition     * e.g., ""The Parallelism Tradeoff: Limitations of Log-Precision Transformers"" shows that log-precision transformers lie in log-space-uniform TC^0",Does the review address Methodology?,FALSE,TRUE,"Critiques a statement about prior theoretical work, not the approach."
"- The proposed architecture is tested on massive experiments including language understanding tasks, optical flow, video audio class autoencoding, image classification, and starcraft II and achieves superior performance.",Does the review address Experiment?,TRUE,FALSE,Notes large-scale experimental validation.
Massively multilingual neural machine translation.,Does the review address Related Work?,TRUE,FALSE,Title referencing prior research.
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.,Does the review address Presentation?,TRUE,FALSE,Suggests reorganizing figures (presentation).
The main weakness of the paper is that it is mainly based on further tuning the existing BERT model and lacks novel contribution in model architecture.,Does the review address Contribution?,TRUE,FALSE,Critiques insufficient novel contribution.
- Experiments are well-designed: many baselines are implemented to compare proposed method with traditional lifelong learning methods.,Does the review address Methodology?,TRUE,FALSE,Notes multiple baselines in the approach.
"- §2: ""study that implement"" -> ""study that implements"" - §3: ""adjectives has"" -> ""adjectives have"" - §4: ""analyzing sub-component"" -> ""analyzing sub-components"" - §5: ""Syllables features also generally performs"" -> ""Syllable features also generally perform""",Does the review address Presentation?,TRUE,FALSE,Addresses typos (presentation).
Missing period at the end of the first paragraph in the related work section.,Does the review address Presentation?,TRUE,FALSE,Notes a minor formatting/typo issue.
This paper proposed to use Graph Neural Networks (GNN) to do type inference for dynamically typed languages.,Does the review address Methodology?,TRUE,FALSE,States a GNN-based approach for type inference.
"Weaknesses, suggested improvements and requested clarifications  1.",Does the review address Presentation?,TRUE,FALSE,Summarizes needed clarifications/improvements (presentation).
"However, Section 3.1 cannot demonstrate effective theoretical information.",Does the review address Theory?,TRUE,FALSE,Criticizes the theoretical part in Section 3.1.
"If the authors can adequately address the following issues around presentation and the interpretation of Theorem 5, I would be satisfied raising my score, as I value the research question raised by the paper and believe the conclusions are valid.",Does the review address Presentation?,TRUE,FALSE,Mentions needing clarity/interpretation improvements.
"* Strength     * This paper proposes an interesting idea and interpretation to connect RM and DM paradigm     * This paper proposes a variance reduction method for DPG which demonstrates its improvement on performance, stability and sample efficiency * Weakness     * From my understanding, the baseline mostly comes from the observation in 3.3, which has limited technical novelty.",Does the review address Result?,TRUE,FALSE,Notes performance/stability improvements.
"Other designs include beam size, whether or not to use a pretrained model, etc.",Does the review address Methodology?,TRUE,FALSE,"Mentions design choices (beam size, etc.) related to the approach."
"Hence, the model relies on whether the parser accurately discovers the crucial information.",Does the review address Result?,TRUE,FALSE,Refers to model outcome depending on parser performance (results).
"**The method is simple with limited contribution, while performance improvement is not significant.",Does the review address Result?,TRUE,FALSE,Comments on the (limited) performance improvement.
"Figure 1 is presently not pleasant to look at, even though it has interesting results`!",Does the review address Presentation?,TRUE,FALSE,Criticizes figure’s visual clarity (presentation).
"Finally, a number of ablation studies are performed and demonstrate the effectiveness of the proposed method to some extent.",Does the review address Ablation?,TRUE,FALSE,Explicitly states ablation studies are conducted.
"3) Continue with 2), as the experiment results shown in Table 2, TS compiler performs poorly.",Does the review address Experiment?,TRUE,FALSE,References experiment results (Table 2).
- The methods and results are presented in an understandable manner.,Does the review address Presentation?,TRUE,FALSE,Praises clarity of methods/results presentation.
It’s very hard to compare the absolute differences Tables 1 and 2 for ourselves.,Does the review address Comparison?,TRUE,FALSE,Mentions difficulty in making comparisons across tables.
"####Minor Comments:  The paper mentions in several places symbolic scaffolding without citations, literature is certainly rich here, e.g. [1,2] are papers integrating symbolic constraints for semantic parsing.",Does the review address Related Work?,TRUE,FALSE,Points out missing citations (related work).
The threshold is definitely related to hardware specifications and model architectures.,Does the review address Presentation?,FALSE,TRUE,"Talks about threshold/hardware, not clarity/organization."
"- In figure 6A, why was performance not increasing for untuned models w.r.t model size?",Does the review address Methodology?,TRUE,FALSE,Questions approach regarding model size/performance.
"If not, the presentation requires to change and reflect only the controllability analysis.",Does the review address Presentation?,TRUE,FALSE,Suggests modifying how content is presented.
Weaknesses * Something that stands out is the lack of discussion and comparison to related works that employ recurrent formulations of attention.,Does the review address Methodology?,TRUE,FALSE,Criticizes the paper’s discussion of certain methodological aspects.
"- P3, Sec 2.2: ""... achieve lower test perplexity than traditional n-gram models"" Why is this true?",Does the review address Related Work?,TRUE,FALSE,Refers to prior methods (n-gram) in comparison.
"However, $R$ is defined as a non-square matrix in the previous paragraph.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out confusion about matrix definition.
What recommendation the authors would give for those interested in using it?,Does the review address Result?,FALSE,TRUE,"Asks for recommendations, not performance findings."
"In addition, improvements on full-shot cases are mostly marginal.",Does the review address Result?,TRUE,FALSE,States that improvements (results) are marginal.
"However, the contribution of this paper is not clear.",Does the review address Contribution?,TRUE,FALSE,Directly questions the paper’s contribution.
They introduce an unsupervised approach (MAMA) to construct a knowledge graph in two phases in which they take a target corpus and output a knowledge graph.,Does the review address Methodology?,TRUE,FALSE,Describes an unsupervised approach for knowledge graph construction.
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Data/Task?,FALSE,TRUE,"Focuses on comparisons/ablations, not a specific dataset/task."
The model is tested in a long range language modeling task.,Does the review address Methodology?,TRUE,FALSE,Notes how/where the model is tested (approach).
"------- Minors: - figure 1: could consider adding x, which would better match the descriptions of the paper (modeling p(y|x) instead of p(y))  Missing references:   [1] Chan, W., Kitaev, N., Guu, K., Stern, M. and Uszkoreit, J., 2019.",Does the review address Related Work?,TRUE,FALSE,Mentions missing references.
The task opens up a huge space for AI-powered general audio creation.,Does the review address Methodology?,FALSE,TRUE,"Notes application scope, not the approach details."
The current paper only indicates that a small gap gives more consistency between the true objective and the optimized objective defined on the training set: they can be still far away from the expected posterior over data distribution.,Does the review address Methodology?,TRUE,FALSE,Talks about the approach’s gap vs. objective.
- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.,Does the review address Analysis?,TRUE,FALSE,Critiques the scope of the analysis.
"- unconstrained, single-concept:     This is adquate to demonstrate that a minimal environment works (as stated in the paper).",Does the review address Experiment?,TRUE,FALSE,Mentions an experimental environment setup.
Weaknesses: There is no contribution/novelty from the modeling/methods side.,Does the review address Methodology?,TRUE,FALSE,States lack of methodological innovation.
"Furthermore, the authors deliberately avoid settings where DP is known to be hard due to the relatively low amount of training data per class (e.g. CIFAR-100/ImageNet).",Does the review address Methodology?,TRUE,FALSE,Points out approach choices regarding DP.
- Many interesting robustness capabilities of VL models only emerge when trained with hundreds of millions of samples.,Does the review address Methodology?,TRUE,FALSE,Talks about training scale and approach.
The proposed RoBERTa achieves/matches state-of-the-art performance on many standard NLU downstream tasks.,Does the review address Result?,TRUE,FALSE,States strong results on NLU tasks.
The authors should conduct experiments beyond English-to-French.,Does the review address Significance?,FALSE,TRUE,"Suggests broader experiments, not overall impact."
"In this paper, the authors present a study of different aspects of language-specific model capacity for massively multilingual machine translation.",Does the review address Methodology?,TRUE,FALSE,Discusses the approach for multilingual MT.
It is great to have a theoretical analysis of the property of the influence function.,Does the review address Theory?,TRUE,FALSE,Praises the theoretical aspect of influence function.
The applicability and the novelty of the SCS representation seem limited.,Does the review address Methodology?,TRUE,FALSE,Questions the method’s novelty/utility.
This paper is an interesting application of a data augmentation or self-supervised learning type of approach for tactic based theorem proving.,Does the review address Theory?,TRUE,FALSE,Relates to a theorem proving approach (theory).
it is likely a relatively minor effect given the results from Appendix B but it seems like it could slightly prevent overfitting  - The ablation in 4.1 was great (number of clusters).,Does the review address Ablation?,TRUE,FALSE,Mentions an ablation study on cluster count.
- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.,Does the review address Ablation?,TRUE,FALSE,Calls for more ablation analysis.
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Mentions theoretical analysis and validation.
"Simply because baselines have done that, it doesn't justify the authors from reporting inflated numbers.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Criticizes justification for reporting certain numbers.
An additional experimental results with multi-task finetuning should also be added.,Does the review address Data/Task?,TRUE,FALSE,Proposes more tasks/data for multi-task finetuning.
The state-of-the-art performance should be appreciated.,Does the review address Result?,TRUE,FALSE,References strong performance (results).
QA- GNN: Reasoning with language models and knowledge graphs for question answering.,Does the review address Related Work?,TRUE,FALSE,Title mentioning prior research.
"- General Discussion: This work tackles an important and interesting event extraction problem -- identifying positive and negative interactions between pairs of countries in the world (or rather, between actors affiliated with countries).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Defines/explains event extraction problem context.
"- Extensive ablation studies to demonstrate the importance of modality interaction layer  - selection, parameter sharing, graph connectivity, and parameter initialization.",Does the review address Methodology?,TRUE,FALSE,Mentions a methodological focus on modality interaction.
The paper is mostly clearly written and discusses server interesting ablation experiments.,Does the review address Presentation?,TRUE,FALSE,Comments on clarity/ablation discussion (presentation).
The results presented in the paper show strong gains against baseline methods on 3 different datasets.,Does the review address Data/Task?,TRUE,FALSE,Mentions results on multiple datasets (tasks).
"When you map ORCHID to UD, you lose information, since the ORCHID tagset is more fine-grained; does this make a big difference for taggers?",Does the review address Comparison?,TRUE,FALSE,Asks about the effect of mapping on comparison.
"According to the evaluation, the proposed method shows its effectiveness especially when the finetuning data is limited.",Does the review address Methodology?,TRUE,FALSE,Talks about method effectiveness in limited-data scenario.
"* It will be cool to show some results on BLEU improvement on machine translation, or user studies on language generation tasks, to demonstrate its practical impact, as the quantitative metrics right now are still kind of artificial.",Does the review address Result?,TRUE,FALSE,Suggests showing BLEU/results for practical impact.
"Under these assumptions, the gradient over the parity distribution samples is zero.",Does the review address Methodology?,TRUE,FALSE,References a methodological detail about gradients.
What is the number of resulting features that were used to train the logistic regression model?,Does the review address Methodology?,TRUE,FALSE,Asks about a detail of the feature design/approach.
"---- Detailed comments: ----  - ""For each dataset, we manually compose ten unique templates"":  Why not have templates per task cluster instead of per dataset?",Does the review address Data/Task?,TRUE,FALSE,Inquires about how templates are set per dataset/task.
I think if the paper will be improved if it resolves the lack of clarity around the temperature in GS being an implicit entropy-regularization parameter.,Does the review address Result?,FALSE,TRUE,"Discusses clarity around temperature, not final performance results."
The authors have done further experiments and show that there are still gains on these tasks when model sized is increased significantly.,Does the review address Methodology?,TRUE,FALSE,Mentions extra experiments about scaling the model (approach detail).
In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (pp.,Does the review address Related Work?,TRUE,FALSE,Citations indicating related prior work.
"- If not, please remove the attention layer after the encoder in figure 5.",Does the review address Presentation?,TRUE,FALSE,Suggests changing figure design (presentation aspect).
"In experiments, mainly accuracy is shown, but since the major motivation to reduce gradient variance, why not show some comparison of gradient variance of MLM and MLM-FE?",Does the review address Experiment?,TRUE,FALSE,Asks for additional experimental metric.
I provide details below examination of how I’ve come to my evaluation rating below.,Does the review address Evaluation?,TRUE,FALSE,Discusses the evaluation rating.
"As proposed in the comments, this should be assessed in the paper by replacing BERT representations by non-contextual representations such as GloVE.",Does the review address Presentation?,FALSE,TRUE,"Suggests a method tweak, not directly about clarity/organization."
"It would be great to define and identify beyond current close-ended tasks with new lower level tasks which really require using the audio, such as counting sound events, ordering of events, etc.",Does the review address Data/Task?,TRUE,FALSE,Proposes new tasks for audio or event counting.
"It is found that the published results of [1], (see reference below) performs better than (with a sufficiently high difference) the current system on Inspec (Hulth, 2003) abstracts dataset.",Does the review address Result?,TRUE,FALSE,Mentions comparing performance results.
"‘Wang & Cho’ were not the first who used Transformers generativity (see Vaswani, 2017).",Does the review address Related Work?,TRUE,FALSE,References earlier related work.
More importantly the PACT methodology is more general; the idea of incorporating diverse auxiliary tasks as a language modeling task by introducing a distinct token for each task is novel.,Does the review address Novelty?,TRUE,FALSE,Highlights the novelty of the PACT methodology.
Weaknesses: Some of the design choices need to be elaborated on further and additional analysis-based experiments would also be useful.,Does the review address Analysis?,TRUE,FALSE,Calls for more analysis of design choices.
"| s) which performs well, instead of a model directly over p*( .",Does the review address Result?,FALSE,TRUE,Not discussing the actual outcome/performance.
I therefore consider the contributions as insufficient for an ICLR submission.,Does the review address Contribution?,TRUE,FALSE,States dissatisfaction with the paper’s contribution.
More theoretical proofs or appropriate literature citations are needed to validate this assertion.,Does the review address Theory?,TRUE,FALSE,Requests more theoretical justification.
"The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",Does the review address Result?,TRUE,FALSE,Refers to results on Parity/Sum task.
I will be more convinced if evaluation is done on a wider range of tasks.,Does the review address Data/Task?,TRUE,FALSE,Wants more tasks included (data/task scope).
"Some of the details for model description are missing and confusing, e.g., (1) How the representation is initialized for a supernode corresponding to a fact triplet and how does the supernode propagate information to the sub-nodes?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques insufficient explanation of model details.
The paper use FLOPS to quantify the arithmetic intensity.,Does the review address Evaluation?,TRUE,FALSE,Mentions how performance/cost is evaluated (FLOPS).
"There's not much justification for it, especially given something simpler like a fixed window average could have been used.",Does the review address Methodology?,TRUE,FALSE,Criticizes method choice justification.
And the results of the proposed model can also be available for downstream detection models.,Does the review address Methodology?,TRUE,FALSE,Points out the approach’s applicability for other models.
"The authors propose to include related texts retrieved by the kNN method in a single training sample, which is proved effective in solving sentence similarity tasks.",Does the review address Data/Task?,TRUE,FALSE,Mentions a data retrieval approach for training samples.
"Section 4.8: Using transformers for generating proteins with natural properties is not new (see Madani et al, 2020, ‘ProGen’ or Rives et al, 2020).",Does the review address Novelty?,TRUE,FALSE,Notes that the idea is not entirely new (challenges novelty).
"(4) In general, the results in table 3 do not tell a consistent story.",Does the review address Presentation?,TRUE,FALSE,Criticizes clarity/consistency in presenting table 3.
However in experiment only 300 projects are involved.,Does the review address Data/Task?,TRUE,FALSE,Notes the limited dataset used in the experiment.
"For this purpose, the authors introduced the definition of a ""natural"" task.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions a newly introduced definition of a “natural” task.
Summary ========= Authors applied reinforcement learning framework to the problem of task-oriented dialog.,Does the review address Methodology?,TRUE,FALSE,Describes an RL-based approach for task-oriented dialog.
I also think it makes sense to switch Figure 1 and Figure 2 entirely.,Does the review address Presentation?,TRUE,FALSE,Suggests changing the order of figures (presentation).
"Leave ""general learner"" imprecise but reframe proposition 1 as your formal definition attempting to capture it: you view an LM hypothesis class is a general learner if it can express a universal circuit family for all poly-size circuits.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Talks about clarifying a definition/proposition.
"around 1% might be reasonable for 30-40% reduction in training time, but it is certainly a reduction in accuracy.",Does the review address Result?,TRUE,FALSE,References a (1%) drop in accuracy (result).
It's great the authors supplied code for part of the system so I don't want to penalize them for missing it -- but this is relevant since the paper itself has so few details on the baselines that they could not really be replicated based on the explanation in the paper.),Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques insufficient baseline explanation.
i. e. representing a word by a set of many Gaussian distributions.,Does the review address Presentation?,TRUE,FALSE,Mentions representation approach (potentially clarity).
"Theoretical Advantages and Theorem Justification:  While you mention that quantum features are theoretically more expressive, the paper falls short of explaining the underlying intuition and proof for this assertion.",Does the review address Theory?,TRUE,FALSE,Discusses theoretical expressiveness.
"* p 4: ""es should set a upper bound"" --> ""es should set an upper bound""  * p 5: "" ec perform better than or "" --> "" ec performs better than or """,Does the review address Presentation?,TRUE,FALSE,Points out typos (presentation details).
See section-2.6 of this tutorial for more details about using neural models to rank: https://www.microsoft.com/en-us/research/uploads/prod/2017/06/INR-061-Mitra-neuralir-intro.pdf.,Does the review address Related Work?,TRUE,FALSE,References a tutorial (related work).
The performance drops significantly when we change any of them.,Does the review address Result?,TRUE,FALSE,Notes significant performance drops.
- Extensive results show improvements over a base model and a larger model across a range of tasks.,Does the review address Result?,TRUE,FALSE,States improvements in results.
The author have opted for some sort of greedy pruning as described in the caption of figure 4.,Does the review address Methodology?,TRUE,FALSE,Describes a pruning approach (method).
"Page 5, line 1: should \tilde{e}^{(l-1)} be \tilde{e}^{l} instead ?",Does the review address Presentation?,TRUE,FALSE,Notes a potential typo in notation.
"If it is the extension to multilingual embeddings, a few lines explaining the novelty would help.",Does the review address Methodology?,TRUE,FALSE,Asks to clarify the approach’s novelty.
"To make the method more convincing, authors may consider use more recent VL models as student works, and try to further push their limits.",Does the review address Methodology?,TRUE,FALSE,Suggests method improvements (using new VL models).
"In experimental details, the slightly better performance in Table 2, can it be attributed to finer generation powered by the RNN generator?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Questions clarity/interpretation of performance improvement.
"The main limitation to me is that, the two novel pre-training tasks proposed in this paper are specific for Wikipedia and they are less effective than the ICT strategy (as shown in Table 5).",Does the review address Presentation?,TRUE,FALSE,Discusses table and how tasks are shown (presentation).
t-SNE plots of these selected examples in the larger context of unlabeled instances might also be a good visualization to show.,Does the review address Presentation?,TRUE,FALSE,Suggests a visualization technique (presentation).
"- Well Structured Experiments sections with 4 RQs and results that confirm each of the hypotheses  - Reproducibility and Transparency in reporting of experiments in terms of available source code, dataset information, details about human evaluation, generation examples.",Does the review address Evaluation?,TRUE,FALSE,Mentions how the experiments and evaluations are reported.
"Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Addresses rationale/validation for the approach.
Enhancing the paper with the aforementioned suggestions could substantially improve its impact and reception by the research community.,Does the review address Result?,FALSE,TRUE,"Suggests improvements, not discussing specific results."
There are also some typos to be corrected: Sec 1: ``...making purchase decision...'' should be ``making a/the purchase decision'' Sec 1: ``...are devoted to explore... '' should be `` are devoted to exploring'' Sec 1: ``...there is on sufficient behaviors...'' should be “there are no sufficient behaviors'' Sec 1: ``...on business trip...'' should be ``on a business trip'' Sec 1: ``...there are abundant behavior information...'' should be ``there is abundant behavior'' Sec 3: ``The new reviewer only provide us...'' should be ``...The new reviewer only provides us...'' Sec 3: ``...features need not to take much...'' should be ``...features need not take much...'' Sec 4: ``...there is not any historical reviews...'' should be ``...there are not any historical reviews...'' Sec 4: ``...utilizing a embedding learning model...'' should be ``...utilizing an embedding learning model...'' Sec 5.2 ``...The experiment results proves...'' should be ``...The experiment results prove...'' - General Discussion: It is a good paper and should be accepted by ACL.,Does the review address Presentation?,TRUE,FALSE,Notes typos and overall acceptance recommendation (presentation details).
** I would like to urge the authors to include more powerful baselines in the experiment rather than hide them.,Does the review address Comparison?,TRUE,FALSE,It requests stronger baselines for comparison.
"Prior work has explored ""learning-to-share""  strategies for parameter sharing in multi-task learning (see Ruder et al., AAAI 2018), and using gating/masking to control computational paths in a differentiable way (see Fan et al., ICLR 2019, Sukhbaatar et al., ACL 2019); it is clear that the focus is NMT but it should be worth mentioning/discussing such studies to better situate the work and to help the reader assess the actual contributions.",Does the review address Related Work?,TRUE,FALSE,It directly cites and discusses relevant prior literature.
Manual parameter sharing schemes are generally costly to come up with and when they are obtained for certain language pairs they do not necessarily generalize well to arbitrary language pairs in multilingual NMT.,Does the review address Methodology?,TRUE,FALSE,It addresses how approaches (schemes) are designed or used.
"However, the paper does not include detailed descriptions about the proposed method, making readers not easy to understand.",Does the review address Methodology?,TRUE,FALSE,It complains about insufficient details on how the method works.
- multi-concept and noise:     The noise you add to the channel has a number of different components; there should be an ablation study to illustrate the effects of these components.,Does the review address Experiment?,TRUE,FALSE,Suggests adding an ablation experiment for different noise components.
Simply adding related sentences in the pre training input context helps end performance.,Does the review address Result?,TRUE,FALSE,It notes improvement in performance (the result).
The authors refer to the fact that MTL can (and often does!),Does the review address Result?,TRUE,FALSE,Mentions an observed outcome/effect in multi-task learning (a result).
The submission has evaluated the proposed algorithms on four datasets and improved SOTA performances.,Does the review address Evaluation?,TRUE,FALSE,Talks about assessing the proposed algorithms and noting SOTA improvements.
"Although the presentation can be polished, the overall narrative and explanation is clear and easy to follow.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,It addresses clarity/“explanation” in the paper’s discussion.
"The authors show that for such tasks, if the pre-training objective is $\epsilon$-optimal, then the downstream objective of a linear classifier is $\mathcal{O}(\sqrt{\epsilon})$-optimal.",Does the review address Methodology?,FALSE,TRUE,"They’re stating a theoretical result, not describing the approach."
"Setting and Main Result:  This paper focuses on classification tasks, and the bulk of the work goes into how to model the next word distributions as features or representations.",Does the review address Result?,TRUE,FALSE,It highlights the primary outcome (result) for classification tasks.
The paper is well-written and the idea is well-motivated.,Does the review address Presentation?,TRUE,FALSE,Praises the paper’s clarity/writing (presentation).
"The annotations from [1] are very simple and short, only including some easy examples as in-context examples.",Does the review address Comparison?,TRUE,FALSE,Compares different annotations or approaches.
"## Logical Flow of Main Results and Relation to Prior Work Should be Clarified  The paper defines T-LLMs as general learners if ""the expressive power of realistic T-LLM model class can cover universal circuits for all circuits of polynomial size"" and says that:  > It is unknown whether the realistic Transformers are expressive enough to be general learners   In fact, it seems that Theorem 3 essentially follows from the TC0 upper bound in previous work.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests clearer explanation of results and prior work.
"The design of the architecture is novel, but it is also not groundbreaking.",Does the review address Methodology?,TRUE,FALSE,Comments on how the architecture is designed (method).
Summary: + Appealing theoretical contributions + Empirical results are encouraging + The use of discriminator for reward shaping in addition to task success rate is interesting  - Writing and explanation can be improved.,Does the review address Presentation?,TRUE,FALSE,Notes that writing/explanation could be better (presentation).
- The methods and results are presented in an understandable manner.,Does the review address Result?,TRUE,FALSE,Addresses clarity of presenting results.
"around 1% might be reasonable for 30-40% reduction in training time, but it is certainly a reduction in accuracy.",Does the review address Methodology?,TRUE,FALSE,Discusses a trade-off in approach/training (method).
The proposed ideas in isolation do not yield significant improvements.,Does the review address Result?,TRUE,FALSE,Speaks about the (lack of) performance gains.
* Related work: I would also include a discussion of this Lazaridou et al paper where they compare ways of combining EC with non-EC learning signals (e.g. image caption training): https://aclanthology.org/2020.acl-main.685.pdf  * Ethics statement: I appreciate this statement and agree with the possible positive impacts.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests adding another reference to related literature.
"If that is the case, that should be made more explicit.",Does the review address Data/Task?,FALSE,TRUE,Requests clarity but not specifically about data or tasks.
It would be really useful to have an ablation study to disentangle which piece of the training or method is contributing to what and how in the performance measure.,Does the review address Ablation?,TRUE,FALSE,Proposes an ablation to isolate contributions of each component.
4) It is not clear how the prediction variance is reduced gradually in order to generate the results in Figure 1(b).,Does the review address Presentation?,TRUE,FALSE,Criticizes the clarity of how a figure/result is explained.
After author response: See reply comment in the thread below for further score justification.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Mentions further justification for the author’s response.
"* Were the proposed architectural additions conceived with the HANS ""counterexamples"" in mind (i.e. is there a specific reason to think that these types of methods would avoid the ""superficial"" reasoning that these examples are supposed to reveal)?",Does the review address Methodology?,TRUE,FALSE,Asks if the approach was designed with a specific purpose in mind.
"But for some of the words, say ""hold"" and ""sits"", could it play a more important role?",Does the review address Significance?,TRUE,FALSE,Questions the importance/impact for certain words.
"It might be good to find the best hyperparameters for each setting to truly do a fair comparison (avoiding hyperparameter tuning isn't really a fair comparison, IMO -- but this depends on how much compute you have available).",Does the review address Comparison?,TRUE,FALSE,Suggests fairer hyperparameter tuning to compare approaches.
"With this approach, that requirement doesn’t exist anymore.",Does the review address Significance?,TRUE,FALSE,Points to the impact of removing a prior requirement.
The experimentation is correct and the qualitative analysis made in table 1 shows results as expected from the approach.,Does the review address Result?,TRUE,FALSE,Praises correctness of experimentation and analysis results.
What was the gain by simply using these embeddings as alternatives to the random embeddings in the LSTM stack parser?,Does the review address Methodology?,TRUE,FALSE,Inquires about the advantage of a certain methodological choice.
"Weaknesses:   The primary weakness of the paper is the lack of convincing justification that the authors have discovered a phenomenon distinct from “collective outliers” (Karamcheti et al., 2021) -- or if it is distinct, how exactly is it distinct?",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Criticizes insufficient justification of a distinct phenomenon.
The current experimental baseline can't reflect this.,Does the review address Comparison?,TRUE,FALSE,Suggests the baseline is not appropriate for comparison.
Figure 1 clearly shows the code generation process.,Does the review address Presentation?,TRUE,FALSE,Mentions clarity of a figure (presentation).
Some comments:  _ It may be interesting to include a brief explanation of the differences between the approach from Tian et al. 2014 and the current one.,Does the review address Comparison?,TRUE,FALSE,Proposes clarifying differences (comparison) with a prior approach.
"Then, taking inspiration from recent work that shows that many downstream tasks can be reframed as sentence completion tasks, it defines a “natural task” as one on which a sparse linear model over the output of the “true” language model (next word probability distribution, conditioned on context) attains strong performance.",Does the review address Methodology?,TRUE,FALSE,Describes how tasks are defined in the approach.
The authors find that the main ingredients for the success of in-context learning are a combination of selective annotation with similarity-based prompt retrieval.,Does the review address Methodology?,TRUE,FALSE,Discusses the core approach behind success.
Providing a more comprehensive elucidation of these processes would aid in bridging the gap between classical and quantum approaches.,Does the review address Methodology?,TRUE,FALSE,Calls for clearer explanation of the approach’s processes.
"In terms of strenghs - The paper has a very throughout analysis of different models and positional encodings - It proposes several contributions, including a new probing task and several positional encoding methods.",Does the review address Data/Task?,TRUE,FALSE,Focuses on analyzing models/positional encodings in a data/task context.
"Given a validation corpus (X,Y), and the corresponding retrieved (tX, tY), the authors should at least show the similarity between (X,tX), (Y,tY), which measures the retrieval quality.",Does the review address Significance?,FALSE,TRUE,"Proposes measuring retrieval quality, not necessarily impact."
"The description of the baselines is lacking and quite confusing: it's not clear why the authors have two DP-SGD baselines, and what they're exactly updating during training.",Does the review address Presentation?,TRUE,FALSE,Criticizes clarity of baseline descriptions.
3) This paper shows visualization of the interaction between words and latent topics in the embedding space.,Does the review address Methodology?,TRUE,FALSE,Describes a method for visualizing word-topic interaction.
- Slight improvements over CaP via the different prompting method.,Does the review address Methodology?,TRUE,FALSE,Discusses a prompting approach (method).
Clarity on Quantum Enhancements:  Section 3.2.2 seems to lack depth in the explanation of how the quantum correlations are calculated and utilized within the graph transformers.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques lack of explanation on quantum aspects.
"While this is not a downside by itself, it is probably something that one implement as a baseline.",Does the review address Methodology?,TRUE,FALSE,Talks about a baseline approach (method).
"One might hypothesize that if using a (subotimal) template that is less natural for language modeling, that zero-shot performance would suffer, but that FLAN performance wouldn't - One might hypothesize that the ""turn the task around"" templates help more than the other more straightforward templates that don't swap information between the prompt and response.",Does the review address Presentation?,FALSE,TRUE,"Suggests a hypothesis about templates, not focusing on clarity/structure."
## Summary The paper shows that Transformers trained unsupervised on millions of protein sequences learn information about protein contacts by using attention maps for contact prediction.,Does the review address Methodology?,TRUE,FALSE,Describes an unsupervised approach using Transformers.
"Considering the BERT is leveraged, you should discuss the relation with BERT + NMT [R1,R2].",Does the review address Related Work?,TRUE,FALSE,Suggests discussing a prior approach (BERT + NMT).
Is any care taken to handle this in training data?,Does the review address Data/Task?,TRUE,FALSE,Asks about handling specifics in the dataset/training.
Both split single word representation into multiple prototypes by using a mixture model.,Does the review address Comparison?,TRUE,FALSE,Compares how word representations are handled.
"Further, the performance improvements are nice, though not impressive.",Does the review address Evaluation?,TRUE,FALSE,Comments on the overall performance gains (evaluation).
"* Why are the lines for ""from scratch"" flat in Figure 2?",Does the review address Presentation?,TRUE,FALSE,Refers to figure clarity/visualization.
"There are many confounding factors such as the number and type of pretraining data, the instruction-tuning data, different architecture designs, and finetuning strategies.",Does the review address Data/Task?,TRUE,FALSE,Talks about data used for pretraining/instruction-tuning.
The PACT methodology: The paper proposes a methodology for extracting auxiliary tasks that can be trained jointly along with the main task (tactic prediction task).,Does the review address Data/Task?,TRUE,FALSE,Describes auxiliary tasks in the approach (data/task).
"However, for tasks that require more information on prior decoding context (machine translation or image generation tasks), does the proposed model can still perform well on those tasks?",Does the review address Result?,TRUE,FALSE,Questions performance on certain tasks (result).
--------------------------------------- Strength:  The hypothesis from the variance reduction is interesting.,Does the review address Methodology?,TRUE,FALSE,Comments on the approach regarding variance reduction.
"Result 1: Under the above assumption over the downstream task, this paper provides a bound on the empirical loss of the downstream prediction task.",Does the review address Data/Task?,TRUE,FALSE,Mentions downstream prediction task setting (data/task).
"- If so, please be more specific in describing it in section 4.2 and Table 4.",Does the review address Presentation?,TRUE,FALSE,Requests clearer presentation details.
"Mainly, for most of the intrinsic metrics, the multilingual embedding techniques do not seem to perform the best.",Does the review address Result?,TRUE,FALSE,Notes subpar performance (result).
Which layers and heads were used and how were they aggregated?,Does the review address Methodology?,TRUE,FALSE,Questions the approach’s layer/head usage.
Section 4.5 discusses that Transformers can be also used for secondary structure prediction.,Does the review address Methodology?,TRUE,FALSE,Mentions a method for structure prediction.
"I.e., Figure 1 should be your results table, and figure 2 should be the examples for us to see.",Does the review address Presentation?,TRUE,FALSE,Suggests reordering figures (presentation).
"- Extensive ablation studies to demonstrate the importance of modality interaction layer  - selection, parameter sharing, graph connectivity, and parameter initialization.",Does the review address Ablation?,TRUE,FALSE,Refers to ablation studies on modality interaction.
"It would have been fascinating if the authors were to do an ablation study to train their model in the format of (Audio, Text) --> Text format - something similar to what PENGI does.",Does the review address Significance?,FALSE,TRUE,Proposes a different ablation setup but not about impact.
"This is a bit confusing and I would suggest either changing the terminology or explicitly clarifying that you are talking about expressive power and not learning (which is fine, limitations on expressive power translate to limitations on what can be learned).",Does the review address Presentation?,TRUE,FALSE,Asks for clarity in wording/terminology.
This paper presents a replication study of BERT pretraining and carefully measures the impact of many key hyperparameters and training data size.,Does the review address Data/Task?,TRUE,FALSE,Discusses training data and hyperparameters.
Can the proposed theory help explain if the same code modeling task for some languages is strictly easier than the others?,Does the review address Data/Task?,TRUE,FALSE,Talks about code modeling tasks in different languages.
"**Areas of Enhancement & Questions to authors**  - The information about each of the ablations (ID, BM) could be explained better.",Does the review address Ablation?,TRUE,FALSE,Mentions clarifying ablation details.
How to efficiently complete the fine-tuning of the pre-trained model is also a direction worthy of attention.,Does the review address Methodology?,TRUE,FALSE,Discusses fine-tuning approach (method).
The experiments are conducted on datasets from questions answering and sentiment analysis.,Does the review address Data/Task?,TRUE,FALSE,Mentions QA and sentiment data usage.
"The primary contribution is an application of supervised, structured neural network models for sentence-level event/relation extraction.",Does the review address Contribution?,TRUE,FALSE,Mentions the paper’s main contribution.
What would happen if the number of scales is increased to capture  longer contexts?,Does the review address Experiment?,TRUE,FALSE,Questions experimental setup for context length.
* The proposed method RandomMask achieves SOTA on various downstream tasks.,Does the review address Methodology?,TRUE,FALSE,Notes the approach achieving SOTA (method).
We failed at finding an alpha meeting the requirements for the FT model.,Does the review address Methodology?,TRUE,FALSE,Mentions a challenge in the approach (alpha for FT model).
The introductions discusses existing work on Transformers for protein languages models.,Does the review address Methodology?,TRUE,FALSE,Talks about the approach for protein language modeling.
"The selected student networks, VL-BERT, UNITER, VILLA, while they are great and highly reputable works in the community, their performance is not as competitive as for today.",Does the review address Result?,TRUE,FALSE,Points out performance results of these networks.
The paper does not discuss the computational complexity of the proposed methods.,Does the review address Methodology?,TRUE,FALSE,Notes missing complexity discussion (method detail).
"- I also think it is reasonable to include a baseline that just input additional knowledge as features to the RNN, e.g. the head of each word, NER results etc.",Does the review address Comparison?,TRUE,FALSE,Suggests adding another baseline for comparison.
"Although the complexity analysis is thorough, I'd like to see empirical results of memory/compute requirements as a function of the context length.",Does the review address Methodology?,TRUE,FALSE,Requests empirical method analysis of complexity.
What recommendation the authors would give for those interested in using it?,Does the review address Methodology?,TRUE,FALSE,Asks about approach usage recommendations.
"**The method is simple with limited contribution, while performance improvement is not significant.",Does the review address Contribution?,TRUE,FALSE,Critiques the paper’s contribution.
The paper has explained and empirically showed that this learned generator needs a resampler.,Does the review address Result?,TRUE,FALSE,References an empirical finding/result.
- Too much detail in related work: I think the related work section is too long and just a list of papers rather than helping to place the work in the research area.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques how related work is described/explained.
- The visualization section is only a minor contribution; there isn't really any innovation or findings about what works or doesn't work here.,Does the review address Contribution?,TRUE,FALSE,Mentions it as a minor contribution.
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Methodology?,TRUE,FALSE,Mentions the need to discuss evaluation approach (method).
"Mainly, for most of the intrinsic metrics, the multilingual embedding techniques do not seem to perform the best.",Does the review address Presentation?,FALSE,TRUE,"Refers to performance, not clarity/organization."
"## Logical Flow of Main Results and Relation to Prior Work Should be Clarified  The paper defines T-LLMs as general learners if ""the expressive power of realistic T-LLM model class can cover universal circuits for all circuits of polynomial size"" and says that:  > It is unknown whether the realistic Transformers are expressive enough to be general learners   In fact, it seems that Theorem 3 essentially follows from the TC0 upper bound in previous work.",Does the review address Result?,TRUE,FALSE,Comments on a theoretical result.
Will the attention model pays more attention to this similar sample resulting in a negative impact on the target task performance since the source task and target task are quite different?,Does the review address Result?,TRUE,FALSE,Questions a potential performance impact (result).
"It is found that the published results of [1], (see reference below) performs better than (with a sufficiently high difference) the current system on Inspec (Hulth, 2003) abstracts dataset.",Does the review address Comparison?,TRUE,FALSE,Compares performance with prior results.
"I would have liked to see these results (also, please fix grammar in this sentence) 9.",Does the review address Presentation?,TRUE,FALSE,Mentions clarity/grammar for presenting results.
I think I'd like to see a discussion of sufficient number D analytically or empirically.,Does the review address Analysis?,TRUE,FALSE,Seeks more discussion/analysis of a parameter (D).
"Therefore, it is not necessary to carry out the forward of the text encoder every iteration during training.",Does the review address Methodology?,TRUE,FALSE,Addresses a detail about the approach (text encoder usage).
The Ablation Study of the paper also provides useful insights about the impact of different pre-training schemas on large-scale information retrieval tasks.,Does the review address Data/Task?,TRUE,FALSE,Mentions tasks (information retrieval) in ablation context.
"Given a validation corpus (X,Y), and the corresponding retrieved (tX, tY), the authors should at least show the similarity between (X,tX), (Y,tY), which measures the retrieval quality.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Suggests measuring retrieval quality for justification.
- Weaknesses: Comparison and credit to existing work is severely lacking.,Does the review address Comparison?,TRUE,FALSE,Criticizes insufficient comparison with prior work.
"A discussion on how to add new tasks to the same framework might help, or a discussion on why the current framework is enough.",Does the review address Methodology?,TRUE,FALSE,Talks about the approach to add new tasks.
"Considering the BERT is leveraged, you should discuss the relation with BERT + NMT [R1,R2].",Does the review address Significance?,FALSE,TRUE,"Asks about approach’s relation to BERT+NMT, not impact."
"Summary ------- Using multi-scale hierarchical and compressive techniques, this paper examines a way to increase the context length of transformers.",Does the review address Methodology?,TRUE,FALSE,Describes a method for context extension in transformers.
An additional experimental results with multi-task finetuning should also be added.,Does the review address Result?,TRUE,FALSE,Calls for more results on multi-task finetuning.
"The techniques used in the paper (multi-branch transformer, pointing mechanism, cross-modal attention, global positional encodings, etc) have been shown to work in the past for image-text tasks [1, 2].",Does the review address Methodology?,TRUE,FALSE,Talks about the approach/techniques.
"Since one of the main contributions of this paper is the analysis of the BERT pretraining process, more experimental analysis on the optimizer should also be included.",Does the review address Analysis?,TRUE,FALSE,Suggests deeper analysis of BERT pretraining.
The training objective allow budgetary constraints on the amount of language-specific parameters.,Does the review address Methodology?,TRUE,FALSE,Mentions how the approach (training objective) handles parameters.
A layman's explanation or intuitive reasoning behind the adoption of quantum features and their computational advantages in graph analysis would be invaluable for the reader's understanding.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Calls for clearer explanation/interpretation of quantum features.
It appears to vary by orders of magnitude according to Table 10 in the Appendix.,Does the review address Presentation?,TRUE,FALSE,Refers to clarity of data shown in Table 10.
"In experiments, there is no comparison with previous retrieval based methods.",Does the review address Comparison?,TRUE,FALSE,Mentions lack of comparison with prior retrieval methods.
"Thus, while concatenating the audio feature and the text feature can introduce desired performance, there could be some advancements not just combining pretrained audio model and LLM.",Does the review address Methodology?,TRUE,FALSE,Discusses the combined approach (audio + LLM).
"Additionally, the authors conclude that pre-training is not a significant factor in the efficacy of active learning, but their numerical results suggest active learning methods (Entropy and Coreset) narrow the gap with the random baseline significantly from BERT-Base to RoBERTa-Base!",Does the review address Methodology?,TRUE,FALSE,Talks about the approach regarding active learning.
Typos: - synthesis -> synthesise - DeepHOLZero -> DeepHOL - wrong bold number in Figure 3,Does the review address Presentation?,TRUE,FALSE,Points out minor typos/figure issues.
Conference on Empirical Methods in Natural Language Processing (2019).,Does the review address Related Work?,TRUE,FALSE,References prior EMNLP proceedings (related work).
In my opinion this is a significant paper as it explores one of the straight-forward ways to couple an audio encoder with a trained LLM and carefully examines this coupling from several different viewpoints and contributes the OpenAQA dataset which can be a useful public resource for future research.,Does the review address Significance?,TRUE,FALSE,Highlights the paper’s importance/impact.
The proposed RoBERTa achieves/matches state-of-the-art performance on many standard NLU downstream tasks.,Does the review address Methodology?,TRUE,FALSE,Describes the approach (RoBERTa achieving SOTA).
The paper starts with the motivation of handling comprehensibility.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Addresses motivation for comprehensibility.
"Mainly, Table 4 provides understandable results showing that multi-turn specifications achieve better performance compared to single-turn specifications.",Does the review address Experiment?,TRUE,FALSE,Mentions results from an experimental setup (Table 4).
"- The definitions, models, and assumptions in the paper are intuitive and clear (e.g., natural task).",Does the review address Methodology?,FALSE,TRUE,Praises clarity of definitions but not the approach itself.
Will the attention model pays more attention to this similar sample resulting in a negative impact on the target task performance since the source task and target task are quite different?,Does the review address Data/Task?,TRUE,FALSE,Questions potential data/task mismatch.
Some experimental settings only include the baselines Random and Vote-k. More methods as mentioned in 4.3.2 can be also included.,Does the review address Experiment?,TRUE,FALSE,Points out limited baselines in an experimental setup.
"However, if we considered this view, it seems like the problem they are solving should be more impactful than type recovery and AST generation.",Does the review address Significance?,TRUE,FALSE,Questions the overall impact/significance.
The results on a mixture of the Parity/Sum task are interesting   2.,Does the review address Data/Task?,TRUE,FALSE,Mentions tasks: Parity/Sum.
Strength: - Thorough study on the robustness of recent popular VL models vs conventional CE models.,Does the review address Result?,TRUE,FALSE,Notes findings on model robustness (result).
"Compared to this, the paper made 2 changes to the model: 1) using Gumble-Softmax instead of REINFORCE, and 2) using mixture-of-signals instead of straightforward gradient back-propagation.",Does the review address Presentation?,TRUE,FALSE,Discusses how changes are shown/presented.
The paper describes the idea of multiple temporal scales.,Does the review address Methodology?,TRUE,FALSE,Addresses approach with multi-scale design.
"The main issue of the paper is in the experiments and results reporting, it needs quite a bit of reworking.",Does the review address Result?,TRUE,FALSE,Criticizes how the results are reported.
"Both those works try to do both (1) extract time series or other statistical information about the polarity of the relationships between countries, and *also* (2) extract topical keywords to explain aspects of the relationships.",Does the review address Related Work?,TRUE,FALSE,Mentions other works addressing similar issues (related).
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Experiment?,TRUE,FALSE,Criticizes insufficient experimental comparisons.
There are a couple decisions related to methodology that may need some further examination.,Does the review address Methodology?,TRUE,FALSE,Points out issues with the study’s approach.
"On top of that, the only data is coming from LeetCode.",Does the review address Data/Task?,TRUE,FALSE,Mentions the dataset (LeetCode).
is a micro-average (all testsets are concatenated and evaluated as one set) or macro-average (average taken across the scores of individual test sets) score.,Does the review address Result?,TRUE,FALSE,Discusses how the results are averaged/evaluated.
I understand that LMU might have limited capacity but this is not specifically discussed and it is unclear how each component contributes to the end performance.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests deeper explanation of component contributions.
"While previous work has examined tasks in the overall area, to my knowledge there has not been any publicly availble sentence-level annotated data for the problem -- the authors here make a contribution as well by annotating some data included with the submission; if it is released, it could be useful for future researchers in this area.",Does the review address Related Work?,TRUE,FALSE,Notes a new data contribution and potential future usage (related).
Clarification on the task setting: Is it the case that the agent's current utterance does not decide what the next user utterance is?,Does the review address Data/Task?,TRUE,FALSE,Seeks clarity about the task scenario.
"Therefore, the obtained task performance is far from state-of-the-art.",Does the review address Data/Task?,TRUE,FALSE,Mentions that the task results are not SOTA.
I also encourage the authors to simplify the experiment described in section 3.1 to make it more clear.,Does the review address Experiment?,TRUE,FALSE,Suggests simplifying a particular experimental setup.
It is a bit difficult to understand the task definitions without first understanding the various constituents of the proof.,Does the review address Presentation?,TRUE,FALSE,Criticizes clarity in presenting the task definitions.
"Such rarity, however, could potentially be a drawback for these types of watermarking methods.",Does the review address Methodology?,TRUE,FALSE,Addresses a methodological drawback (watermarking).
"For example, what is the experiment environment and training receipts.",Does the review address Methodology?,TRUE,FALSE,Asks for details on the approach’s environment/training.
"This indicates that with the same training objective, different inference methods have different gaps to the posterior lower bound.",Does the review address Methodology?,TRUE,FALSE,Contrasts inference methods under the same training objective.
"They train low resource NMTs using 4 different tokenization strategies, to show that their proposed tokenization method leads to the best NMT results by several metrics.",Does the review address Evaluation?,TRUE,FALSE,Mentions how they evaluate different tokenization strategies.
Is it a margin of an SVM classifier that solves $\mathcal{T}$?,Does the review address Data/Task?,TRUE,FALSE,Asks about task specifics (SVM margin).
"-----Weaknesses----- I'm not very convinced by the empirical results, mostly due to the lack of details of the baselines.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques insufficient discussion/explanation of baselines.
- The presentation could be improved and distracts from the content at times.,Does the review address Presentation?,TRUE,FALSE,Notes that the paper’s clarity/flow can be improved.
"Given that there is a wealth of existing work that performs the same task and the lack of novelty of this work, the authors need to include experiments that demonstrate that their technique outperforms others on this task, or otherwise show that their dataset is superior to others (e.g. since it is much larger than previous, does it allow for better generalization?)",Does the review address Novelty?,TRUE,FALSE,Points to insufficient novelty.
"- Also, regarding section 3.3, please cite appropriate publications the ""previous work"" presented in the tables.",Does the review address Related Work?,TRUE,FALSE,Requests references to prior work.
The curriculum learning is yet another contribution which makes a lot of sense and the authors have proposed an intuitive curriculum and backed it up with apt ablation study to show its utility.,Does the review address Novelty?,FALSE,TRUE,Praises an approach but doesn’t question originality.
"Some kind of analysis of the qualitative strengths and weaknesses of the binary code prediction would be welcome -- what kind of mistakes does the system make, and how does this compare to standard softmax and/or hierarchical and differentiated softmax?",Does the review address Comparison?,TRUE,FALSE,Suggests comparing with standard softmax.
(ii) a new way to aggregate multiple inputs (using M-BERT) and several different decoding methods.,Does the review address Methodology?,TRUE,FALSE,Describes a new input aggregation approach.
"I think more could be done here, some ideas, probably there are better ways to test: - Have templates that leave out ""instructions"":  I would guess it wouldn't affect held-in task performance much, but would affect held-out tasks.",Does the review address Data/Task?,TRUE,FALSE,Suggests changes to the data/task templates.
They have to tune this parameter empirically instead of configure it theoretically.,Does the review address Methodology?,TRUE,FALSE,Addresses a parameter-tuning aspect of the approach.
**Experimental results** The presentation of the experimental results is clear.,Does the review address Result?,TRUE,FALSE,Mentions clarity of reported experimental results.
The model sizes are varied across experiments to achieve on par performance which makes the comparison of the computational cost not so obvious.,Does the review address Result?,TRUE,FALSE,Discusses how results are impacted by model size changes.
"For experiments, Table 1 shows the FOCAL Reasoner (DeBERTa) brings much performance gain, compared to FOCAL Reasoner (RoBERTa) (the performance seems comparable with DAGN and LReasoner using RoBERTa).",Does the review address Result?,TRUE,FALSE,Notes performance gains (result).
"- The authors have evaluated their models on multiple settings, proving that their models trained on Wikipedia can potentially generalize to multiple downstream tasks.",Does the review address Methodology?,TRUE,FALSE,Mentions broad evaluation of the approach.
The authors also propose two novel pre-training settings which also show improvement over the baseline BM-25.,Does the review address Methodology?,TRUE,FALSE,Talks about novel pre-training approaches (methods).
"Before describing your algorithm, humans are only mentioned once in the algorithm.",Does the review address Methodology?,TRUE,FALSE,Refers to how the algorithm is explained (approach detail).
But a direct head to head comparison for the computational cost of a multi-task model and individual models is not provided.,Does the review address Data/Task?,FALSE,TRUE,"This is about cost comparison, not data/task details."
"It is a report of various NLP efforts for several Indigenous languages of Canada It goes deeply enough into the technical details of the projects to show that the efforts are viable and successful, without getting bogged down in numbers or linguistic details that are unimportant to people external to the projects.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Talks about the level of detail/explanation in the paper.
The paper is mainly an empirical analysis of a different way of formulating an existing problem.,Does the review address Analysis?,TRUE,FALSE,States that the paper is an empirical analysis.
"The authors should make it clear that on different evaluation sets, the scores differs.",Does the review address Result?,TRUE,FALSE,Refers to differences in scores (results).
The paper pointed out that ELECTRA framework [1] explored the idea of using REINFORCE [2] as the the way of adding adversarial training signals to the model but observed degenerated results.,Does the review address Methodology?,TRUE,FALSE,Mentions a specific training approach (method).
The authors should discuss the relationship with other in-context example selection methods and compare the performance.,Does the review address Comparison?,TRUE,FALSE,Suggests comparing with other selection methods.
The idea that combining the output of several models using the attention strategy is not novel in deep learning.,Does the review address Novelty?,TRUE,FALSE,Criticizes the approach’s originality.
"The claimed contributions include: 1) The proposed method is free from the common issue of diverging from human language, because it learns from the sentences sampled from the pre-trained LM.",Does the review address Contribution?,TRUE,FALSE,Mentions the paper’s stated contributions.
Experiments on LEGO and code interpretation task are done.,Does the review address Data/Task?,TRUE,FALSE,"Refers to tasks (LEGO, code interpretation)."
"For example, if for the baseline model, we also only use one data sample and apply different masks, will there be improvement?",Does the review address Data/Task?,TRUE,FALSE,Talks about usage of data samples and masks.
The bad: * Figure 1 is difficult to read and messy.,Does the review address Presentation?,TRUE,FALSE,Critiques figure clarity (presentation).
"However, the BERT analysis results provided in this paper should also be valuable to the community.",Does the review address Analysis?,TRUE,FALSE,Refers to BERT analysis and its value.
The training procedure mentioned in section 5.2.2 talks about joint training but the procedure followed for training for individual tasks or a subset of tasks is not described in detail.,Does the review address Data/Task?,TRUE,FALSE,Mentions how tasks are trained (data/task).
- Experiments are well-designed: many baselines are implemented to compare proposed method with traditional lifelong learning methods.,Does the review address Comparison?,TRUE,FALSE,Indicates multiple baseline comparisons.
Did the authors try this as another compared baseline?,Does the review address Comparison?,TRUE,FALSE,Asks if they compared with another baseline.
Ad-hoc regularization parameter selection is necessary for getting performance gains.,Does the review address Result?,TRUE,FALSE,Mentions performance gain specifics (results).
- Extensive results show improvements over a base model and a larger model across a range of tasks.,Does the review address Methodology?,TRUE,FALSE,Describes outcomes of the approach (method).
The proposed ConceptQA architecture is intuitive and quite straightforward.,Does the review address Methodology?,TRUE,FALSE,Evaluates the approach’s architecture (method).
The task opens up a huge space for AI-powered general audio creation.,Does the review address Data/Task?,TRUE,FALSE,Refers to an audio creation task (data/task).
What recommendation the authors would give for those interested in using it?,Does the review address Contribution?,FALSE,TRUE,"Asks for recommendations, not referencing the paper’s contribution aspect."
I think if the paper will be improved if it resolves the lack of clarity around the temperature in GS being an implicit entropy-regularization parameter.,Does the review address Presentation?,TRUE,FALSE,Discusses clarity around a hyper-parameter (presentation).
Each task is supported with a detailed ablation study to shed light on future research.,Does the review address Ablation?,TRUE,FALSE,Indicates that an ablation study is performed per task.
"Figure 1 is presently not pleasant to look at, even though it has interesting results`!",Does the review address Result?,TRUE,FALSE,Mentions that figure shows interesting results (result).
Users cannot follow their strategy to set hyper-parameters in an optimal way.,Does the review address Methodology?,TRUE,FALSE,Talks about setting hyper-parameters (method).
"Is it possible to split Thai words into syllables without any ambiguity, or do you need a heuristic?",Does the review address Methodology?,TRUE,FALSE,Questions approach for splitting words (method).
"Rather than using the ad-hoc approach for selecting which augmentation ""stacking"" scheme is helpful, it would have been better to compare/use an approach highlighted in ""Learning to Compose Domain-Specific Transformations for Data Augmentation"" [NeuRIPS 2017].",Does the review address Comparison?,TRUE,FALSE,Suggests a different method for comparison.
"These prior methods do not incorporate the SFT stage, making it unclear how the model performs before this crucial phase.",Does the review address Presentation?,TRUE,FALSE,Mentions clarity/organization about prior methods.
"Why do you choose case-insensitive BLEU score for En->Fr, which is not commonly used in previous baselines.",Does the review address Comparison?,TRUE,FALSE,Questions the comparison approach (case-insensitive BLEU).
"In the experimental sections, it seems that only two scales are used.",Does the review address Experiment?,TRUE,FALSE,Observes the experimental setup (scales used).
"In terms of the experiments, there are only dev results reported on GLUE (Table 2).",Does the review address Result?,TRUE,FALSE,Refers to reported dev results (result).
"Placing Figure 1 and Table 1 on page 1 would improve readability, given that the main content describing Figure 1 and Table 1 is in the first page.",Does the review address Presentation?,TRUE,FALSE,Suggests reordering for clarity (presentation).
"Revisiting GNN for Question Answering](https://openreview.net/forum?id=hzmQ4wOnSb), whose hypothesis seems to be that by only using embeddings for node types and relation types, the models are able to attain good performance (86.67 acc on OpenBookQA) without needing any cross-modal information.",Does the review address Result?,TRUE,FALSE,Mentions a performance metric (86.67 acc).
(And the comparison to their BERT_base-based model yields roughly equal scores.),Does the review address Comparison?,TRUE,FALSE,States a comparison with a BERT_base-based model.
"**Pros**  - The paper is well structured and easy to follow, the idea of modeling sentences to a Brownian bridge latent space is neat and generic enough to (1) allow for noise given its stochasticity (2) doesn't require explicit domain knowledge for planning.",Does the review address Presentation?,TRUE,FALSE,Praises paper structure/organization (presentation).
"- OpenAQA-5M is a good contribution to provide open-ended question answering in audio domain, especially it is verified with human evaluation.",Does the review address Evaluation?,TRUE,FALSE,Refers to the human evaluation aspect.
"A qualitative analysis was required in Karamcheti et al., (2021) to explain “collective outliers”.",Does the review address Analysis?,TRUE,FALSE,Points to the need for a qualitative analysis.
"Result 2: The authors further extend this result to word embedding features, which are obtained by a weighted average of word embedding vectors based on the next word distributions.",Does the review address Result?,TRUE,FALSE,Mentions an extended result in the study.
"However, they only mention a single pruning rate of 50%, which could easily over-prune (all challenging as well as outlier examples) for the NLP datasets used here.",Does the review address Data/Task?,TRUE,FALSE,Critiques a data usage (pruning) approach.
But a direct head to head comparison for the computational cost of a multi-task model and individual models is not provided.,Does the review address Methodology?,TRUE,FALSE,Addresses a missing cost comparison (method).
The authors should discuss the relationship with other in-context example selection methods and compare the performance.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,"It's specifically about comparing approaches, not deeper definitions."
"Within the evaluation section, there are numerous intriguing findings that hold significant value for dissemination within the wider research community.",Does the review address Evaluation?,TRUE,FALSE,Mentions interesting evaluation findings.
"The primary contribution is an application of supervised, structured neural network models for sentence-level event/relation extraction.",Does the review address Methodology?,TRUE,FALSE,Describes a supervised neural approach (method).
The key contribution of the paper appears to be the formulation of the Concept-QA model based on query information and answers from GPT + CLIP.,Does the review address Contribution?,TRUE,FALSE,Mentions the main contribution (Concept-QA model).
* Additional general discussion and statistics studies are presented in the Appendix.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Indicates further explanation/discussion is in Appendix.
"The authors experiment both with pre-training and fine-tuning of contextual models (BERT-{base,large}) and claim large reduction in training time, with reasonable loss in performance.",Does the review address Methodology?,TRUE,FALSE,Mentions approach with pre-training/fine-tuning (method).
"I thought that this paper was very thought-provoking, and I appreciated the attempts to better understand what is going on with pre-trained language models, why they work well, and what might we be able to improve from theses insights.",Does the review address Methodology?,TRUE,FALSE,Discusses insights into pre-trained language model approach.
Will need some clarification to better judge the results.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Calls for more explanation to interpret results.
The proposed method is simple and relatively straightforward to implement.,Does the review address Methodology?,TRUE,FALSE,References the simplicity of the approach (method).
"However, Section 3.1 cannot demonstrate effective theoretical information.",Does the review address Analysis?,TRUE,FALSE,It critiques the theoretical depth (analysis) in Section 3.1.
"-----Weaknesses----- I'm not very convinced by the empirical results, mostly due to the lack of details of the baselines.",Does the review address Comparison?,TRUE,FALSE,Criticizes insufficient baseline details for comparison.
"I look forward to seeing the authors discuss a comprehensive comparison of DeFo's training time and other methods, such as CoOp and CLIP-adapter.",Does the review address Methodology?,TRUE,FALSE,Requests comparisons of training time details (method).
Why are all publications not used in training the baselines?,Does the review address Methodology?,TRUE,FALSE,Questions how baselines are trained (method detail).
* The proposed method RandomMask achieves SOTA on various downstream tasks.,Does the review address Data/Task?,FALSE,TRUE,"Mentions SOTA achievements, not a specific dataset/task."
Compilers tend to lower a representation of a software program into something that is closer to the hardware and therefore potentially more efficient.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Explains compilers at a conceptual level.
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Analysis?,TRUE,FALSE,States a theoretical/analytical approach to hyper-parameter selection.
"Unfortunately, many aspects of the models, experimentation, and evaluation are not explained very well.",Does the review address Evaluation?,TRUE,FALSE,Critiques the clarity of the evaluation details.
I suspect that a statistical analysis [1] might conclude that BERT and the proposed method are indistinguishable on the GLUE suite.,Does the review address Result?,TRUE,FALSE,Questions the difference in outcomes (results) on GLUE.
It is a bit difficult to understand the task definitions without first understanding the various constituents of the proof.,Does the review address Data/Task?,FALSE,TRUE,Criticizes clarity of definitions; not specifically about data/task.
Maybe adding another ablation on this would be a good idea.,Does the review address Ablation?,TRUE,FALSE,Suggests an additional ablation study.
This makes their empirical results extremely weak.,Does the review address Result?,TRUE,FALSE,Criticizes the empirical results.
"The experiments in the paper demonstrated the superiority of adding adversarial training to a self-supervision framework, in that significant improvements can be obtained for similar-sized networks.",Does the review address Result?,TRUE,FALSE,Discusses performance improvements (results).
Their findings on learning complex tasks contribute to the understanding of large language model learning and provide valuable insights for future related work on efficient training.,Does the review address Methodology?,TRUE,FALSE,Talks about how the approach informs future training methods.
"As proposed in the comments, this should be assessed in the paper by replacing BERT representations by non-contextual representations such as GloVE.",Does the review address Presentation?,TRUE,FALSE,Requests clarity/improvement in how representations are presented.
Such a comparison would highlight the advantages of the multi-task model and would be helpful for the relevant audience.,Does the review address Data/Task?,FALSE,TRUE,Focuses on method comparison rather than a dataset/task angle.
it doesn't seem straightforward for me to use constituent parse as knowledge here.,Does the review address Methodology?,TRUE,FALSE,Questions the feasibility of a certain method choice.
"This idea is novel and interesting to me, and the derivation and experiment results look encouraging.",Does the review address Novelty?,TRUE,FALSE,Praises the originality of the idea.
Weaknesses: - Somewhat weaker results on some CommonGen metrics are disappointing.,Does the review address Evaluation?,TRUE,FALSE,References a weaker evaluation outcome on CommonGen metrics.
"The authors investigate L=12 in the ablation, but in a real setting, it seems unlikely practitioners will label <50 examples before re-training.",Does the review address Ablation?,TRUE,FALSE,Mentions how a specific ablation setup is unrealistic.
"The paper could make more of an advocacy point for what relatively modest funding could do for languages in places where leaders have not yet had the same impetuses as witnessed in Canada, including India and Africa where ""minority"" language is often a misnomer.",Does the review address Significance?,TRUE,FALSE,Addresses the impact/significance of funding.
Theoretical discussion proves that the gradients derived from the new masking schema have a smaller variance and can lead to more efficient self-supervised training.,Does the review address Methodology?,TRUE,FALSE,Points to a theoretically backed aspect of the approach.
"> However, in every task except CommonGEN the authors do not discuss any methods that are even close to the state of the art.",Does the review address Data/Task?,TRUE,FALSE,Mentions tasks but complains about lack of SOTA-level discussion.
The authors clearly present their ideas and describe the technical details.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Praises clarity of technical explanations.
"Some things that are worth looking into are the work on Scalable static analysis [Scaling], the inference of necessary preconditions [Logozzo], and bug detection that is based on ""belief"" [deviant, belief], which is closely related to your intuition about naturalness and human-written invariants.",Does the review address Related Work?,TRUE,FALSE,Suggests relevant prior literature.
There are few places (see details) that authors have assumptions in mind but do not provide those assumptions until later.,Does the review address Methodology?,TRUE,FALSE,Criticizes how assumptions are revealed in the approach.
The findings of (2)(3)(4)(5) mentioned in the summary section above are especially interesting and can be helpful to the community when comparing new VL methods with existing methods.,Does the review address Comparison?,TRUE,FALSE,Addresses how these findings help in method comparisons.
"- If so, please be more specific in describing it in section 4.2 and Table 4.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests more detail/clarification.
Empirical results on MultiWoz 2 and 2.1 shows improvement over other state-of-the-art techniques.,Does the review address Result?,TRUE,FALSE,Indicates improvements on MultiWoz tasks (results).
"Even, Ref-[2] can be a strong baseline to compare the performance of the current system.",Does the review address Comparison?,TRUE,FALSE,Suggests comparing with a strong baseline.
"The paper said: “the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between text segments that appeared in different training examples.”  Acutally it seems quite natural for me and I did not realize it is a problem until I saw more explanations in section 1.1.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions how the paper’s explanations clarified the issue.
It does not follow from the theoretical results that adding similar sentences will be a good thing.,Does the review address Result?,TRUE,FALSE,Points to a conclusion about results vs. theory.
I would also urge the authors to have a speculative discussion on what successful inductive biases might look like.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Encourages more interpretative discussion.
The experimental results are promising for both settings.,Does the review address Experiment?,TRUE,FALSE,Discusses experiment outcomes.
"It is widely acknowledged and studied that the complexity (i.e., the length or reasoning steps of the CoT annotations) significantly influences the performance of the LLMs.",Does the review address Result?,TRUE,FALSE,Points to complexity affecting model performance.
"Typos: 1. compared with Enhanced baseline… -> Comparison with enhanced baseline   ** Refereces **  R1: Zhu, Jinhua, Yingce Xia, Lijun Wu, Di He, Tao Qin, Wengang Zhou, Houqiang Li, and Tie-Yan Liu.",Does the review address Presentation?,TRUE,FALSE,Highlights typos (presentation aspect).
The experimental results on RoBERTa highlight the applicability and importance of this data augmentation approach on the downstream task of text classification (GLUE).,Does the review address Result?,TRUE,FALSE,Addresses RoBERTa-based improvements (results).
Do the authors expect better results with a larger vocab size?,Does the review address Result?,TRUE,FALSE,Asks about potential outcome changes (results).
"For example, Figure 4 validates Assumption 4.1 (log-partition function is roughly quadratic in theta), and Table 1 shows many real tasks are approximately “natural”.",Does the review address Data/Task?,TRUE,FALSE,Talks about tasks and assumptions in the study.
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Criticizes the lack of justification in evaluation approach.
- Strengths: The paper is well organized and clearly written.,Does the review address Presentation?,TRUE,FALSE,Praises organization and clarity.
Can the proposed theory help explain some of the successes of one architecture over others?,Does the review address Theory?,TRUE,FALSE,Asks if the theory can explain architecture differences.
"In particular, it considers language models which compute a probability distribution over the next word in a text, given the previous context.",Does the review address Methodology?,TRUE,FALSE,Describes how the approach models next-word probabilities.
It seems that the authors have the infrastructure for computing single-model test-set results.,Does the review address Result?,TRUE,FALSE,Points out result-computation capability.
1.The performance of this model is closely related to both the AST encoding frontend and the LLaMA model's performance.,Does the review address Methodology?,TRUE,FALSE,Comments on factors affecting the approach (method).
"However, if the video is quite long, say 10 minutes, 30 minutes, or even few hours, will the method still be efficient and effective?",Does the review address Methodology?,TRUE,FALSE,Questions scalability of the approach.
"I'm concerned whether these improvements will hold after optimizing BERT carefully like RoBERTa, or using more advanced backbone methods like ALBERT.",Does the review address Methodology?,TRUE,FALSE,Questions the approach’s durability under different setups.
Cluster embeddings are then obtained which serve as embeddings for the words that reside in each cluster.,Does the review address Methodology?,TRUE,FALSE,Describes a method for obtaining cluster embeddings.
"The proposed method represents a novel approach to multimodal techniques, distinguishing itself from previous Vision-Language Models (VLMs) like Flamingo and PaLI.",Does the review address Methodology?,TRUE,FALSE,Mentions a new multimodal method.
"However, there are unclear parts to be addressed or clarified.",Does the review address Presentation?,TRUE,FALSE,Critiques clarity in presenting certain parts.
"* Extensive empirical results and analysis, providing some findings about overlapping strategy in DNA tokenization, could benefit the community.",Does the review address Analysis?,TRUE,FALSE,Mentions “analysis” in DNA tokenization.
"After reading other reviews and the authors’ responses to all of the reviewers, I recommend this paper by accepted—extensive results show that the CALM objectives offer more signal from data than current pretraining methods.",Does the review address Methodology?,TRUE,FALSE,Refers to the CALM pretraining approach (method).
The paper proposes a  HRL/options framework based method to learn a dialog policy over learned latent dialog acts which can then guide the lower level NLG.,Does the review address Methodology?,TRUE,FALSE,Describes a hierarchical RL approach.
"I still feel that the authors’ use of “concept” and “commonsense” is vague, when their method can be defined more clearly with more mundane terminology.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes unclear terminology.
"The authors empirically evaluate their N-Bref’s accuracy on a number of problems from the open source LeetCode problem set and generate 25,000 pairs of high-level source and low-level source which are broken into training (60%), validation (20%), and testing (20%).",Does the review address Evaluation?,TRUE,FALSE,Talks about accuracy evaluation.
"Some of the details for model description are missing and confusing, e.g., (1) How the representation is initialized for a supernode corresponding to a fact triplet and how does the supernode propagate information to the sub-nodes?",Does the review address Methodology?,TRUE,FALSE,Points to missing approach details.
Will need some clarification to better judge the results.,Does the review address Result?,TRUE,FALSE,Seeks clarity on the outcomes.
"* Even though this paper proposes a new efficient transformer, the evaluation does not focus on computational efficiency aspects and comes across as incomplete.",Does the review address Evaluation?,TRUE,FALSE,Criticizes the study’s evaluation focus.
"The strongest result is the HANS ""lexical_overlap"" case, where the proposed method has a clear advantage.",Does the review address Result?,TRUE,FALSE,Mentions a strong outcome (result).
"For instance, they ask how different amounts of data influence model behavior or if their data sampling method can react to task difficulty.",Does the review address Data/Task?,TRUE,FALSE,Discusses data amounts and task difficulty.
"Then it solves two tasks with two network branches: the first branch minimizes the loss for NER, and the second branch minimizes the loss for RE.",Does the review address Data/Task?,TRUE,FALSE,"Refers to multiple tasks (NER, RE)."
And the results of the proposed model can also be available for downstream detection models.,Does the review address Result?,TRUE,FALSE,Talks about model results.
I highly recommend bringing this assumption earlier to avoid readers confusion.,Does the review address Methodology?,TRUE,FALSE,Suggests clarifying an assumption in the approach.
"Minor: Only half the datasets are shown in Tables 3 and 4, but it’s unclear how/why those were chosen?",Does the review address Data/Task?,TRUE,FALSE,Questions dataset selection.
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Presentation?,TRUE,FALSE,Mentions how contributions/results are shown.
The results on Split H are positive and they also conducted a range of ablation and error analysis.,Does the review address Analysis?,TRUE,FALSE,Notes ablation and error analysis.
I'd like to see another ablation study of whether RE helps NER.,Does the review address Ablation?,TRUE,FALSE,Requests an additional ablation.
This is the newest of a small but growing body of literature that seeks to connect emergent communication with genuine NLP tasks.,Does the review address Data/Task?,TRUE,FALSE,Refers to emergent-communication NLP tasks.
(ii) a new way to aggregate multiple inputs (using M-BERT) and several different decoding methods.,Does the review address Novelty?,TRUE,FALSE,Proposes a potentially innovative aggregation approach.
"For table 4, please also include the significance of the BLEU improvement made by the pRNN with respect to the the baseline, see https://github.com/jhclark/multeval General Discussion ==== As the main contribution of this work is on the phrasal effect of the new RNN architecture, it's rather important to show that the phrases are more coherent than the vanilla LSTM / RNN model.",Does the review address Significance?,TRUE,FALSE,Asks about the importance (significance) of BLEU gains.
It will be great if authors can justify more on the technical novelty.,Does the review address Novelty?,TRUE,FALSE,Calls for more justification of originality.
(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.,Does the review address Data/Task?,TRUE,FALSE,Mentions tasks on MSMARCO.
"The paper is clear and detailed, and well situated in the literature.",Does the review address Presentation?,TRUE,FALSE,Praises clarity and structure.
Definition of Variables and Positional Encodings:  The paper would greatly benefit from a more detailed explanation of the positional encodings used.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests more in-depth explanation.
The paper then uses an existing result from Liao & Berg (2017) to show that the gap can be bounded by the variance of prediction probability.,Does the review address Result?,TRUE,FALSE,Refers to a stated result.
"Based on the large-scale training data and the proposed visual expert module, the proposed method achieves a number of state-of-the-art results across a wide range of vision-language tasks.",Does the review address Data/Task?,TRUE,FALSE,Talks about large-scale data for vision-language tasks.
"However, it is confusing to me how this interacts with the prior results in the paper.",Does the review address Result?,TRUE,FALSE,Unsure about how new info affects prior results.
A figure containing the whole process could be helpful to better understand the processing required to train / test such models.,Does the review address Methodology?,TRUE,FALSE,Recommends a figure for explaining the approach.
"1.The paper introduces for the first time a large language model that combines both general audio perception capabilities and language reasoning abilities, along with the datasets used for training.",Does the review address Methodology?,TRUE,FALSE,Describes a new model approach.
"They do pre-train their model (BROS) on a large dataset with 11M documents, and then used such models to perform downstream tasks in four smaller datasets.",Does the review address Methodology?,TRUE,FALSE,Talks about the approach (pre-training).
"So, it would be better to compare this system, which also captures semantics.",Does the review address Comparison?,TRUE,FALSE,Suggests direct comparison.
I can not understand why sample-specific rather than task-specific preference is important for prompt tuning.,Does the review address Related Work?,TRUE,FALSE,References other prompt-tuning methods.
"Positives --------- Increasing the context length of transformers is an interesting and relevant topic, and the proposed solution can have real impact in moving the state of the art forward.",Does the review address Significance?,TRUE,FALSE,Addresses the impact/importance.
The embedding methods are:  (1) multiCluster : Uses a dictionary to map words to multilingual clusters.,Does the review address Methodology?,TRUE,FALSE,Explains an embedding approach.
"Also, the lack of attention mechanism provides a disadvantage to the baseline enc-dec system and it's unclear whether the pRNN can outperform or be an additive feature to the enc-dec system with an attention mechanism.",Does the review address Methodology?,TRUE,FALSE,Notes a missing approach component (attention).
The auxiliary tasks themselves will be useful for designing similar tasks for other theorem provers.,Does the review address Data/Task?,TRUE,FALSE,Mentions tasks for theorem proving.
- Ablation study shown in table 5 provides good insights for choices of LoRA params and the benefit of curriculum in staged training.,Does the review address Presentation?,TRUE,FALSE,Refers to how ablation is presented in table form.
"Empirically, it demonstrates that several NLP tasks are “natural”.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Talks about validating tasks as “natural.”
Weaknesses * Something that stands out is the lack of discussion and comparison to related works that employ recurrent formulations of attention.,Does the review address Comparison?,TRUE,FALSE,Notes insufficient comparison to certain approaches.
- General Discussion: The authors perform relation extraction as reading comprehension.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions how RE is interpreted.
"Moreover, the authors better answer questions in 2 so I can gauge if their hyper-parameters were chosen in the principled ways.",Does the review address Presentation?,TRUE,FALSE,Talks about clarity of hyper-parameter decisions.
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Theory?,TRUE,FALSE,References the paper’s theoretical analysis.
"In the ablation study, the authors only consider the fixed \alpha as the base.",Does the review address Ablation?,TRUE,FALSE,Mentions a specific ablation setup.
It also compares different subword representation strategies and finds that syllable representations perform best (when not using BERT).,Does the review address Comparison?,TRUE,FALSE,Compares subword strategies.
"The motivation is to leverage unimodal data, which are assumed easier to obtain than image-text pairs.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Talks about rationale for using unimodal data.
####Pros:  The paper proposes the first RNN based neural generator to perform data augmentation for “extreme” compositionality inference.,Does the review address Data/Task?,TRUE,FALSE,Addresses data augmentation tasks.
I am also wondering if the extracted facts could bring too much noise to the question.,Does the review address Methodology?,TRUE,FALSE,Questions the approach about extracted facts.
"(In particular, pre-training on emergent language performs on average better than synthetic hierarchical data, but not quite as well as a different natural language, and all of these pre-training methods do better than training from scratch.)",Does the review address Data/Task?,TRUE,FALSE,Discusses various pre-training data sets.
"The authors argued that most of the previous multimodal LLMs used shallow connections between vision and models, and thus proposed a new module called visual expert.",Does the review address Methodology?,TRUE,FALSE,Introduces a new approach module.
"If the authors would like to compare the number of additional parameters of DeFo with CoOp and CLIP-adapter, I think it may be very helpful for us to comprehensively evaluate and compare these methods.",Does the review address Methodology?,TRUE,FALSE,Suggests comparing parameter usage (method).
The description of how you compare your invariants to those inferred by Daikon is not clear unless all relevant cases related to (pre)conditions on method parameters.,Does the review address Methodology?,TRUE,FALSE,Mentions how invariants are compared (method).
These papers and other methods for contact prediction beyond Gremlin are not described.,Does the review address Methodology?,TRUE,FALSE,Points to missing descriptions of methods.
"The true contribution appears to be the improvement of the overlapping strategy tokenization for DNA pretraining, which diverges from the broader theme of ""rethinking the pretraining for DNA sequence.""",Does the review address Methodology?,TRUE,FALSE,States the main contribution is a tokenization method.
"A significant part of the contribution was in the analysis of the results, obtained by this learning-based parameter sharing approach, which was quite informative and revealed some interesting insights about where and when a language-specific computation is required.",Does the review address Result?,TRUE,FALSE,Mentions analysis of the results.
**Reproducibility** I believe reproducing the results is possible given the clear description provided in the main paper and the appendix.,Does the review address Presentation?,TRUE,FALSE,Credits the clarity for reproducibility.
"The layers are described in a textual fashion, barely any math (and extended in the pseudo-code).",Does the review address Presentation?,TRUE,FALSE,Comments on textual layer descriptions.
"Given the way p(guess=Ii) is used above, I think this should be more like E[argmax(p(guess=Ii)) = i].",Does the review address Result?,TRUE,FALSE,Mentions the outcome or formula for results.
It is then not clear how each fact block (grey squares in Figure 4) functions as a whole.,Does the review address Methodology?,TRUE,FALSE,Criticizes clarity in the approach.
"- The paper uses code clone detection and semantic labeling to motivate their theory, but the theory focuses on characterizing language tractability.",Does the review address Theory?,TRUE,FALSE,Mentions a theoretical aspect.
Experimental results show improvements over both the base T5 model and the large T5 model.,Does the review address Experiment?,TRUE,FALSE,States experimental improvements.
"Additionally, there are some minor things I would add or improve: - I would add references to multi-task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE).",Does the review address Result?,TRUE,FALSE,Suggests references for comparing results.
"Additionally, the authors conclude that pre-training is not a significant factor in the efficacy of active learning, but their numerical results suggest active learning methods (Entropy and Coreset) narrow the gap with the random baseline significantly from BERT-Base to RoBERTa-Base!",Does the review address Result?,TRUE,FALSE,Talks about the findings in the results.
"If these method can also achieve very good results, then I feel that the novelty and effectiveness of DeFo may be challenged.",Does the review address Methodology?,FALSE,TRUE,"Focus is on novelty/effectiveness, not the approach/technique."
"Even if pruning is ineffective (at multiple pruning rates), it’s never really explained why, despite this being a core contribution of the paper.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes missing explanation for pruning.
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Data/Task?,TRUE,FALSE,References multiple datasets for QA tasks.
Section 3.4  does not describe clearly enough how attention maps were used for predicting contact maps.,Does the review address Presentation?,TRUE,FALSE,Complains about unclear description (presentation issue).
"Regarding that CLIP does not release the 400M dataset (mentioned in this paper by the authors), the authors may not be able to train OTTER on the 400M dataset.",Does the review address Methodology?,FALSE,TRUE,"Focus is on unavailable data, not an approach detail."
- The authors perform quite a lot of ablation studies.,Does the review address Ablation?,TRUE,FALSE,Explicitly says “ablation studies.”
Why don't the authors of this work do this evaluation as well?,Does the review address Evaluation?,TRUE,FALSE,Asks why they don’t perform a certain evaluation.
The provided experiments are more like baselines for self-evaluation other than state-of-the-art performance.,Does the review address Experiment?,TRUE,FALSE,References “provided experiments.”
"For example, the paper https://arxiv.org/abs/1505.06798 also goes beyond simply considering the reconstruction objective on the weights, and includes the nonlinearity as well in the reconstruction objective.",Does the review address Related Work?,TRUE,FALSE,Cites another paper as prior/related work.
"- Proposition 3.1 is a trivial consequence of the basic theorems of DP, and Algorithm 1 is a simple modification of DP-SGD (that is already available in standard DP-training libraries).",Does the review address Methodology?,TRUE,FALSE,Mentions approach (DP-SGD modification).
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Comparison?,TRUE,FALSE,Talks about comparing with an empirical law.
"Negatives --------- The experiments do not compare to many other approaches, even though those approaches are cited throughout the paper.",Does the review address Comparison?,TRUE,FALSE,Criticizes lack of comparisons.
"Contributions: - A new algorithm for unsupervised knowledge graph creation from a target corpus - Demonstrating the utility of large pre-trained language models towards knowledge graph creation (though, there are other works in this area that should probably be discussed more.",Does the review address Contribution?,TRUE,FALSE,States a “new algorithm” contribution.
"It's important to discuss why these improvements are non-trivial and how they advance the field, considering the rapidly evolving landscape of both quantum computing and graph analysis.",Does the review address Analysis?,TRUE,FALSE,Mentions discussing/improving understanding (analysis).
"It would help to clarify when what you predict is a guard, a precondition, an invariant, or something else.",Does the review address Result?,FALSE,TRUE,"It’s about clarifying items, not outcome/performance."
- Weaknesses: Many points are not explained well in the paper.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes lack of explanation or detail.
"- Extensive results and discussions are put in the Appendix, costing great effort in going back and forth.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions extensive discussion placed in the Appendix.
More discussions on comparing with symbolic logic reasoner model LReasoner are needed.,Does the review address Comparison?,TRUE,FALSE,Asks for more comparisons.
"* Extensive empirical results and analysis, providing some findings about overlapping strategy in DNA tokenization, could benefit the community.",Does the review address Result?,FALSE,TRUE,Focus is on “analysis” not specific results/performance.
"For the theoretical analysis, it was not clear to me what is the contribution of the current analysis compared to the Levine 2020 paper.",Does the review address Analysis?,TRUE,FALSE,Questions the value of current vs. prior analysis.
Case studies show that the method can help improve training efficiency.,Does the review address Methodology?,TRUE,FALSE,Mentions a method’s improvement to training efficiency.
"- reasonable initial experimental results demonstrating some ways to help models better use cross-text-chunk dependencies (put them into a contiguous text chunk), providing some hope that these results could make models better.",Does the review address Result?,TRUE,FALSE,Talks about experimental outcomes.
This work tries to address the issue by proposing a technique that carefully amalgamates multiple previously known approaches to generate diverse label preserving examples.,Does the review address Methodology?,TRUE,FALSE,Mentions a proposed technique (approach).
Is the speedup over total computational time or just the attention part?,Does the review address Methodology?,TRUE,FALSE,Questions detail of the approach’s speedup.
(I assumed authors used the same strategy as LayoutLM).,Does the review address Comparison?,TRUE,FALSE,References similarity to LayoutLM as a comparison.
"(2) In this paper, similarity and alignment structures are proposed, but no ablation experiments have been carried out to prove the effectiveness of the improved model.",Does the review address Ablation?,TRUE,FALSE,Notes missing ablation for the new structures.
"Terms such as θ, t, δ, and especially the adjacency matrix A, which are crucial for understanding the method, require clear definitions and contextual usage within the proposed quantum framework.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Calls for clearer definitions of variables.
"The two datasets have some “toy flavor”, while SCAN great favors example combination (with recomb-2 performs much better than recomb-1), recomb-1 seem to perform better for morphological analysis dataset, leaving questions about how to choose the exact models in general.",Does the review address Analysis?,TRUE,FALSE,Raises questions about analyzing model choice.
The paper then does a good job of showing how using one-hot encodings compared to SCS change the problem definition leading to a difference in performance on the same task.,Does the review address Comparison?,TRUE,FALSE,Contrasts two approaches (one-hot vs. SCS).
- How will the pseudo data generation amount affect the learning / forgetting performance?,Does the review address Result?,TRUE,FALSE,Asks about effect on performance (result).
This is the first such dataset for the Lean Theorem prover.,Does the review address Data/Task?,TRUE,FALSE,Refers to a new dataset.
"It is just a combination of the strong pretrained LLM and the existing audio encoder, AST.",Does the review address Methodology?,TRUE,FALSE,Mentions a method combining two components.
The visualization of OTTER’s matching illustrates its effectiveness in handling many-to-many relationships.,Does the review address Methodology?,TRUE,FALSE,Notes how the method handles many-to-many matching.
It would be impossible to replicate based on the two-line explanation here.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes insufficient explanation.
The authors should conduct experiments on more types of sentence pair tasks.,Does the review address Data/Task?,TRUE,FALSE,Suggests more tasks for experiments.
The concept of fact units is interesting and novel which are easily constructed via dependency trees.,Does the review address Novelty?,TRUE,FALSE,Calls the “fact units” concept novel.
"Furthermore, when there is a gap between the empirical results and the theoretical results (e.g., validation of Lemma 4.3 at the end of Section 4), the paper makes these limitations clear, which I appreciated very much as a reader (paper does not over-claim its contributions).",Does the review address Presentation?,TRUE,FALSE,Praises clarity about limitations.
"I also believe that the downstream tasks are also somewhat similar (language command grounding, tappability, UI object detection, UI summarization, widget captioning).",Does the review address Data/Task?,TRUE,FALSE,Mentions multiple tasks in UI domain.
"I still feel that the authors’ use of “concept” and “commonsense” is vague, when their method can be defined more clearly with more mundane terminology.",Does the review address Presentation?,TRUE,FALSE,Criticizes clarity of wording.
Otherwise for example it is not clear to me if the improvement in Blue compared to LaRL comes from the extra reward using the language model or from the options framework.,Does the review address Methodology?,TRUE,FALSE,Questions source of improvement in the approach.
"However, they merely note that their data was annotated at the “relation” level rather than at the triple (relation, entity pair) level… but couldn’t Bordes et al. have done the same in their annotation?",Does the review address Data/Task?,TRUE,FALSE,Discusses how the data was annotated.
"Although the individual components are similar to previous work, they are combined in a novel way that shows a path toward longer and more efficient context lengths.",Does the review address Novelty?,TRUE,FALSE,Points to a novel combination of components.
"Running a baseline model that runs *for the same amount of time* is essential to appreciate the contribution of this work (e.g., repeat the same analysis in Figure 3 for the vanilla BERT).",Does the review address Presentation?,TRUE,FALSE,Mentions showing baseline for clarity.
The same applies to Table 3: it is unclear to me why or how the baseline T5 model has been chosen.,Does the review address Comparison?,TRUE,FALSE,Criticizes unclear choice in baseline.
"Summary:  The augmentation of NLP samples is an important task with no clear ""applicable to all"" mechanism.",Does the review address Data/Task?,TRUE,FALSE,Mentions a data augmentation task.
"- Extensive results and discussions are put in the Appendix, costing great effort in going back and forth.",Does the review address Result?,FALSE,TRUE,"Focuses on results/discussion placement, not actual performance."
(3) Are there any advantages of using the multi-Skip approach instead of learning bilingual embeddings and performing multi-CCA to learning projections across the distinct spaces?,Does the review address Methodology?,TRUE,FALSE,Questions the advantage of a certain approach.
The paper made a significant contribution to idea of using adversarial training as part of the self-supervision signal for language learning.,Does the review address Contribution?,TRUE,FALSE,States a “significant contribution.”
Summary: + Appealing theoretical contributions + Empirical results are encouraging + The use of discriminator for reward shaping in addition to task success rate is interesting  - Writing and explanation can be improved.,Does the review address Theory?,TRUE,FALSE,Praises “theoretical contributions.”
Clustering to find exemplar terms for keyphrase extraction.,Does the review address Related Work?,TRUE,FALSE,"Mentions a keyphrase approach, referencing prior knowledge."
"The second sentence is confusing to me, and I am a native English speaker.",Does the review address Presentation?,TRUE,FALSE,Criticizes clarity of writing.
P5: Section 4.4: I am still eager to know how you select your dialog actions.,Does the review address Methodology?,TRUE,FALSE,Asks about how the approach picks dialog actions.
The performance is impressive and could be a better baseline for the future work.,Does the review address Comparison?,TRUE,FALSE,Mentions a baseline comparison.
"Since they both use $m$ nodes, does it mean the supergraph also operates on each sub fact node?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Asks for clarity on “supergraph” usage.
"The authors analyze the in-context bias of the self-attention model, which could inspire some research works on designing training examples.",Does the review address Methodology?,TRUE,FALSE,Talks about analyzing a model’s approach (in-context bias).
"It may be useful to show how the performance changes when using different M. - According to [2], the CommonsenseQA IH-dev set contains 1,221 questions in total.",Does the review address Result?,TRUE,FALSE,Mentions performance changes.
* It is hypothesized that PACT acts a regularizer while imparting useful knowledge to the model due to mutual information across tasks.,Does the review address Methodology?,TRUE,FALSE,Describes the approach’s effect on the model.
"- Well Structured Experiments sections with 4 RQs and results that confirm each of the hypotheses  - Reproducibility and Transparency in reporting of experiments in terms of available source code, dataset information, details about human evaluation, generation examples.",Does the review address Data/Task?,TRUE,FALSE,Mentions dataset details in experiments.
"\phi(x) as introduced in eq 2 is in R^{2D} but S_{t-1} is in R{D}, not sure what does + mean in this context.",Does the review address Presentation?,TRUE,FALSE,Questions notation explanation.
"- Strengths: Useful modeling contribution, and potentially useful annotated data, for an important problem -- event extraction for the relationships between countries as expressed in news text.",Does the review address Contribution?,TRUE,FALSE,Notes a “useful modeling contribution.”
All of the results in this work seem to be previously known: * Theorem 1 is general to any polynomial-size circuit -- there is nothing special about Transformers.,Does the review address Theory?,TRUE,FALSE,Refers to theorem/circuit theory.
"Experiments show that the induced ""best-first"" order outperforms fixed orders, which verifies the motivation of the paper` 4.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Talks about verifying motivation.
"* ""Moreover, it should be noted that BROS achieves higher f1 score than 79.27 of LayoutLM using visual features"".",Does the review address Presentation?,FALSE,TRUE,"States a result comparison, not clarity/structure."
More discussion is required on a) what are the reasons of loss in comprehensibility in this case (it is briefly mentioned in the intro) b) why their individual design choices and how they handles the different reasons c) some evaluation to verify this 2.,Does the review address Evaluation?,TRUE,FALSE,Requests further evaluation.
"It is reported that current system uses 527,830 documents for training, while 40,000 publications are held out for training baselines.",Does the review address Methodology?,TRUE,FALSE,Describes how baselines are trained.
"For the second ablation, why do all the larger splits lead to similar performance?",Does the review address Result?,TRUE,FALSE,Asks about performance outcome.
"While I think it's nice to analyze the connection between RM and DM, the math provided in the paper is simple, and the main contribution is just to add a baseline to the algorithm of Khalifa et al.",Does the review address Methodology?,TRUE,FALSE,Mentions approach/baseline addition.
"* Strength     * This paper proposes an interesting idea and interpretation to connect RM and DM paradigm     * This paper proposes a variance reduction method for DPG which demonstrates its improvement on performance, stability and sample efficiency * Weakness     * From my understanding, the baseline mostly comes from the observation in 3.3, which has limited technical novelty.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,"Focus on novelty, not detailed explanation."
"Furthermore, BERT doesn’t predict these masked words using a linear softmax model over a contextual embedding for the whole sentence, which is the assumed structure for the softmax language models considered in the analysis.",Does the review address Methodology?,TRUE,FALSE,Explains BERT's approach vs. assumed structure.
The authors present a simple technique for in-context learning with large language models that achieves consistently good results across a variety of NLP tasks.,Does the review address Data/Task?,TRUE,FALSE,References various NLP tasks.
"The main motivation/result of the paper appears to be that the authors can perform zero-shot relation extraction, extracting relations only seen at test time.",Does the review address Result?,TRUE,FALSE,Mentions the main result (zero-shot RE).
"Hence, the overall novelty of the work appears very low.",Does the review address Novelty?,TRUE,FALSE,Criticizes the work’s novelty.
"It may be useful to show how the performance changes when using different M. - According to [2], the CommonsenseQA IH-dev set contains 1,221 questions in total.",Does the review address Data/Task?,TRUE,FALSE,Talks about data usage (CommonsenseQA).
Cons:  - The main result (Thm 4.1) applies to next/conditional word distributions that are very close to the optimal distribution.,Does the review address Result?,TRUE,FALSE,Refers to a main theorem/result.
- Table 1 would be much more readable if you didn't use horizontal lines after every ORCHID tag.,Does the review address Presentation?,TRUE,FALSE,Suggests a presentation/format change.
The submission has evaluated the proposed algorithms on four datasets and improved SOTA performances.,Does the review address Data/Task?,TRUE,FALSE,References multiple datasets.
"Now consider a prior accepted ICLR 2020 paper, Hoppity (Dinella et al. ), which trained on nearly 300k code change commits in GitHub.",Does the review address Comparison?,TRUE,FALSE,Compares to a prior approach (Hoppity).
"For example, experiments could investigate if using words which are phonologically similar (e.g., ""boat"" and ""moat"") is harder to distinguish than dissimilar words.",Does the review address Experiment?,TRUE,FALSE,Suggests an experimental investigation.
Using Transformer attention maps for protein contact prediction is not new.,Does the review address Novelty?,TRUE,FALSE,States it’s not novel.
"In particular, instead of modeling the context information between the sentence and each video frame, wMAN tried to learn the representation with multi-level and co-attention, which considers all possible pairs between the word and the frame.",Does the review address Presentation?,FALSE,TRUE,"Describes method, not clarity/organization."
"Clarification of contribution  Eq 6,7 reads like RNN style update but the intuition is lacking.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Mentions lacking intuition.
-  Consistent performance improvement over the baseline models on all of the three QA benchmarks.,Does the review address Result?,TRUE,FALSE,Mentions performance improvement.
"For instance, the greater instability of larger Transformers to active learning bodes poorly for practitioners leveraging ever increasing model sizes for low-resource datasets.",Does the review address Methodology?,TRUE,FALSE,Talks about method with active learning.
"Good set of ablation studies to show that each component of the model is necessary, especially because the entire model already has many moving parts in addition to adversarial training.",Does the review address Ablation?,TRUE,FALSE,Mentions ablation studies.
The key contribution of the paper is the approach to overcome the limitation of annotating  query sets and labels.,Does the review address Contribution?,TRUE,FALSE,States “key contribution.”
"Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.",Does the review address Data/Task?,TRUE,FALSE,Mentions LM tasks (data usage).
This could be done by visualizing the planning trajectory difference between coherent and incoherent text.,Does the review address Presentation?,TRUE,FALSE,Suggests a visualization approach.
"- grounded language learning:     In both of these experiments, there is analysis provided on what aspects of the audio-based communication channel make the problem harder, easier, or just different from the same experiment with a discrete channel.",Does the review address Experiment?,TRUE,FALSE,Refers to analysis in experiments.
"- Overall the paper would have benefited from an intrinsic visualization of the latent space, to make sure for example that there's no  Information collapse of the embeddings when dealing with long sentences.",Does the review address Presentation?,TRUE,FALSE,Mentions visualization (presentation).
It handles the hallucination problem of LLM by training close-ended dataset and then non-answerable question-answer pairs.,Does the review address Methodology?,TRUE,FALSE,Notes a specific method approach.
"The two datasets have some “toy flavor”, while SCAN great favors example combination (with recomb-2 performs much better than recomb-1), recomb-1 seem to perform better for morphological analysis dataset, leaving questions about how to choose the exact models in general.",Does the review address Result?,TRUE,FALSE,Talks about performance differences.
"I compared their numbers explicitly to Liu et al. (2019), and RoBERTa_base outperforms their approach on nearly all tasks (and on average).",Does the review address Related Work?,TRUE,FALSE,Mentions a direct comparison to prior work.
"- P8, Table 2: The results from using Quad look worse than the above two.",Does the review address Result?,TRUE,FALSE,Compares results using “Quad.”
"This idea is novel and interesting to me, and the derivation and experiment results look encouraging.",Does the review address Experiment?,TRUE,FALSE,Talks about experiment results.
"Therefore it would be interesting to see how this affects performance, i.e. just run the method on the CaP benchmark without the oracle.",Does the review address Methodology?,TRUE,FALSE,Suggests an approach tweak.
The explanation at the end of Section 4 is not persuasive.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes clarity of explanation.
"3.The model excels in various audio-related tasks and open-ended question answering, demonstrating its outstanding performance.",Does the review address Result?,TRUE,FALSE,Mentions the model’s performance.
"- Do you have any initial experiments on the ""self-improving"" aspect of this technique?",Does the review address Experiment?,TRUE,FALSE,Asks about an experimental aspect.
"- In Table 1, can you explain more explicitly (in caption and text) what “subset” and “class words” means?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests more explanation.
The authors present a method that builds on the lottery ticket hypothesis (LTH).,Does the review address Methodology?,TRUE,FALSE,States it’s built on LTH (approach).
In case of the textual prompts benchmarks its also not clear to me why no standard errors on results are reported?,Does the review address Methodology?,TRUE,FALSE,Questions the reporting approach.
"With this approach, that requirement doesn’t exist anymore.",Does the review address Methodology?,TRUE,FALSE,Describes a new approach removing a requirement.
"I would suggest using the phrase ""weighted SVD"" early on in the introduction (e.g., exactly when you introduce your new method).",Does the review address Methodology?,TRUE,FALSE,Recommends clarity for the method.
**Empirical**:  One issue with the language modelling experiment is the choice of evaluation and train set.,Does the review address Evaluation?,TRUE,FALSE,Talks about evaluation choice.
- General Discussion: The main focus of this paper is the introduction of a new model for learning multimodal word distributions formed from Gaussian mixtures for multiple word meanings.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Explains a new multimodal word distribution model.
Can the theory guide how to develop new models to learn program representations?,Does the review address Theory?,TRUE,FALSE,Asks about theory guiding model development.
The paper's presentation could be improved in several ways:     1.,Does the review address Result?,FALSE,TRUE,"It’s about presentation, not result."
This paper studies why language model pre-training has been such an effective technique in improving downstream performance across a wide range of NLP tasks recently.,Does the review address Data/Task?,TRUE,FALSE,Refers to broad NLP tasks.
This paper demonstrates why self-knowledge distillation as a prior distribution is a form of regularization with theoretical analysis on the gradients.,Does the review address Theory?,TRUE,FALSE,Mentions a theoretical analysis of distillation.
The model sizes are varied across experiments to achieve on par performance which makes the comparison of the computational cost not so obvious.,Does the review address Presentation?,TRUE,FALSE,Talks about clarity of comparing cost.
- multi-concept and noise:     The noise you add to the channel has a number of different components; there should be an ablation study to illustrate the effects of these components.,Does the review address Ablation?,TRUE,FALSE,Suggests an ablation.
"- I know GPT3 access is hard to get, but I wish experiments with k=8 prompts could be compared against  Post rebuttal: I think another pass for clarity over the paper would be good for the final version, but otherwise I'm happy with the paper updates and I'm happy to see the ablation numbers aren't too sensitive to token count.",Does the review address Experiment?,TRUE,FALSE,Mentions ablation in an experimental context.
Contrastive training (negative sampling) is one of the crucial contributions of this work.,Does the review address Methodology?,TRUE,FALSE,States a key method (contrastive training).
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Presentation?,TRUE,FALSE,Talks about how contributions are presented.
"In addition, the authors empirically demonstrate that the token-level masked-LM model used by BERT is not a good choice as pre-training task for the two-tower Transformer when deployed for large-scale information retrieval applications.",Does the review address Data/Task?,TRUE,FALSE,Refers to a pre-training approach (data usage).
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Discusses motivation behind QA idea.
- Using capital and lower case tau in Theorem 4.2 is confusing notation.,Does the review address Presentation?,TRUE,FALSE,Criticizes confusing notation (presentation).
"While it is also true that corpus transfer _enables_ this divergence in model types, to really test whether transferring the whole model versus using the corpus works or not, I would think you would want to compare fine-tuning the sender GRU on the LM data vs. starting from scratch _with a GRU of the same type_ and pre-training on the EC corpus before fine-tuning.",Does the review address Experiment?,TRUE,FALSE,Proposes a comparative experimental setup.
"I will discuss my concerns one-by-one in detail: - Most importantly, the evaluation is confusing.",Does the review address Evaluation?,TRUE,FALSE,Calls the evaluation confusing.
"FLOPS is a measure of computer performance, while arithmetic intensity is the ratio of total floating-point operations to total data movement.",Does the review address Data/Task?,FALSE,TRUE,"Explains metrics, not about data/task."
The methodology is explained clearly and experiments are executed with a considerable amount of detail.,Does the review address Experiment?,TRUE,FALSE,States “experiments are executed.”
"Specifically, I would expect authors provide more detailed recommendation for AL, DS, and multi-domain sampling in terms of sampling techniques, and population of different sources for certain application.",Does the review address Methodology?,TRUE,FALSE,Requests more detail on sampling approaches (method).
It's great the authors supplied code for part of the system so I don't want to penalize them for missing it -- but this is relevant since the paper itself has so few details on the baselines that they could not really be replicated based on the explanation in the paper.),Does the review address Comparison?,TRUE,FALSE,Complains about baseline details for comparison.
- Definition of equivalence seems to be insufficient and lacks important components.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes how equivalence is defined.
I think adapting CaP to the VIMA benchmark would be a more insightful baseline.,Does the review address Data/Task?,TRUE,FALSE,Suggests using a specific benchmark (task/data).
"- Extensive ablation studies that showcase specific abilities of the model (types of OOD generalization), investigate the role of the foundation models and study the importance of the components of the prompt.",Does the review address Ablation?,TRUE,FALSE,Mentions “ablation studies.”
2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues.,Does the review address Experiment?,TRUE,FALSE,Talks about adding evaluations to ablation experiments.
"Another question: does ""prompts of complexity n"" mean prompts of length n?",Does the review address Methodology?,TRUE,FALSE,Questions the approach/definition of prompt complexity.
The wide range of datasets and active learning techniques they use (including BALD which prior works shows is very competitive) lends credence to the conclusions.,Does the review address Data/Task?,TRUE,FALSE,References multiple datasets and AL techniques.
"There are several follow-up results built on these two results, such as a new loss objective for predicting the downstream task, but to the best of my understanding, these two results are the main claims of this paper.",Does the review address Result?,TRUE,FALSE,Points to main “results/claims” of the paper.
The complexity of learning options would be way different in the two different settings.,Does the review address Methodology?,TRUE,FALSE,Talks about the approach’s “options” framework.
"So there's a 3x3 contingency table of gold and predicted (POS, NEU, NEG) classes, but this sentence leaves ambiguous how precision and recall are calculated from this information.",Does the review address Presentation?,TRUE,FALSE,Critiques how performance metrics are presented.
The paper does a systematic analysis on the role of language specific parameters using the proposed architecture.,Does the review address Analysis?,TRUE,FALSE,Mentions “systematic analysis.”
I think significant presentation changes are required to clarify that the paper focuses on inference and finetuning.,Does the review address Presentation?,TRUE,FALSE,Calls for changes in presentation.
"I think more could be done here, some ideas, probably there are better ways to test: - Have templates that leave out ""instructions"":  I would guess it wouldn't affect held-in task performance much, but would affect held-out tasks.",Does the review address Result?,TRUE,FALSE,Discusses performance for different tasks.
"Second, it is really hard to capture which part is really making the main contribution to the final performance.",Does the review address Result?,TRUE,FALSE,Talks about contribution to performance (results).
Combining Translation Memory with Neural Machine Translation.,Does the review address Related Work?,TRUE,FALSE,References a concept from prior literature.
"Comparative Analysis and Benchmarking:  The comparisons presented in Tables 1 and 2 focus solely on the improvements over one reference work (Ma et al., 2023).",Does the review address Analysis?,TRUE,FALSE,Mentions “comparative analysis.”
"Yet, it is difficult for me to trust that the effects in this paper will generalize to better performing models without further evidence: what if the CALM intermediate objectives only help with mistakes that larger models do not make in the first place?",Does the review address Methodology?,FALSE,TRUE,"Refers to possible reasons for improvement, not the approach itself."
"Maybe I've missed this in the paper, if there is, please be more explicit about it because it affects the model quite drastically if for every sentence the largest phrase length is the sentence length.",Does the review address Presentation?,TRUE,FALSE,Suggests clarity issue about sentence length usage.
"Unfortunately, many aspects of the models, experimentation, and evaluation are not explained very well.",Does the review address Methodology?,TRUE,FALSE,Mentions insufficient explanation of the approach.
"In addition, I have several notation confusions:  Assumption1: What is the hamming distance m_1 and m_2, when m_i are random variables?",Does the review address Presentation?,TRUE,FALSE,Points to notation explanation issues (presentation).
"Second paragraph of related work: McCarley et al. (2019) appears twice with different descriptions, is this intentional?",Does the review address Related Work?,TRUE,FALSE,Mentions a duplication in the related work.
"**Strengths** - To the best of my knowledge, this is the first work that _mathematically_ justifies the connection between the pre-training objective and the downstream performance.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Talks about justifying pre-training & downstream link.
I find the analysis presented in the paper very interesting and insightful - and distinguishes it from previous work in this area.,Does the review address Related Work?,TRUE,FALSE,References prior vs. “previous work.”
"However, there is a lack of unified experimental standards and ablation experiments in this paper.",Does the review address Ablation?,TRUE,FALSE,Mentions missing ablation experiments.
"- Easy but probably not great thing to try:  held-out tasks with wrong/useless templates  A final thought:  It's not obvious that using as many training examples per dataset as possible is optimal, given that the model could overfit to dataset-specific spurious correlations.",Does the review address Methodology?,TRUE,FALSE,Talks about a strategy for training examples.
"The presented method chooses action primitives such as ""PickAndPlace"" but does not need much training data (apart from the examples).",Does the review address Data/Task?,TRUE,FALSE,Mentions data usage for training.
"These prior methods do not incorporate the SFT stage, making it unclear how the model performs before this crucial phase.",Does the review address Result?,TRUE,FALSE,Points to performance question about the model.
"Ablation studies on the varying parameter counts of these two components would be valuable, if possible.",Does the review address Presentation?,FALSE,TRUE,"Mentions ablation but focuses on param counts, not clarity/structure."
"The paper in general is well-written and easy to follow, the qualitative analysis and the additional diagrams in the appendix illustrating the variations in policies are appreciated.",Does the review address Analysis?,TRUE,FALSE,Mentions “qualitative analysis.”
"Comparative Analysis and Benchmarking:  The comparisons presented in Tables 1 and 2 focus solely on the improvements over one reference work (Ma et al., 2023).",Does the review address Result?,TRUE,FALSE,Discusses improvements in results.
"Additionally,        The topical details of the dataset (527,830 scientific documents) used in training RNN and Copy RNN are also missing.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Lacks detail/description about the dataset.
The analysis shows that it outperforms only all the other baselines only on 5/9 games and matches on 3.,Does the review address Result?,TRUE,FALSE,Mentions performance vs. baselines.
"In algorithm 1, in each iteration, only data sample (S_i) is used, how is this choice motivated?",Does the review address Data/Task?,TRUE,FALSE,Questions the data usage in the algorithm.
The comparison in Observation 1 does not seem to be an apples-to-apples comparison.,Does the review address Comparison?,TRUE,FALSE,Criticizes fairness of the comparison.
"what part of the performance is coming from pretraining (especially if using VAE type is novel, then quantifying that is important with and without VAE type SL), etc.",Does the review address Result?,TRUE,FALSE,Asks about performance source.
"Therefore it would be interesting to see how this affects performance, i.e. just run the method on the CaP benchmark without the oracle.",Does the review address Result?,TRUE,FALSE,Suggests testing performance on CaP benchmark.
"* Most of the methodology appears to me like standard low quantized training techniques, e.g., using additional scales that are determined dynamically, adapted directly to FP8.",Does the review address Methodology?,TRUE,FALSE,Comments on the approach’s training technique.
It is better to compare with more demonstration selection methods such as similarity-based and diversity-based methods which are widely used in practice.,Does the review address Methodology?,TRUE,FALSE,Recommends comparing approach for demonstration selection.
"Running a baseline model that runs *for the same amount of time* is essential to appreciate the contribution of this work (e.g., repeat the same analysis in Figure 3 for the vanilla BERT).",Does the review address Analysis?,TRUE,FALSE,Talks about repeating an analysis with baseline.
* It is interesting to know that WebMath pre-training is still helpful even in the presence of PACT.,Does the review address Methodology?,TRUE,FALSE,Notes a detail about pre-training approach.
"Related Work: Contrastive learning - Under an unsupervised setting, ontrastive -> contrastive  Overall:  This work highlights the importance of incorporating contrastive training for data augmentation.",Does the review address Related Work?,TRUE,FALSE,Mentions a concept from prior approaches (contrastive learning).
"i,.e the agent is given the ground truth context every time and asked to predict the correct next utterance.",Does the review address Methodology?,TRUE,FALSE,Describes approach (dialog context).
"You *tell* us that Fon is ""a language with special tokenization needs"" and that ""standard tokenization methods do not alwaysadequately deal with the grammatical, diacritical, and tonal properties of some African language"", and you cite the relevant papers.",Does the review address Related Work?,TRUE,FALSE,Mentions relevant prior work on tokenization.
It seems possible that these improvements could instead be due to the high quality semantic/syntactic relations encoded in the attention mechanism.,Does the review address Presentation?,FALSE,TRUE,"Talks about reasons for improvement, not clarity or structure."
"* ""Moreover, it should be noted that BROS achieves higher f1 score than 79.27 of LayoutLM using visual features"".",Does the review address Result?,TRUE,FALSE,Mentions BROS’s f1 score (result).
"Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.",Does the review address Experiment?,TRUE,FALSE,Mentions “Experiments show…”
"Previous work [2] has already shown that by selecting the most complex examples from the training dataset, the performance can be largely improved compared to the original annotations from [1].",Does the review address Related Work?,TRUE,FALSE,References prior approach (previous work).
It would be nice if these baselines are described before Fig.,Does the review address Comparison?,TRUE,FALSE,Suggests describing baselines (comparison).
"Was this using the development set, and if so for which dataset?",Does the review address Data/Task?,TRUE,FALSE,Questions which dataset is used.
More specifically description would help the readers to understand the task clearly.,Does the review address Presentation?,TRUE,FALSE,Asks for clearer description.
"However, all the parameters/variables in the neural networks are freely designated and are not correlated to each other, thus they cannot work together to meet the requirements in the binding-unbinding mechanism.",Does the review address Methodology?,TRUE,FALSE,Criticizes the approach’s parameter design.
"For the first ablation, it just gives out the performance of intermediate models on a single task.",Does the review address Methodology?,TRUE,FALSE,Mentions an ablation approach for models.
Theoretical analysis is provided to demonstrate the effectiveness of the proposed method under a greedy search algorithm.,Does the review address Analysis?,TRUE,FALSE,States a theoretical analysis.
The results are intriguing and promising and should be of interest both to the emergent communication community as well as to the broader community working on low-resource NLP.,Does the review address Result?,TRUE,FALSE,Mentions intriguing results.
"Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",Does the review address Experiment?,TRUE,FALSE,Talks about tests/ablation as experimental aspects.
"Second, it is really hard to capture which part is really making the main contribution to the final performance.",Does the review address Contribution?,TRUE,FALSE,Mentions what is contributing to performance (contribution).
It would be great if the authors discuss this or provide some supporting evidence about its correctness.,Does the review address Comparison?,FALSE,TRUE,"Suggests more evidence, not direct comparison of methods."
Implementation details are only given for the vanilla BERT Are they similar to the EarlyBERT model as well?,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Asks for more detail in describing the model.
Strengths:   The authors connect active learning example selection to more severe training instability than random selection.,Does the review address Methodology?,FALSE,TRUE,Focuses on the finding (instability) rather than approach details.
My another is concern is that the motivation of the experimental design is not clear.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Criticizes clarity of motivation for the experiment.
It is nontrivial to gather the data as it involves hooking into the Lean's compilation process.,Does the review address Data/Task?,TRUE,FALSE,Talks about the difficulty of gathering the dataset.
"The main limitations seem to be: (1) the proposed method is a bit limited in that it can only be used with a corpus in which the target head, relation, and tail spans need to be directly mentioned in a single sentence (2) it’s not clear whether the quantitative improvements are due to factual knowledge in the pretrained model or the syntactic/semantic relationships encoded in the self-attention.",Does the review address Methodology?,FALSE,TRUE,"Discusses limitations & possible reasons, but not approach details."
"I know you cite the Abbott & Martinus, 2018 paper, stating that BPE is bad for analytical languages, but I still think it would prove a point to show BPE performing badly for your data.",Does the review address Comparison?,TRUE,FALSE,Suggests comparing to BPE (another method).
The current experimental baseline can't reflect this.,Does the review address Experiment?,TRUE,FALSE,Criticizes baseline in an experimental context.
I liked the idea of removing conditionals to infer likely necessary preconditions.,Does the review address Result?,TRUE,FALSE,Refers to an outcome (inferred preconditions).
"The proposed models -- which seem to be an application of various tree-structured recursive neural network models -- demonstrate a nice performance increase compared to a fairly convincing, broad set of baselines (if we are able to trust them; see below).",Does the review address Comparison?,TRUE,FALSE,Compares performance with baselines.
The system performs on par with recently proposed GECA for SCAN and favorably to GECA on morphological analysis.,Does the review address Result?,TRUE,FALSE,Mentions performance results.
"Contributions: - A new algorithm for unsupervised knowledge graph creation from a target corpus - Demonstrating the utility of large pre-trained language models towards knowledge graph creation (though, there are other works in this area that should probably be discussed more.",Does the review address Presentation?,FALSE,TRUE,"States a new algorithm (contribution), not clarity/structure."
Is there any special reason for restraining it to single-task finetuning if earlier results demonstrates multi-task finetuning is better?,Does the review address Data/Task?,TRUE,FALSE,Questions the data/task setting (single-task finetuning).
"However, they only show that the hyperparameter search on \alpha is removed and the adaptive smoothing parameter can be connected to the gradient rescaling effect on self-distillation.",Does the review address Methodology?,TRUE,FALSE,Talks about an approach detail (hyperparameter smoothing).
"The methods have been tested on two benchmarks focusing on the issue, SCAN and morphological analysis.",Does the review address Data/Task?,TRUE,FALSE,"Refers to benchmarks (SCAN, morphological analysis)."
"- It's because if the largest phrase length is the sentence length, then model can be simplified into a some sort of convolution RNN where the each state of the RNN goes through some convolution layer before a final softmax and attention.",Does the review address Presentation?,TRUE,FALSE,Mentions how the model is explained or structured.
Were the same hyperparameters used for all configurations?,Does the review address Methodology?,TRUE,FALSE,Questions approach consistency (hyperparameters).
"In terms of modelling, the work follows in the line of recent work on language-specific parameters for multilingual NMT.",Does the review address Methodology?,TRUE,FALSE,Refers to a modeling approach.
"- Because the policy learning procedure utilizes the additionally generated dialogue acts and corresponding responses, it is easy to think that naively fine-tuning the GPT-2 model on the additional generated data may also improve the dialogue model performance in terms of its policy and responses (similar to a data augmentation method).",Does the review address Presentation?,FALSE,TRUE,"Describes the approach’s policy learning, not clarity/structure."
Theorem 2 is presented with no intuition and the proof in the appendix is only for a special case.,Does the review address Theory?,TRUE,FALSE,References a theorem and its proof.
"2) As the authors claimed in Introduction, ‘plenty of training data is available’.",Does the review address Methodology?,FALSE,TRUE,"Talks about data availability, not approach details."
"Rather than using the ad-hoc approach for selecting which augmentation ""stacking"" scheme is helpful, it would have been better to compare/use an approach highlighted in ""Learning to Compose Domain-Specific Transformations for Data Augmentation"" [NeuRIPS 2017].",Does the review address Methodology?,TRUE,FALSE,Suggests comparing a different approach.
"Reasons for Score ----------------- The idea proposed in the paper is novel and exciting, but I have some concerns about whether the gains promised by the theoretical analysis can be realized while maintaining modeling quality.",Does the review address Analysis?,TRUE,FALSE,Mentions theoretical analysis.
- Discussion in Section 4.1 - I think Figure 4 should be explained in more detail (in caption and/or text).,Does the review address Presentation?,TRUE,FALSE,Requests a clearer explanation (presentation) of Figure 4.
Weaknesses: There is no contribution/novelty from the modeling/methods side.,Does the review address Novelty?,TRUE,FALSE,States “no novelty” from the methods.
# Summary  The authors propose to use corpora generated from _emergent communication_ as a fine-tuning signal for NLP tasks (language modeling and image captioning in particular).,Does the review address Data/Task?,TRUE,FALSE,Mentions using certain data (emergent communication).
"While the authors describe two applications (Section 2), these applications often deal with common programming languages that are intractable, e.g., code clones across binary code for vulnerability detection.",Does the review address Methodology?,FALSE,TRUE,"Discusses application context, not approach details."
"In semantic parsing problem, langugae to programatic language is a typical task.",Does the review address Data/Task?,TRUE,FALSE,Mentions a standard task (semantic parsing).
"However, we should credit the core idea and (part of the implementation) to the earlier work on label-free CBMs.",Does the review address Presentation?,FALSE,TRUE,"Talks about crediting an idea, not clarity/structure."
CALM shows better results with less data than the base model.,Does the review address Data/Task?,TRUE,FALSE,Mentions data usage/performance.
"Where the paper does get technical is in a discussion of the differing difficulties of speech recognition for different languages, providing a useful case study to demonstrate that one-size technology approaches are not necessarily universal stand-alone solutions.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Discussion of language difficulties.
But the authors didn’t compare against these agent-based system design.,Does the review address Comparison?,TRUE,FALSE,Notes missing comparison.
"I appreciate that the authors do not read too much into it and focus more on the analysis of the results, but one thing that remains unanswered in this paper is how the proposed method fairs against multilingual baselines that utilize (roughly) the same number of parameters; currently, the best models outperform the LS baseline by ~28M and ~10M parameters on OPUS-100 and WMT-14 respectively.",Does the review address Comparison?,TRUE,FALSE,Asks for comparison with multilingual baselines.
That more templates per dataset didn't help is particularly interesting and suggests some questions.,Does the review address Data/Task?,TRUE,FALSE,Mentions dataset and template usage.
"Given the issued pointed out in 1 and 2, I am not sure if the results are really sound as the authors claimed.",Does the review address Result?,TRUE,FALSE,Questions the validity of the results.
"Put in another way, using RFA in transformer is from Rawat et al., 19 so do you think your major contribution is to design such  a gated usage of RFA?",Does the review address Methodology?,TRUE,FALSE,Asks about a design approach.
- Section 3: ...append a prompt like “This movie is” (the final quotation mark is on the next line).,Does the review address Methodology?,FALSE,TRUE,"Mentions a formatting detail, not the approach."
"Overall, I think this paper has a clear motivation and some interesting ideas on how to incorporate semantic language information into planning algorithms.",Does the review address Methodology?,TRUE,FALSE,Mentions incorporating language info into planning (approach).
"**Updates after rebuttal period**  The authors addressed some of the concerns -- showing inference time, model size and a discussion about training details and hyperparameters in the appendix.",Does the review address Methodology?,TRUE,FALSE,Mentions additional method details.
"- Even though there is a “explain” component in PEER, it is not evaluated and studied regarding its correctness.",Does the review address Evaluation?,TRUE,FALSE,Points out missing evaluation of “explain” component.
The authors did not provide what the retrieved sentences are like.,Does the review address Significance?,FALSE,TRUE,"Criticizes missing detail, not the impact significance."
"It would be to show more experiment results for some settings, for example, performance on Sum task when training with a mixture distribution, or more Sum task samples and fewer Parity task samples ( p range from 0.5 to 1.",Does the review address Experiment?,TRUE,FALSE,Suggests more experiment results.
- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.,Does the review address Result?,FALSE,TRUE,"Refers to ablation for results, but explicitly about more ablation, not the result itself."
Experiments on LEGO and code interpretation task are done.,Does the review address Experiment?,TRUE,FALSE,States “Experiments on LEGO and code interpretation.”
The experiment results in Tables 1 & 2 cannot plausibly prove OTTER is more effective than CLIP.,Does the review address Result?,TRUE,FALSE,Mentions experiment results.
"Weakness While the ablation study and visualization analysis are done, the key evaluations are missing.",Does the review address Ablation?,TRUE,FALSE,Mentions ablation study.
"The main motivation/result of the paper appears to be that the authors can perform zero-shot relation extraction, extracting relations only seen at test time.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,States a “main motivation/result.”
"As I understand it, this result shows that any part of p_f(s) orthogonal to row-span(Phi) doesn’t affect the cross-entropy of the language model (first order optimality condition would still be satisfied).",Does the review address Methodology?,TRUE,FALSE,Discusses a detail of the approach (partial).
"While previous work has examined tasks in the overall area, to my knowledge there has not been any publicly availble sentence-level annotated data for the problem -- the authors here make a contribution as well by annotating some data included with the submission; if it is released, it could be useful for future researchers in this area.",Does the review address Contribution?,TRUE,FALSE,Mentions a data-related contribution.
Ablation studies show that the model achieves good performance on more complex questions.,Does the review address Methodology?,FALSE,TRUE,"Focuses on ablation results, but mentions performance (not approach detail)."
The authors utilize figures and tables well to illustrate the ideas.,Does the review address Presentation?,TRUE,FALSE,Mentions how figures/tables are used (presentation).
"The introduction is somewhat verbose, indirectly causing the first two weaknesses and making the paper hard to read.",Does the review address Presentation?,TRUE,FALSE,Criticizes the introduction’s verbosity (presentation).
-  The proposed model has two main parts: sentence embedding and substructure embedding.,Does the review address Methodology?,TRUE,FALSE,Describes the model’s approach.
"- What is the ""margin of task $\mathcal{T}$"" mentioned on p.5?",Does the review address Data/Task?,TRUE,FALSE,Asks about a task-related concept (“margin of task”).
"Additionally,        The topical details of the dataset (527,830 scientific documents) used in training RNN and Copy RNN are also missing.",Does the review address Data/Task?,TRUE,FALSE,Points to missing dataset details.
"For example, what if the authors don’t use a LogicForm-to-NaturalLanguage conversion?",Does the review address Result?,FALSE,TRUE,"This is about an alternative approach, not actual results."
"If the tasks are not similar, and the learning objectives are not aligned, then the motivation for multi-task learning is solely for reducing memory footprint and computational cost.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Talks about the motivation for multi-task learning.
"Starting from trivialities like the fact that the problem is generally undecidable (and not as stated in Section 2), through the use of incorrect terminology for invariants, guards, pre/post conditions, etc.",Does the review address Presentation?,TRUE,FALSE,Points to confusion in terminology usage (presentation).
"First, much of the improvement (I think) comes from reducing the number of epochs and/or the number of steps.",Does the review address Result?,TRUE,FALSE,Mentions a reason for improvement (result).
Since the authors point out that using class labels to generate text embeddings may bring challenges with expressive sensitivity.,Does the review address Methodology?,TRUE,FALSE,Comments on an approach detail (text embeddings).
"- Consider HellaSwag/PiQA/etc, where FLAN underperformed few-shot and even zero-shot.",Does the review address Data/Task?,TRUE,FALSE,Mentions tasks (HellaSwag/PiQA).
"Your work obviously is different enough to stand on its own, but it might be good to make a mention of this work and others (e.g. do more of a lit search / related work on low rank compression).",Does the review address Methodology?,TRUE,FALSE,Suggests referencing other methods for compression approach.
"I also wanted to mention that I appreciate the addition of the suggested related work, but I would still suggest that the authors consider looking into more detailed means of comparison in the future (especially to the Petroni work), since this seemed to be a concern in multiple reviews.",Does the review address Related Work?,TRUE,FALSE,Cites “Petroni” and more detailed comparison is suggested.
"It requires more analysis about experimental results, such as Figure 1 and tables in Section D.",Does the review address Analysis?,TRUE,FALSE,Requests further analysis of results.
"This is in sharp contrast to computer vision where techniques like rotation, modification of hue, saturation as well as umpteen other techniques exist.",Does the review address Presentation?,FALSE,TRUE,"Compares domains, but not about clarity/structure."
I would recommend the authors to at least assume the availability of some public data that is kept out of training and evaluations and to run all the baselines fairly in this setting.,Does the review address Methodology?,TRUE,FALSE,Suggests a fair baseline approach.
is a micro-average (all testsets are concatenated and evaluated as one set) or macro-average (average taken across the scores of individual test sets) score.,Does the review address Methodology?,TRUE,FALSE,Asks about the evaluation approach (method detail).
* Section 4 - I think you really need to re-state that the algorithm has a human-in-the-loop for clarity.,Does the review address Presentation?,TRUE,FALSE,Suggests clarifying an algorithm detail.
"I appreciate that the authors do not read too much into it and focus more on the analysis of the results, but one thing that remains unanswered in this paper is how the proposed method fairs against multilingual baselines that utilize (roughly) the same number of parameters; currently, the best models outperform the LS baseline by ~28M and ~10M parameters on OPUS-100 and WMT-14 respectively.",Does the review address Result?,TRUE,FALSE,Questions model performance vs. baselines.
"The authors say ""we focus on larger datasets from GLUE (MNLI, QNLI, QQP and SST-2), as it is less meaningful to discuss efficient training"", but then report and analyze results from other GLUE datasets as well.",Does the review address Analysis?,TRUE,FALSE,Mentions analyzing GLUE results.
There are several parts to the method and there are I assume several differences in the architecture etc with baselines etc.,Does the review address Methodology?,TRUE,FALSE,Refers to the method’s architecture differences.
"These objectives certainly improve over the original T5 base _and_ larges models that are used as initializations, and especially outperform the base model in the low-data regime.",Does the review address Methodology?,TRUE,FALSE,Notes approach improvements for T5.
"Given the success of MLM as a powerful pre-training objective, please consider formulating your claims in a more general way.",Does the review address Methodology?,TRUE,FALSE,Suggests generalizing the approach.
The Ablation Study of the paper also provides useful insights about the impact of different pre-training schemas on large-scale information retrieval tasks.,Does the review address Ablation?,TRUE,FALSE,Explicitly mentions an ablation study.
Do you want to claim that this structure design is inspired by RNN and it leads to a better result?,Does the review address Result?,TRUE,FALSE,Asks about an outcome (better result).
"Provide a formal definition for ""general learner"" before stating the proposition.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests a formal definition.
* One idea I had here: Could you define a natural task as one for which there exists a sparse linear model over the *logits* of p*( .,Does the review address Result?,FALSE,TRUE,"Asks for a definition, not actual results."
"But from the paper, I can hardly tell what the researchers should proceed to further improve the performance.",Does the review address Result?,TRUE,FALSE,Refers to improving performance (results).
"Concerning the claim, “the proposed fully-explored masking strategies lead to pre-trained models with stronger generalization ability.”, it is not clear how the proposed method yields stronger generalization ability.",Does the review address Methodology?,TRUE,FALSE,Questions how the approach yields better generalization.
"- wMAN explicitly utilized multi-level context information between the sentence and the video frame, and used the graph neural network and the message passing to model the representation.",Does the review address Presentation?,FALSE,TRUE,"Describes the approach, not clarity/structure."
"Without the experimental results using the same training settings, I do not think the authors are able to prove the superiority of OTTER over CLIP fully.",Does the review address Result?,TRUE,FALSE,Mentions proving one model’s superiority (result).
"Also it seems that these are not fully annotated, and the ‘forward type inference functionality from TypeScript’ is required to obtain labels.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,References annotation clarity.
CALM shows better results with less data than the base model.,Does the review address Methodology?,FALSE,TRUE,"States an outcome, not the approach detail."
"What is ""in-distribution"" instructions and how would an instruction from non-oracle look to an instruction from oracle?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Asks for definition/clarification.
"It's ok for the proposed method to be one particular way, but that discussion would be useful.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests further discussion/explanation.
"Indeed, the proposed graph model seems to only implicitly convey knowledge across facts in terms of local reasoning.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions how knowledge is conveyed (interpretation).
Can the proposed theory help explain if the same code modeling task for some languages is strictly easier than the others?,Does the review address Methodology?,FALSE,TRUE,"Asks about theory explaining code tasks, not approach."
Their models achieve better quantitative results when compared to the provided baselines.,Does the review address Comparison?,TRUE,FALSE,Mentions comparing results to baselines.
"Also, the authors did a great job in terms of conducting evaluations from different angles.",Does the review address Evaluation?,TRUE,FALSE,Praises varied evaluations.
- Choice of baselines: For the VIMABench I find the choice of baselines not insightful.,Does the review address Comparison?,TRUE,FALSE,Critiques baseline choice (comparison).
Using a model capable of streaming would make sense from the point of view of inductive biases.,Does the review address Methodology?,TRUE,FALSE,Suggests an approach for streaming.
Will need some clarification to better judge the results.,Does the review address Presentation?,TRUE,FALSE,Calls for clarity (presentation).
I suggest the authors investigate the effect of such differences.,Does the review address Analysis?,TRUE,FALSE,Advises further analysis.
"- (The supplied code does not seem to include the baselines, just the recursive NN models.",Does the review address Comparison?,TRUE,FALSE,Mentions missing baselines for comparison.
"With the strengths being said, I hope to also point out that the paper's application of adversarial training is one attempt in many possibilities, and in many cases it is not clear where the improvements come from.",Does the review address Result?,TRUE,FALSE,Unclear improvement source (result).
The methods is evaluated on 5 standard NER+RE datasets with good performances.,Does the review address Result?,TRUE,FALSE,Mentions performance outcomes.
"The architecture does not look entirely novel, but I kind of like the simple and practical approach compared to prior work.",Does the review address Methodology?,TRUE,FALSE,Comments on approach/architecture.
"Given the nature of the problem statement (with multiple tasks, inputs and outputs), the authors have done a good job in explaining each of them properly.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Praises clarity in explaining tasks.
"PE seems to be important for wMAN, and the authors provides few sentences analysis about this, but I don't think I fully understand this part.",Does the review address Analysis?,TRUE,FALSE,Mentions partial analysis of PE.
"This is especially disappointing as the objectives introduced _directly_ match the task in CommonGEN, making this intermediate training a form of noisy training data rather than pretraining.",Does the review address Methodology?,TRUE,FALSE,Describes an approach to training data.
"Within the evaluation section, there are numerous intriguing findings that hold significant value for dissemination within the wider research community.",Does the review address Result?,TRUE,FALSE,Mentions intriguing findings (results).
The authors present a simple technique for in-context learning with large language models that achieves consistently good results across a variety of NLP tasks.,Does the review address Result?,TRUE,FALSE,States good results.
"Weakness While the ablation study and visualization analysis are done, the key evaluations are missing.",Does the review address Analysis?,FALSE,TRUE,"Mentions ablation/evaluations, not deeper analysis detail."
Some important concepts are repeatedly used without a definition.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes missing definitions.
lead to performance decrease for individual tasks.,Does the review address Data/Task?,TRUE,FALSE,Talks about performance on tasks.
"For example, is there any restriction on the parameters in encoder and decoder respectively to reflect the property $UR=I$ as in Section 2.",Does the review address Theory?,TRUE,FALSE,Asks about a theoretical property $UR=I$.
"Indeed, at first, the words ""The following algorithm"" confused me, because I thought it was more a ""methodology"", since Step 2 is where the humans are in the loop, unless you have a Fon POS tagger and I am misunderstanding?",Does the review address Methodology?,TRUE,FALSE,Unclear if it's an algorithm or methodology.
"(3) This model still needs to calculate the similarity matrix for queries and documents, so the computational efficiency is not improved compared with other multi-vector retrieval models in the training stage.",Does the review address Methodology?,TRUE,FALSE,Comments on approach efficiency.
"This is relevant because, by training end to end, that work effectively generates arbitrary amounts of training data through interaction the the HOL4 ITP system (intermediate theorems which are proven give some reward in that work).",Does the review address Methodology?,TRUE,FALSE,Mentions approach generating training data.
Concerns around novelty and the multi-task setup was also raised by another reviewer (e7Hg).,Does the review address Data/Task?,TRUE,FALSE,Discusses multi-task approach (data/task).
"- P3, Sec 2.2: ""... achieve lower test perplexity than traditional n-gram models"" Why is this true?",Does the review address Methodology?,TRUE,FALSE,Questions approach behind perplexity improvement.
There’s not much that can be faulted and all my comments below are meant to help the paper gain additional clarity.,Does the review address Presentation?,TRUE,FALSE,Mentions clarity improvement.
The findings illustrate the substantial impact this choice can have on the final model's behavior.,Does the review address Result?,TRUE,FALSE,Talks about effect on model’s behavior (result).
"For example, is there any restriction on the parameters in encoder and decoder respectively to reflect the property $UR=I$ as in Section 2.",Does the review address Methodology?,TRUE,FALSE,Questions approach constraints.
Weakness   The paper is poorly organized and very hard to follow.,Does the review address Presentation?,TRUE,FALSE,Criticizes organization/readability.
They have evaluated their architecture based on (i) the language modelling test evaluated on PTB and FBIS and (ii) Chinese-English machine translation task on NIST MT02-08 evaluation sets.,Does the review address Evaluation?,TRUE,FALSE,Mentions how architecture was evaluated.
- How will the pseudo data generation amount affect the learning / forgetting performance?,Does the review address Data/Task?,TRUE,FALSE,Asks about data generation effect on tasks.
NIT:  - Grammar last sentence of Section 1.1 (“…analyze the efficiency *of* …”) - Proposition 2.2: Maybe write “\forall s \in S” instead of “\forall s ~ p_L”.,Does the review address Presentation?,TRUE,FALSE,Suggests a notation fix (presentation).
An emerging use of LeetCode is to use it as a baseline for machine programming (MP) in a variety of different ways.,Does the review address Data/Task?,TRUE,FALSE,Mentions dataset/task usage (LeetCode).
"- Technical Novelty and Significance: 3 - Empirical Novelty and Significance: 1  ## Questions _What_ is unique about the environment has been presented well, so my primary question is _how_ is it unique?",Does the review address Novelty?,TRUE,FALSE,Mentions “technical novelty.”
"While this is not a downside by itself, it is probably something that one implement as a baseline.",Does the review address Comparison?,TRUE,FALSE,Suggesting a baseline usage.
"- After definition 5.1, what does Omega[w] = Omega[w’] mean?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Asks for clarity on definitions.
Conducting real-human interactions can better justify the effectiveness of the proposed RL method in practical scenarios.,Does the review address Presentation?,FALSE,TRUE,"Focuses on practical RL justification, not clarity/structure."
"In the first phase (match), they extract knowledge tuples from each sentence in a corpus using a beam search over the self-attention within a pre-trained language model.",Does the review address Methodology?,TRUE,FALSE,Describes the approach (beam search with a pre-trained LM).
Since we observe that the randomly pruned models do not competitive performance ...: how uncompetitive?,Does the review address Presentation?,FALSE,TRUE,"Questions performance impact, not clarity/organization."
"To name a few:   -“Language Models as Knowledge Bases?” EMNLP 2019   -“Commonsense Knowledge Mining from Pretrained Models.” EMNLP 2019   -“Comet: Commonsense Transformers for Automatic Knowledge Graph Construction.” ACL 2019 - Although the proposed model achieves quantitative improvements over Angeli et al. (2015), it seems unclear whether these improvements are due to the factual knowledge encoded in the pre-trained LM, as claimed.",Does the review address Related Work?,TRUE,FALSE,References prior works (Petroni et al. etc.).
The theory is a bit complicated and not easy to follow.,Does the review address Methodology?,FALSE,TRUE,"Criticizes theory’s complexity, not the approach or technique details."
"- Similarly, using bold and not-bold B in Theorem 5.2 is confusing notation.",Does the review address Theory?,TRUE,FALSE,Talks about theorem notation.
I feel that the conclusions are in general well supported by the results.,Does the review address Result?,TRUE,FALSE,Mentions that conclusions align with results.
"Then it is reasonable to include the baseline suggest above, i.e. input additional features.",Does the review address Comparison?,TRUE,FALSE,Recommends adding a baseline for comparison.
"Writing:  The writing is overall clear and easy to follow, although it took me quite some time to map out the definitions of various notations.",Does the review address Presentation?,TRUE,FALSE,Praises clarity/structure of writing.
"## Justification As my primary critique concerns the experiments, I will address each individually mentioning any deficiencies and potential improvements.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Critiques justification of experiments.
The method proposed has limited methodology contribution to the research community.,Does the review address Methodology?,TRUE,FALSE,Criticizes the approach’s limited methodological contribution.
* One idea I had here: Could you define a natural task as one for which there exists a sparse linear model over the *logits* of p*( .,Does the review address Data/Task?,FALSE,TRUE,"Asks for a definition, not referencing a dataset or task used in the study."
This paper conducts comprehensive evaluations on the influence of selecting specific examples for inclusion in the prompt.,Does the review address Evaluation?,TRUE,FALSE,Talks about “comprehensive evaluations.”
The authors refer to the fact that MTL can (and often does!),Does the review address Related Work?,TRUE,FALSE,Mentions multi-task learning context from prior works.
"Without the experimental results using the same training settings, I do not think the authors are able to prove the superiority of OTTER over CLIP fully.",Does the review address Experiment?,TRUE,FALSE,Criticizes the experimental setup for OTTER vs. CLIP.
---- Appendix: ----  I liked the section B ablations (as implied above).,Does the review address Ablation?,TRUE,FALSE,Explicitly refers to “ablations.”
"In my opinion, this idea has a potential to be applied to domains other than theorem proving.",Does the review address Methodology?,FALSE,TRUE,Suggests broader application; not approach details.
Should also discuss related work in 2d spatial visualization of country-country relationships by Peter Hoff and Michael Ward.,Does the review address Related Work?,TRUE,FALSE,Recommends referencing another prior work.
"The paper focuses on a critical and urgent issue, the training and inference efficiency of LLMs.",Does the review address Methodology?,TRUE,FALSE,Mentions approach focus (LLM efficiency).
The empirical part of the paper shows improved performance of adding similar sentences to the context of LM training.,Does the review address Methodology?,TRUE,FALSE,Describes a technique for LM training.
"Additionally, there are some minor things I would add or improve: - I would add references to multi-task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE).",Does the review address Related Work?,TRUE,FALSE,Suggests referencing additional prior works.
"As, deep recurrent neural networks are already used in keyphrase extraction (shows very good performance also), so, it will be interesting to have a proper motivation to justify the use of  RNN and Copy RNN over deep recurrent neural networks.",Does the review address Methodology?,TRUE,FALSE,"Asks for justification of an approach (RNN, Copy RNN)."
"- I think it makes sense in the comparison with CaP to compare using an oracle object detector, but one of the main novelties of the work is replacing the perceptual modules of CaP with foundation models.",Does the review address Methodology?,TRUE,FALSE,Discusses novelty in the approach.
"The proposed method represents a novel approach to multimodal techniques, distinguishing itself from previous Vision-Language Models (VLMs) like Flamingo and PaLI.",Does the review address Novelty?,TRUE,FALSE,Calls it a novel approach.
This reminds us of the sensitivity of BERT pretraining to the optimizers.,Does the review address Methodology?,TRUE,FALSE,"Talks about the approach (optimizers, BERT)."
Such choice and associated thresholds seem arbitrary: how were they actually found out?,Does the review address Presentation?,TRUE,FALSE,Questions clarity of threshold choice.
"As I understand it, it’s called decompilation because it tends to do the opposite of what a compiler does.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Explains the reasoning for “decompilation.”
"\phi(x) as introduced in eq 2 is in R^{2D} but S_{t-1} is in R{D}, not sure what does + mean in this context.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Questions notation.
Strength: - Thorough study on the robustness of recent popular VL models vs conventional CE models.,Does the review address Presentation?,FALSE,TRUE,"Mentions robust study, not about clarity/structure."
The Human evaluation study adds a ton of value in judging LTU in my perspective.,Does the review address Novelty?,FALSE,TRUE,"Mentions a human evaluation, not originality."
**SCS**  The authors propose a new method to represent symbolic stimuli as continuous representations as an alternative to one-hot encodings.,Does the review address Methodology?,TRUE,FALSE,Describes a new method for representation.
Experiments on both continual pre-training and general pre-training from scratch show the effectiveness of the proposed method.,Does the review address Methodology?,TRUE,FALSE,Notes an approach for continual & general pre-training.
"Reasons for Score ----------------- The idea proposed in the paper is novel and exciting, but I have some concerns about whether the gains promised by the theoretical analysis can be realized while maintaining modeling quality.",Does the review address Novelty?,TRUE,FALSE,Calls the idea “novel.”
* Using the Legendre Memory Unit to substitute self-attention in transformers is interesting and has several potential merits: it can reduce the complexity and does not increase the size of the layer.,Does the review address Methodology?,TRUE,FALSE,Mentions an approach with LMU in transformers.
"Experiments show that the induced ""best-first"" order outperforms fixed orders, which verifies the motivation of the paper` 4.",Does the review address Experiment?,TRUE,FALSE,References experimental finding (best-first order).
"Additionally, showing this for negations and / or examples which GreaseLM gets correct but QA-GNN does not (and vice-versa) can shed some light on what the model improves on (and what are the limitations).",Does the review address Result?,TRUE,FALSE,Talks about what the model improvements reveal.
"Even if pruning is ineffective (at multiple pruning rates), it’s never really explained why, despite this being a core contribution of the paper.",Does the review address Contribution?,TRUE,FALSE,"Notes a core contribution (pruning), not well explained."
"Overall, I like the idea of the paper: it is important to reduce the parameters needed for sets of tasks, to enable NLP models to be deployed in a larger variety of settings, and reducing the amount of data needed.",Does the review address Methodology?,TRUE,FALSE,Mentions approach on parameter/data reduction.
"The authors provide several reasonable insights that might be relevant to the user interface modeling community — using object detection as part of multi-task learning instead of standalone pre-training task, design choices to create a single unified architecture for all the tasks, multi-task learning outperforming single-task learning etc.",Does the review address Methodology?,TRUE,FALSE,Describes approach design.
The paper presents a novel way of combining information from text and a KB in a bidirectional way.,Does the review address Methodology?,TRUE,FALSE,Mentions a novel text–KB combination approach.
"With the proposed CaptionNet dataset, it is now possible to have a fairer comparison between VL models and CE models.",Does the review address Comparison?,TRUE,FALSE,Mentions a “fairer comparison” between models.
This work tries to address the issue by proposing a technique that carefully amalgamates multiple previously known approaches to generate diverse label preserving examples.,Does the review address Data/Task?,TRUE,FALSE,References data generation approach (label preserving examples).
"For a more comprehensive analysis, it would be instructive to see how the approach compares with a broader spectrum of state-of-the-art methods.",Does the review address Analysis?,TRUE,FALSE,Suggests broader analysis of approach.
I think adapting CaP to the VIMA benchmark would be a more insightful baseline.,Does the review address Comparison?,TRUE,FALSE,Suggests a more insightful baseline comparison.
**Experimental results** The presentation of the experimental results is clear.,Does the review address Experiment?,TRUE,FALSE,Mentions clarity of “experimental results.”
What did the authors do in their attempt to find it?,Does the review address Methodology?,TRUE,FALSE,Asks about the approach or method steps.
It is not intuitive to understand to what extent the model relies on the input audio versus on the common sense knowledge that is already encoded in the LLMs.,Does the review address Presentation?,TRUE,FALSE,Asks for clarity about model reliance.
"Especially because of the surprising magnitude by which this pruning degrades absolute performance, it is unfortunately necessary to try more pruning rates for a fair comparison.",Does the review address Comparison?,TRUE,FALSE,Mentions need for a fair comparison with pruning.
It paves the way for more widespread application of VIP in scenarios where interpretable-by-design approaches are critical.,Does the review address Methodology?,TRUE,FALSE,Mentions applying the approach (VIP).
I felt similar conclusions can be drawn from the results of that paper as well.,Does the review address Result?,TRUE,FALSE,Talks about conclusions from results.
All of the results in this work seem to be previously known: * Theorem 1 is general to any polynomial-size circuit -- there is nothing special about Transformers.,Does the review address Methodology?,FALSE,TRUE,"Criticizes the results/theorem, not approach details."
"Unfortunately, many aspects of the models, experimentation, and evaluation are not explained very well.",Does the review address Experiment?,TRUE,FALSE,Critiques the experimental clarity.
This paper set an assumption that the teacher network makes a less confident prediction than that of the student and extends gradient analysis in the perspective of regularization effect in the proposed adaptive label smoothing.,Does the review address Analysis?,TRUE,FALSE,Mentions gradient analysis aspect.
Both split single word representation into multiple prototypes by using a mixture model.,Does the review address Methodology?,TRUE,FALSE,Talks about a mixture model approach.
There seems to be a lack of thought about model structure and loss.,Does the review address Methodology?,TRUE,FALSE,Criticizes a missing approach detail.
It would be great if the authors discuss this or provide some supporting evidence about its correctness.,Does the review address Evaluation?,TRUE,FALSE,Suggests more evidence for correctness (evaluation).
The key technique is to construct a type dependency graph and infer the type on top of it.,Does the review address Methodology?,TRUE,FALSE,Mentions a typed approach (graph + inference).
"- Technical Novelty and Significance: 3 - Empirical Novelty and Significance: 1  ## Questions _What_ is unique about the environment has been presented well, so my primary question is _how_ is it unique?",Does the review address Significance?,TRUE,FALSE,Refers to “Significance” of the work.
"For instance, ensuring that comparisons are fair (same number of parameters, etc) for the object detection task.",Does the review address Comparison?,TRUE,FALSE,Mentions fairness in comparing approaches.
"Try using horizontal lines only after each UD tag category, and consider the ""booktabs"" guidelines for making good-looking tables.",Does the review address Presentation?,TRUE,FALSE,Suggests table formatting for clarity.
The idea of using cosine similarity in word embeddings is a simple but effective way of biasing the MCTS in the right directions.,Does the review address Methodology?,TRUE,FALSE,Points to an approach (cosine sim in MCTS).
Their findings on learning complex tasks contribute to the understanding of large language model learning and provide valuable insights for future related work on efficient training.,Does the review address Result?,TRUE,FALSE,Mentions findings about learning complex tasks.
The experimental results also look promising in compared with the exsiting models.,Does the review address Experiment?,TRUE,FALSE,Talks about “experimental results.”
"The paper appraisal therefore rests on the clarity of presentation, how convincing the experiments are, and how reproducible.",Does the review address Experiment?,TRUE,FALSE,Mentions experiments’ persuasiveness.
- Experiments contain 3 different tasks and each has datasets from different domains.,Does the review address Data/Task?,TRUE,FALSE,Mentions tasks/datasets from various domains.
"For polysynthetic languages, though, one could posit that a fairly small set of rules might be highly predictive - humans invoke algorithms to construct patterned speech that would otherwise be incomprehensible for the listener to deconstruct, and those same algorithms can be encoded for use by machines.",Does the review address Methodology?,FALSE,TRUE,"Discusses language construction rules, not the approach details."
"It seems like a hard task (there are hundreds of those CAMEO categories....) Did the authors consider using the Goldstein scaling, which has been used in political science, as well as the cited work by O'Connor et al.?",Does the review address Related Work?,TRUE,FALSE,Refers to other techniques/cited work in political science.
"**Strengths** - To the best of my knowledge, this is the first work that _mathematically_ justifies the connection between the pre-training objective and the downstream performance.",Does the review address Result?,TRUE,FALSE,Highlights justified connection to downstream performance (results).
"The results are highly correlated with concepts that are actually present in the images; i.e., there seems to be very little confabulation (often called “hallucination”).",Does the review address Result?,TRUE,FALSE,Points to strong correlation (a result).
"Other designs include beam size, whether or not to use a pretrained model, etc.",Does the review address Experiment?,TRUE,FALSE,Talks about design choices in experiments.
A single value of $k=150$ was chosen for experiments across all tasks.,Does the review address Experiment?,TRUE,FALSE,Mentions a fixed in experiments.
"In addition, I have several notation confusions:  Assumption1: What is the hamming distance m_1 and m_2, when m_i are random variables?",Does the review address Methodology?,FALSE,TRUE,"Questions notation details, not the overall approach."
One may also refer to https://opencompass.org.cn/leaderboard-llm for the performance of LLMs (I acknowledge that the performance of ChatGPT on GSM8K from that website is possibly still underestimated).,Does the review address Result?,TRUE,FALSE,Refers to performance of LLMs (results).
"Some discussions are required on the convergence of the proposed joint learning process (for RNN and CopyRNN), so that readers can understand, how the stable points in probabilistic metric space are obtained?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Seeks explanation of convergence/stable points.
"Their goal is to reduce the amount of parameters and data needed, while improving (or maintaining) state-of-the-art performance.",Does the review address Result?,TRUE,FALSE,Mentions improving/maintaining performance (results).
"- There are also many typos in the text, for example page 2: “Our results that when” -> “Our results show that when”, page 5: “CaptionNet subset can be found in Section ?",Does the review address Presentation?,TRUE,FALSE,Notes typos and writing clarity.
"For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.",Does the review address Result?,TRUE,FALSE,Compares performance metrics (results).
"The authors switch between using BERT_base and RoBERTa_base without being very clear about when and why, e.g., in Table 2 they have both models, but only in different sections.",Does the review address Evaluation?,TRUE,FALSE,Criticizes how they evaluate or report baseline usage.
I would appreciate the explanation and further evidence to address these concerns.,Does the review address Result?,FALSE,TRUE,"Asks for clarity, not referencing outcomes/performance."
In case of the textual prompts benchmarks its also not clear to me why no standard errors on results are reported?,Does the review address Result?,TRUE,FALSE,Queries missing standard errors on results.
"The experimental settings in Section 3 lack detailed descriptions, potentially making reproduction difficult and potentially misleading.",Does the review address Experiment?,TRUE,FALSE,Criticizes incomplete experimental details.
"For checking the generalization of the method and better comparison w/ InDIGO (though InDIGO also conducted on MSCOCO, Django and the current comparison is sufficiently fair), I would like to increase my rating if seeing more experiments on large scale machine translation benchmarks as those in InDIGO.",Does the review address Comparison?,TRUE,FALSE,Suggests more experiments for fair comparison.
A key parameter that occurs in obtaining the above results is a worst-case coefficient that bounds the distributional shift between language model distributions of the training dataset and that of the downstream task.,Does the review address Methodology?,TRUE,FALSE,Mentions a parameter for distributional shift in approach.
"- There's a clear Inconsistency in the best TC method between different latent dimensions (8,6,32), in most of the experiments there's at least one of the 3 that is performing drastically worse than the other baselines, while there's overall no clear winner.",Does the review address Result?,TRUE,FALSE,Discusses varied performance in experiments (results).
"It's also not explained how Theorem 2 justifies the main conclusion: that ""a prompt engineer aided by enough time and memory can force an LLM to output an arbitrary sequence of ℓ tokens.""",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Seeks clarity on theorem usage/interpretation.
It is hard to know here which one of these actually made the adversarial setup useful.,Does the review address Result?,TRUE,FALSE,Queries which factor improved adversarial results.
"Altogether, I think this paper makes an interesting contribution to the question of: How can we get the most pretraining signal from unstructured data using off-the-shelf tools?",Does the review address Data/Task?,TRUE,FALSE,Talks about leveraging data for pretraining.
The evaluation method uses CCA to maximize the correlation between the word embeddings and possibly hand crafted linguistic data.,Does the review address Data/Task?,TRUE,FALSE,Mentions using linguistic data in evaluation.
"To best of my knowledge, under many circumstances in particular for short sequence, attention alone might not be the  most time-consuming part of the model.",Does the review address Methodology?,TRUE,FALSE,Talks about approach detail (attention/time cost).
This may strengthen the contribution of the paper.,Does the review address Contribution?,TRUE,FALSE,Suggests something to enhance the paper’s contribution.
"The evaluation results are based on the authors' implementations, for both baseline and the proposed method.",Does the review address Evaluation?,TRUE,FALSE,Mentions how the evaluation is done.
- Using capital and lower case tau in Theorem 4.2 is confusing notation.,Does the review address Theory?,TRUE,FALSE,Points to a theorem’s notation confusion.
"In algorithm 1, in each iteration, only data sample (S_i) is used, how is this choice motivated?",Does the review address Methodology?,TRUE,FALSE,Asks about the approach design (algorithm).
There's also some missing related work in extracting knowledge from pretrained models that should probably be discussed.,Does the review address Presentation?,FALSE,TRUE,"Criticizes missing literature mention, not about clarity/structure."
"As such, in my opinion this is unquestionably an important subtopic for the field of machine programming and the authors approach also seems satisfactory to me for ICLR (described below).",Does the review address Significance?,TRUE,FALSE,Emphasizes importance (significance) of the subtopic.
"More importantly, the experiments are not convincing as it is presented now.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,"Focuses on experiment persuasiveness, not deeper explanation."
"If the tasks are not similar, and the learning objectives are not aligned, then the motivation for multi-task learning is solely for reducing memory footprint and computational cost.",Does the review address Data/Task?,TRUE,FALSE,Discusses tasks in multi-task learning context.
"Further, how does the network perform when a longer context is obtained *maintaining the same number of parameters* as a network with less temporal scales?",Does the review address Methodology?,TRUE,FALSE,Questions approach detail (longer context with same params).
"This paper proposes the adaptive \alpha computed by the entropic level of model probability distribution per sample, which leads to updating the model parameters to lower the predictive score on the ground-truth target, as opposed to the effect of the cross-entropy with hard targets.",Does the review address Methodology?,TRUE,FALSE,Talks about an adaptive alpha approach.
"Compared to Pengi, the closed-ended audio task performances are lower.",Does the review address Result?,TRUE,FALSE,Compares performance results vs. Pengi.
"In sum, the proposed method is relatively novel and the idea is reasonable.",Does the review address Novelty?,TRUE,FALSE,Calls the method “novel.”
- What is it about an audio channel model that makes compositionality easier or more difficult to learn?,Does the review address Methodology?,TRUE,FALSE,Asks about approach factors for compositionality.
"Their goal is to reduce the amount of parameters and data needed, while improving (or maintaining) state-of-the-art performance.",Does the review address Data/Task?,TRUE,FALSE,Speaks about data usage/performance.
The authors chose to not rerank if the candidates' scores are too low or high but close.,Does the review address Experiment?,TRUE,FALSE,Details an experimental procedure (reranking).
"In the least, it's unclear how to assess the differences shown in this table.",Does the review address Presentation?,TRUE,FALSE,Mentions unclear presentation of table differences.
My main problem with this paper at the moment is that it could be much better written: The overall narrative of the paper is unpolished and it’s hard at first to understand the contributions of the paper.,Does the review address Presentation?,TRUE,FALSE,Criticizes clarity/structure.
The idea of learning which parameters to share across languages in multilingual transformer models is original and potentially useful for designing and analyzing multilingual models in the context of NMT.,Does the review address Methodology?,TRUE,FALSE,Mentions approach for multilingual parameter sharing.
"I do understand that the main point is the reduction of the amount of parameters (per task), but this doesn't mean that the evaluation should paint a wrong picture.",Does the review address Methodology?,TRUE,FALSE,Criticizes approach to evaluation in the method context.
It is therefore not surprising that multi-task learning should help these tasks.,Does the review address Data/Task?,TRUE,FALSE,Mentions multi-task learning tasks.
"Had `calculateTime()` been part of some standard library shared between programs, the case for generalization would have been much stronger.",Does the review address Methodology?,FALSE,TRUE,"Discusses a hypothetical scenario, not approach details."
- General Discussion: It would be nice if the survey of prior work in 2.2 explicitly related those methods to the desiderata in the introduction (i.e. specify which they satisfy).,Does the review address Related Work?,TRUE,FALSE,Suggests expanding prior literature in section 2.2.
"Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",Does the review address Ablation?,TRUE,FALSE,Mentions an ablation study.
This paper demonstrates why self-knowledge distillation as a prior distribution is a form of regularization with theoretical analysis on the gradients.,Does the review address Analysis?,TRUE,FALSE,Mentions theoretical analysis for regularization.
Performance better than previous approaches (although minor).,Does the review address Comparison?,TRUE,FALSE,Compares performance to previous approaches.
"Steinert-Threlkeld (2020) ""Towards the Emergence of Non-trivial Compositionality"" makes similar points and could be cited here as well.",Does the review address Related Work?,TRUE,FALSE,Suggests citing additional prior work.
It could be easy to be re-implemented and deployed for further research.,Does the review address Methodology?,FALSE,TRUE,"Talks about ease of re-implementation, not approach detail."
"Additionally, it would be good if the authors could report the number of examples (either raw number or as a fraction of the total dev set) for each of the categories: having that would help draw better conclusions.",Does the review address Data/Task?,TRUE,FALSE,Suggests reporting dataset details (counts).
"For example, the $p^{\star}$ notation is also defined in Sec 2.1.",Does the review address Presentation?,TRUE,FALSE,Mentions notation definition clarity.
The evaluation process shows that the current system (which extracts 1.,Does the review address Evaluation?,TRUE,FALSE,Talks about the evaluation process.
I think the presentation of the paper needs to be improved.,Does the review address Presentation?,TRUE,FALSE,Criticizes overall clarity/structure.
So my point 5 is important to answer and I would like to see all the details are clarified in order to make the contribution stronger.,Does the review address Presentation?,TRUE,FALSE,Calls for clarity to strengthen the contribution.
Is this threshold a hyper-parameter need to be configured?,Does the review address Presentation?,TRUE,FALSE,Asks for clarity about threshold as a hyper-parameter.
"-----General Discussion----- This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths).",Does the review address Methodology?,FALSE,TRUE,"Criticizes novelty, not approach details."
"The overall problem is framed as a judgment question, further enhancing the method's Uniqueness and Efficiency.",Does the review address Methodology?,TRUE,FALSE,Mentions framing as a “judgment question” approach.
And more space can be freed up to further explain the results section.,Does the review address Result?,TRUE,FALSE,Suggests further explanation of results.
"As similar efforts are already applied in several query expansion techniques (with the aim to relate the document with the query, if matching terms are absent in document).",Does the review address Related Work?,TRUE,FALSE,Refers to query expansion techniques used in prior works.
The authors also propose two novel pre-training settings which also show improvement over the baseline BM-25.,Does the review address Result?,TRUE,FALSE,States performance improvement (result) over BM-25.
There are some unclear expressions and inconsistent explanations.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out unclear/inconsistent explanations.
"In order to train reading comprehension models to perform relation extraction, they create a large dataset of 30m “querified” (converted to natural language) relations by asking mechanical turk annotators to write natural language queries for relations from a schema.",Does the review address Data/Task?,TRUE,FALSE,Describes a large dataset creation (data/task).
I also did not find a Related Work section discussing this in more detail.,Does the review address Related Work?,TRUE,FALSE,Criticizes missing in-depth related work discussion.
"The description of the baselines is lacking and quite confusing: it's not clear why the authors have two DP-SGD baselines, and what they're exactly updating during training.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Complains about confusing baseline explanations.
Experimental results show improvements over both the base T5 model and the large T5 model.,Does the review address Methodology?,FALSE,TRUE,"Focuses on performance outcome, not the approach details."
This is very promising to simplify the construction of highly tuned task-specific neural pipelines and improve the multimodal and multi-task problems.,Does the review address Methodology?,TRUE,FALSE,Talks about an approach for building neural pipelines (method).
strengths 1) This paper is well written and easy to read.,Does the review address Presentation?,TRUE,FALSE,Praises clarity/organization of the writing.
The world oracle conveys the meaning of being absolute truth which sounds a bit unexpected.,Does the review address Presentation?,TRUE,FALSE,Comments on wording/terminology use (clarity).
The method proposed has limited methodology contribution to the research community.,Does the review address Contribution?,TRUE,FALSE,Criticizes the paper’s contribution.
"We expect that the model can not only achieve good performance on a single dataset, but also have the potential to transfer beyond a single dataset.",Does the review address Data/Task?,TRUE,FALSE,Refers to performance across different datasets (data/task).
"I think authors wanted to say that even though BROS does not rely on visual features, it does outperform LayoutLM which, in turn, uses visual features.",Does the review address Result?,TRUE,FALSE,Mentions performance outcome vs. LayoutLM.
"Authors could have provided more in-depth details (visualizations, analysis, examples) to show main differences between the proposed approach and baselines (specially LayoutLM).",Does the review address Analysis?,TRUE,FALSE,"Suggests more analysis (visualizations, etc.)."
"Please report the total training and total inference time, and make a comparison with standard Transformer model.",Does the review address Methodology?,TRUE,FALSE,Requests approach detail (training/inference comparison).
"Generally speaking, this paper puts forward a universal retrieval scheme, and achieves good results, the specific advantages are as follows:  (1) The sparse alignment of multi-vector retrieval is a good solution to solve the retrieval effect and efficiency.",Does the review address Result?,TRUE,FALSE,States “good results” are achieved.
"Are the authors using off-the-shelf code (in which case, please refer and cite, which would also make it easier for the reader to understand and replicate if necessary)?",Does the review address Related Work?,TRUE,FALSE,Suggests citing existing code (related work).
"I am concerned this is quite low and could yield exaggerated instability, especially for large Transformer models.",Does the review address Methodology?,TRUE,FALSE,Criticizes approach detail (instability concern).
"Although the presentation can be polished, the overall narrative and explanation is clear and easy to follow.",Does the review address Presentation?,TRUE,FALSE,Praises clarity while noting it could be polished.
"Theoretically, they showed that synchronized updates to the low-level and high-level policy may never converge, yet asynchronized updates guarantees convergence.",Does the review address Methodology?,TRUE,FALSE,Describes policy update approach (method).
"The authors say ""we focus on larger datasets from GLUE (MNLI, QNLI, QQP and SST-2), as it is less meaningful to discuss efficient training"", but then report and analyze results from other GLUE datasets as well.",Does the review address Data/Task?,TRUE,FALSE,Talks about the use of multiple GLUE datasets.
", do you mean Table 3?Does the review address Presentation?
1936The Non-trivial Sub-network"" paragraph feels like it should be part of the Experiments section.",Does the review address Experiment?,TRUE,FALSE,Suggests the paragraph belongs in the experiment section (experiment context).
The way in which you have collected these samples is likely to create a bias towards simple missing conditions.,Does the review address Methodology?,TRUE,FALSE,Points to approach’s sampling/bias.
They should have comparable numbers of parameters.,Does the review address Methodology?,TRUE,FALSE,Suggests approach detail (parameter comparability).
They provide a training that guarantees convergence to local maxima.,Does the review address Methodology?,TRUE,FALSE,Mentions a convergent training approach.
"####Summary:  To tackle situations where compositionality is mostly required at inference time, the paper proposes a novel data augmentation method with an RNN based generator (recombination); to make the generator generate highly compositional patterns, the paper proposes a resampling method.",Does the review address Data/Task?,TRUE,FALSE,Discusses data augmentation approach.
* The paper is well motivated and easy to understand and follow.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Mentions good motivation.
"If successful, the approach could be impactful because it speeds up prediction.",Does the review address Significance?,TRUE,FALSE,Refers to the approach’s potential impact.
It is then not clear how each fact block (grey squares in Figure 4) functions as a whole.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Seeks explanation of fact blocks.
"* Because BPE is such a standard baseline, why do you not include it as a baseline?",Does the review address Comparison?,TRUE,FALSE,Questions missing baseline for comparison.
1.The performance of this model is closely related to both the AST encoding frontend and the LLaMA model's performance.,Does the review address Result?,TRUE,FALSE,Mentions performance relationship.
"The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",Does the review address Experiment?,TRUE,FALSE,Notes thorough experiment details + ablation.
"Due to the very “flat” portions of the softmax function, there can be meaningful differences between the logits corresponding to 2 different words, but the LM probabilities for those words are extremely similar (and thus, harder for a linear model to distinguish).",Does the review address Presentation?,TRUE,FALSE,Notes the explanation detail/clarity of LM probability differences.
"The work introduces the Transformer-QL, a transformer-based model that aims to capture long distance dependencies in the input.",Does the review address Methodology?,TRUE,FALSE,Presents a new approach (Transformer-QL).
Some discussion on the current design choices and why making the proposed methods features to some of the other baselines is not a way to achieve some benefits is not the right way to do it.,Does the review address Comparison?,TRUE,FALSE,Comments on design vs. other baselines.
Weaknesses: There is no contribution/novelty from the modeling/methods side.,Does the review address Contribution?,TRUE,FALSE,States no novelty in the approach (contribution).
The fact that the previous study reported a 126 perplexity baseline using LSTM and the LSTM's perplexity of 106.9 provided by the author showed that the FBIS gives an advantage to computing the language model's perplexity when tested on PTB.,Does the review address Methodology?,TRUE,FALSE,Mentions approach detail re: perplexity computing.
I understand that LMU might have limited capacity but this is not specifically discussed and it is unclear how each component contributes to the end performance.,Does the review address Result?,TRUE,FALSE,Mentions performance/end result.
"In sec4.1, the authors said ""A batch size of 256 is employed, "", does that mean K=256 in Algorithm 1?",Does the review address Presentation?,TRUE,FALSE,Questions clarity of a paper detail.
Many of the notations look cumbersome and I suspect that there is still room for making the notations more accessible for new readers.,Does the review address Presentation?,TRUE,FALSE,Critiques clarity of notation.
* It is explained in the paper that the runtime environment ensures that the proofs are never circular.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Explains how proofs remain non-circular.
It seems to be making every previously known augmentation approach better.,Does the review address Result?,TRUE,FALSE,States improvement over prior methods.
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Ablation?,TRUE,FALSE,Explicitly refers to ablation studies.
"Prior work has explored ""learning-to-share""  strategies for parameter sharing in multi-task learning (see Ruder et al., AAAI 2018), and using gating/masking to control computational paths in a differentiable way (see Fan et al., ICLR 2019, Sukhbaatar et al., ACL 2019); it is clear that the focus is NMT but it should be worth mentioning/discussing such studies to better situate the work and to help the reader assess the actual contributions.",Does the review address Methodology?,TRUE,FALSE,Discusses methodological approaches.
"In section 3.3.3 ""THE MIX-UP OF MULTIPLE TYPES,"" the authors mention that ""it is possible to embed multiple Double-I watermarks in a model, which theoretically has the potential to enhance the robustness of our watermarking technique.""",Does the review address Result?,TRUE,FALSE,Suggests improved robustness/performance.
This paper conducts comprehensive evaluations on the influence of selecting specific examples for inclusion in the prompt.,Does the review address Presentation?,FALSE,TRUE,"Discusses evaluations, not clarity/structure."
"2016 [2] A syntactic neural model for general-purpose code generation, Yin and Neubig 2017 [3] Making Neural Programming Architectures Generalize via Recursion, Cai et al. 2017  ####Authors have engaged in the discussion, clarified questions about the paper and addressed comments in its newest revision.",Does the review address Methodology?,FALSE,TRUE,No direct mention of the study’s approach.
Pros: - Weakly-supervised method for video moment localization is a reasonable and important direction.,Does the review address Presentation?,FALSE,TRUE,"Addresses method/importance, not presentation."
2) The presentation is very good and easy to follow.,Does the review address Presentation?,TRUE,FALSE,Directly praises presentation clarity.
"Finally, writing in general can be made clearer:  1.",Does the review address Presentation?,TRUE,FALSE,Mentions writing clarity.
I think I'd like to see a discussion of sufficient number D analytically or empirically.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Calls for more discussion/explanation.
"## (Minor) Imprecise Claim about Poly(n) Size  In Theorem 1, the authors claim: > We consider log-precision, constant-depth, and polynomial-size Transformers: for Transformers whose input is of length n, the values at all neurons are represented with O(log n) bits, the depth is constant, and the number of neurons is O(poly (n)).",Does the review address Theory?,TRUE,FALSE,References a theorem/conceptual foundation.
It's not really okay to put up the tables and show the perplexity and BLEU scores without some explanation.,Does the review address Result?,TRUE,FALSE,Mentions perplexity and BLEU scores (results).
"Edit after seeing others reviews -- I think I gave this paper a MUCH higher score than the other reviewers, simply because it is very novel with Fon language.",Does the review address Novelty?,TRUE,FALSE,Praises the paper’s novelty (Fon language).
"First, the authors are missing a great deal of related work: Neelakantan at al. 2015 (https://arxiv.org/abs/1504.06662) perform zero-shot relation extraction using RNNs over KB paths.",Does the review address Related Work?,TRUE,FALSE,Points out missing prior literature.
"But then at the end, I saw you include Encode as step 4, so it is the machine...",Does the review address Methodology?,TRUE,FALSE,Refers to the procedural/algorithmic step.
The graph indicates that for MNLI and QNLI 60% seems like a better choice.,Does the review address Result?,TRUE,FALSE,Refers to performance findings.
The difference in the ablation results seem quite small (tables 3 and 4).,Does the review address Result?,TRUE,FALSE,Discusses ablation-based performance differences.
"Considering the actual experimental setting is significantly different from the VIP setting, the title “Answering Queries with CLIP Adversely affects VIPs explanations” and the conclusions seem a bit misleading.",Does the review address Experiment?,TRUE,FALSE,Mentions the experimental setup.
The difference in the ablation results seem quite small (tables 3 and 4).,Does the review address Significance?,TRUE,FALSE,Questions the overall impact/significance.
Margins are very small for the Average differences across all datasets as well -- have you considered confidence intervals on those as well?,Does the review address Data/Task?,TRUE,FALSE,References datasets explicitly.
"Consequently, there is a possibility that it could be utilized in real-world applications of in-context learning.",Does the review address Methodology?,FALSE,TRUE,"Refers to usage/impact, not the approach itself."
"I look forward to the author's discussion of the additional learnable parameters introduced in addition to CLIP's pre-trained model, and compare the number with other methods.",Does the review address Comparison?,TRUE,FALSE,Suggests comparing parameter counts.
(2) Is table 1 an average over the 17 embeddings described in section 5.1?,Does the review address Methodology?,TRUE,FALSE,Asks about how the experiment/approach is done.
Solid experiments demonstrating the proposed method outperforms other existing approaches.,Does the review address Experiment?,TRUE,FALSE,Mentions experimental demonstration.
(3) The loss for answer prediction in Eq 6 is not clearly described: do you use an aggregated embedding over all nodes for prediction?,Does the review address Methodology?,TRUE,FALSE,Questions the method’s details.
The provided experiments are more like baselines for self-evaluation other than state-of-the-art performance.,Does the review address Evaluation?,TRUE,FALSE,Critiques how the methods are assessed.
"Consider, for a moment, that they are using only 25,000 input/output pairs for their training/validation/testing.",Does the review address Data/Task?,TRUE,FALSE,"References data usage (25,000 pairs)."
"Did the author try other window widths, for example width `1' to extract unigram features, `3' to trigram, or use them together?",Does the review address Presentation?,FALSE,TRUE,"This is about the method choice, not clarity."
An ablation study is carried out to rule out the possibility that the benefits from PACT come from simply regularizing the model.,Does the review address Ablation?,TRUE,FALSE,Explicitly mentions the ablation study.
Another limitation is that it is unclear whether the improvement would hold when the size of the model increases; the evaluation is dealing with scaling laws after all.,Does the review address Evaluation?,TRUE,FALSE,References the evaluation concerns.
The optimality of deterministic inference does not hold empirically due to class imbalance or discrepancy between training and test sets.,Does the review address Methodology?,TRUE,FALSE,Points to a limitation in the approach.
Experimental evaluation shows competitive performance.,Does the review address Evaluation?,TRUE,FALSE,Mentions competitive performance in evaluation.
I agree with the authors that extending the context is important.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Expresses support for the paper’s motivation.
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Methodology?,TRUE,FALSE,Discusses the comparison of approaches (method).
"Sec 3.1 contains results on captionnet, Sec 4 also contains results on captionnet.",Does the review address Result?,TRUE,FALSE,Refers to reported results in sections.
"Some of the details for model description are missing and confusing, e.g., (1) How the representation is initialized for a supernode corresponding to a fact triplet and how does the supernode propagate information to the sub-nodes?",Does the review address Presentation?,TRUE,FALSE,Critiques clarity of model description.
Strengths * Improving the data efficiency in language models is an important problem that so far studies have shown that can be achieved by scaling the size of the model.,Does the review address Methodology?,TRUE,FALSE,References the approach to improve data efficiency.
"It is important to note that while BLEU of other methods reduced on the Fr→Fon task, WB improved on it.",Does the review address Presentation?,FALSE,TRUE,"Talks about results, not clarity/structure."
- During the training of the decoder how do you make sure that the decoder uses the information given by the latent plan?,Does the review address Methodology?,TRUE,FALSE,Questions the training/approach details.
"It is also strange that the multi-cluster approach, which discards inter-cluster (word and language) semantic information performs the best with respect to the extrinsic metrics.",Does the review address Evaluation?,TRUE,FALSE,Comments on extrinsic metrics and evaluation.
"For example, sentence inference tasks such as MNLI and RTE are common tasks in NLP field.",Does the review address Data/Task?,TRUE,FALSE,"Mentions common tasks (MNLI, RTE)."
Explicit modeling the generation order is not a very novel idea that there have been many works on this topic.,Does the review address Novelty?,TRUE,FALSE,Points to a lack of novelty.
"It would help to clarify when what you predict is a guard, a precondition, an invariant, or something else.",Does the review address Presentation?,TRUE,FALSE,Requests clearer explanation or definitions.
"I do understand that the main point is the reduction of the amount of parameters (per task), but this doesn't mean that the evaluation should paint a wrong picture.",Does the review address Evaluation?,TRUE,FALSE,Discusses how evaluation is presented.
"Second, the authors neither 1) evaluate their model on another dataset or 2) evaluate any previously published models on their dataset.",Does the review address Data/Task?,TRUE,FALSE,Notes dataset usage/evaluation.
Hyper-parameter balancing strategies in Section 3.1 is not a solid theoretical analysis.,Does the review address Theory?,TRUE,FALSE,Mentions (criticizes) theoretical grounding.
"I would suggest the following:   * To make the comparison more fair, I would suggest to train transformer models with varying size and derive a power law based on the exact same experimental configuration used for LMU models.",Does the review address Presentation?,FALSE,TRUE,"Focuses on experimental setup, not presentation."
- I don't see why your theory does not generalize to a _masked_ language modeling (MLM).,Does the review address Theory?,TRUE,FALSE,Questions the theory’s generalizability.
"The paper has ""support set"" and ""support instructions"" at many places but it is unclear to me what it actually means.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Seeks clarification of terms.
"-----General Discussion----- This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,"Criticizes novelty, not deeper explanation details."
Details / Questions: * It seems to me that the GLUE results might be within the margin of error.,Does the review address Result?,TRUE,FALSE,Talks about the GLUE results.
Might be useful to define what is exactly meant by 'comprehensibility' 4.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Calls for a clearer definition of “comprehensibility.”
"But from Table 5., the trend of performance seems to increase with the increased prepositional phrases (with 84.7 being the max for 4 PPs).",Does the review address Methodology?,FALSE,TRUE,"Focuses on performance trends (results), not the approach or technique."
"**Major concern** If I understand correctly (and please correct me if I am wrong), in Theorem B.1, the ratio between the downstream error $\ell_\mathcal{T}(\\{p_{\cdot\mid s}\\}) - \tau$ and the pre-training error $\ell_\text{xent}(\\{p_{\cdot\mid s}\\})-\ell_\text{xent}^\ast$ is _hidden_ in the $\gamma(p_{\mathcal{T}}; \\{p_{\cdot\mid s}\\})$ coefficient.",Does the review address Methodology?,TRUE,FALSE,Discusses how the method/theorem is formulated.
- Improvement over previous state-of-the-art models.,Does the review address Methodology?,FALSE,TRUE,States a result/improvement rather than the approach itself.
"Therefore, it is necessary to compare OTTER and CLIP on the same-scaled datasets.",Does the review address Data/Task?,TRUE,FALSE,Refers to dataset scaling/comparison.
"Overall, I think the paper provides an interesting view of discussion, but there are many flaws in the current version which needs to be corrected before a more serious consideration.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,Gives a broad critique; does not specify definitions/explanations.
I suppose it would be hard to define auxiliary tasks for simpler systems.,Does the review address Methodology?,TRUE,FALSE,Talks about defining tasks in the method/approach.
(4) How exactly is the interaction module processed?,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests an explanation of how the module is processed.
* Description of refl and tidy-bfs baselines appears much late in the paper.,Does the review address Comparison?,TRUE,FALSE,"Refers to baselines, indicating comparison with other methods."
"According to the evaluation, the proposed method shows its effectiveness especially when the finetuning data is limited.",Does the review address Data/Task?,TRUE,FALSE,Mentions the finetuning data aspect.
Could you explain the significance of this result again?,Does the review address Significance?,TRUE,FALSE,Asks about the importance/impact of the result.
"But I support given a fixed set of phrase pairs at train time, the attention mechanism at the phrasal level can be pre-computed but at inference (apply the attention on new data at test time), this might be kind of problematic when the architecture is scaled to a larger dataset.",Does the review address Methodology?,TRUE,FALSE,Concerns about how the method scales with attention and datasets.
"-----General Discussion----- This paper proposes a practical model which seems working well on one dataset, but the main ideas are not very novel (see comments in Strengths).",Does the review address Novelty?,TRUE,FALSE,Critiques the novelty of the paper’s ideas.
• It is stated that (page 7) the submission to GLUE leaderboard uses only single-task finetuning.,Does the review address Data/Task?,TRUE,FALSE,References single-task finetuning (task usage).
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.,Does the review address Methodology?,FALSE,TRUE,Focuses on paper organization/placement (presentation concern).
It is not clear to me what the value of OpenAQA dataset is on top of of the textual metadata available with most of these datasets.,Does the review address Significance?,TRUE,FALSE,Questions the importance/value of the dataset.
"‘Wang & Cho’ were not the first who used Transformers generativity (see Vaswani, 2017).",Does the review address Methodology?,FALSE,TRUE,References prior work/origins rather than the paper’s approach.
"For this purpose, the authors introduced the definition of a ""natural"" task.",Does the review address Data/Task?,TRUE,FALSE,Introduces a specific type of task.
The findings from the analysis are an important addition to the understanding of the role of language specific parameters in multilingual NMT.,Does the review address Analysis?,TRUE,FALSE,Explicitly refers to “analysis” of parameters.
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Analysis?,FALSE,TRUE,Discusses a theoretical guarantee rather than an analysis of data/methods/results.
"The true contribution appears to be the improvement of the overlapping strategy tokenization for DNA pretraining, which diverges from the broader theme of ""rethinking the pretraining for DNA sequence.""",Does the review address Contribution?,TRUE,FALSE,Directly addresses the paper’s contribution.
"The paper made a impactful finding for practicing adversarial training, that mixture of signals at different depth of of the generator can stabilize ELECTRA-style models trained adversarially using Gumble-Softmax relaxation.",Does the review address Methodology?,TRUE,FALSE,Highlights the adversarial training approach.
"I would suggest using the phrase ""weighted SVD"" early on in the introduction (e.g., exactly when you introduce your new method).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests clearer definition or explanation of “weighted SVD.”
Chain-of-thought prompting elicits reasoning in large language models.,Does the review address Related Work?,TRUE,FALSE,References chain-of-thought (related work).
"If the experiment does not peer inside the structure of the noise and treats it as a gray box instead, it is not much different than a discrete-channel environment where random edits are made to the message.",Does the review address Experiment?,TRUE,FALSE,Discusses the experimental approach to noise.
Why isn’t an asymmetric architecture more natural?,Does the review address Methodology?,TRUE,FALSE,Questions the architectural design (method).
- The ablation experiments and optimized prompt analysis are insightful.,Does the review address Methodology?,FALSE,TRUE,"Refers to ablation and prompt analysis, not the broader approach."
"*  What is the contribution of each specific design choice, such as the FFN/global attention and implicit self-attention, to the end performance?",Does the review address Ablation?,TRUE,FALSE,Asks about each design choice in the ablation study.
"- P5, Sec 4.1: ""The result suggests that small test cross-entropy (hence test perplexity)..."" Same question as above.",Does the review address Presentation?,FALSE,TRUE,Focuses on result/performance rather than clarity/structure.
"Main weaknesses (for each of them, see detailed comments below): - The description of the corpus and the experimental setup frequently lacked some details; there is also no comparison to an existing Thai UD resource.",Does the review address Comparison?,TRUE,FALSE,Points out missing comparison to another resource.
**Experimental results** The presentation of the experimental results is clear.,Does the review address Presentation?,TRUE,FALSE,States clarity of presenting experimental results.
- The analysis of compositionality given is insufficient.,Does the review address Analysis?,TRUE,FALSE,Critiques the compositionality analysis.
The cost of training NLP models: A concise overview.,Does the review address Related Work?,TRUE,FALSE,References prior overview/work.
"Despite very encouraging results, several important methodological questions about the source of the efficiency gains and other aspects of the paper are left unanswered.",Does the review address Result?,TRUE,FALSE,Mentions “encouraging results.”
"To name a few:   -“Language Models as Knowledge Bases?” EMNLP 2019   -“Commonsense Knowledge Mining from Pretrained Models.” EMNLP 2019   -“Comet: Commonsense Transformers for Automatic Knowledge Graph Construction.” ACL 2019 - Although the proposed model achieves quantitative improvements over Angeli et al. (2015), it seems unclear whether these improvements are due to the factual knowledge encoded in the pre-trained LM, as claimed.",Does the review address Methodology?,TRUE,FALSE,Questions how the method uses knowledge from the LM.
Section 3.4  does not describe clearly enough how attention maps were used for predicting contact maps.,Does the review address Presentation?,TRUE,FALSE,Criticizes clarity in explaining attention usage.
"#### Weakness - In Table 1, the WNLI task is excluded from the GLUE benchmark, I wonder what is the reason this task is removed?",Does the review address Data/Task?,TRUE,FALSE,Mentions the exclusion of a specific dataset/task.
- The visualization section is only a minor contribution; there isn't really any innovation or findings about what works or doesn't work here.,Does the review address Result?,FALSE,TRUE,"Focuses on the visualization section, not reported results."
And there is no further explanation and ablation study on the design of the dynamic threshold.,Does the review address Ablation?,TRUE,FALSE,Notes missing ablation for the dynamic threshold.
The algorithms were clear and the comments were useful for understanding the proposed idea.,Does the review address Methodology?,TRUE,FALSE,Praises clarity of the proposed approach.
"It requires more analysis about experimental results, such as Figure 1 and tables in Section D.",Does the review address Experiment?,TRUE,FALSE,Calls for more analysis of experimental results.
"In contrast, focusing on a solid target and ignoring the rest of potential targets, CLIP may still infer the generalized information provided by many-to-many relationships due to the wide range of data collection.",Does the review address Data/Task?,TRUE,FALSE,Discusses data collection aspect.
"Discussion of D  Since RF is not the major contribution, you summarize existing results of FA in sec2.2.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Refers to summarizing existing results (discussion).
"It is widely acknowledged and studied that the complexity (i.e., the length or reasoning steps of the CoT annotations) significantly influences the performance of the LLMs.",Does the review address Presentation?,FALSE,TRUE,"Addresses complexity/performance, not clarity/structure."
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions assumptions and definitions in analysis.
It is also hard to navigate through all the information due to different ablation targets.,Does the review address Ablation?,TRUE,FALSE,Discusses various ablation targets.
"The description of the baselines is lacking and quite confusing: it's not clear why the authors have two DP-SGD baselines, and what they're exactly updating during training.",Does the review address Comparison?,TRUE,FALSE,Mentions confusion in baseline comparisons.
"Comparative Analysis and Benchmarking:  The comparisons presented in Tables 1 and 2 focus solely on the improvements over one reference work (Ma et al., 2023).",Does the review address Data/Task?,TRUE,FALSE,Discusses data focus for benchmarking.
"This idea is novel and interesting to me, and the derivation and experiment results look encouraging.",Does the review address Result?,TRUE,FALSE,Highlights results as encouraging.
Using Transformer attention maps for protein contact prediction is not new.,Does the review address Methodology?,TRUE,FALSE,Critiques use of known methodology.
"That is, unless I’ve just missed something, it seems that all of the core components of N-Bref are lifted from prior work with perhaps some minor augmentation.",Does the review address Novelty?,TRUE,FALSE,Questions the novelty of contributions.
"For a more comprehensive analysis, it would be instructive to see how the approach compares with a broader spectrum of state-of-the-art methods.",Does the review address Methodology?,TRUE,FALSE,Suggests comparing methodology with more methods.
"Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",Does the review address Ablation?,TRUE,FALSE,Covers ablations and their comparisons.
This paper presents an effective way to make use of this idea.,Does the review address Methodology?,TRUE,FALSE,Praises the effectiveness of methodology.
The proposed method improves modestly on BERT on the GLUE suite of problems.,Does the review address Result?,TRUE,FALSE,Notes improvement on GLUE tasks.
"* It will be cool to show some results on BLEU improvement on machine translation, or user studies on language generation tasks, to demonstrate its practical impact, as the quantitative metrics right now are still kind of artificial.",Does the review address Evaluation?,TRUE,FALSE,Suggests practical evaluation metrics like BLEU improvement.
**Empirical**:  One issue with the language modelling experiment is the choice of evaluation and train set.,Does the review address Methodology?,TRUE,FALSE,Points out issues with the evaluation and training sets.
Ablations show the necessity of applying a 2-step intermediate training scheme with mixed training followed by joint training.,Does the review address Methodology?,TRUE,FALSE,Highlights the necessity of the 2-step training scheme.
"The key ideas are: (i) training longer with bigger batches over more data, (ii) removing NSP, (iii) training over long sequences, and (iv) dynamically changing the masking pattern.",Does the review address Data/Task?,TRUE,FALSE,Lists key ideas related to data and tasks.
"In fact, empirical evidence suggest that LMs do memorize n-grams from their training data somewhat, but not full examples (see [McCoy et al.",Does the review address Result?,TRUE,FALSE,Provides empirical evidence related to memorization.
"Although the individual components are similar to previous work, they are combined in a novel way that shows a path toward longer and more efficient context lengths.",Does the review address Methodology?,TRUE,FALSE,Mentions the novel combination of components.
"Finally, the CALM intermediate objectives share many properties with all of the datasets tested on and are likely calibrating the model to the kind of correlations they should expect to predict in advance of finetuning.",Does the review address Methodology?,TRUE,FALSE,Discusses the calibration of the model with datasets.
It might be valuable to evaluate PENGI on Open ended tasks.,Does the review address Significance?,TRUE,FALSE,Suggests evaluating PENGI on open-ended tasks.
"I have no experience with these kinds of NLU models, so I can't say with confidence whether the architectural additions proposed are well-motivated, but to me it feels like there is not a strong justification for adding these particular features to the BERT architecture, and the results do not clearly demonstrate their utility except in the ""lexical_overlap"" case.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Questions the justification for architectural additions.
"The only interesting aspect is adapting the training procedure to contrastive learning, which is trivial.",Does the review address Methodology?,TRUE,FALSE,Comments on the simplicity of adapting the training procedure.
"In sec4.1, the authors said ""A batch size of 256 is employed, "", does that mean K=256 in Algorithm 1?",Does the review address Methodology?,TRUE,FALSE,"It discusses a specific implementation detail (batch size) in an algorithm, indicating a focus on the approach/technique."
It also substantially improves on BERT with respect to a class of examples that are designed to confound models that learn superficial heuristics based on word occurrence.,Does the review address Result?,TRUE,FALSE,"It directly states that the method ""substantially improves"" on BERT, referencing performance outcomes."
"About type dependency graph: 1) Comparing to previous work (e.g, Allamanis et.al, ICLR 18), it seems the construction of the task specific graph is the major contribution, where the novelty is a bit limited.",Does the review address Novelty?,TRUE,FALSE,"It explicitly comments on how “novel” the approach is, noting limited novelty."
"This setting captures the design and the hardware restriction of realistic T-LLMs and is common in the literature on the theoretical power of T-LLMs (Hahn, 2020; Hao et al., 2022; Merrill et al., 2022; Merrill & Sabharwal, 2023).",Does the review address Presentation?,FALSE,TRUE,"It describes the setup and references prior work but does not address clarity, structure, or organization of the paper."
"This is especially disappointing as the objectives introduced _directly_ match the task in CommonGEN, making this intermediate training a form of noisy training data rather than pretraining.",Does the review address Data/Task?,TRUE,FALSE,It explicitly refers to the “task in CommonGEN” and training data.
Both publications appeared on arXiv at least one month before the ICLR submission deadline and are not clearly discussed in the paper.,Does the review address Related Work?,TRUE,FALSE,"It mentions other publications that should have been discussed, indicating a reference to related literature."
It does not follow from the theoretical results that adding similar sentences will be a good thing.,Does the review address Methodology?,FALSE,TRUE,It focuses on theoretical implications rather than describing the approach or technique.
"However, the teacher networks used in the experiments are not always uni-modal.",Does the review address Experiment?,TRUE,FALSE,It explicitly refers to how the teacher networks are used in “the experiments.”
The methodology is explained clearly and experiments are executed with a considerable amount of detail.,Does the review address Methodology?,TRUE,FALSE,It explicitly praises the clarity of the “methodology.”
"I think authors wanted to say that even though BROS does not rely on visual features, it does outperform LayoutLM which, in turn, uses visual features.",Does the review address Comparison?,TRUE,FALSE,It compares the performance of BROS to LayoutLM.
"Weakness While the ablation study and visualization analysis are done, the key evaluations are missing.",Does the review address Presentation?,FALSE,TRUE,"It notes missing evaluations but does not comment on the paper’s clarity, organization, or structure."
"- P6, Sec 4.3: ""In fact, $f$ almost always performs better than ..."" This part seems intriguing despite the linear relationship shown in figure 1.",Does the review address Presentation?,FALSE,TRUE,"It references a figure to discuss performance findings, not the clarity or structure of how it is presented."
"- P8, Table 2: The results from using Quad look worse than the above two.",Does the review address Significance?,FALSE,TRUE,It highlights results but does not address their impact or importance in the field.
"In my knowledge, the previous work has not yet attempted to tackle this problem.",Does the review address Novelty?,TRUE,FALSE,"It indicates the research problem has not been addressed before, pointing to originality."
- The choice in deciding how many template tokens are used is unclear.,Does the review address Presentation?,TRUE,FALSE,It critiques the clarity or explanation of how a parameter (template tokens) is decided.
It might be good to address the existing literature on compressing trained neural networks which also goes beyond simply trying to minimize the Frobenius norm of the difference between the weights.,Does the review address Related Work?,TRUE,FALSE,"It explicitly recommends addressing existing literature, pointing to relevant prior work."
Since we observe that the randomly pruned models do not competitive performance ...: how uncompetitive?,Does the review address Result?,TRUE,FALSE,"It discusses the (lack of) competitiveness in model performance, referencing results."
"Nonetheless, the current paper leaves too many open questions regarding the validity of the experiments.",Does the review address Experiment?,TRUE,FALSE,"It raises concerns about experiment validity, explicitly referencing the study’s experiments."
"The proposed models -- which seem to be an application of various tree-structured recursive neural network models -- demonstrate a nice performance increase compared to a fairly convincing, broad set of baselines (if we are able to trust them; see below).",Does the review address Methodology?,TRUE,FALSE,"It describes the specific approach (tree-structured RNNs), indicating a discussion of the methodology."
"This paper makes comparison with techniques used in active learning (AL), domain shift detection (DS), and multi-domain sampling to combine data from multiple sources.",Does the review address Methodology?,TRUE,FALSE,"It references specific techniques and processes (AL, DS, multi-domain sampling), relating to the approach used."
"This setting captures the design and the hardware restriction of realistic T-LLMs and is common in the literature on the theoretical power of T-LLMs (Hahn, 2020; Hao et al., 2022; Merrill et al., 2022; Merrill & Sabharwal, 2023).",Does the review address Related Work?,TRUE,FALSE,"It cites prior research (multiple references), indicating discussion of relevant work."
Performance: Concept-QA appears to perform well when evaluated along multiple axes.,Does the review address Result?,TRUE,FALSE,"It points out that Concept-QA ""performs well,"" indicating discussion of results."
The results on Split H are positive and they also conducted a range of ablation and error analysis.,Does the review address Ablation?,TRUE,FALSE,It explicitly states that they conducted “ablation” analysis.
"in Table 2, it's necessary to explain why the LSTM's perplexity from previous work is higher than the author's implementation.",Does the review address Result?,TRUE,FALSE,"It references perplexity results, comparing previous work to the new implementation."
"* In the results section there is a typo: *""performances with a large margins of 2.32pp in""*.",Does the review address Result?,TRUE,FALSE,"It specifically mentions the “results section,” indicating discussion of results."
"- Strengths: This paper has high originality, proposing a fundamentally different way of predicting words from a vocabulary that is more efficient than a softmax layer and has comparable performance on NMT.",Does the review address Novelty?,TRUE,FALSE,"It highlights the “high originality,” pointing to novelty."
"Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally.",Does the review address Analysis?,TRUE,FALSE,It explicitly references “analysis” as the basis for recommendations.
The idea of learning which parameters to share across languages in multilingual transformer models is original and potentially useful for designing and analyzing multilingual models in the context of NMT.,Does the review address Novelty?,TRUE,FALSE,"It calls the approach “original,” emphasizing the study’s novelty."
"Overall, I think this paper has a clear motivation and some interesting ideas on how to incorporate semantic language information into planning algorithms.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"It explicitly praises the paper’s motivation, which fits under justification and motivation."
"It is good to know that it works for 2D-coordinates for the task at hand, though it seems to be more a marginal improvement on existing work rather than a standalone contribution.",Does the review address Result?,TRUE,FALSE,"It comments on the performance (improvement) regarding the task, thus referencing results."
I would appreciate further elaboration on the limitations of sparse attention in DNA sequence representation.,Does the review address Methodology?,TRUE,FALSE,"It requests more details about a specific technical approach (“sparse attention”), indicating a focus on the methods used."
"Specifically, having the BFS analysis of the attention weights as a function of different GreaseLM layers (as done by Yasunaga et al.)",Does the review address Analysis?,TRUE,FALSE,"It explicitly refers to analyzing attention weights (BFS analysis), which involves an investigative/analytical process."
"Experiments on type predictions for TypeScript have shown better performance than the previous methods, with or without user specified types.",Does the review address Experiment?,TRUE,FALSE,"It describes experimental results on type prediction, directly referencing the conducted experiments."
The experimental results also look promising in compared with the exsiting models.,Does the review address Comparison?,TRUE,FALSE,"It compares the experimental results to existing models, indicating a direct comparison."
"Given that there is a wealth of existing work that performs the same task and the lack of novelty of this work, the authors need to include experiments that demonstrate that their technique outperforms others on this task, or otherwise show that their dataset is superior to others (e.g. since it is much larger than previous, does it allow for better generalization?)",Does the review address Methodology?,TRUE,FALSE,"It discusses the need to demonstrate how the proposed technique (method) compares or outperforms others, thus pointing to methodological concerns."
"These are not weakness, but I think some work in this direction may help improve the paper.",Does the review address Experiment?,FALSE,TRUE,It gives a general suggestion for improvement but does not refer specifically to experiments.
The authors have somewhat clarified in this in their updated version.,Does the review address Presentation?,TRUE,FALSE,"It notes that the authors “have somewhat clarified” a point, indicating discussion about clarity or how something is presented."
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Theory?,TRUE,FALSE,"It references a theoretical guarantee about language model performance, thus addressing the study’s theoretical underpinnings."
"Some things that are worth looking into are the work on Scalable static analysis [Scaling], the inference of necessary preconditions [Logozzo], and bug detection that is based on ""belief"" [deviant, belief], which is closely related to your intuition about naturalness and human-written invariants.",Does the review address Analysis?,TRUE,FALSE,"It discusses different forms of analysis (static analysis, inference of preconditions), indicating an analytical component."
The cold-start problem is actually an urgent problem to several online review analysis applications.,Does the review address Significance?,TRUE,FALSE,"It highlights the urgency and importance of addressing the cold-start problem, pointing to the significance of the work."
My another is concern is that the motivation of the experimental design is not clear.,Does the review address Experiment?,TRUE,FALSE,"It explicitly critiques the clarity of the experimental design, thus mentioning experiments."
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Result?,TRUE,FALSE,"It refers directly to “experimental results” and their limitations, thus addressing results."
"I would suggest the following:   * To make the comparison more fair, I would suggest to train transformer models with varying size and derive a power law based on the exact same experimental configuration used for LMU models.",Does the review address Experiment?,TRUE,FALSE,"It proposes changes to how experiments are conducted (training transformer models differently), indicating an experimental discussion."
"The term ""intermediate neurons"" (section 3.2) was unclear to me.",Does the review address Presentation?,TRUE,FALSE,"It comments on the clarity or explanation of a term in the paper, which is related to presentation."
"Discussion of D  Since RF is not the major contribution, you summarize existing results of FA in sec2.2.",Does the review address Result?,TRUE,FALSE,"It specifically notes the “existing results of FA,” referring to results presented in the paper."
The hypothesis are clearly stated and the experiments are well designed.,Does the review address Methodology?,TRUE,FALSE,Mentions well-designed experiments (method).
**Student networks** are too weak to prove the proposed techniques are useful for the more recent (and more powerful) models.,Does the review address Presentation?,FALSE,TRUE,No comment on clarity/structure/organization.
"For example, besides the quantative improvements, does the rapid convergence and under-training still exist after applying RandomMask?",Does the review address Result?,TRUE,FALSE,Refers to performance/convergence.
"**Related work** The authors clearly describe the related prior works from both the perspectives of program synthesis, large language models, and benchmarks for program synthesis.",Does the review address Related Work?,TRUE,FALSE,Explicitly cites prior works.
"New Outlooks for Low-Bit Quantization on Large Language Models, Zhang et al. [3] FP8 Quantization: The Power of the Exponent, Kuzmin et al.",Does the review address Related Work?,TRUE,FALSE,Lists relevant prior publications.
It is not clear how certain experimental designs were made.,Does the review address Presentation?,TRUE,FALSE,Points to unclear presentation of design.
- The algorithm presented here is able to be used in an unsupervised way and can work with both open-ended and more structured knowledge graph schema.,Does the review address Methodology?,TRUE,FALSE,Describes the algorithmic approach.
- The analysis which builds on these definitions/models/assumptions provides meaningful theoretical insight into why language model pre-training may be so beneficial for downstream training.,Does the review address Theory?,TRUE,FALSE,Mentions theoretical insight.
"Having an ablation on the number of GreaseLM layers would also be quite useful to answer if performance improves with more GreaseLM layers, are there diminishing returns or do we need just a few GreaseLM layers, beyond which it is detrimental to the model's performance.",Does the review address Result?,TRUE,FALSE,References performance outcomes.
S: - The idea of controlling the generation of language models step-by-step in a recurred manner is interesting.,Does the review address Methodology?,TRUE,FALSE,Discusses the method for generation.
I felt this was quite separate from the theoretical analysis.,Does the review address Theory?,TRUE,FALSE,References theoretical analysis.
The paper proposes Options framework based method for using the hierarchical structure in dialog to learn the dialog policy and NLG in a hierarchical fashion.,Does the review address Methodology?,TRUE,FALSE,Describes a proposed methodological approach.
"But from Table 5., the trend of performance seems to increase with the increased prepositional phrases (with 84.7 being the max for 4 PPs).",Does the review address Result?,TRUE,FALSE,Discusses performance metrics.
I would recommend include some references in semantic parsing.,Does the review address Related Work?,TRUE,FALSE,Suggests adding references.
Time analysis on language modeling is not presented.,Does the review address Analysis?,TRUE,FALSE,Mentions (missing) time analysis.
"This is the key weakness, but this makes me find it really difficult to judge the overall technical quality and significance.",Does the review address Significance?,TRUE,FALSE,Mentions overall significance.
Also the pointer mechanism used for predicting user specified types is a good strategy that advances the previous method.,Does the review address Result?,TRUE,FALSE,Notes improvement over a previous method.
The description of how you compare your invariants to those inferred by Daikon is not clear unless all relevant cases related to (pre)conditions on method parameters.,Does the review address Comparison?,TRUE,FALSE,Discusses how invariants are compared.
"- Secondly, this main result depends on the worst-case coefficient, which is also unclear to me.",Does the review address Result?,TRUE,FALSE,Refers to the main result.
"Based on the large-scale training data and the proposed visual expert module, the proposed method achieves a number of state-of-the-art results across a wide range of vision-language tasks.",Does the review address Result?,TRUE,FALSE,Mentions state-of-the-art results.
"While I appreciate the environment introduced and believe it to be promising, the experiments presented fail to highlight the novelty of the environment.",Does the review address Novelty?,TRUE,FALSE,Explicitly questions its novelty.
The work successfully leverages the framing of general learners in terms of circuits to conclude that transformer LMs are not universal learners.,Does the review address Methodology?,TRUE,FALSE,References the approach/framework.
The submission has evaluated the proposed algorithms on four datasets and improved SOTA performances.,Does the review address Result?,TRUE,FALSE,Notes improved SOTA performance.
"Typos: In Sec 5.2 Tasks (f), ""$\phi_2(x)=1$"" should be ""$\bar \mu_2=1$"".",Does the review address Presentation?,TRUE,FALSE,Points out a typo in the presentation of formulas.
"On the one hand the baselines make use of a large set of training trajectories, but on the other hand these methods train policies that choose low-level actions.",Does the review address Comparison?,TRUE,FALSE,Highlights comparison between baselines and methods.
"The claimed contributions include: 1) The proposed method is free from the common issue of diverging from human language, because it learns from the sentences sampled from the pre-trained LM.",Does the review address Methodology?,TRUE,FALSE,Mentions the methodology of learning from pre-trained LM.
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.,Does the review address Data/Task?,TRUE,FALSE,Mentions evaluation on public datasets.
"Last sentence of intro: ""without scarifying accuracy"" seems like an inaccurate description of the results presented in this paper.",Does the review address Result?,TRUE,FALSE,Critiques the accuracy claim in the results.
Here there is no direct comparison of the performance of the current system w.r.t.,Does the review address Comparison?,TRUE,FALSE,Points out the lack of direct performance comparison.
"This makes it difficult to conclusively prove that this is an ""applicable to all"" data augmentation scheme.",Does the review address Methodology?,TRUE,FALSE,Questions the methodology of data augmentation scheme.
I suppose it would be hard to define auxiliary tasks for simpler systems.,Does the review address Data/Task?,TRUE,FALSE,Suggests difficulty in defining tasks for simpler systems.
"The architecture does not look entirely novel, but I kind of like the simple and practical approach compared to prior work.",Does the review address Related Work?,TRUE,FALSE,Compares the approach to prior work.
"This makes it difficult to conclusively prove that this is an ""applicable to all"" data augmentation scheme.",Does the review address Data/Task?,TRUE,FALSE,Reiterates difficulty in proving data augmentation scheme.
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Ablation?,TRUE,FALSE,Highlights the importance of the ablation study.
"But using neural models to rank (or rerank) is a long-existing technique, regardless of the chosen parametrization of the reranking model.",Does the review address Methodology?,TRUE,FALSE,Discusses the use of neural models for ranking.
"Sometimes, sparse attention can improve generalization [1].",Does the review address Methodology?,TRUE,FALSE,It discusses an approach (sparse attention) relevant to methodology.
Please let me know if I have misunderstood something(s),Does the review address Presentation?,TRUE,FALSE,The request indicates a concern about understanding the presentation.
- The proof technique (pre-training performance $\to$ covariance of pre-training errors $\to$ covariance of downstream errors $\to$ downstream performance) is itself interesting.,Does the review address Result?,TRUE,FALSE,The comment acknowledges a result related to the proof technique.
"However, I am unable to grasp nuances, leaving important questions untouched such as: In what scenarios do we expect the model to perform better than GECA?",Does the review address Comparison?,TRUE,FALSE,"The review questions scenarios where performance might exceed GECA, implying comparison."
"- The definitions, models, and assumptions in the paper are intuitive and clear (e.g., natural task).",Does the review address Presentation?,TRUE,FALSE,"It evaluates the clarity of definitions and assumptions, relevant to presentation."
The authors should conduct experiments on more types of sentence pair tasks.,Does the review address Experiment?,TRUE,FALSE,"Suggests additional experiments, directly referencing experimentation."
One issue is that the main contribution is  mostly condensed into section 3.2 which is less than one page.,Does the review address Contribution?,TRUE,FALSE,It critiques the limited elaboration on the paper's contribution.
"For the first ablation, it just gives out the performance of intermediate models on a single task.",Does the review address Ablation?,TRUE,FALSE,"Refers to ablation, specifically intermediate model performance."
Strengths: The paper is well-written with clear motivations and structure.,Does the review address Presentation?,TRUE,FALSE,It assesses the clarity and structure of the paper.
"The authors experiment both with pre-training and fine-tuning of contextual models (BERT-{base,large}) and claim large reduction in training time, with reasonable loss in performance.",Does the review address Experiment?,TRUE,FALSE,Refers to experiments involving pre-training and fine-tuning.
Incorporating bert into neural machine translation.,Does the review address Related Work?,TRUE,FALSE,References previous work involving BERT for neural machine translation.
The idea itself is not completely new as the authors readily explain in the paragraph MACHINE LEARNING WITH PROOF ARTIFACTS on page 2.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Addresses the explanation of prior concepts.
Existing performance improvement is quite limited.,Does the review address Result?,TRUE,FALSE,Evaluates the results by highlighting limited performance gains.
* I found the discussion in Section 4.1 pretty confusing.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques the clarity of explanations in a specific section.
This seems to contradict findings from Brown et al where larger models did better on essentially all tasks.,Does the review address Methodology?,TRUE,FALSE,Questions methodological assumptions regarding model size and performance.
"Minor Issues  ==== Figure 2 is a little redundant, I think figure 1 is enough to compare it against the pRNN (figure3 and 4).",Does the review address Presentation?,TRUE,FALSE,"Critiques the redundancy and necessity of figures, related to presentation."
This could be tested by ablating elements from the input or ablating the recurrent memory vectors (setting them to zero during inference).,Does the review address Experiment?,TRUE,FALSE,Suggests further ablation experiments for testing.
"Strengths:  - The paper is generally well-written, with excellent motivation and empirical setup/analysis  - The overall strategy of differentiable prompt optimized to maintain fluency is reasonable and novel.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Praises the motivation and justification for the study.
- Experiments are well-designed: many baselines are implemented to compare proposed method with traditional lifelong learning methods.,Does the review address Experiment?,TRUE,FALSE,"Discusses the design of experiments, comparing methods."
"Detailed comments:  1) Reducing the variance of output prediction can reduce the gap on variational posterior, but how does the gap relate to the generalization error?",Does the review address Methodology?,TRUE,FALSE,Discusses methodological implications of reducing variance.
This paper presents a replication study of BERT pretraining and carefully measures the impact of many key hyperparameters and training data size.,Does the review address Methodology?,TRUE,FALSE,References a methodological focus on hyperparameter analysis.
- The data preprocessing and training steps are complex.,Does the review address Methodology?,TRUE,FALSE,Highlights complexity in methodology-related processes.
The theory can be more practically useful if it can be extended to quantify the intractability level so the resulting embeddings' error can be bounded or compared.,Does the review address Theory?,TRUE,FALSE,Relates theoretical results to practical usability and error analysis.
"As the main contribution of this paper is the increased efficiency of the proposed approach, it must be clear how efficiency is measured.",Does the review address Contribution?,TRUE,FALSE,Focuses on the clarity and significance of contributions.
The paper is mostly clearly written and discusses server interesting ablation experiments.,Does the review address Ablation?,TRUE,FALSE,Highlights interest in specific ablation experiments.
- Standard Errors: The VIMABench experiments were run over three random seeds for each meta-task but results are reported without any standard errors?,Does the review address Experiment?,TRUE,FALSE,critiques the reporting of results in experiments
"Furthermore, they have clarified that on the key metric of CommonGen they achieved SoTA with only slightly more than half the parameters of the current SoTA model.",Does the review address Presentation?,TRUE,FALSE,evaluates the clarity and detail in presenting key results
"However, two recent papers that appeared on arXiv before the ICLR submission deadlines also use Transformers for protein contact prediction.",Does the review address Methodology?,TRUE,FALSE,references other methods (using Transformers) relevant to the study
"- It's because if the largest phrase length is the sentence length, then model can be simplified into a some sort of convolution RNN where the each state of the RNN goes through some convolution layer before a final softmax and attention.",Does the review address Presentation?,FALSE,TRUE,"describes a technical simplification of the model rather than addressing the clarity, structure, or organization of the paper."
"In addition, the explanations (query-answer chains) are shorter and more human-interpretable.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,discusses the interpretability and human-readability of explanations
"Compared to a softmax layer and hierarchical/differentiated softmax, is binary code prediction a natural way to predict words?",Does the review address Comparison?,TRUE,FALSE,compares binary code prediction with softmax and hierarchical softmax layers
"Intuitively, a smaller gap might lead to better performance.",Does the review address Result?,TRUE,FALSE,speculates on the impact of a smaller gap on performance
"However, the way they convert the logic forms is different for each dataset and they have to manually design rules for each logic form.",Does the review address Methodology?,TRUE,FALSE,discusses the manual rule design and dataset-specific approaches used in converting logic forms
More importantly the PACT methodology is more general; the idea of incorporating diverse auxiliary tasks as a language modeling task by introducing a distinct token for each task is novel.,Does the review address Methodology?,TRUE,FALSE,highlights the generalization and novelty of the PACT methodology
"In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 257–266.",Does the review address Related Work?,FALSE,TRUE,cites a reference without discussing or reviewing its relevance to the study
**Summary** This work relates a pre-training performance with a downstream performance for tasks that _can_ be reformulated as next word prediction tasks.,Does the review address Result?,TRUE,FALSE,connects pre-training performance to downstream task outcomes
"(iii) Some suggested baselines that make these assumptions would be a heuristic A\* search, or modifying any of the existing algorithms to use smaller action spaces and/or apply alternative exploration strategies seen in previous works such as modular policy chaining (that MC!Q*BERT uses) or Go-Explore (Madotto et al.",Does the review address Comparison?,FALSE,TRUE,proposes alternative baselines and strategies while comparing them to existing algorithms
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Experiment?,FALSE,TRUE,"critiques the experimental setup, specifically noting limited validation and lack of human evaluation or error analysis."
"I’m not sure about this, so any discussion would be appreciated.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,"invites discussion on a topic, explicitly seeking further clarification and insights"
"For example, if you could give us one or two sentences of Fon in the beginning of the paper, that demonstrate some of the difficulties of the language, I think this would greatly strengthen the motivation.",Does the review address Intuition/Justification/Motivation/Validation?,FALSE,TRUE,including examples to enhance the paper’s motivation and contextual justification.
Questions:  * How can we be sure that the specific power law derived from a different experimental configuration in Kaplan et al. (2020) corresponds to the empirical law that can be derived for transformers in this particular evaluation setting?,Does the review address Evaluation?,TRUE,FALSE,The review questions the applicability of a derived power law in the specific evaluation setting of transformers.
This looks like an order of magnitude difference in dataset empirical evaluation to me.,Does the review address Data/Task?,TRUE,FALSE,"The review discusses empirical evaluation related to datasets, addressing their scale and differences."
"- The definitions, models, and assumptions in the paper are intuitive and clear (e.g., natural task).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,The review praises the clarity and intuitiveness of the paper‚Äôs conceptual framework and explanations.
Could you explain the significance of this result again?,Does the review address Presentation?,FALSE,TRUE,The request focuses on understanding the importance of a result rather than its clarity or structure.
In case of the textual prompts benchmarks its also not clear to me why no standard errors on results are reported?,Does the review address Data/Task?,TRUE,FALSE,"The critique addresses the reporting of results specific to textual prompt benchmarks, which relates to tasks and datasets."
"Hence, to my understanding, it may not be suitable to use the term ""global reasoning"" in this work.",Does the review address Presentation?,TRUE,FALSE,"The review critiques the appropriateness of terminology used in the paper, addressing clarity and expression."
The show improved performance in MultiWoz dataset.,Does the review address Result?,TRUE,FALSE,"The review discusses improved performance on the MultiWoz dataset, directly referencing results."
More details should be reported to show the benefits of adopting the adaptive smoothing parameter.,Does the review address Methodology?,TRUE,FALSE,"The review requests additional details to clarify the benefits of a methodological component, relating to its use and impact."
"Specifically, having the BFS analysis of the attention weights as a function of different GreaseLM layers (as done by Yasunaga et al.)",Does the review address Methodology?,TRUE,FALSE,The review highlights a specific methodological analysis (BFS attention weights) and compares it to previous work.
"This paper suggests a number of cheap-to-compute corruptions of the input data that, when used to reconstruct the input, enrich the underlying model.",Does the review address Methodology?,TRUE,FALSE,The review focuses on the methodological proposal of input data corruptions and their impact on the model.
"For the theoretical analysis, it was not clear to me what is the contribution of the current analysis compared to the Levine 2020 paper.",Does the review address Theory?,TRUE,FALSE,"The review questions the contribution of the theoretical analysis in comparison to prior work, addressing its conceptual foundation."
"In particular, they used the option framework to represent the connection between the dialog policy and the natural language generation.",Does the review address Methodology?,TRUE,FALSE,Mentions the use of the option framework.
Performance better than previous approaches (although minor).,Does the review address Result?,TRUE,FALSE,Notes improved performance over baselines.
"It provides a nice theoretical framework for thinking about the connection between language models and downstream tasks, which future work could build on.",Does the review address Data/Task?,TRUE,FALSE,Discusses framework connecting tasks.
Some experimental settings only include the baselines Random and Vote-k. More methods as mentioned in 4.3.2 can be also included.,Does the review address Methodology?,TRUE,FALSE,Critiques baseline inclusion in experiments.
* The paper doesn’t explain why learning a linear model directly on the context embeddings f(s) performs better than using the contextual mean embeddings.,Does the review address Result?,TRUE,FALSE,Questions the performance difference.
"The first use of the proposed definitions to make a non-trivial claim is in Section 5 with Postulate 1, but this claim is not justified.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Notes lack of claim justification.
"Thus, it seems to me that you are essentially applying past results to answer a specific question you have (which is still a valuable contribution).",Does the review address Contribution?,TRUE,FALSE,Recognizes application of past results.
"*  What is the contribution of each specific design choice, such as the FFN/global attention and implicit self-attention, to the end performance?",Does the review address Analysis?,TRUE,FALSE,Asks for analysis of design choices.
- No error analysis about the generated plans and the edited text.,Does the review address Analysis?,TRUE,FALSE,Critiques missing error analysis.
"The presentation can be improved, all the definitions are hard to follow.",Does the review address Presentation?,TRUE,FALSE,Suggests improving unclear definitions.
Summary of review:  There have been lots of interests to understand why self-supervised learning approaches such as the next word prediction task learn a useful representation for downstream tasks.,Does the review address Data/Task?,TRUE,FALSE,Discusses the utility of the next word prediction task for downstream use.
- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.,Does the review address Analysis?,TRUE,FALSE,Requests additional ablation analysis.
"Yet, it is difficult for me to trust that the effects in this paper will generalize to better performing models without further evidence: what if the CALM intermediate objectives only help with mistakes that larger models do not make in the first place?",Does the review address Result?,TRUE,FALSE,Questions generalizability of results to better-performing models.
So a very straightforward idea is that we can directly set an independently learnable parameter as the prototype of each category to calculate the cosine similarity with image embeddings.,Does the review address Methodology?,TRUE,FALSE,Describes an idea related to the methodology for image embedding.
(2) Another weakness is that the comparison with the vanilla and LS baselines does not seem to be properly controlled in terms of parameters.,Does the review address Methodology?,TRUE,FALSE,Critiques control of parameters in methodology.
As noted in contemporary works such assumptions dramatically reduce the difficulty and language understanding capabilities of text games (Yao et al. (ii) The second issue is that MC-LAVE assumes that the simulator is deterministic and can conduct rollouts and reset within the span of an episode - standard planning assumptions but incompatible with all other baselines (except for MC!Q\*BERT) which do not use this handicap.,Does the review address Presentation?,TRUE,FALSE,Highlights issues with presentation of assumptions.
The separate table on the left in Table 2 appears to be redundant.,Does the review address Presentation?,TRUE,FALSE,Notes redundancy in the presentation of Table 2.
"These prior methods do not incorporate the SFT stage, making it unclear how the model performs before this crucial phase.",Does the review address Comparison?,TRUE,FALSE,Points out missing comparison with models excluding the SFT stage.
"- Similarly, using bold and not-bold B in Theorem 5.2 is confusing notation.",Does the review address Presentation?,TRUE,FALSE,Critiques unclear notation in Theorem 5.2.
"In experimental details, the slightly better performance in Table 2, can it be attributed to finer generation powered by the RNN generator?",Does the review address Result?,TRUE,FALSE,Questions the cause of performance differences in experimental results.
"Overall, I like the idea of the paper: it is important to reduce the parameters needed for sets of tasks, to enable NLP models to be deployed in a larger variety of settings, and reducing the amount of data needed.",Does the review address Data/Task?,TRUE,FALSE,"Discusses reducing parameters and data requirements for NLP models, directly relating to the ""Data/Task"" aspect."
"It might be good to find the best hyperparameters for each setting to truly do a fair comparison (avoiding hyperparameter tuning isn't really a fair comparison, IMO -- but this depends on how much compute you have available).",Does the review address Methodology?,TRUE,FALSE,"Mentions hyperparameter tuning and the fairness of methodological comparisons, directly addressing the methodology aspect."
- The analysis which builds on these definitions/models/assumptions provides meaningful theoretical insight into why language model pre-training may be so beneficial for downstream training.,Does the review address Methodology?,TRUE,FALSE,"Highlights theoretical insight into language model pre-training, which relates to the methodology aspect of the study."
"With the proposed CaptionNet dataset, it is now possible to have a fairer comparison between VL models and CE models.",Does the review address Methodology?,TRUE,FALSE,"Mentions the proposed dataset enabling fairer comparisons, which relates to methodological evaluation."
"The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",Does the review address Data/Task?,TRUE,FALSE,"Discusses assumptions and theoretical results related to tasks like Parity/Sum, directly addressing ""Data/Task."""
"Firstly, in the last paragraph of Section 2, the authors claim that the role matrix $R$ would be invertible such that there exists a matrix $U = R^{-1}$ such that the fillers would be recovered.",Does the review address Theory?,TRUE,FALSE,"Refers to theoretical claims about matrix invertibility and filler recovery, directly relating to ""Theory."""
* The paper is well motivated and easy to understand and follow.,Does the review address Presentation?,TRUE,FALSE,"Praises the clarity and structure of the paper, directly addressing the ""Presentation"" aspect."
The authors have created a large dataset for relation extraction as question answering which would likely be useful to the community.,Does the review address Data/Task?,TRUE,FALSE,"Discusses the creation of a large dataset for a specific task, addressing ""Data/Task."""
"Section 4.8: Using transformers for generating proteins with natural properties is not new (see Madani et al, 2020, ‘ProGen’ or Rives et al, 2020).",Does the review address Methodology?,TRUE,FALSE,"Highlights related work in methodology, particularly using transformers for generating proteins, addressing ""Methodology."""
"Similarly, for pretraining, the model runs 80% of the training steps (20% reduction), which accounts much of the training time reduction reported on section 4.3.",Does the review address Methodology?,TRUE,FALSE,"Mentions training step reduction and pretraining methodology, directly addressing the ""Methodology"" aspect."
"**Pros**  - The paper is well structured and easy to follow, the idea of modeling sentences to a Brownian bridge latent space is neat and generic enough to (1) allow for noise given its stochasticity (2) doesn't require explicit domain knowledge for planning.",Does the review address Methodology?,TRUE,FALSE,Discusses the methodological design of Brownian bridge latent space for modeling sentences.
"However, the main driving force in the choice of the language-specific computation is currently a single hyper-parameter p which is the same across languages; so, this will lead to choices that are good on average for all language pairs involved for a given *universal* budget.",Does the review address Methodology?,TRUE,FALSE,Highlights methodology involving a universal hyperparameter for language-specific computation.
"Unfortunately, many aspects of the models, experimentation, and evaluation are not explained very well.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Criticizes inadequate explanation of models, experiments, and evaluation."
The method's innovative and effective feature fusion into the language model sets it apart.,Does the review address Presentation?,TRUE,FALSE,Mentions how the innovative feature fusion is clearly presented.
This paper is meaningful and presents a reasonable analysis.,Does the review address Analysis?,TRUE,FALSE,Acknowledges the presence of meaningful and reasonable analysis.
"Detailed comments:  - P2, Sec 1.1: ""analyze the efficiency language model features"" -> analyze the efficiency of language model features  - P2, Sec 2: you started introducing these notations without explaining what they mean.",Does the review address Presentation?,TRUE,FALSE,Points out presentation issues like unclear notation and grammar errors.
It is not clear how certain experimental designs were made.,Does the review address Experiment?,TRUE,FALSE,Criticizes the lack of clarity in experimental design decisions.
"- I know GPT3 access is hard to get, but I wish experiments with k=8 prompts could be compared against  Post rebuttal: I think another pass for clarity over the paper would be good for the final version, but otherwise I'm happy with the paper updates and I'm happy to see the ablation numbers aren't too sensitive to token count.",Does the review address Methodology?,TRUE,FALSE,Discusses methodology regarding prompt count sensitivity and experimentation clarity.
"It is also strange that the multi-cluster approach, which discards inter-cluster (word and language) semantic information performs the best with respect to the extrinsic metrics.",Does the review address Result?,TRUE,FALSE,Comments on unexpected results from the multi-cluster approach.
"- One huge benefit of perceiver IO is to train different tasks together and explore the transfer between different tasks/modalities, which is not explored in this paper.",Does the review address Methodology?,TRUE,FALSE,Highlights the methodology potential of Perceiver IO for multi-task training and transfer.
Their models achieve better quantitative results when compared to the provided baselines.,Does the review address Result?,TRUE,FALSE,"Discusses quantitative improvements over baselines, indicating results."
The authors find that the main ingredients for the success of in-context learning are a combination of selective annotation with similarity-based prompt retrieval.,Does the review address Data/Task?,TRUE,FALSE,Highlights the role of data-related strategies like selective annotation and prompt retrieval.
"Some kind of analysis of the qualitative strengths and weaknesses of the binary code prediction would be welcome -- what kind of mistakes does the system make, and how does this compare to standard softmax and/or hierarchical and differentiated softmax?",Does the review address Analysis?,TRUE,FALSE,Requests qualitative analysis of binary code prediction's strengths and weaknesses.
"While previous work has examined tasks in the overall area, to my knowledge there has not been any publicly availble sentence-level annotated data for the problem -- the authors here make a contribution as well by annotating some data included with the submission; if it is released, it could be useful for future researchers in this area.",Does the review address Data/Task?,TRUE,FALSE,Mentions the creation of new annotated data and its potential utility.
"(2) In this paper, similarity and alignment structures are proposed, but no ablation experiments have been carried out to prove the effectiveness of the improved model.",Does the review address Experiment?,TRUE,FALSE,Points out the lack of ablation experiments for evaluating the model's effectiveness.
* Section 4 - I think you really need to re-state that the algorithm has a human-in-the-loop for clarity.,Does the review address Methodology?,TRUE,FALSE,Suggests clarification of a methodological aspect involving human-in-the-loop.
The provided experiments are more like baselines for self-evaluation other than state-of-the-art performance.,Does the review address Result?,TRUE,FALSE,Critiques the experimental results as self-evaluative rather than showing state-of-the-art outcomes.
"Authors could have provided more in-depth details (visualizations, analysis, examples) to show main differences between the proposed approach and baselines (specially LayoutLM).",Does the review address Presentation?,TRUE,FALSE,Criticizes the lack of detailed presentation for comparisons with baselines.
The analysis shows that it outperforms only all the other baselines only on 5/9 games and matches on 3.,Does the review address Comparison?,TRUE,FALSE,Compares performance against baselines across different tasks (games).
The paper presents an end-to-end methods for jointly training named entity recognition (NER) and relation extraction (RE).,Does the review address Methodology?,TRUE,FALSE,Describes an end-to-end methodological approach for NER and RE tasks.
"Comparing the proposed method to earlier approaches such as PaLI, CoCa, and Flamingo may not be entirely fair.",Does the review address Comparison?,TRUE,FALSE,Discusses comparisons with other approaches and highlights fairness issues in the evaluation.
A single value of $k=150$ was chosen for experiments across all tasks.,Does the review address Data/Task?,TRUE,FALSE,Mentions specific data/task-related experimental parameter choices.
"However, all the parameters/variables in the neural networks are freely designated and are not correlated to each other, thus they cannot work together to meet the requirements in the binding-unbinding mechanism.",Does the review address Theory?,TRUE,FALSE,Refers to theoretical issues with parameter/variable interaction in the neural network.
"In terms of strenghs - The paper has a very throughout analysis of different models and positional encodings - It proposes several contributions, including a new probing task and several positional encoding methods.",Does the review address Analysis?,TRUE,FALSE,Highlights strengths in the analysis of models and contributions in the study.
"* I think it should be discussed earlier (in intro/related work) why the paper focuses on language models which do next word prediction via linear softmax models over fixed dimensional context embeddings, and that BERT is out of scope.",Does the review address Methodology?,TRUE,FALSE,Suggests clarification of methodological scope and focus on specific language models.
"By converting the logic forms to natural languages, the authors can leverage paraphrase datasets and pre-train the critic as a paraphrase model.",Does the review address Presentation?,TRUE,FALSE,Discusses presentation strategies involving paraphrase datasets and logic forms.
"- The paper is well written: it gives an appropriate context, presents the main theoretical results, and verifies _some_ of the claims experimentally.",Does the review address Experiment?,TRUE,FALSE,Refers to experimental verification of some claims in the study.
"335: consider defining GPGPU Table 3: Highlight the best BLEU scores in bold Equation 15: remind the reader that q is defined in equation 6 and b is a function of w. I was confused by this at first because w and h appear on the LHS but don't appear on the right, and I didn't know what b and q were.",Does the review address Presentation?,TRUE,FALSE,"Requests clarification in presentation, including defining terms and improving table clarity."
Should also discuss related work in 2d spatial visualization of country-country relationships by Peter Hoff and Michael Ward.,Does the review address Presentation?,TRUE,FALSE,Suggests integrating related work for better contextual presentation.
"It would be to show more experiment results for some settings, for example, performance on Sum task when training with a mixture distribution, or more Sum task samples and fewer Parity task samples ( p range from 0.5 to 1.",Does the review address Data/Task?,TRUE,FALSE,Recommends additional data/task-specific experimental results for clarity.
"They use the reading comprehension model of Seo et al. 2016, adding the ability to return “no relation,” as the original model must always return an answer.",Does the review address Methodology?,TRUE,FALSE,Describes modifications to an existing model's methodology.
It paves the way for more widespread application of VIP in scenarios where interpretable-by-design approaches are critical.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Discusses interpretability in the context of VIP and its application.
* Related work: I would also include a discussion of this Lazaridou et al paper where they compare ways of combining EC with non-EC learning signals (e.g. image caption training): https://aclanthology.org/2020.acl-main.685.pdf  * Ethics statement: I appreciate this statement and agree with the possible positive impacts.,Does the review address Methodology?,TRUE,FALSE,Suggests integrating related methodological discussions to enrich the paper.
"According to Table 6, I can hardly see a clear improvement brought by the introduced new VE modules.",Does the review address Result?,TRUE,FALSE,Evaluates the impact of new modules based on tabulated results.
A uniform framework for resampling Different recombinations perform more or less favorably across different datasets.,Does the review address Methodology?,TRUE,FALSE,Discusses a framework and its varying performance across datasets.
Why don't the authors of this work do this evaluation as well?,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Questions the justification for the scope of evaluations included.
It is unclear why the authors only show the response generation results.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Highlights a lack of explanation about the scope of presented results.
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.,Does the review address Evaluation?,TRUE,FALSE,Mentions evaluation on publicly available datasets and the results.
Their thorough ablation experiments and other analysis yield some interesting findings the authors could emphasize more.,Does the review address Result?,TRUE,FALSE,Refers to findings from ablation experiments and their implications.
The authors curated a large-scale dataset for first-stage pretraining and second-stage instruction tuning.,Does the review address Data/Task?,TRUE,FALSE,Discusses the creation of a large-scale dataset for pretraining and tuning.
"(In particular, pre-training on emergent language performs on average better than synthetic hierarchical data, but not quite as well as a different natural language, and all of these pre-training methods do better than training from scratch.)",Does the review address Result?,TRUE,FALSE,Evaluates the comparative performance of different pre-training methods.
"Overall, the authors show better accuracy for their tested problem set against REWARD, a baseline system (a transformer), lang2logic, and Ins2AST across two dimensions: data type recovery and abstract syntax tree (AST) generation.",Does the review address Result?,TRUE,FALSE,Mentions improved accuracy compared to baselines in two specific dimensions.
"It would be useful if following the suggestions of [2,3] the authors could present results in settings with low data regimes and with significant distribution shift with respect to the pre-training set, which represents a more realistic application setting.",Does the review address Data/Task?,TRUE,FALSE,Discusses the need to test on data settings that reflect realistic scenarios.
Why does Recomb-2 perform less well than GECA in SCAN?,Does the review address Result?,TRUE,FALSE,Questions specific performance results in comparison to another method.
"In the 6.2.3 visualization of clusters, it would be very useful to have a visualization of clusters from some baselines on other ways of learning.",Does the review address Presentation?,TRUE,FALSE,Requests additional visualizations to enhance clarity of comparisons.
Some theoretical and empirical evidence is shown for the learning effect.,Does the review address Result?,TRUE,FALSE,Mentions evidence supporting the claimed learning effect.
"The authors propose to include related texts retrieved by the kNN method in a single training sample, which is proved effective in solving sentence similarity tasks.",Does the review address Methodology?,TRUE,FALSE,Describes a specific methodological proposal involving kNN for training.
- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.,Does the review address Experiment?,TRUE,FALSE,Mentions limitations in the experimental design focusing on certain datasets.
But the authors didn’t compare against these agent-based system design.,Does the review address Methodology?,TRUE,FALSE,Points out the absence of comparisons with specific methodological designs.
"The authors could add more content to figure 1, which may resolve this issue.",Does the review address Presentation?,TRUE,FALSE,Suggests improving the content of a figure to address clarity issues.
Minor issues that did not affect score ------------------ Figure 1 has some scaling/resolution issues that make it hard to read.,Does the review address Presentation?,TRUE,FALSE,Notes technical issues with the readability of a figure.
The paper provides an image on GCP to reproduce their partial results.,Does the review address Result?,TRUE,FALSE,Mentions reproducibility of partial results using GCP.
"> On the generative task CALM performs closer to SOTA, but it improves only slightly on T5.",Does the review address Data/Task?,TRUE,FALSE,Discusses the task (generative task) and performance in comparison to SOTA.
"Contribution: The authors contribute a new tokenization method, code, and a dataset.",Does the review address Contribution?,TRUE,FALSE,"Highlights the contributions of a new tokenization method, code, and dataset."
The model architecture should be better justified.,Does the review address Methodology?,TRUE,FALSE,Suggests the need for stronger justification of the model architecture.
Also they could visually demonstrate the advantages of their approach.,Does the review address Presentation?,TRUE,FALSE,Recommends visual demonstrations to highlight advantages.
Such a comparison would highlight the advantages of the multi-task model and would be helpful for the relevant audience.,Does the review address Methodology?,TRUE,FALSE,Suggests comparison to better highlight the advantages of the multi-task model.
There are few places (see details) that authors have assumptions in mind but do not provide those assumptions until later.,Does the review address Presentation?,TRUE,FALSE,"Notes delayed presentation of assumptions, affecting clarity."
"(2) multiCCA : Extends the approach presented by Faruqui and Dyer (2014) for embedding bilingual words, to multilingual words by using English embeddings as the anchor space.",Does the review address Methodology?,TRUE,FALSE,Describes a methodological extension for multilingual embeddings.
"It is not clear whether the proposed method can be applied to other hardware settings, such as other GPUs, TPUs and large scale.",Does the review address Methodology?,TRUE,FALSE,Questions the generalizability of the method to different hardware settings.
"In experiments, there is no comparison with previous retrieval based methods.",Does the review address Significance?,TRUE,FALSE,Highlights the lack of comparison with retrieval-based methods in the experiments.
* I found the discussion in Section 4.1 pretty confusing.,Does the review address Presentation?,TRUE,FALSE,Points out confusion in the presentation of Section 4.1.
The visualization of OTTER’s matching illustrates its effectiveness in handling many-to-many relationships.,Does the review address Presentation?,TRUE,FALSE,Mentions the effectiveness of visualization for OTTER’s matching.
"Negatives --------- The experiments do not compare to many other approaches, even though those approaches are cited throughout the paper.",Does the review address Experiment?,TRUE,FALSE,Critiques the lack of experimental comparison with cited approaches.
(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.,Does the review address Methodology?,TRUE,FALSE,Discusses the results achieved by the proposed model on specific tasks.
Hyper-parameter balancing strategies in Section 3.1 is not a solid theoretical analysis.,Does the review address Analysis?,TRUE,FALSE,Critiques the theoretical analysis of hyper-parameter balancing strategies.
The proposed model is then experimentally verified on three logic-driven datasets which demonstrates some performance gain.,Does the review address Result?,TRUE,FALSE,Mentions experimental verification and observed performance gain.
Some comments:  _ It may be interesting to include a brief explanation of the differences between the approach from Tian et al. 2014 and the current one.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests explaining differences between approaches for clarity.
"For the second ablation, why do all the larger splits lead to similar performance?",Does the review address Ablation?,TRUE,FALSE,Questions the outcomes of an ablation study regarding larger splits.
Experimental evaluation shows competitive performance.,Does the review address Experiment?,TRUE,FALSE,Highlights competitive performance shown in experimental evaluations.
"(3) The proposed model in this paper uses sparse alignment matrix to aggregate token-level similarity, where each element represents the alignment of a pair of tokens, which can develop different retrieval models in a unified way and identify the shortcomings of existing models.",Does the review address Presentation?,TRUE,FALSE,Describes aspects of presentation related to the sparse alignment matrix.
"For example, in the visualization in Figure 2, the maximum many-to-many relationship of a sample is 3.",Does the review address Presentation?,TRUE,FALSE,"Discusses the visualization details in Figure 2, related to presentation."
"However, there are many numbers in different tables.",Does the review address Presentation?,TRUE,FALSE,"Mentions the abundance of numbers in tables, which relates to presentation clarity."
"what part of the performance is coming from pretraining (especially if using VAE type is novel, then quantifying that is important with and without VAE type SL), etc.",Does the review address Methodology?,TRUE,FALSE,Focuses on the methodology and its impact on performance.
"However, they compare to BERT models and build themselves on RoBERTa_base; how are the results meaningful if they use a stronger model to start with?",Does the review address Comparison?,TRUE,FALSE,Raises a concern about the fairness of the comparison methodology.
So my point 5 is important to answer and I would like to see all the details are clarified in order to make the contribution stronger.,Does the review address Contribution?,TRUE,FALSE,Suggests clarifying details to strengthen the contribution of the paper.
"**Updates after rebuttal period**  The authors addressed some of the concerns -- showing inference time, model size and a discussion about training details and hyperparameters in the appendix.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Mentions added details about training, which falls under elucidation."
The paper made a significant contribution to idea of using adversarial training as part of the self-supervision signal for language learning.,Does the review address Methodology?,TRUE,FALSE,Highlights a methodological contribution to adversarial training for self-supervision.
Making these comparisons would require a heavy rewrite starting from the abstract to the analysis and so I would recommend reject right now but look forward to seeing an updated version of the paper in the future with some of these changes.,Does the review address Comparison?,TRUE,FALSE,Discusses the need for significant comparison-related revisions.
"However, the way they convert the logic forms is different for each dataset and they have to manually design rules for each logic form.",Does the review address Data/Task?,TRUE,FALSE,Highlights dataset-specific handling of logic forms.
- Major contributions of the work should be described in the main paper.,Does the review address Contribution?,TRUE,FALSE,Suggests the inclusion of major contributions in the main body of the paper.
Solid experiments demonstrating the proposed method outperforms other existing approaches.,Does the review address Result?,TRUE,FALSE,Discusses experimental results demonstrating the superiority of the method.
Human evaluation is costly and could also have bias like the paper points out.,Does the review address Evaluation?,TRUE,FALSE,"Addresses aspects of evaluation, particularly human evaluation biases and costs."
"-----Strengths----- I think the main contribution of this paper is a simple way to ""flatten"" structured information to an array of vectors (the memory), which is then connected to the tagger as additional knowledge.",Does the review address Contribution?,TRUE,FALSE,Highlights the contribution of a novel method for integrating structured information into a model.
"If there are particular differences in the above, it would nice to clearly state them and also say why the different choices and verify if the different choices are beneficial compared to the previous ones.",Does the review address Evaluation?,TRUE,FALSE,Suggests clarity in evaluation and validation of the choices made.
"Finally, a number of ablation studies are performed and demonstrate the effectiveness of the proposed method to some extent.",Does the review address Methodology?,TRUE,FALSE,Mentions ablation studies that demonstrate methodological effectiveness.
How can the authors use a pair of logic forms as negative examples (in figure-2)?,Does the review address Methodology?,TRUE,FALSE,Inquires about the methodological details involving negative examples in the study.
A key parameter that occurs in obtaining the above results is a worst-case coefficient that bounds the distributional shift between language model distributions of the training dataset and that of the downstream task.,Does the review address Data/Task?,TRUE,FALSE,Discusses data/task parameters related to distributional shifts in language models.
"In comparison, if we look at Page 17, the actual annotations from the authors are very long and detailed.",Does the review address Comparison?,TRUE,FALSE,Refers to a comparison of annotation styles or lengths.
The experiment results in Tables 1 & 2 cannot plausibly prove OTTER is more effective than CLIP.,Does the review address Experiment?,TRUE,FALSE,Questions the validity of experimental evidence in proving effectiveness.
"), yet I could not find any actual training experiments, that is training a large LLM from scratch, in the paper.",Does the review address Experiment?,TRUE,FALSE,Notes the absence of specific training experiments in the study.
"Writing:  The writing is overall clear and easy to follow, although it took me quite some time to map out the definitions of various notations.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Comments on the clarity of notations and their definitions in the paper.
"It would have been better to see the performance gains on more difficult text-classification tasks (non-GLUE), or underperforming models (non-BERT based).",Does the review address Result?,TRUE,FALSE,Suggests additional results to demonstrate performance gains on challenging tasks or models.
(4) Translation invariance : Uses a low rank decomposition of the word PMI matrix with an objective with includes bilingual alignment frequency components.,Does the review address Methodology?,TRUE,FALSE,Describes a methodological approach involving translation invariance and low-rank decomposition techniques.
"Of course, it is valuable to see the great performance achieved by single-task finetuning for RoBERTa.",Does the review address Methodology?,TRUE,FALSE,Mentions single-task finetuning as a methodological approach for achieving great performance with RoBERTa.
A closer look at evaluating the phrases in a subset of the evaluation set would be necessary to support the claims.,Does the review address Evaluation?,TRUE,FALSE,"The review directly refers to evaluating phrases in a subset of the evaluation set, highlighting the need for better assessment."
I would recommend the authors to at least assume the availability of some public data that is kept out of training and evaluations and to run all the baselines fairly in this setting.,Does the review address Evaluation?,TRUE,FALSE,The review discusses the need for fair evaluation using public data excluded from training.
"As far as I know, this is indeed the first work for handling this task using binding-unbinding mechanism.",Does the review address Novelty?,TRUE,FALSE,It highlights the novelty of the task being addressed for the first time using this mechanism.
"How would it perform if LLM is not GPT-4, but rather those open-source alternatives like Llama.",Does the review address Result?,FALSE,TRUE,"The review questions performance on alternative models, not directly mentioning results."
Using meta-learning for compositional generalization is reasonable.,Does the review address Methodology?,TRUE,FALSE,The review evaluates the methodology's reasonability for compositional generalization.
"In Figure 1, results with p ranges from 0.1 to 0.5 are shown.",Does the review address Result?,TRUE,FALSE,Specific results are mentioned in relation to figure data.
Authors also used a discriminator reward signal to cope with sparse reward (dialog success rate) and better representation of the human evaluation.,Does the review address Evaluation?,TRUE,FALSE,The review discusses evaluation in the context of a reward signal.
(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.,Does the review address Related Work?,TRUE,FALSE,It mentions comparison with prior work and improvements.
(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.,Does the review address Result?,TRUE,FALSE,The review explicitly states improved results.
It also compares different subword representation strategies and finds that syllable representations perform best (when not using BERT).,Does the review address Result?,TRUE,FALSE,Comparison of results is discussed in the context of subword representations.
"Its not that I/readers dont believe you when we are *told*, but being *shown* makes it much more interesting and give people an appreciation for Fon tokenization challenges!",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,The review suggests improving motivation through explicit demonstration.
How do the settings used in the experiments compare to those used for the analysis?,Does the review address Analysis?,TRUE,FALSE,Questions the alignment of experimental settings with analysis.
N-Bref has a number of components that it relies on to perform its decompilation.,Does the review address Methodology?,TRUE,FALSE,The methodology components are explicitly discussed.
Although it turns out that additional components need to be introduced for good performance.,Does the review address Result?,TRUE,FALSE,The review mentions performance results needing further improvement.
"The idea, at the time the paper was originally written, was indeed very novel as there were not many audio language models around back in May.",Does the review address Novelty?,TRUE,FALSE,Highlights the originality of the idea during the paper’s creation.
"To reduce the variance due to the sampling of masks, the authors propose a fully-explored masking strategy, where a text sequence is divided into a certain number of non-overlapping segments.",Does the review address Methodology?,TRUE,FALSE,Discusses a proposed methodology to reduce variance through masking strategy.
* One idea I had here: Could you define a natural task as one for which there exists a sparse linear model over the *logits* of p*( .,Does the review address Presentation?,TRUE,FALSE,Discusses the clarity and definition of terms related to task presentation.
- Perhaps adding more pre-trained LMs such as GPT-2 and different sizes of T-5.,Does the review address Methodology?,TRUE,FALSE,Suggests expanding methodology with more pre-trained models.
"5.3 L638-639: ""unions of countries"" isn't a well defined concept.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"Points out the lack of clarity in defining ""unions of countries."""
"About type dependency graph: 1) Comparing to previous work (e.g, Allamanis et.al, ICLR 18), it seems the construction of the task specific graph is the major contribution, where the novelty is a bit limited.",Does the review address Contribution?,TRUE,FALSE,Highlights the contribution related to task-specific graph construction while noting limited novelty.
"Though the paper promises faster training speeds in the introduction, Table 3 shows only modest (less than x2) speedups for training.",Does the review address Methodology?,TRUE,FALSE,Discusses the effectiveness of the methodology for training speed improvements.
- The visualization section is only a minor contribution; there isn't really any innovation or findings about what works or doesn't work here.,Does the review address Presentation?,TRUE,FALSE,Notes the lack of innovation in the visualization section's presentation.
* The paper doesn’t explain why learning a linear model directly on the context embeddings f(s) performs better than using the contextual mean embeddings.,Does the review address Methodology?,TRUE,FALSE,Questions the methodology for model learning decisions.
"Hence, it is hard to directly relate ""reducing the gap"" and ""improve the test-set performance"".",Does the review address Result?,TRUE,FALSE,Raises concerns about interpreting results related to performance improvement.
"As mentioned in the paper, the authors also used some in-house data, which I guess cannot be released to the public.",Does the review address Data/Task?,TRUE,FALSE,Mentions the use of private data in the context of datasets.
"Based on the analysis, recommendations on design of multilingual NMT architectures are proposed and their efficacy validated experimentally.",Does the review address Methodology?,TRUE,FALSE,Discusses the proposed methodology and its experimental validation.
"The paper here is only concerned with #1 and less concerned with #2, but certainly the previous work addresses #1.",Does the review address Related Work?,TRUE,FALSE,Mentions prior work addressing the concerns highlighted in the review.
There are several parts to the method and there are I assume several differences in the architecture etc with baselines etc.,Does the review address Comparison?,TRUE,FALSE,Discusses differences in methodology and architecture compared to baselines.
The hyperparameter search on \alpha in label smoothing is removed.,Does the review address Methodology?,TRUE,FALSE,Highlights a methodological decision related to hyperparameter search removal.
"- reasonable initial experimental results demonstrating some ways to help models better use cross-text-chunk dependencies (put them into a contiguous text chunk), providing some hope that these results could make models better.",Does the review address Experiment?,TRUE,FALSE,Mentions experimental results supporting cross-text-chunk dependency handling.
Is any care taken to handle this in training data?,Does the review address Methodology?,TRUE,FALSE,Asks about methodological attention to data handling.
This paper studies why language model pre-training has been such an effective technique in improving downstream performance across a wide range of NLP tasks recently.,Does the review address Methodology?,TRUE,FALSE,Explores the methodology behind language model pre-training effectiveness.
"For example, besides the quantative improvements, does the rapid convergence and under-training still exist after applying RandomMask?",Does the review address Methodology?,TRUE,FALSE,Questions the methodological impact of RandomMask on training characteristics.
weaknesses 1) Approaches are straightforward and lack originality.,Does the review address Novelty?,TRUE,FALSE,Critiques the lack of originality in the proposed approaches.
"Of course, it is valuable to see the great performance achieved by single-task finetuning for RoBERTa.",Does the review address Result?,TRUE,FALSE,Acknowledges performance improvements in single-task fine-tuning.
"- Figure 1: unclear why certain input sizes have their accuracy going down, even though they have reached 100% in the earlier epochs.",Does the review address Result?,TRUE,FALSE,Points out inconsistencies in accuracy trends presented in Figure 1.
"I think this paper can reasonably be rejected, but I'd like to give actionable of constructive criticism, since I do think the work on this low resource language is important for the NLP community.",Does the review address Significance?,TRUE,FALSE,"Highlights the importance of the work for the NLP community, especially for low-resource languages."
"The first is selecting the most uncertain examples, and the second is making the CoT annotations longer.",Does the review address Result?,TRUE,FALSE,"Mentions strategies that influence the results, such as selecting uncertain examples and modifying CoT annotations."
Did you use dynamic masking as that was previous used in RoBERTa?,Does the review address Methodology?,TRUE,FALSE,Asks about the use of dynamic masking in relation to the methodology.
"While it is hard to formally define meaningful comments, it would be insightful to at least calculate the document frequency of interleaved natural and programming language.",Does the review address Analysis?,TRUE,FALSE,Suggests an analytical approach involving document frequency calculations.
Its current form doesn’t seem to give insight on how the proposed method really helps.,Does the review address Analysis?,TRUE,FALSE,Critiques the lack of clarity in demonstrating the helpfulness of the proposed method through analysis.
"Similar numbers are true for the rest of the tasks: 60.90 vs. 87 for OBQA, 71.01 vs. 90 for PIQA, and 63.20 vs.  89.70 for aNLI.",Does the review address Result?,TRUE,FALSE,Provides numerical results comparing performance across tasks.
The experimental results mainly address similar networks with similar context lengths.,Does the review address Comparison?,TRUE,FALSE,Discusses experimental results in the context of similar networks and settings.
"Absent both kinds of keyphrases) is evaluated against baselines (which contains only ""present"" type of keyphrases).",Does the review address Evaluation?,TRUE,FALSE,Mentions the evaluation methodology involving baseline comparisons.
It is unclear for readers the details of the selection.,Does the review address Presentation?,TRUE,FALSE,Points out a lack of clarity in the presentation of selection details.
About experiments: 1) I think one ablation study I’m most interested in is to simply run GNN on the AST (or simply use Allamanis et.al’s method).,Does the review address Experiment?,TRUE,FALSE,Suggests an ablation study related to GNNs and the AST for experimental clarity.
"On the other hand, eq 7 should be the same as eq 5.",Does the review address Comparison?,TRUE,FALSE,Compares eq 7 and eq 5.
Look forward to the author discussing in following version.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions future discussion.
"While I think it's nice to analyze the connection between RM and DM, the math provided in the paper is simple, and the main contribution is just to add a baseline to the algorithm of Khalifa et al.",Does the review address Contribution?,TRUE,FALSE,Mentions the main contribution.
"- The paper also emphasizes sample efficiency, which is an essential problem in practical molecular design.",Does the review address Methodology?,TRUE,FALSE,Mentions sample efficiency.
The other baselines all use the full template-based action space (except the DRRN) of size 10^8 - a auxiliary entropy loss is used there derived from the valid actions but it is not a hard constraint.,Does the review address Comparison?,TRUE,FALSE,Discusses different baselines.
Very well written manuscript with clear non-monotonic description of details.,Does the review address Presentation?,TRUE,FALSE,Praises manuscript clarity.
"* Theorem 2 is a restatement of past work, showing that transformers lie in logspace-uniform TC^0 * Theorem 3 assumes TC^0 \neq P / poly, and then derives that transformers cannot simulate any poly-time circuit.",Does the review address Theory?,TRUE,FALSE,Mentions theoretical aspects of transformers.
Also helpful to look at [loopInvariant] and the related work mentioned there.,Does the review address Related Work?,TRUE,FALSE,References related work.
It seems like more quantitative analysis would be needed to determine how much the LM's attention is correlating empirically to factual knowledge or if there are other factors that are affecting the downstream improvements.,Does the review address Analysis?,TRUE,FALSE,Suggests need for quantitative analysis.
I think this means that some amount of claim rewriting is required in addition to the changed baselines.,Does the review address Comparison?,TRUE,FALSE,Discusses claim rewriting and baselines.
"Weaknesses, suggested improvements and requested clarifications  1.",Does the review address Result?,FALSE,TRUE,Does not mention results.
An additional ablation experiment trying different number of tokens to optimize could be illuminating (even for just 1 dataset).,Does the review address Experiment?,TRUE,FALSE,Mentions ablation experiment.
"As sort of an ensemble of expert models, the paper does not include any system-level ablation studies by comparing against other design choices.",Does the review address Ablation?,TRUE,FALSE,Mentions lack of ablation studies.
The provided experiments are more like baselines for self-evaluation other than state-of-the-art performance.,Does the review address Comparison?,TRUE,FALSE,Mentions experiments as baselines.
It would be good if the authors could provide some discussion around this observation.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests providing discussion.
"If it is the extension to multilingual embeddings, a few lines explaining the novelty would help.",Does the review address Novelty?,TRUE,FALSE,Suggests explaining novelty.
It is a bit difficult to understand the task definitions without first understanding the various constituents of the proof.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions difficulty in understanding task definitions.
"Especially because of the surprising magnitude by which this pruning degrades absolute performance, it is unfortunately necessary to try more pruning rates for a fair comparison.",Does the review address Result?,TRUE,FALSE,Mentions performance degradation.
"In Figure 1, results with p ranges from 0.1 to 0.5 are shown.",Does the review address Presentation?,TRUE,FALSE,Mentions results in Figure 1.
"- Definition of meaning seems to defeat the whole purpose of this paper, as it allows for any gibberish/random sequence of tokens to still induce a meaning and possibly a set of many other gibberish sequences to be in their equivalent class.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Discusses definition of meaning.
Implementation details are only given for the vanilla BERT Are they similar to the EarlyBERT model as well?,Does the review address Methodology?,TRUE,FALSE,Asks about implementation details.
"####Summary:  To tackle situations where compositionality is mostly required at inference time, the paper proposes a novel data augmentation method with an RNN based generator (recombination); to make the generator generate highly compositional patterns, the paper proposes a resampling method.",Does the review address Presentation?,TRUE,FALSE,Summarizes the paper’s approach.
"- In Table 1, can you explain more explicitly (in caption and text) what “subset” and “class words” means?",Does the review address Presentation?,TRUE,FALSE,Asks for more explanation in Table 1.
"What the authors can do is: you can sample some sentences from the test/development set and count how many comparative words are misused in the original model, among which how many are corrected by reranking.",Does the review address Analysis?,TRUE,FALSE,Suggests analyzing comparative words.
They have evaluated their architecture based on (i) the language modelling test evaluated on PTB and FBIS and (ii) Chinese-English machine translation task on NIST MT02-08 evaluation sets.,Does the review address Methodology?,TRUE,FALSE,Mentions evaluation of architecture.
"- The literature of DP in multi-modality is lacking, and therefore the work could be interesting  - There are several factually inappropriate usages of the notion of DP.",Does the review address Related Work?,TRUE,FALSE,Mentions related work.
I realize that PENGI's checkpoint was probably not available when this paper was submitted but it is now.,Does the review address Significance?,FALSE,TRUE,Does not mention significance.
An additional ablation experiment trying different number of tokens to optimize could be illuminating (even for just 1 dataset).,Does the review address Data/Task?,TRUE,FALSE,Mentions ablation experiment on dataset.
*  The claims regarding the 10x better data efficiency are not well supported and I would suggest the authors to compare with transformer models on standard LM benchmarks and potentially to some downstream tasks such as MT to make a stronger case.,Does the review address Methodology?,TRUE,FALSE,Suggests comparison with transformer models.
The error analysis might be better to be a bit more quantitative.,Does the review address Analysis?,TRUE,FALSE,Suggests quantitative error analysis.
- You provide the mapped ORCHID corpus in JSON format in the Supplementary Material.,Does the review address Data/Task?,TRUE,FALSE,Mentions ORCHID corpus in JSON format.
"Without the ablation studies on these two aspects, we cannot determine whether the performance improvement truly comes from the author's contribution or just longer CoT annotations.",Does the review address Ablation?,TRUE,FALSE,Mentions ablation studies.
The results on Split H are positive and they also conducted a range of ablation and error analysis.,Does the review address Result?,TRUE,FALSE,Mentions positive results on Split H.
"I really like the research question and goals of this work, as it draws an interesting connection between transformers' ability to execute instructions (posed as circuits) and existing results analyzing transformers via circuits and classical work on universal circuits.",Does the review address Methodology?,TRUE,FALSE,Mentions connection between transformers and circuits.
The simple combination of the audio model and LLM does not seem to be novel.,Does the review address Methodology?,TRUE,FALSE,Mentions combination of audio model and LLM.
"There's not much justification for it, especially given something simpler like a fixed window average could have been used.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Suggests simpler alternatives.
"_ There are some missing citations that could me mentioned in related work as : Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space Neelakantan, A., Shankar.",Does the review address Related Work?,TRUE,FALSE,Mentions missing citations in related work.
Authors could have plugged their embedding strategy in LayoutLM to understand the impact of that particular component.,Does the review address Comparison?,TRUE,FALSE,Suggests comparison in LayoutLM.
"2016 [2] A syntactic neural model for general-purpose code generation, Yin and Neubig 2017 [3] Making Neural Programming Architectures Generalize via Recursion, Cai et al. 2017  ####Authors have engaged in the discussion, clarified questions about the paper and addressed comments in its newest revision.",Does the review address Related Work?,TRUE,FALSE,Mentions discussion and comments addressed in revision.
"If not, it seems unfair to compare with PMO's best baseline REINVENT.",Does the review address Comparison?,TRUE,FALSE,Mentions comparison with baseline.
"** Again, the performance improvement may come from two aspects.",Does the review address Result?,TRUE,FALSE,Mentions performance improvement.
The authors have done further experiments and show that there are still gains on these tasks when model sized is increased significantly.,Does the review address Experiment?,TRUE,FALSE,Mentions further experiments.
A thorough proofreading could enhance the clarity of writing and word choice.,Does the review address Presentation?,TRUE,FALSE,Suggests proofreading for clarity.
"They do pre-train their model (BROS) on a large dataset with 11M documents, and then used such models to perform downstream tasks in four smaller datasets.",Does the review address Data/Task?,TRUE,FALSE,Mentions pre-training on a large dataset.
Can the proposed theory help explain some of the successes of one architecture over others?,Does the review address Methodology?,TRUE,FALSE,Asks about theory explaining success.
"Specifically, I would expect authors provide more detailed recommendation for AL, DS, and multi-domain sampling in terms of sampling techniques, and population of different sources for certain application.",Does the review address Data/Task?,TRUE,FALSE,Suggests detailed recommendations.
May I know many questions are in each data split shown in Table 5?,Does the review address Presentation?,TRUE,FALSE,Asks about data split in Table 5.
- Performance with relatively little finetuning data are encouraging.,Does the review address Data/Task?,TRUE,FALSE,Mentions finetuning data.
"However, they merely note that their data was annotated at the “relation” level rather than at the triple (relation, entity pair) level… but couldn’t Bordes et al. have done the same in their annotation?",Does the review address Related Work?,TRUE,FALSE,Mentions related work on annotation.
I see this work more as an analysis on language-specific parameters for a particular LS-model rather than a novel architecture.,Does the review address Methodology?,TRUE,FALSE,Describes as analysis on parameters.
"To me, D looks to be an important efficiency tradeoff.",Does the review address Methodology?,TRUE,FALSE,Mentions efficiency tradeoff.
(ii) a new way to aggregate multiple inputs (using M-BERT) and several different decoding methods.,Does the review address Significance?,TRUE,FALSE,Mentions aggregation of inputs.
I’m not saying these problems aren’t important – especially type recovery (I think this problem is deeply important) – but that it should go further to demonstrate more dimensions of decompilation.,Does the review address Significance?,TRUE,FALSE,Discusses importance of problems.
- The model uses two RNNs: a chain-based one and a knowledge guided one.,Does the review address Methodology?,TRUE,FALSE,Mentions use of two RNNs.
And there is no further explanation and ablation study on the design of the dynamic threshold.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions lack of explanation on dynamic threshold.
"Their goal is to reduce the amount of parameters and data needed, while improving (or maintaining) state-of-the-art performance.",Does the review address Methodology?,TRUE,FALSE,Mentions goal related to methodology.
"If that is the case, that should be made more explicit.",Does the review address Presentation?,TRUE,FALSE,Suggests explicitness.
"[5] FP8 Formats for Deep Learning, Micikevicius et al. 1- The paper is well-written and organized.",Does the review address Related Work?,TRUE,FALSE,Mentions related work.
"The experiments in the paper demonstrated the superiority of adding adversarial training to a self-supervision framework, in that significant improvements can be obtained for similar-sized networks.",Does the review address Methodology?,TRUE,FALSE,Mentions experiments and methodology.
"* In the results section there is a typo: *""performances with a large margins of 2.32pp in""*.",Does the review address Presentation?,TRUE,FALSE,Points out typo.
"In particular, using a carefully selected subset of ""prompt"" words, the authors observe that learning a linear predictor over the next word distributions of these words achieves performance close to a pre-trained GPT-2 model.",Does the review address Presentation?,TRUE,FALSE,Mentions observation on prompt words.
"* Strength     * This paper proposes an interesting idea and interpretation to connect RM and DM paradigm     * This paper proposes a variance reduction method for DPG which demonstrates its improvement on performance, stability and sample efficiency * Weakness     * From my understanding, the baseline mostly comes from the observation in 3.3, which has limited technical novelty.",Does the review address Novelty?,TRUE,FALSE,Discusses limited novelty.
"Why are the backbone models (RoBERTa and BERT, respectively) different in Table 1 and Table 2?",Does the review address Presentation?,TRUE,FALSE,Questions backbone models.
"It will be interesting to see the impact of the RNN and Copy RNN based model on automatic extraction of local or ""present"" type of key phrases.",Does the review address Significance?,TRUE,FALSE,Discusses significance of models.
"Once more baselines are included, it is very possible that the performance will be surpassed.",Does the review address Comparison?,TRUE,FALSE,Mentions baselines comparison.
The authors try to interpret the design of the neural networks using the concepts in the proposed binding-unbinding theorybut are not convincible.,Does the review address Theory?,TRUE,FALSE,Mentions theory interpretation.
It would be great if the authors discuss this or provide some supporting evidence about its correctness.,Does the review address Methodology?,TRUE,FALSE,Suggests discussing correctness.
I had to go multiple times back-and-forward in this paper to understand what was new in it.,Does the review address Presentation?,TRUE,FALSE,Mentions clarity and structure.
* The rationale behind the architectural choices for the self-attention component is not well explained or empirically verified.,Does the review address Methodology?,TRUE,FALSE,Mentions rationale behind architectural choices.
"It is not clear how this model would compare to other models using language specific parameters (sparsely gated mixture of experts (Lepikhin et al 2020), light-weight adapters (Bapna et al 2019)  ).",Does the review address Comparison?,TRUE,FALSE,Mentions comparison with other models.
"How would it perform if LLM is not GPT-4, but rather those open-source alternatives like Llama.",Does the review address Methodology?,TRUE,FALSE,Discusses performance of different models.
"Or if they are measuring the probability assigned to the true image and not just accuracy, the name shoudl be changed from accuracy.",Does the review address Presentation?,TRUE,FALSE,Mentions naming accuracy and measurement.
"The presented method chooses action primitives such as ""PickAndPlace"" but does not need much training data (apart from the examples).",Does the review address Methodology?,TRUE,FALSE,Mentions training data requirement.
Details of training and dataset are logical and delicate.,Does the review address Data/Task?,TRUE,FALSE,Mentions training and dataset details.
"Or, is the label distribution on the annotated subsets derived via vote-*k* indeed skewed for some tasks and the performance improvements are mainly coming from improvements on the labels that are well-represented?",Does the review address Result?,TRUE,FALSE,Discusses performance improvements based on label distribution.
Pros:  - A new framework for understanding why learning how to predict the next word helps the downstream task.,Does the review address Methodology?,TRUE,FALSE,Mentions new framework for predicting the next word.
"I think authors wanted to say that even though BROS does not rely on visual features, it does outperform LayoutLM which, in turn, uses visual features.",Does the review address Presentation?,TRUE,FALSE,Discusses performance comparison with visual features.
"Another problem is that there is only few qualitative results, and in both these two examples, predicted results cover the GT segments.",Does the review address Result?,TRUE,FALSE,Mentions qualitative results covering GT segments.
"The two datasets have some “toy flavor”, while SCAN great favors example combination (with recomb-2 performs much better than recomb-1), recomb-1 seem to perform better for morphological analysis dataset, leaving questions about how to choose the exact models in general.",Does the review address Data/Task?,TRUE,FALSE,Discusses performance on different datasets.
"T-LLMs are trained with huge batches, and it can be hard to pick out all the information about one example from a batch.",Does the review address Methodology?,TRUE,FALSE,Mentions training with large batches.
"FLOPS is a measure of computer performance, while arithmetic intensity is the ratio of total floating-point operations to total data movement.",Does the review address Result?,TRUE,FALSE,Explains measures of performance.
"3) The experimental results reported are validated on a single dataset, and no human evaluation and error analysis.",Does the review address Evaluation?,TRUE,FALSE,Mentions validation and lack of human evaluation.
In Proceedings of the 6th Workshop on Asian Translation (pp.,Does the review address Related Work?,TRUE,FALSE,Mentions the reference to a relevant workshop.
"As far as I know, this is indeed the first work for handling this task using binding-unbinding mechanism.",Does the review address Data/Task?,TRUE,FALSE,Mentions the task and mechanism used.
"Ablation studies on the varying parameter counts of these two components would be valuable, if possible.",Does the review address Ablation?,TRUE,FALSE,Suggests ablation studies.
"I appreciate that the authors do not read too much into it and focus more on the analysis of the results, but one thing that remains unanswered in this paper is how the proposed method fairs against multilingual baselines that utilize (roughly) the same number of parameters; currently, the best models outperform the LS baseline by ~28M and ~10M parameters on OPUS-100 and WMT-14 respectively.",Does the review address Analysis?,TRUE,FALSE,Discusses analysis of the results.
The performance is impressive and could be a better baseline for the future work.,Does the review address Result?,TRUE,FALSE,Mentions performance and baseline.
"Also, what is the meaning of the two segments of ""suppress""?",Does the review address Presentation?,TRUE,FALSE,Asks for explanation of terminology.
Is there any reason to use a static attention for all words?,Does the review address Methodology?,TRUE,FALSE,Questions the methodology used.
"The paper in general is well-written and easy to follow, the qualitative analysis and the additional diagrams in the appendix illustrating the variations in policies are appreciated.",Does the review address Presentation?,TRUE,FALSE,Mentions clarity and qualitative analysis.
"The evaluation results are based on the authors' implementations, for both baseline and the proposed method.",Does the review address Comparison?,TRUE,FALSE,Discusses comparison of evaluation results.
"The latter is typically used in two different ways in the transformer architecture, each resulting in a different computation for RF  is confusing as the RFA is now redefined.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Discusses definitions and explanations in the study.
"I think it would improve the paper if you could focus on a certain kind of invariants, and show that these invariants can in fact generalize across programs.",Does the review address Methodology?,TRUE,FALSE,Mentions methodology improvements.
"Further, [5] finetunes (and even trains from scratch) large Transformers in FP8.",Does the review address Methodology?,TRUE,FALSE,Mentions finetuning and training methodology.
"* The current analysis doesn’t apply directly to BERT, which is trained to predict masked words in a sentence, instead of the next word.",Does the review address Analysis?,TRUE,FALSE,Discusses analysis applicability.
I had to read it a couple of times before I could fully follow the method.,Does the review address Methodology?,TRUE,FALSE,Mentions difficulty in following the method.
This could be tested by ablating elements from the input or ablating the recurrent memory vectors (setting them to zero during inference).,Does the review address Ablation?,TRUE,FALSE,Suggests ablation studies.
And are the previous work using the same training set?,Does the review address Related Work?,TRUE,FALSE,Questions previous work's training set.
This paper set an assumption that the teacher network makes a less confident prediction than that of the student and extends gradient analysis in the perspective of regularization effect in the proposed adaptive label smoothing.,Does the review address Methodology?,TRUE,FALSE,Discusses assumptions and methodology.
The paper proposed a weakly-supervised wMAN model for moment localization in untrimmed videos.,Does the review address Methodology?,TRUE,FALSE,Mentions proposed model methodology.
"Other smaller suggested fixes:  * Section 5, near the end - Little grammatical mistake.",Does the review address Presentation?,TRUE,FALSE,Suggests grammatical corrections.
The paper sets out to formally characterize controllability of LLMs which is an important issue in preventing adversarial attacks on language models and preventing LLMs from producing undesirable content.,Does the review address Methodology?,TRUE,FALSE,Mentions controllability and adversarial attacks.
"The paper proposes a new joint learning algorithm that works for two tasks, NER and RE.",Does the review address Data/Task?,TRUE,FALSE,Mentions tasks for the proposed algorithm.
I doubt that InfoNCE can represent the best performance of CLIP trained on CC (3M) and WIT(5M).,Does the review address Result?,TRUE,FALSE,Questions the performance representation.
The Graph connectivity ablation states that connecting the e_int node to all entities (instead of just the input text entities) hurts performance.,Does the review address Result?,TRUE,FALSE,Discusses performance impact of graph connectivity ablation.
"- (The supplied code does not seem to include the baselines, just the recursive NN models.",Does the review address Methodology?,TRUE,FALSE,Mentions inclusion of recursive NN models in supplied code.
## Paper strengths and contributions **Motivation and intuition** The motivation for multi-turn code generation is convincing.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Mentions motivation for multi-turn code generation.
"Assuming that these are two different programs, there is no reason to assume that the contract of `calculateTime()` remains the same.",Does the review address Presentation?,TRUE,FALSE,Assumes program contract remains the same.
Other questions for the authors: (1) What is the loss in performance by fixing the word embeddings in the dependency parsing task?,Does the review address Result?,TRUE,FALSE,Questions performance loss in dependency parsing.
Do you think the conclusion would be still the same if a language-specific hyper-parameter p_l was used instead?,Does the review address Methodology?,TRUE,FALSE,Questions the use of language-specific hyper-parameter.
"Neither the proposed “Quad” loss function, nor the theoretically inspired “conditional mean features”, perform better than the baselines.",Does the review address Comparison?,TRUE,FALSE,Mentions comparison of performance with baselines.
The experimental results are promising for both settings.,Does the review address Result?,TRUE,FALSE,Mentions promising experimental results.
An ablation analysis would be most appropriate for quantifying this.,Does the review address Evaluation?,TRUE,FALSE,Suggests ablation analysis.
"The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions ablation study and validation of design components.
LOW LEVEL COMMENTS Equation 5: what's the difference between id(w) = id(w') and w = w' ?,Does the review address Presentation?,TRUE,FALSE,Asks for clarification on Equation 5.
"I know you cite the Abbott & Martinus, 2018 paper, stating that BPE is bad for analytical languages, but I still think it would prove a point to show BPE performing badly for your data.",Does the review address Result?,TRUE,FALSE,Mentions performance of BPE for analytical languages.
- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.,Does the review address Data/Task?,TRUE,FALSE,Mentions focus on computer vision datasets.
"In the experiments, the authors make comparisons with traditional methods, and show the effectiveness of their model.",Does the review address Experiment?,TRUE,FALSE,Mentions comparisons and effectiveness of the model.
"Additionally, the rationale for choosing (Ma et al., 2023) as a benchmark, along with the significance of the improvements observed, even if minute, should be clearly articulated.",Does the review address Data/Task?,TRUE,FALSE,Suggests rationale for choosing benchmark.
"The idea is similar to structured / syntax-based attention (i.e. attention over nodes from treeLSTM); related work includes Zhao et al on textual entailment, Liu et al. on natural language inference, and Eriguchi et al.",Does the review address Methodology?,TRUE,FALSE,Mentions methodology related to structured/syntax-based attention.
Section 3.4  does not describe clearly enough how attention maps were used for predicting contact maps.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions the lack of clarity in the description of how attention maps were used.
"Conventionally the ITM loss is a binary prediction task, while the particular one used in this work is more often referred as contrastive learning loss.",Does the review address Presentation?,TRUE,FALSE,Discusses the terminology used for the loss function.
- Figure 1 is helpful in comprehending the effect of different loss functions vs robustness.,Does the review address Presentation?,TRUE,FALSE,Mentions the helpfulness of Figure 1 in understanding loss functions.
"There is a lack of experimental analysis supporting the source of the observed improvements, which is crucial for substantiating the paper's main claims.",Does the review address Result?,TRUE,FALSE,Mentions the need for experimental analysis to support the observed improvements.
"Each network branch is from known structures, but the combination is not proposed before.",Does the review address Novelty?,TRUE,FALSE,Mentions the originality of the combination of known structures.
It also exhibits explainability during the generation.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Mentions the explainability of the generation process.
"More importantly, the experiments are not convincing as it is presented now.",Does the review address Experiment?,TRUE,FALSE,Mentions the unconvincing nature of the experiments.
This paper is meaningful and presents a reasonable analysis.,Does the review address Significance?,TRUE,FALSE,Mentions the significance and meaningful analysis of the paper.
(3) How much does coverage affect the score in table 2?,Does the review address Presentation?,TRUE,FALSE,Asks about the effect of coverage on the score in Table 2.
"Then, most of the paper is spent discussing preliminaries and introducing notation and definitions.",Does the review address Presentation?,TRUE,FALSE,"Mentions the focus on preliminaries, notation, and definitions."
"- For the open-ended questions, this work seems to focus mainly on solely LLMs assisted question answer generation.",Does the review address Methodology?,TRUE,FALSE,Mentions the focus on LLMs assisted question answer generation.
"Strengths:  - The paper is generally well-written, with excellent motivation and empirical setup/analysis  - The overall strategy of differentiable prompt optimized to maintain fluency is reasonable and novel.",Does the review address Presentation?,TRUE,FALSE,Mentions the well-written nature of the paper and the presentation of the strategy.
- The analysis which builds on these definitions/models/assumptions provides meaningful theoretical insight into why language model pre-training may be so beneficial for downstream training.,Does the review address Analysis?,TRUE,FALSE,Highlights the theoretical insight provided.
"In the 2nd paragraph of Section 4.1, ``For each s_k in s, we try to find a matched example (tx, ty) from D what tx contains the s_k’’: (1) There should be many sentence pairs (tx,ty) that tx contains s_k.",Does the review address Presentation?,TRUE,FALSE,Points out issues with clarity in explanation.
"2.Through a significant number of ablation experiments, this paper extensively researched the model's hyperparameter configurations and training strategies, offering highly instructive guidance for related work.",Does the review address Methodology?,TRUE,FALSE,Describes ablation and training strategies.
"There is a lack of experimental analysis supporting the source of the observed improvements, which is crucial for substantiating the paper's main claims.",Does the review address Analysis?,TRUE,FALSE,Emphasizes the need for experimental analysis.
There is a lot missing to actually justify this claim: 1.,Does the review address Result?,TRUE,FALSE,Points out missing justifications in results.
Here's how I would reconstruct the proof of Theorem 3:  *Proof.,Does the review address Theory?,TRUE,FALSE,Addresses reconstruction of proof.
"But that would also mean that the phrases are determined by token ngrams which produces a sliding window of the ""pyramid encoders"" for each sentence where there are instance where the parameter for these phrases will be set close to zero to disable the phrases and these phrases would be a good intrinsic evaluation of the pRNN in addition to evaluating it purely on perplexity and BLEU extrinsically.",Does the review address Evaluation?,TRUE,FALSE,Suggests intrinsic evaluation.
"- The proposed architecture is tested on massive experiments including language understanding tasks, optical flow, video audio class autoencoding, image classification, and starcraft II and achieves superior performance.",Does the review address Result?,TRUE,FALSE,Notes superior performance across experiments.
or adopt the exponential-moving-average (EMA) manner [3].,Does the review address Methodology?,TRUE,FALSE,Refers to the EMA approach.
I suggest authors to add discussion about the perfomance of DeFo for domain generalization.,Does the review address Methodology?,TRUE,FALSE,Recommends discussion on DeFo performance.
The second uses Gaussian blurring to encourage information sharing among neighboring words.,Does the review address Methodology?,TRUE,FALSE,Highlights the use of Gaussian blurring technique.
Perhaps there is some visual representation that could help demonstrate the comparisons you make in the text?,Does the review address Comparison?,TRUE,FALSE,Suggests visual representation for comparisons.
- General Discussion: The main focus of this paper is the introduction of a new model for learning multimodal word distributions formed from Gaussian mixtures for multiple word meanings.,Does the review address Methodology?,TRUE,FALSE,Describes the introduction of a new model for learning word distributions.
"This paper proposes a neural network architecture that represent structural linguistic knowledge in a memory network for sequence tagging tasks (in particular, slot-filling of the natural language understanding unit in conversation systems).",Does the review address Presentation?,TRUE,FALSE,Describes the proposed neural network architecture and its application.
- It seems like the optimal value of $k$ in vote-*k* would depend on the number of instances in the unlabeled set that changes with the tasks.,Does the review address Data/Task?,TRUE,FALSE,Discusses how the optimal value of $k$ depends on the number of instances and tasks.
The paper is mostly clearly written and discusses server interesting ablation experiments.,Does the review address Experiment?,TRUE,FALSE,Mentions discussion of ablation experiments.
"Did the author try other window widths, for example width `1' to extract unigram features, `3' to trigram, or use them together?",Does the review address Experiment?,TRUE,FALSE,Asks about different window widths for feature extraction.
2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues.,Does the review address Ablation?,TRUE,FALSE,Suggests adding subjective evaluations to ablation experiments.
"Theoretically, they showed that synchronized updates to the low-level and high-level policy may never converge, yet asynchronized updates guarantees convergence.",Does the review address Contribution?,TRUE,FALSE,Highlights the theoretical contribution of synchronized vs. asynchronized updates.
We have no empirical demonstration that this approach will work on other datasets outside of LeetCode.,Does the review address Data/Task?,TRUE,FALSE,Points out lack of empirical demonstration on other datasets.
"Questions:   - Previous work has tried to combine both language-specific and shared parameters (Wang et al 2018), rather than making a binary choice between these.",Does the review address Related Work?,TRUE,FALSE,References previous work on combining language-specific and shared parameters.
"This is relevant because, by training end to end, that work effectively generates arbitrary amounts of training data through interaction the the HOL4 ITP system (intermediate theorems which are proven give some reward in that work).",Does the review address Data/Task?,TRUE,FALSE,Discusses generation of training data through interaction with the HOL4 ITP system.
The authors first qualitatively and quantitatively analyze the cold-start problem.,Does the review address Analysis?,TRUE,FALSE,Addresses both qualitative and quantitative analysis.
"- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other ""oracle"" baselines.",Does the review address Methodology?,TRUE,FALSE,Discusses evaluation with datasets and comparisons.
The result presented in Table 4 don't match the description in Section 4.3:  - It's not true that the pRNN outperforms both PBSMT and Enc-Dec model.,Does the review address Result?,TRUE,FALSE,Points out inconsistency in the results.
"Given that one of the primary goals of this paper was to create embeddings that perform well under the word translation metric (intra-language), it is disappointing that the method that performs best (by far) is the invariance approach.",Does the review address Evaluation?,TRUE,FALSE,Comments on the evaluation of methods.
"A similar analysis here could greatly demystify why these sets of examples cause instability, and whether they are indeed “informative”.",Does the review address Analysis?,TRUE,FALSE,Suggests conducting a similar analysis.
(4) The dictionary extraction approach (from parallel corpora via alignments or from google translate) may not reflect the challenges of using real lexicons.,Does the review address Methodology?,TRUE,FALSE,Critiques the methodology for dictionary extraction.
"Presentation: - The ""Crime Suppression Division"" example would be clearer if you showed it graphically in a figure.",Does the review address Presentation?,TRUE,FALSE,Suggests graphical representation for clarity.
The idea is straightforward and the motivation is clear.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Praises the clarity of motivation.
The proposed beam enumeration significantly outperforms REINVENT (the strongest baseline in the existing benchmark).,Does the review address Comparison?,TRUE,FALSE,Highlights comparison with REINVENT baseline.
"I would recommend to put the citation around it (Andreas, 2000) although previously cited.",Does the review address Related Work?,TRUE,FALSE,Suggests adding a citation.
"Good set of ablation studies to show that each component of the model is necessary, especially because the entire model already has many moving parts in addition to adversarial training.",Does the review address Methodology?,TRUE,FALSE,Praises the inclusion of ablation studies.
"You are clearly not trying to infer any loop invariants, and it would help clarify that upfront.",Does the review address Result?,TRUE,FALSE,Clarifies the focus of the study.
"In Empirical Methods in Natural Language Processing (EMNLP), 2019.",Does the review address Related Work?,TRUE,FALSE,Cites EMNLP 2019 work.
3) This paper shows visualization of the interaction between words and latent topics in the embedding space.,Does the review address Presentation?,TRUE,FALSE,Visual interaction discussed.
"Furthermore, the authors deliberately avoid settings where DP is known to be hard due to the relatively low amount of training data per class (e.g. CIFAR-100/ImageNet).",Does the review address Data/Task?,TRUE,FALSE,Discusses avoided task settings.
"Summary: This paper presents a method of incorporating prior knowledge into MCTS via language, using interactive fiction games as a test bed.",Does the review address Methodology?,TRUE,FALSE,Method utilizes prior knowledge.
Some discussion on the current design choices and why making the proposed methods features to some of the other baselines is not a way to achieve some benefits is not the right way to do it.,Does the review address Methodology?,TRUE,FALSE,Questions design and baseline use.
Novel weighting scheme for SVD for low-rank weight compression (though should double check this more thoroughly).,Does the review address Novelty?,TRUE,FALSE,Mentions novelty in SVD weighting.
"In the presence of definitive results, this might be acceptable, but in its absence, as in this paper, there needs to be quantitative analysis across multiple runs to demonstrate the robustness of the phenomenon.",Does the review address Result?,TRUE,FALSE,Highlights need for robust results.
"Experiments on type predictions for TypeScript have shown better performance than the previous methods, with or without user specified types.",Does the review address Result?,TRUE,FALSE,Demonstrates performance improvement.
"However, in its current state - the comparisons made are not meaningful which makes the claim of state of the art tenuous (state of the art does not matter so much as showing that you make progress in line with the motivation).",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Critiques state-of-the-art claim validity.
The authors present a simple technique for in-context learning with large language models that achieves consistently good results across a variety of NLP tasks.,Does the review address Methodology?,TRUE,FALSE,Describes effective methodology.
**Strengths** - The paper is generally quite clearly written and the claims are well-validated.,Does the review address Presentation?,TRUE,FALSE,Writing and claims validation noted.
"I look forward to the author's discussion of the additional learnable parameters introduced in addition to CLIP's pre-trained model, and compare the number with other methods.",Does the review address Methodology?,TRUE,FALSE,Focuses on parameter comparison.
"The authors first identify redundant structures early during training, then prune these structures, which leads to faster training.",Does the review address Methodology?,TRUE,FALSE,Discusses structure pruning method.
"I think just including two sentences that have some of these features, and that gets the point accross of ""how would we tokenize this?""",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Suggests illustrative tokenization.
"The experments are fairly convincing, although it is not entirely surprising that this approach works, and to repeat, the basic idea of extracting additional training data in this way is not entirely new.",Does the review address Methodology?,TRUE,FALSE,Reiterates known methodological idea.
"In the experiments, it is not reported that the learning rate or the mini-batch size is well tuned for the baseline.",Does the review address Experiment?,TRUE,FALSE,Highlights missing experimental tuning.
"In the conclusion, the paper mentions comparison with Multi-Scale approaches, but that is not present in the experiments.",Does the review address Comparison?,TRUE,FALSE,Comparison noted but not executed.
"It may be useful to show how the performance changes when using different M. - According to [2], the CommonsenseQA IH-dev set contains 1,221 questions in total.",Does the review address Methodology?,TRUE,FALSE,Discusses methodological variations.
Suggested additions: * I think more specific linguistic details about Fon are missing.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Missing linguistic details mentioned.
"The main limitations seem to be: (1) the proposed method is a bit limited in that it can only be used with a corpus in which the target head, relation, and tail spans need to be directly mentioned in a single sentence (2) it’s not clear whether the quantitative improvements are due to factual knowledge in the pretrained model or the syntactic/semantic relationships encoded in the self-attention.",Does the review address Result?,TRUE,FALSE,Notes specific result limitations.
"**Please put the verbose caption description in the main text for Figure 3, 4, 5 and Table 4** Spacing in between some of the equations can also be reduced (e.g. in latex use \vspace{-5mm} )",Does the review address Presentation?,TRUE,FALSE,Presentation improvements suggested.
_ A question to the authors: What do you attribute the loss of performance of w2gm against w2g in the analysis of SWCS?,Does the review address Result?,TRUE,FALSE,Asks about the loss of performance.
"It'll be good to have some ablation study of the combined effect of using only one data sample in a mini-batch, and the full-explored masking.",Does the review address Data/Task?,TRUE,FALSE,Suggests an ablation study involving data samples and masking.
"In addition, the notation in (6) looks wrong to me.",Does the review address Presentation?,TRUE,FALSE,Points out an error in notation.
"Or if they are measuring the probability assigned to the true image and not just accuracy, the name shoudl be changed from accuracy.",Does the review address Result?,TRUE,FALSE,Questions the terminology used for accuracy.
The larger dataset may relate to more many-to-many relationships when training the model.,Does the review address Data/Task?,TRUE,FALSE,Discusses the implications of a larger dataset.
The empirical analysis section answers several interesting questions.,Does the review address Analysis?,TRUE,FALSE,Highlights the empirical analysis section.
"The fact that I flustered a bit with my understanding here, was confused, and had to spend a few minutes thinking about it, means it needs a bit of tweaking.",Does the review address Presentation?,TRUE,FALSE,Suggests the need for clearer presentation.
"To this end, language-specific behaviour is achieved via a combination of conditional computation to decide whether to use language-specific parameters or not and statically assigning experts for each languages.",Does the review address Presentation?,TRUE,FALSE,Explains the approach to language-specific behavior.
"However, there is no theoretical result about the effectiveness of assigning the self-knowledge distillation to label smoothing.",Does the review address Theory?,TRUE,FALSE,Points out the lack of theoretical results.
I would shorten it and move interesting results from the Appendix to the main paper.,Does the review address Related Work?,TRUE,FALSE,Suggests restructuring related work.
"The comparison of some other important baseline is missing, such as Tip-adapter [1] and CoCoOp [2].",Does the review address Comparison?,TRUE,FALSE,Notes missing baseline comparisons.
It becomes difficult to fathom if the gains are actually due to good objective function or a case of chance for choosing better examples.,Does the review address Result?,TRUE,FALSE,Questions the validity of result gains.
Another limitation is that it is unclear whether the improvement would hold when the size of the model increases; the evaluation is dealing with scaling laws after all.,Does the review address Result?,TRUE,FALSE,Discusses the scalability of the results.
The authors clearly present their ideas and describe the technical details.,Does the review address Presentation?,TRUE,FALSE,Praises the clarity of presentation.
"Despite very encouraging results, several important methodological questions about the source of the efficiency gains and other aspects of the paper are left unanswered.",Does the review address Methodology?,TRUE,FALSE,Raises concerns about methodology.
"However, I feel that experiments can be strengthened, and notations can be improved.",Does the review address Experiment?,TRUE,FALSE,Highlights experiment improvement.
"- I know GPT3 access is hard to get, but I wish experiments with k=8 prompts could be compared against  Post rebuttal: I think another pass for clarity over the paper would be good for the final version, but otherwise I'm happy with the paper updates and I'm happy to see the ablation numbers aren't too sensitive to token count.",Does the review address Ablation?,TRUE,FALSE,Discusses ablation experiments.
"Compared to Pengi, the closed-ended audio task performances are lower.",Does the review address Comparison?,TRUE,FALSE,Provides performance comparison.
"In the second phase (match), they ground facts to a knowledge graph schema by using combinations of entity linking and relation matching techniques from previous work.",Does the review address Methodology?,TRUE,FALSE,Details schema grounding method.
"However, \alpha could also be changed in the training process.",Does the review address Methodology?,TRUE,FALSE,Discusses parameter adjustment.
The proposed RoBERTa achieves/matches state-of-the-art performance on many standard NLU downstream tasks.,Does the review address Data/Task?,TRUE,FALSE,Notes task-related performance.
"Questions: - According to the parameters presented in Table 8, the knowledge from LM and GNN are only fused at the last 5 layers (parameter M) when 24-layer LMs are used, and at the last 3 layers when 12-layer LMs are used.",Does the review address Methodology?,TRUE,FALSE,Examines layer-based methodology.
(2) The use of super-sense annotations across multiple languages is a problem.,Does the review address Data/Task?,TRUE,FALSE,Highlights issue with task annotations.
It is not clear to me why we cannot use HDSA+R or LARL + NLG + language model reward.,Does the review address Methodology?,TRUE,FALSE,Questions use of alternative methods.
"To really become a benchmark to measure the progress of LFLL, more tasks/datasets will be needed.",Does the review address Data/Task?,TRUE,FALSE,Recommends additional benchmarking.
Ablations show the necessity of applying a 2-step intermediate training scheme with mixed training followed by joint training.,Does the review address Ablation?,TRUE,FALSE,Describes ablation findings.
"For example, a lot of BERT-style models exploit dense interactions.",Does the review address Methodology?,TRUE,FALSE,Discusses dense interactions in methodology.
"Please don't abuse figure/table captions, whenever possible, please try to keep the description of the tables and figures in-text.",Does the review address Presentation?,TRUE,FALSE,Recommends better captioning practices.
It would helpful to place it more clearly where the contribution of the paper lies in the related work.,Does the review address Related Work?,TRUE,FALSE,Encourages situating contributions in context.
"The same work, with a more carefully written paper, could be really great.",Does the review address Presentation?,TRUE,FALSE,Critiques clarity and writing quality.
The research shows how low-level proof artifact data may be used to significantly boost performance on high-level theorem proving by co-training auxiliary tasks.,Does the review address Data/Task?,TRUE,FALSE,Highlights data use in auxiliary tasks.
It’s not easy to follow what the authors try to convey quickly at first glance.,Does the review address Presentation?,TRUE,FALSE,Notes lack of clarity in communication.
Will the attention model pays more attention to this similar sample resulting in a negative impact on the target task performance since the source task and target task are quite different?,Does the review address Methodology?,TRUE,FALSE,Questions methodology in attention models.
"Prior work has explored ""learning-to-share""  strategies for parameter sharing in multi-task learning (see Ruder et al., AAAI 2018), and using gating/masking to control computational paths in a differentiable way (see Fan et al., ICLR 2019, Sukhbaatar et al., ACL 2019); it is clear that the focus is NMT but it should be worth mentioning/discussing such studies to better situate the work and to help the reader assess the actual contributions.",Does the review address Contribution?,TRUE,FALSE,Recommends framing contributions in context.
"Strengths:  - The paper is generally well-written, with excellent motivation and empirical setup/analysis  - The overall strategy of differentiable prompt optimized to maintain fluency is reasonable and novel.",Does the review address Novelty?,TRUE,FALSE,Highlights novel aspects of the approach.
"However, there are still major gaps between the theoretical analysis, the conclusion and the empirical solution (please see the detailed comments).",Does the review address Analysis?,TRUE,FALSE,Notes inconsistencies in analysis and findings.
"We expect that the model can not only achieve good performance on a single dataset, but also have the potential to transfer beyond a single dataset.",Does the review address Result?,TRUE,FALSE,Discusses expected model performance.
"That raises the question -- Gerrish and O'Connor both conduct evaluations with an external database of country relations developed in political science (""MID"", military interstate disputes).",Does the review address Data/Task?,TRUE,FALSE,Mentions use of external datasets for evaluation.
"- Strengths: This paper has high originality, proposing a fundamentally different way of predicting words from a vocabulary that is more efficient than a softmax layer and has comparable performance on NMT.",Does the review address Result?,TRUE,FALSE,Highlights efficiency and performance outcomes.
"Instead, they turn to rely on the abundant textual and behavioral information of the existing reviewer to augment the information of a new user.",Does the review address Methodology?,TRUE,FALSE,Describes methodology leveraging user data.
This would be much more useful for other researchers as it is the file format used by UD.,Does the review address Data/Task?,TRUE,FALSE,Advocates for data compatibility and sharing.
"The selected student networks, VL-BERT, UNITER, VILLA, while they are great and highly reputable works in the community, their performance is not as competitive as for today.",Does the review address Presentation?,TRUE,FALSE,Critiques competitiveness in presentation.
How many include simple string operations and/or other simple method calls as implied by Table 2?,Does the review address Presentation?,TRUE,FALSE,Seeks clarity on presentation of results.
"Overview: This paper discusses the problems of common tokenization strategies for low resource african languages, and proposes a new tokenization method to overcome these problems.",Does the review address Methodology?,TRUE,FALSE,Addresses proposed methodology improvements.
"The techniques used in the paper (multi-branch transformer, pointing mechanism, cross-modal attention, global positional encodings, etc) have been shown to work in the past for image-text tasks [1, 2].",Does the review address Data/Task?,TRUE,FALSE,Highlights reliance on proven techniques.
Contributions of the paper don't seen particularly novel.,Does the review address Contribution?,TRUE,FALSE,Comments on lack of novelty in contributions.
"Overall, I like the idea of the paper: it is important to reduce the parameters needed for sets of tasks, to enable NLP models to be deployed in a larger variety of settings, and reducing the amount of data needed.",Does the review address Significance?,TRUE,FALSE,Notes significance in broader applicability.
"If so, does the global node $V_g$ connect to all the sub fact nodes?",Does the review address Methodology?,TRUE,FALSE,Questions methodological implementation details.
"I agree with all of your points about what is lacking, but in my mind, the novelty was enough to still give a 7.",Does the review address Novelty?,TRUE,FALSE,Considers the novelty aspect positively.
- The data preprocessing and training steps are complex.,Does the review address Data/Task?,TRUE,FALSE,Mentions complexity in data-related processes.
"The paper shows the reasonable claim that it is necessary to gradually train the model from close-ended datasets to open-ended ones because if the open-ended dataset is trained first, the model is heavily dependent on language capability so it is hard to train the audio representation.",Does the review address Methodology?,TRUE,FALSE,Discusses training methodology for model development.
- Slight improvements over CaP via the different prompting method.,Does the review address Result?,TRUE,FALSE,Highlights performance improvements with a new method.
"Regarding preposition phrases as a proxy for complexity: since the hypothesis is that the more the number of prepositional phrases in a question, the harder it is to answer.",Does the review address Methodology?,TRUE,FALSE,Describes methodology using linguistic proxies.
it's very clearly presented -- I like cross-referencing the models with the diagrams in Table 2.,Does the review address Presentation?,TRUE,FALSE,Appreciates clarity and referencing in presentation.
"Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.",Does the review address Methodology?,TRUE,FALSE,Discusses methodology for improving task performance.
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.,Does the review address Methodology?,TRUE,FALSE,Mentions evaluation methodology for proposed model.
"The studies here show that, pre-training with Inverse Cloze Task (ICT) the two-tower Transformer models significantly outperform the widely used BM-25 algorithm for large-scale information retrieval.",Does the review address Data/Task?,TRUE,FALSE,Highlights data task focus on information retrieval.
"The paper only performs some finetuning on GLUE tasks, which is significantly less interesting given that it is comparatively cheap and FP8 speedups thus not so crucial while, in many cases, even more affordable finetuning techniques like QLoRA also work well.",Does the review address Data/Task?,TRUE,FALSE,Discusses data tasks in the context of model finetuning.
It is a bit hard to identify the interestingness or novelty in the approach.,Does the review address Methodology?,TRUE,FALSE,Critiques the methodology's lack of distinctiveness.
"Page 5, Equations (6, 7, 8): should e^{l}_{s} and e^{l}_{j} be e^{(l-1)}_{s} and e^{(l-1)}_{j} respectively ?",Does the review address Presentation?,TRUE,FALSE,Identifies presentation issue in equation notation.
* Ablation: the model vs corpus transfer comparison seems unfair to me.,Does the review address Comparison?,TRUE,FALSE,Points out comparison between model and corpus transfer.
"For instance: Roee Aharoni, Melvin Johnson, and Orhan Firat.",Does the review address Related Work?,TRUE,FALSE,References related work by specific authors.
"After reading other reviews and the authors’ responses to all of the reviewers, I recommend this paper by accepted—extensive results show that the CALM objectives offer more signal from data than current pretraining methods.",Does the review address Result?,TRUE,FALSE,Highlights the results showing the effectiveness of CALM.
"As such, in my opinion this is unquestionably an important subtopic for the field of machine programming and the authors approach also seems satisfactory to me for ICLR (described below).",Does the review address Presentation?,TRUE,FALSE,Expresses satisfaction with the approach and presentation.
This is very promising to simplify the construction of highly tuned task-specific neural pipelines and improve the multimodal and multi-task problems.,Does the review address Data/Task?,TRUE,FALSE,Discusses task-specific pipelines and their impact on data usage.
"It is hard to tell what are the standalone contributions of the paper, and what is coming from other works.",Does the review address Novelty?,TRUE,FALSE,Questions the originality and uniqueness of the contributions.
"The authors say ""the axes in the plots are the number of training steps finished.""",Does the review address Presentation?,TRUE,FALSE,Refers to clarity in the labeling of plots.
"The input would be the source sentence with its appropriate tokenization, no?",Does the review address Presentation?,FALSE,TRUE,This query does not directly relate to the clarity or structure of the paper.
- The evaluation on PTB (table 2) isn't a fair one since the model was trained on a larger corpus (FBIS) and then tested on PTB.,Does the review address Methodology?,TRUE,FALSE,Highlights fairness concerns in the evaluation process.
I think significant presentation changes are required to clarify that the paper focuses on inference and finetuning.,Does the review address Methodology?,TRUE,FALSE,Suggests improvements in the explanation of the methodology.
"Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.",Does the review address Result?,TRUE,FALSE,Validates the effectiveness of the proposed tuning approach.
I would like the authors to have a more extended discussion of how SCS can be used outside of their work.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests further elaboration on the broader applicability of SCS.
The methods is evaluated on 5 standard NER+RE datasets with good performances.,Does the review address Evaluation?,TRUE,FALSE,Clearly discusses evaluation metrics and results.
"The paper is clear and detailed, and well situated in the literature.",Does the review address Related Work?,TRUE,FALSE,Highlights strong connection with existing literature.
"How does the method work if the candidate with the highest score is always picked: in the end, this is what the model is supposed to learn, correct?",Does the review address Methodology?,TRUE,FALSE,Questions a specific aspect of the method's design.
Nit: I would have tried to move the (datasets per cluster/templates per dataset) ablation to the main body as well and shortened Section 3  - The 4.2 (scaling laws) ablation is perhaps the most interesting of all.,Does the review address Data/Task?,TRUE,FALSE,Proposes changes to data-related analysis.
"Furthermore, the authors are neglecting parameter efficient fine-tuning baselines, for instance like [1].",Does the review address Methodology?,TRUE,FALSE,Notes omission of methodological comparisons.
It is not clear how the proposed method considers the correlations among the retrieved data points.,Does the review address Data/Task?,TRUE,FALSE,Discusses missing considerations related to data.
I can not understand why sample-specific rather than task-specific preference is important for prompt tuning.,Does the review address Data/Task?,TRUE,FALSE,Questions justification for data choices.
"If the authors would like to compare the number of additional parameters of DeFo with CoOp and CLIP-adapter, I think it may be very helpful for us to comprehensively evaluate and compare these methods.",Does the review address Comparison?,TRUE,FALSE,Suggests further comparisons for clarity.
"Finally, the CALM intermediate objectives share many properties with all of the datasets tested on and are likely calibrating the model to the kind of correlations they should expect to predict in advance of finetuning.",Does the review address Data/Task?,TRUE,FALSE,Explains data alignment with intermediate objectives.
* I suggest using the same x-axis scale on the two charts in Figure 3 to avoid confusion about the magnitudes of the differences.,Does the review address Presentation?,TRUE,FALSE,Recommends improving figure presentation for clarity.
- The number of tasks and domains is minimal setting.,Does the review address Data/Task?,TRUE,FALSE,Critiques insufficient task/domain variety.
"- unconstrained, multi-concept:     This needs a direct comparison to a traditional discrete-channel referential game.",Does the review address Comparison?,TRUE,FALSE,Proposes missing comparative analysis.
"For example, the sentiment lexicon is not explained for the SVM.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out a lack of detail in an explanation.
"Granted, the final effect of MTL depends on task similarities, but that's probably the same for the proposed approach.",Does the review address Methodology?,TRUE,FALSE,Links methodology to MTL similarities.
The paper features extensive experiments that convincingly validate the effectiveness of the proposed method.,Does the review address Experiment?,TRUE,FALSE,Highlights thorough experimental validation.
- The captions are too small to read in Figure 2 & 3.,Does the review address Presentation?,TRUE,FALSE,Notes issues with figure caption readability.
"## ""General Learner"": Missing Formal Definition and Misleading Name  The ""general learner"" concept used in the title and throughout is named in a somewhat misleading way, as the results here have to do more with *expressive power* than learning.",Does the review address Presentation?,TRUE,FALSE,Critiques clarity and accuracy in presentation.
"Existing methods for contact prediction (beyond Gremlin), however, are not described sufficiently.",Does the review address Methodology?,TRUE,FALSE,Points out insufficient methodological details.
It might be better to give out the trend of training loss and validation loss.,Does the review address Methodology?,TRUE,FALSE,Proposes additional method-related visualizations.
"Although I understand the experiment setup, missing reference to more recent VL works prevent readers from getting a good research landscape in the multimodal pre-training.",Does the review address Related Work?,TRUE,FALSE,Highlights gaps in related work discussion.
"- Without this ablation study, the contributions of this paper are to show that using BERT representations as input (1) leads to better performances for NER+RE  and (2) makes the model faster to train.",Does the review address Contribution?,TRUE,FALSE,Highlights contribution demonstrated by ablation study.
"Once more baselines are included, it is very possible that the performance will be surpassed.",Does the review address Result?,TRUE,FALSE,Suggests additional baselines could alter performance outcomes.
"- Consider HellaSwag/PiQA/etc, where FLAN underperformed few-shot and even zero-shot.",Does the review address Result?,TRUE,FALSE,Mentions specific results from evaluation.
Comments below are ranked by decreasing importance.,Does the review address Significance?,TRUE,FALSE,Notes prioritization based on significance.
"Also, please show the performance trends based on different augmentation sizes.",Does the review address Result?,TRUE,FALSE,Proposes exploring performance across augmentation variations.
"Comparing the proposed method to earlier approaches such as PaLI, CoCa, and Flamingo may not be entirely fair.",Does the review address Methodology?,TRUE,FALSE,Critiques fairness in method comparisons.
"However, the dataset with 400M may contain too many many-to-many relationships like 7 or 8 (maybe more, the data scale is about 100 times the used datasets in this paper).",Does the review address Data/Task?,TRUE,FALSE,Highlights concerns about dataset complexity.
"Strengths: - Thorough theoretical analysis that reveals the connection between (practically-necessary) small learning rates and inability to use dependencies across text chunks - Useful framing and discussion of the ""in-context bias"", where models are more likely to learn dependencies within text chunks seen during pre-training.",Does the review address Theory?,TRUE,FALSE,Discusses theoretical insights on learning dependencies.
"As pointed out by the authors in section 3.3.1 ""TRIGGER IN 'INPUT' KEY,"" decorations can utilize specific keywords or phrases that are rare in regular instructions.",Does the review address Methodology?,TRUE,FALSE,Refers to specific methodological features.
"Elaboration on Theorem 1, with an intuitive breakdown of its implications, would significantly enhance the readability and credibility of the results.",Does the review address Theory?,TRUE,FALSE,Suggests improving explanation of theoretical results.
"For one, it would require doing some experiments with trained LMs and finding evidence of memorization.",Does the review address Experiment?,TRUE,FALSE,Proposes experiments for additional evidence.
"Since the architecture (ignoring the compression) is similar to multi-scale approaches, it would be good to compare against empirically.",Does the review address Methodology?,TRUE,FALSE,Suggests comparative analysis with similar methods.
"- Excellent clarity and presentation of ideas  ## Weaknesses - The experiments provided do not analyze the unique characteristics of the environment introduced; instead, the experiments are similar to the typical gamut for a discrete symbol-based referential game.",Does the review address Experiment?,TRUE,FALSE,Critiques the lack of environment-specific experiments.
The curriculum training is yet another aspect that makes this effort worthy as it shows that a brute force approach to just wrap in all possible audio-text paired data may not be as good overall.,Does the review address Significance?,TRUE,FALSE,Discusses the significance of curriculum training.
"The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",Does the review address Theory?,TRUE,FALSE,Highlights reliance on theoretical assumptions.
This paper focuses on improving the dialogue policy together with the responses by utilizing a pre-trained language model and offline RL.,Does the review address Methodology?,TRUE,FALSE,Refers to methodological focus on dialogue policy.
Experimental results show improvements over both the base T5 model and the large T5 model.,Does the review address Result?,TRUE,FALSE,Highlights improvements in experimental results.
The applicability and the novelty of the SCS representation seem limited.,Does the review address Novelty?,TRUE,FALSE,Highlights limitations in originality of SCS representation.
"Additionally, there's some limitations to the way the language model is being leveraged and the types of knowledge it can extract.",Does the review address Methodology?,TRUE,FALSE,Critiques the method's implementation.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Theory?,TRUE,FALSE,Links empirical results to theoretical assumptions.
"It is not the case that I find the experimental results inadequate, rather, the experiments run in the first place are generic and do not illustrate the points of interest with a continuous-channel referential game.",Does the review address Experiment?,TRUE,FALSE,Critiques the design and relevance of experiments.
The fact that the previous study reported a 126 perplexity baseline using LSTM and the LSTM's perplexity of 106.9 provided by the author showed that the FBIS gives an advantage to computing the language model's perplexity when tested on PTB.,Does the review address Evaluation?,TRUE,FALSE,Discusses evaluation of model performance.
The system performs on par with recently proposed GECA for SCAN and favorably to GECA on morphological analysis.,Does the review address Analysis?,TRUE,FALSE,Refers to performance analysis and comparison.
I would recommend the authors to at least assume the availability of some public data that is kept out of training and evaluations and to run all the baselines fairly in this setting.,Does the review address Data/Task?,TRUE,FALSE,Proposes improvements to task-related fairness.
"Furthermore, an explicit definition of the feature matrix X of the nodes would help in understanding how these features interact with the quantum-inspired positional encodings.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Recommends detailed clarification of feature matrix.
"There is no comparison provided with any baseline for 2/5 tasks (Language grounding, Tappability) 5.",Does the review address Comparison?,TRUE,FALSE,Notes missing baseline comparisons.
Strengths:   - Combining lifelong and few-shot learning is a new setting.,Does the review address Novelty?,TRUE,FALSE,Highlights the innovative combination of settings.
"Moreover, the authors better answer questions in 2 so I can gauge if their hyper-parameters were chosen in the principled ways.",Does the review address Presentation?,TRUE,FALSE,Suggests clarity in presenting hyperparameter choices.
"As pointed by one public comment, the ablation study should show how much improvement is from BERT vectors.",Does the review address Ablation?,TRUE,FALSE,Proposes a focus on specific ablation outcomes.
"While I understand this is contemporaneous work, but since the work is so relevant to this paper and seems to directly contradict the premise of this paper, it might be good to have a short discussion on this (just a suggestion).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Recommends addressing contradictions in related work.
"The experiments in the paper demonstrated the superiority of adding adversarial training to a self-supervision framework, in that significant improvements can be obtained for similar-sized networks.",Does the review address Experiment?,TRUE,FALSE,Highlights experimental validation of the proposed method.
"The paper appraisal therefore rests on the clarity of presentation, how convincing the experiments are, and how reproducible.",Does the review address Presentation?,TRUE,FALSE,Mentions evaluation criteria related to presentation.
"Put in another way, using RFA in transformer is from Rawat et al., 19 so do you think your major contribution is to design such  a gated usage of RFA?",Does the review address Contribution?,TRUE,FALSE,Questions the originality of the claimed contribution.
"Therefore, the dynamic \alpha by hyperparameter searching should also be added as a base.",Does the review address Methodology?,TRUE,FALSE,Suggests improving the methodological framework.
Keyphrase extraction using deep recurrent neural networks on Twitter.,Does the review address Related Work?,TRUE,FALSE,Refers to related work in the domain.
"However, the designed specific neural network does not support the claimed binding-unbinding theory very well.",Does the review address Theory?,TRUE,FALSE,Critiques the theoretical support of the method.
"For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.",Does the review address Comparison?,TRUE,FALSE,Discusses comparative performance across metrics.
The idea that combining the output of several models using the attention strategy is not novel in deep learning.,Does the review address Methodology?,TRUE,FALSE,Critiques the lack of novelty in methodology.
- The experimental results are thorough and solid.,Does the review address Experiment?,TRUE,FALSE,Praises the robustness of the experiments.
"Therefore, it's not ideal that the uncertainty sampling algorithm has been moved to the appendix.",Does the review address Methodology?,TRUE,FALSE,Critiques presentation of methodological details.
One of the important motivations of multi-modal multi-task learning mentioned was to achieve better or on-par performance with a single model (and supposedly fewer computations) which is crucial for devices with limited computing resources.,Does the review address Result?,TRUE,FALSE,Notes performance goals and outcomes.
"However, I am unable to grasp nuances, leaving important questions untouched such as: In what scenarios do we expect the model to perform better than GECA?",Does the review address Result?,TRUE,FALSE,Questions specific conditions for performance improvements.
"**Major concern** If I understand correctly (and please correct me if I am wrong), in Theorem B.1, the ratio between the downstream error $\ell_\mathcal{T}(\\{p_{\cdot\mid s}\\}) - \tau$ and the pre-training error $\ell_\text{xent}(\\{p_{\cdot\mid s}\\})-\ell_\text{xent}^\ast$ is _hidden_ in the $\gamma(p_{\mathcal{T}}; \\{p_{\cdot\mid s}\\})$ coefficient.",Does the review address Theory?,TRUE,FALSE,discusses Theorem B.1 and the theoretical relationship between downstream and pre-training errors.
"While this paper provides extensive empirical results and quantitively demonstrates the effectiveness of RandomMask, there are several areas where it could be further enhanced.",Does the review address Result?,TRUE,FALSE,Highlights the empirical results of RandomMask.
"In the conclusion, the paper mentions comparison with Multi-Scale approaches, but that is not present in the experiments.",Does the review address Experiment?,TRUE,FALSE,Notes the absence of a specific comparison in experiments.
"The in-depth experimental analysis of the BERT pretraining process in this paper answers many open questions (e.g., the usefulness of NSP objective) and also provide some guidance in how to effectively tweak the performance of pretrained model (e.g., large batch size).",Does the review address Experiment?,TRUE,FALSE,Discusses detailed experimental analysis.
"(4) In general, the results in table 3 do not tell a consistent story.",Does the review address Result?,TRUE,FALSE,Comments on the inconsistency in results.
"## Paper weaknesses and questions  **Code comment analysis**  Some programmers like to write comments, while some are not.",Does the review address Analysis?,TRUE,FALSE,Mentions the analysis of code comments.
"Mainly, for most of the intrinsic metrics, the multilingual embedding techniques do not seem to perform the best.",Does the review address Evaluation?,TRUE,FALSE,Evaluates multilingual embedding techniques.
"- If not, please remove the attention layer after the encoder in figure 5.",Does the review address Methodology?,TRUE,FALSE,Suggests changes to the method's design.
"Do we need better model design, or more data and computations?",Does the review address Methodology?,TRUE,FALSE,Questions model design and resource needs.
What is the result if we directly learn to match input and logic forms?,Does the review address Methodology?,TRUE,FALSE,Refers to a specific methodological question.
"Furthermore, when there is a gap between the empirical results and the theoretical results (e.g., validation of Lemma 4.3 at the end of Section 4), the paper makes these limitations clear, which I appreciated very much as a reader (paper does not over-claim its contributions).",Does the review address Result?,TRUE,FALSE,Notes gaps between empirical and theoretical results.
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Result?,TRUE,FALSE,Comments on the sufficiency of experimental analysis.
"- Strengths: Useful modeling contribution, and potentially useful annotated data, for an important problem -- event extraction for the relationships between countries as expressed in news text.",Does the review address Data/Task?,TRUE,FALSE,Highlights tasks and data contributions.
"Perhaps an entropy-regularized setup is a useful comparison to show that it provides marginal benefit over the setup studied, and this might resolve the lack of clarity around the implications of the claims made from the first set of experiments.",Does the review address Presentation?,TRUE,FALSE,Suggests improving clarity in presentation.
Pros: - Weakly-supervised method for video moment localization is a reasonable and important direction.,Does the review address Significance?,TRUE,FALSE,Notes the significance of the method.
Weaknesses - The writing and the paper organization can be improved.,Does the review address Presentation?,TRUE,FALSE,Refers to writing and organization.
"1 ""Rule based approaches may seem outdated in contrast to statistical or neural methods.",Does the review address Methodology?,TRUE,FALSE,Discusses rule-based methodology.
"It describes a mapping of ORCHID, a Thai-specific POS tagset, to the Universal Dependencies (UD) scheme, and evaluates various state-of-the-art POS taggers on this scheme.",Does the review address Evaluation?,TRUE,FALSE,Refers to evaluation of taggers.
It also includes the recurrent memory extension from Transformer-XL from Dai et al.,Does the review address Methodology?,TRUE,FALSE,Mentions methodological details.
"On the other hand, the symbolic logic rules are able to express global patterns.",Does the review address Comparison?,TRUE,FALSE,Compares symbolic rules with patterns.
Contributions of the paper don't seen particularly novel.,Does the review address Novelty?,TRUE,FALSE,Highlights limited novelty.
"Thus, while concatenating the audio feature and the text feature can introduce desired performance, there could be some advancements not just combining pretrained audio model and LLM.",Does the review address Result?,TRUE,FALSE,Notes results and future advancements.
It would helpful to place it more clearly where the contribution of the paper lies in the related work.,Does the review address Contribution?,TRUE,FALSE,Proposes better highlighting of contributions.
"However, there is no theoretical result about the effectiveness of assigning the self-knowledge distillation to label smoothing.",Does the review address Result?,TRUE,FALSE,Notes absence of theoretical support for results.
* Can we get any information about how the annotators were trained?,Does the review address Methodology?,TRUE,FALSE,Questions annotator training methods.
"It would be great to define and identify beyond current close-ended tasks with new lower level tasks which really require using the audio, such as counting sound events, ordering of events, etc.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Proposes expanding task scope.
"- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other ""oracle"" baselines.",Does the review address Data/Task?,TRUE,FALSE,Refers to dataset use and comparisons.
The ablations cannot serve the topic of this paper well.,Does the review address Ablation?,TRUE,FALSE,Critiques the relevance of ablation studies.
But a direct head to head comparison for the computational cost of a multi-task model and individual models is not provided.,Does the review address Comparison?,TRUE,FALSE,Notes absence of computational cost comparison.
* Authors reproduced results from their strongest baseline.,Does the review address Result?,TRUE,FALSE,Refers to reproduced baseline results.
The paper is taking all the lessons from past works and applying it to a new domain.,Does the review address Methodology?,TRUE,FALSE,Refers to applying methods to a new domain.
"A significant part of the contribution was in the analysis of the results, obtained by this learning-based parameter sharing approach, which was quite informative and revealed some interesting insights about where and when a language-specific computation is required.",Does the review address Analysis?,TRUE,FALSE,Highlights analysis of learning-based parameter sharing.
"2. the FlexGen proposed in (Sheng et al., 2023) have showed -> has shown 3.",Does the review address Presentation?,TRUE,FALSE,Points out grammatical errors in presentation.
The proposed distillation loss is standard and by itself is not technically new.,Does the review address Novelty?,TRUE,FALSE,Notes lack of novelty in the distillation loss.
"Strengths: The paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",Does the review address Methodology?,TRUE,FALSE,Refers to the proposed approach for question-answering.
"3.The model excels in various audio-related tasks and open-ended question answering, demonstrating its outstanding performance.",Does the review address Methodology?,TRUE,FALSE,Highlights the methodology's performance.
"Additionally, the rationale for choosing (Ma et al., 2023) as a benchmark, along with the significance of the improvements observed, even if minute, should be clearly articulated.",Does the review address Presentation?,TRUE,FALSE,Suggests clarifying benchmark choice.
- Discussion in Section 4.1 - I think Figure 4 should be explained in more detail (in caption and/or text).,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Requests detailed explanation of Figure 4.
Such choice and associated thresholds seem arbitrary: how were they actually found out?,Does the review address Experiment?,TRUE,FALSE,Questions experimental threshold selection.
The same comment is applicable to oracle database (DB) results.,Does the review address Presentation?,TRUE,FALSE,Refers to clarity of results presentation.
It will be good to rewrite highlighting the contributions.,Does the review address Presentation?,TRUE,FALSE,Suggests improving presentation of contributions.
"Experiments show that the induced ""best-first"" order outperforms fixed orders, which verifies the motivation of the paper` 4.",Does the review address Result?,TRUE,FALSE,Discusses experimental results.
Theoretical analysis is provided to demonstrate the effectiveness of the proposed method under a greedy search algorithm.,Does the review address Presentation?,FALSE,TRUE,"Refers to theoretical analysis, not presentation."
"In its current form, the two arguments (input query and output sequence translated from a logic form) are interchangeable.",Does the review address Methodology?,TRUE,FALSE,Discusses method's argument structure.
The findings from the analysis are an important addition to the understanding of the role of language specific parameters in multilingual NMT.,Does the review address Methodology?,TRUE,FALSE,Refers to analysis of method parameters.
"I recommend this paper for acceptance, though I encourage the authors to revise their paper to make this the focus of the story, rather than the vaguely defined notion of “concept”.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Suggests clearer explanation of concepts.
The main weakness of the paper is that it is mainly based on further tuning the existing BERT model and lacks novel contribution in model architecture.,Does the review address Novelty?,TRUE,FALSE,Notes lack of novelty in architecture.
"Therefore, the training is stable and guarantee to converge.",Does the review address Methodology?,TRUE,FALSE,Refers to the stability and convergence of the method.
Strengths: The paper is well-written with clear motivations and structure.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Highlights clear motivations.
"- The authors have evaluated their models on multiple settings, proving that their models trained on Wikipedia can potentially generalize to multiple downstream tasks.",Does the review address Data/Task?,TRUE,FALSE,Refers to task generalization.
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Contribution?,TRUE,FALSE,Questions the novelty and impact of contributions.
I also encourage the authors to simplify the experiment described in section 3.1 to make it more clear.,Does the review address Presentation?,TRUE,FALSE,Suggests improving clarity of presentation.
"The motivation is to leverage unimodal data, which are assumed easier to obtain than image-text pairs.",Does the review address Data/Task?,TRUE,FALSE,Refers to leveraging unimodal data for tasks.
"One novel finding of this paper is that the distribution of the next word, conditional on the context, can provide a strong discriminative signal for the downstream task.",Does the review address Data/Task?,TRUE,FALSE,Discusses task-related findings.
"A lot of attention/space is dedicated to locality and symmetry properties of positional encodings, which from my understanding, isn’t very novel and has been explored in previous work.",Does the review address Novelty?,TRUE,FALSE,Questions the novelty of positional encoding exploration.
The empirical study that compares the prediction ensemble with the prompt ensemble is quite interesting and can inspire many related fields.,Does the review address Methodology?,TRUE,FALSE,Refers to a methodological comparison.
About experiments: 1) I think one ablation study I’m most interested in is to simply run GNN on the AST (or simply use Allamanis et.al’s method).,Does the review address Ablation?,TRUE,FALSE,Suggests a specific ablation study.
"I appreciate that the authors do not read too much into it and focus more on the analysis of the results, but one thing that remains unanswered in this paper is how the proposed method fairs against multilingual baselines that utilize (roughly) the same number of parameters; currently, the best models outperform the LS baseline by ~28M and ~10M parameters on OPUS-100 and WMT-14 respectively.",Does the review address Methodology?,TRUE,FALSE,Questions parameter usage in method comparisons.
W: - Human evaluation is missing and could add more insights to the interactive process.,Does the review address Evaluation?,TRUE,FALSE,Highlights the absence of human evaluation.
Could you explain more precisely what exactly is new?,Does the review address Novelty?,TRUE,FALSE,Requests clarification on novelty.
"Theoretically, they showed that synchronized updates to the low-level and high-level policy may never converge, yet asynchronized updates guarantees convergence.",Does the review address Theory?,TRUE,FALSE,Refers to theoretical convergence.
This paper is an interesting application of a data augmentation or self-supervised learning type of approach for tactic based theorem proving.,Does the review address Data/Task?,TRUE,FALSE,Discusses a task-related approach.
Authors also used a discriminator reward signal to cope with sparse reward (dialog success rate) and better representation of the human evaluation.,Does the review address Methodology?,TRUE,FALSE,Refers to a method involving a reward signal.
"I also appreciate that due care has been taken to present the work as understanding a phenomenon, to avoid any misconceptions about a new method being proposed.",Does the review address Presentation?,TRUE,FALSE,Compliments presentation clarity.
- The experimental results are thorough and solid.,Does the review address Result?,TRUE,FALSE,Praises the thoroughness of results.
"Therefore, it is necessary to compare OTTER and CLIP on the same-scaled datasets.",Does the review address Comparison?,TRUE,FALSE,Suggests comparison on same datasets.
"For the transferability coefficient proposed in Section 5.1, is it possible to measure it in experiments?",Does the review address Experiment?,TRUE,FALSE,Proposes measuring transferability in experiments.
"The annotations from [1] are very simple and short, only including some easy examples as in-context examples.",Does the review address Data/Task?,TRUE,FALSE,Refers to the simplicity of annotations.
"The main limitation to me is that, the two novel pre-training tasks proposed in this paper are specific for Wikipedia and they are less effective than the ICT strategy (as shown in Table 5).",Does the review address Methodology?,TRUE,FALSE,Discusses pre-training task methods.
It shows that BERT was significantly undertrained and propose an improved training recipe called RoBERTa.,Does the review address Methodology?,TRUE,FALSE,Refers to improved training methods.
"There are several follow-up results built on these two results, such as a new loss objective for predicting the downstream task, but to the best of my understanding, these two results are the main claims of this paper.",Does the review address Data/Task?,TRUE,FALSE,Mentions downstream tasks.
This seems to contradict findings from Brown et al where larger models did better on essentially all tasks.,Does the review address Result?,TRUE,FALSE,Compares results with prior findings.
"2) The proposed method outperforms other SOTA models in offline and interactive online settings, MultiWOZ and ConvLab respectively.",Does the review address Result?,TRUE,FALSE,Highlights performance improvements.
"Also, I think putting the english translation in a different font or color would be greatly helpful to our eyes.",Does the review address Presentation?,TRUE,FALSE,Suggests improving visual clarity.
I understand that LMU might have limited capacity but this is not specifically discussed and it is unclear how each component contributes to the end performance.,Does the review address Contribution?,TRUE,FALSE,Questions individual contributions of components.
This work has the potential to set a precedent in the fusion of quantum computing with graph transformers.,Does the review address Methodology?,TRUE,FALSE,Refers to the fusion method.
"Reasons for Score ----------------- The idea proposed in the paper is novel and exciting, but I have some concerns about whether the gains promised by the theoretical analysis can be realized while maintaining modeling quality.",Does the review address Theory?,TRUE,FALSE,Questions the theoretical claims.
- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.,Does the review address Methodology?,TRUE,FALSE,Notes limited experimental scope.
"* ""By achieving the best, these results prove that BROS"" this sentence can be improved.",Does the review address Result?,TRUE,FALSE,Refers to how results are stated.
"2) The proposed method outperforms other SOTA models in offline and interactive online settings, MultiWOZ and ConvLab respectively.",Does the review address Presentation?,FALSE,TRUE,"Focuses on results, not presentation."
"However, only one member (alpha=0.5) from the family has been evaluated in the experiments, and it does not achieve the best performance in most experiments.",Does the review address Result?,TRUE,FALSE,Discusses experimental outcomes.
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Analysis?,TRUE,FALSE,Refers to ablation and analysis.
"According to my understanding, at least there should be some direct connections between the parameters in the encoder and decoder.",Does the review address Methodology?,TRUE,FALSE,Suggests method improvements.
However in experiment only 300 projects are involved.,Does the review address Experiment?,TRUE,FALSE,Refers to limited experimental scale.
"### Major issue 1 The paper ""**theoretically**"" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental validation in Section 5.1.",Does the review address Methodology?,TRUE,FALSE,Refers to hyper-parameter analysis.
"They show improved total performance in MultiWoz dataset compared to recent, relevant baselines.",Does the review address Comparison?,TRUE,FALSE,Mentions comparisons with baselines.
"The experments are fairly convincing, although it is not entirely surprising that this approach works, and to repeat, the basic idea of extracting additional training data in this way is not entirely new.",Does the review address Experiment?,TRUE,FALSE,Refers to experimental findings.
What is the result if we directly learn to match input and logic forms?,Does the review address Result?,TRUE,FALSE,Asks about results of a specific method.
"Based on the large-scale training data and the proposed visual expert module, the proposed method achieves a number of state-of-the-art results across a wide range of vision-language tasks.",Does the review address Methodology?,TRUE,FALSE,Refers to a specific training approach.
"The main limitation to me is that, the two novel pre-training tasks proposed in this paper are specific for Wikipedia and they are less effective than the ICT strategy (as shown in Table 5).",Does the review address Data/Task?,TRUE,FALSE,Discusses dataset specificity and tasks.
This is very promising to simplify the construction of highly tuned task-specific neural pipelines and improve the multimodal and multi-task problems.,Does the review address Result?,TRUE,FALSE,Highlights positive outcomes of the approach.
Clarification on the task setting: Is it the case that the agent's current utterance does not decide what the next user utterance is?,Does the review address Methodology?,TRUE,FALSE,Questions task-specific methodology.
"- Well Structured Experiments sections with 4 RQs and results that confirm each of the hypotheses  - Reproducibility and Transparency in reporting of experiments in terms of available source code, dataset information, details about human evaluation, generation examples.",Does the review address Experiment?,TRUE,FALSE,Refers to experiment structure and reproducibility.
"(3) In the experiment about linguistic similarity, it appears that the capacity schedule is the same across languages and the authors conclude from this that the schedule has little to do with linguistic characteristics.",Does the review address Experiment?,TRUE,FALSE,Discusses results from a specific experiment.
"(In particular, pre-training on emergent language performs on average better than synthetic hierarchical data, but not quite as well as a different natural language, and all of these pre-training methods do better than training from scratch.)",Does the review address Methodology?,TRUE,FALSE,Refers to pre-training methods used.
"(2) Specifically, in the encoder side, the M-BERT model is leveraged to jointly encode the $x,tx,ty$.",Does the review address Presentation?,TRUE,FALSE,Explains encoding specifics.
**Limited technical novelty and incremental empirical gains**.,Does the review address Novelty?,TRUE,FALSE,Notes the limited novelty of the paper.
Do you learn a vector of each tag of BIOES and then take a weighted sum of these vectors with predicted probabilities as weights?,Does the review address Presentation?,TRUE,FALSE,Asks for clarification on how tags are represented.
"Altogether, I think this paper makes an interesting contribution to the question of: How can we get the most pretraining signal from unstructured data using off-the-shelf tools?",Does the review address Methodology?,TRUE,FALSE,Refers to pretraining techniques and tools.
"In practice, the authors use nouns and verbs as their concepts, which is fine in terms of pretraining objectives, but surely does not capture the generality of concepts.",Does the review address Methodology?,TRUE,FALSE,Discusses the method's conceptual limitations.
Could you explain the significance of this result again?,Does the review address Result?,TRUE,FALSE,Refers to the significance of the result.
"For checking the generalization of the method and better comparison w/ InDIGO (though InDIGO also conducted on MSCOCO, Django and the current comparison is sufficiently fair), I would like to increase my rating if seeing more experiments on large scale machine translation benchmarks as those in InDIGO.",Does the review address Methodology?,TRUE,FALSE,Suggests extending the method's evaluation.
*  The evaluation focuses on comparing with an empirical law learned on a different experimental configuration and there is a concern about how comparable are the results to the ones obtained in this study and the validity of the conclusions.,Does the review address Evaluation?,TRUE,FALSE,Questions the comparability and validity of evaluation results.
CALM shows better results with less data than the base model.,Does the review address Result?,TRUE,FALSE,Refers to the results achieved by CALM.
"It provided me with a much more thoughtful explanation for why language model pre-training improves downstream task performance, beyond simply “it helps learn good general representations of language using large amounts of unlabeled text data” (my previous reasoning).",Does the review address Methodology?,FALSE,TRUE,"Discusses pretraining benefits, not method details."
The paper is well-written and the idea is well-motivated.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,Highlights strong motivation behind the work.
Strengths: - The algorithms presented here are relatively straightforward but surprisingly effective.,Does the review address Methodology?,TRUE,FALSE,Refers to the effectiveness of the presented algorithms.
"Although the authors identify three potential challenges -- rapid convergence, the risk of under-training, and the potential for sparse attention -- they do not adequately explain how RandomMask addresses or mitigates these issues.",Does the review address Methodology?,TRUE,FALSE,Discusses unresolved methodological issues.
"If so, does the global node $V_g$ connect to all the sub fact nodes?",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Asks for clarification on the connection between nodes.
"Overall this paper tackles a nice application of GNN, which is the type prediction problem that utilizes structural information of the code.",Does the review address Methodology?,TRUE,FALSE,Refers to the use of GNN for type prediction.
"- Strengths: This paper has high originality, proposing a fundamentally different way of predicting words from a vocabulary that is more efficient than a softmax layer and has comparable performance on NMT.",Does the review address Methodology?,TRUE,FALSE,Highlights a new prediction method.
"They show improved total performance in MultiWoz dataset compared to recent, relevant baselines.",Does the review address Data/Task?,TRUE,FALSE,Mentions the MultiWoz dataset and performance.
"Your work is so similar to much of this work that you should really cite and establish novelty wrt at least some of them as early as the introduction -- that's how early I was wondering how your work differed, and it was not made clear.",Does the review address Novelty?,TRUE,FALSE,Suggests establishing novelty compared to existing work.
The experiments are conducted on datasets from questions answering and sentiment analysis.,Does the review address Experiment?,TRUE,FALSE,Describes experiments conducted on specific datasets.
"The paper claims that Balance Beam is ""an workflow to optimize the trade-off between latency and throughput performance of LLMs"".",Does the review address Presentation?,TRUE,FALSE,Refers to how the paper presents Balance Beam.
3) The ablation study and visualization analysis of the experimental results are sufficient.,Does the review address Presentation?,TRUE,FALSE,Comments on result presentation clarity.
"**Weaknesses**:   (1) Even though it is the first time such a method is applied in the context of NMT, the idea is not as much novel in the broader context of deep learning.",Does the review address Novelty?,TRUE,FALSE,Questions the broader novelty of the method.
The current paper only indicates that a small gap gives more consistency between the true objective and the optimized objective defined on the training set: they can be still far away from the expected posterior over data distribution.,Does the review address Data/Task?,TRUE,FALSE,Discusses the consistency gap in training objectives.
"However, only one member (alpha=0.5) from the family has been evaluated in the experiments, and it does not achieve the best performance in most experiments.",Does the review address Experiment?,TRUE,FALSE,Refers to the evaluation of one specific setup.
The experiments are conducted on datasets from questions answering and sentiment analysis.,Does the review address Analysis?,FALSE,TRUE,Describes datasets but not analysis.
It is better to compare with more demonstration selection methods such as similarity-based and diversity-based methods which are widely used in practice.,Does the review address Comparison?,TRUE,FALSE,Suggests comparisons with other methods.
"- The experiments contain two setups, one is offline response evaluation via MultiWOZ, and another is interactive simulation via ConvLab.",Does the review address Experiment?,TRUE,FALSE,Describes the two experimental setups.
"Related Work: Contrastive learning - Under an unsupervised setting, ontrastive -> contrastive  Overall:  This work highlights the importance of incorporating contrastive training for data augmentation.",Does the review address Data/Task?,TRUE,FALSE,Refers to data augmentation through contrastive training.
Presumably this is because much of the training iteration time is consumed by other parts of the network.,Does the review address Methodology?,TRUE,FALSE,Discusses computational aspects of the training method.
One of the important motivations of multi-modal multi-task learning mentioned was to achieve better or on-par performance with a single model (and supposedly fewer computations) which is crucial for devices with limited computing resources.,Does the review address Data/Task?,FALSE,TRUE,Discusses motivation but does not mention specific data or tasks.
This is to verify and support the usage of proposed type dependency graph.,Does the review address Experiment?,TRUE,FALSE,Mentions the experimental purpose to validate the graph.
"The two datasets have some “toy flavor”, while SCAN great favors example combination (with recomb-2 performs much better than recomb-1), recomb-1 seem to perform better for morphological analysis dataset, leaving questions about how to choose the exact models in general.",Does the review address Methodology?,TRUE,FALSE,Discusses dataset and model selection methodologies.
"For instance, they ask how different amounts of data influence model behavior or if their data sampling method can react to task difficulty.",Does the review address Evaluation?,TRUE,FALSE,Refers to how evaluation relates to data and task difficulty.
"In experiments, mainly accuracy is shown, but since the major motivation to reduce gradient variance, why not show some comparison of gradient variance of MLM and MLM-FE?",Does the review address Comparison?,TRUE,FALSE,Suggests a comparison of gradient variance.
"For example, by selecting the most complex examples, the performance of ChatGPT (i.e., gpt-3.5-turbo) can easily achieve more than 80% accuracy (without self-consistency) compared to the number 77.1% in Table 1.",Does the review address Result?,TRUE,FALSE,Highlights performance outcomes in Table 1.
"Without the experimental results using the same training settings, I do not think the authors are able to prove the superiority of OTTER over CLIP fully.",Does the review address Methodology?,TRUE,FALSE,Critiques lack of comparable experimental settings.
Questions:  * How can we be sure that the specific power law derived from a different experimental configuration in Kaplan et al. (2020) corresponds to the empirical law that can be derived for transformers in this particular evaluation setting?,Does the review address Methodology?,TRUE,FALSE,Questions the methodology of deriving power laws.
"They show that, especially in small-data regimes, pre-training on an emergent language can yield significant performance boosts in both tasks.",Does the review address Data/Task?,TRUE,FALSE,Refers to tasks and data context.
Cons: Some of the claims are not quite accurate even when compared to the works already cited here - 1.,Does the review address Result?,TRUE,FALSE,Highlights inaccuracies in reported results.
"It is hard to tell what are the standalone contributions of the paper, and what is coming from other works.",Does the review address Contribution?,TRUE,FALSE,Questions the paper’s distinct contributions.
"Furthermore, when there is a gap between the empirical results and the theoretical results (e.g., validation of Lemma 4.3 at the end of Section 4), the paper makes these limitations clear, which I appreciated very much as a reader (paper does not over-claim its contributions).",Does the review address Theory?,TRUE,FALSE,Discusses theoretical validation and limitations.
"The authors should make it clear that on different evaluation sets, the scores differs.",Does the review address Evaluation?,TRUE,FALSE,Refers to clarity in evaluation sets.
"Terms such as θ, t, δ, and especially the adjacency matrix A, which are crucial for understanding the method, require clear definitions and contextual usage within the proposed quantum framework.",Does the review address Methodology?,TRUE,FALSE,Discusses crucial method definitions.
"Therefore, I think it is very necessary to supplement this experiment.",Does the review address Experiment?,TRUE,FALSE,Suggests adding an experiment.
And they show this technique improves accuracy in downstream tasks.,Does the review address Result?,TRUE,FALSE,Highlights accuracy improvements.
The problem is a terrific one and the application of the recursive models seems like a contribution to this problem.,Does the review address Presentation?,FALSE,TRUE,"Refers to the problem, not presentation clarity."
Enhancing the paper with the aforementioned suggestions could substantially improve its impact and reception by the research community.,Does the review address Significance?,TRUE,FALSE,Suggests improvements to increase impact.
* I think there should be more discussion about the implications of Proposition 2.2.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,FALSE,TRUE,Asks for more discussion of implications.
- The proof technique (pre-training performance $\to$ covariance of pre-training errors $\to$ covariance of downstream errors $\to$ downstream performance) is itself interesting.,Does the review address Methodology?,FALSE,TRUE,Highlights the proof technique as part of the method.
"Of course, it is valuable to see the great performance achieved by single-task finetuning for RoBERTa.",Does the review address Data/Task?,FALSE,TRUE,Refers to a specific task (finetuning for RoBERTa).
"The authors use objectives which capture both generative and discriminative information, which some have suggested contain mutually beneficial signal but have not been unified in a single training method.",Does the review address Methodology?,TRUE,FALSE,Refers to the combined training approach.
- The original option framework assumes given options.,Does the review address Methodology?,TRUE,FALSE,Refers to the structure of the framework.
"335: consider defining GPGPU Table 3: Highlight the best BLEU scores in bold Equation 15: remind the reader that q is defined in equation 6 and b is a function of w. I was confused by this at first because w and h appear on the LHS but don't appear on the right, and I didn't know what b and q were.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Points out missing definitions and clarifications.
The authors take time to implement and evaluate several prominent baselines.,Does the review address Evaluation?,TRUE,FALSE,Refers to evaluating baselines.
"> However, in every task except CommonGEN the authors do not discuss any methods that are even close to the state of the art.",Does the review address Presentation?,TRUE,FALSE,Refers to missing discussion on relevant methods.
This paper suggestsan intermediate training regime that can be used between pretraining and the end-task finetuning.,Does the review address Methodology?,TRUE,FALSE,Refers to a new training regime.
"* Why does the EC pre-training use |V| = 4035, as opposed to 50 that's used in the other tasks and the fine-tuning corpora?",Does the review address Methodology?,TRUE,FALSE,specific methodological choice regarding the vocabulary size used in pre-training
"The in-depth experimental analysis of the BERT pretraining process in this paper answers many open questions (e.g., the usefulness of NSP objective) and also provide some guidance in how to effectively tweak the performance of pretrained model (e.g., large batch size).",Does the review address Result?,TRUE,FALSE,Highlights findings on BERT pretraining.
"While the authors say that they use vocabulary permutation, it is not clear what the size of the vocabulary is.",Does the review address Presentation?,TRUE,FALSE,Refers to clarity of information presentation.
Were there perhaps some poor datasets that happened to be in the held-in split (since the held-out tasks don't seem to have the same trend)?,Does the review address Data/Task?,TRUE,FALSE,Questions dataset splits.
"In this way, the conclusion is only supported by the empirical observations but not the presented theoretical analysis.",Does the review address Analysis?,TRUE,FALSE,Critiques lack of analysis to support conclusions.
"To alleviate the difficulty of optimizing discrete latent variables, the authors propose to cast it as a one-step Markov Decision problem and optimize it using the policy gradient.",Does the review address Methodology?,TRUE,FALSE,Describes a proposed optimization method.
(2) Equation 2 and 3 use the same graph encoder $F_{G}$.,Does the review address Methodology?,TRUE,FALSE,Mentions specific details of the method used.
Weaknesses:   - The empirical study is not convincing by only evaluating BERT-Tiny.,Does the review address Methodology?,TRUE,FALSE,Discusses evaluation choices within the method.
* The rationale behind the architectural choices for the self-attention component is not well explained or empirically verified.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Asks for explanation of architectural choices.
The result presented in Table 4 don't match the description in Section 4.3:  - It's not true that the pRNN outperforms both PBSMT and Enc-Dec model.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques inconsistency between results and explanation.
It will be good to rewrite highlighting the contributions.,Does the review address Contribution?,TRUE,FALSE,Suggests emphasizing contributions.
"Since the selective annotation is based entirely on similarities derived from sentence embeddings, there is nothing explicit ensuring that the label distribution over the selected subset is not skewed.",Does the review address Presentation?,TRUE,FALSE,Critiques clarity of annotation approach.
The authors suggest that their method captures more commonsense knowledge by being focused on capturing knowledge about “concepts”.,Does the review address Methodology?,TRUE,FALSE,Highlights the focus of the proposed method.
"The result section cannot be simply presenting a table without explanation:  - Still on the result sections, although it's clear that BLEU and perplexity are objective automatic measure to evaluate the new architecture.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Critiques lack of explanation for results presented.
"Without the ablation studies on these two aspects, we cannot determine whether the performance improvement truly comes from the author's contribution or just longer CoT annotations.",Does the review address Data/Task?,FALSE,TRUE,"It discusses ablation studies, not dataset or task details."
Summary: + Appealing theoretical contributions + Empirical results are encouraging + The use of discriminator for reward shaping in addition to task success rate is interesting  - Writing and explanation can be improved.,Does the review address Contribution?,TRUE,FALSE,It highlights the paper’s contributions.
"In particular, you are comparing a small GRU LM to a larger transformer LM, where the latter is, as you mention, a much more powerful model.",Does the review address Comparison?,TRUE,FALSE,It compares models of different capacities.
"Other concerns along these lines: all of this paper's results are averaged over 3 runs while the other baselines are over 5 runs - an indication of variance would be useful to assess whether the differences are significant, especially since some of the margins quite small (23 on MC-LAVE-RL vs 22.8 for the next best on Ludicorp) added to the fact that hyperparameters are different for each game - does that imply that the authors tuned the hyperparameters for each game?",Does the review address Significance?,FALSE,TRUE,"It discusses result variability, not overall impact."
"The result section cannot be simply presenting a table without explanation:  - Still on the result sections, although it's clear that BLEU and perplexity are objective automatic measure to evaluate the new architecture.",Does the review address Result?,TRUE,FALSE,It critiques the result presentation and measures.
"Rules may be ""outdated"" because they are inefficient for certain languages with reams of available data and scads of phenomena that don't fit.",Does the review address Methodology?,FALSE,TRUE,"It critiques rules, not the method itself."
The methodology is explained clearly and experiments are executed with a considerable amount of detail.,Does the review address Presentation?,TRUE,FALSE,It compliments the clarity of explanation and detail.
"Does the definition of ""event word""s here come from any particular previous work that motivates it?",Does the review address Related Work?,TRUE,FALSE,It asks for a link to previous work.
"Then, taking inspiration from recent work that shows that many downstream tasks can be reframed as sentence completion tasks, it defines a “natural task” as one on which a sparse linear model over the output of the “true” language model (next word probability distribution, conditioned on context) attains strong performance.",Does the review address Data/Task?,TRUE,FALSE,It provides a definition related to task formulation.
Are these rather the ppl resulting from training an LM on the full dataset?,Does the review address Methodology?,TRUE,FALSE,Refers to training details.
"To me saying ""BLUE reduced for the other methods"" means that you have some other baseline you are comparing to.",Does the review address Comparison?,TRUE,FALSE,Implies comparison with other baselines.
"However, they compare to BERT models and build themselves on RoBERTa_base; how are the results meaningful if they use a stronger model to start with?",Does the review address Methodology?,TRUE,FALSE,Questions model selection and design choices.
"**Related work** The authors clearly describe the related prior works from both the perspectives of program synthesis, large language models, and benchmarks for program synthesis.",Does the review address Data/Task?,FALSE,TRUE,"Focuses on related work, not datasets/tasks."
"It is hard to infer the test gains, given the possibly significant hyperparameter optimization on the dev set.",Does the review address Presentation?,TRUE,FALSE,Highlights unclear reporting of experimental details.
It is great to have a theoretical analysis of the property of the influence function.,Does the review address Analysis?,TRUE,FALSE,Mentions a theoretical analysis aspect.
"However, there are still major gaps between the theoretical analysis, the conclusion and the empirical solution (please see the detailed comments).",Does the review address Theory?,TRUE,FALSE,Notes inconsistencies in the theoretical analysis.
- It is unclear why the zero-shot prediction of CLIP is not used as a baseline (as it would be equivalent to epsilon = 0).,Does the review address Comparison?,TRUE,FALSE,Questions the choice of baselines.
"Compared to the related work, the novel part of this work is: (i) a new retrieval way, which is not quite clear and convincing to me.",Does the review address Novelty?,TRUE,FALSE,Evaluates the uniqueness of the retrieval approach.
This is an interesting topic that can spur further research and help predictability and understand the LLM's behaviours in general.,Does the review address Methodology?,FALSE,TRUE,"Comments on topic significance, not on method details."
The proposed model explored to utilize better context information and captured the relation between video and sentence/word via graph neural networks.,Does the review address Methodology?,TRUE,FALSE,Mentions use of graph neural networks to capture relations.
The annotations in baseline [1] are much shorter compared to the annotations by the authors.,Does the review address Data/Task?,TRUE,FALSE,Discusses annotation differences in datasets.
#### Strength - The idea of perceiver IO is novel and solid -- a general architecture capable of handling general-purpose inputs and outputs across different tasks and modalities.,Does the review address Methodology?,TRUE,FALSE,Highlights a specific architectural design.
It handles the hallucination problem of LLM by training close-ended dataset and then non-answerable question-answer pairs.,Does the review address Data/Task?,TRUE,FALSE,Refers to training on specific datasets and question types.
(2) Another weakness is that the comparison with the vanilla and LS baselines does not seem to be properly controlled in terms of parameters.,Does the review address Comparison?,TRUE,FALSE,Points out issues with baseline parameter control.
Their thorough ablation experiments and other analysis yield some interesting findings the authors could emphasize more.,Does the review address Analysis?,TRUE,FALSE,Mentions ablation experiments and additional analysis.
"On the other hand, one could argue that N-Bref is novel because it combines a number of existing components in a unique way to achieve better performance that prior work.",Does the review address Novelty?,TRUE,FALSE,Emphasizes unique component combination for novelty.
The margin of change seems even larger than some results which are discussed in the paper as significant.,Does the review address Significance?,TRUE,FALSE,Observes a large performance change implying high impact.
"It is also strange that the multi-cluster approach, which discards inter-cluster (word and language) semantic information performs the best with respect to the extrinsic metrics.",Does the review address Methodology?,TRUE,FALSE,Questions the design of the multi-cluster method.
"you explained this in page 6, in Task Description.",Does the review address Presentation?,TRUE,FALSE,Refers to clarity in the task description presentation.
Is this strategy guaranteed optimal theoretically?,Does the review address Theory?,TRUE,FALSE,Asks about theoretical optimality.
"It is not the case that I find the experimental results inadequate, rather, the experiments run in the first place are generic and do not illustrate the points of interest with a continuous-channel referential game.",Does the review address Result?,TRUE,FALSE,Critiques the experimental outcomes.
"The authors cite Bordes et al. (https://arxiv.org/pdf/1506.02075.pdf), who collect a similar dataset and perform relation extraction using memory networks (which are commonly used for reading comprehension).",Does the review address Data/Task?,TRUE,FALSE,Mentions a dataset and associated task.
Impact: The labeling requirement was a huge bottleneck.,Does the review address Significance?,TRUE,FALSE,Highlights a practical impact issue.
"On the one hand the baselines make use of a large set of training trajectories, but on the other hand these methods train policies that choose low-level actions.",Does the review address Methodology?,TRUE,FALSE,Describes baseline method choices.
Or an experiment could address if using the phonotactics from a natural language results is more effective than using a randomly selected phonemes due to necessity for natural languages to have acoustically distinct words.,Does the review address Experiment?,TRUE,FALSE,Suggests an additional experiment.
My understanding is that contribution of the paper is in exploring using options framework to goal-oriented dialog to handle the issue in question.,Does the review address Methodology?,FALSE,TRUE,"Focuses on contribution, not method details."
"Are there any overheads/disadvantages because of multi-task learning (Like a larger model size, inference time for individual tasks etc)?",Does the review address Data/Task?,FALSE,TRUE,"Discusses model overhead, not datasets/tasks."
More of an issue is that the fact that the definition of general learner in Section 2.2 is not clearly structured.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Criticizes the clarity of a definition.
"The main contribution are the following innovations: a special attention mechanism called block-diagonal conditional attention, a set of modules for adaptation of a pretrained model, and an uncertainty-based multi-task data sampling method.",Does the review address Contribution?,TRUE,FALSE,Lists the paper’s technical contributions.
"If this secondary goal is valid, the paper requires sufficient reasoning for why the presented approach is superior.",Does the review address Methodology?,FALSE,TRUE,"It demands reasoning for superiority, not details of the method."
"It provided me with a much more thoughtful explanation for why language model pre-training improves downstream task performance, beyond simply “it helps learn good general representations of language using large amounts of unlabeled text data” (my previous reasoning).",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,It provides a detailed explanation of pre-training benefits.
Strength: - A novel architecture to enable deeper interaction between LM and GCN.,Does the review address Methodology?,TRUE,FALSE,It highlights a new architectural design.
**Strengths** - The paper is generally quite clearly written and the claims are well-validated.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,It notes that the claims are well-validated.
The research shows how low-level proof artifact data may be used to significantly boost performance on high-level theorem proving by co-training auxiliary tasks.,Does the review address Result?,TRUE,FALSE,It reports a performance boost in theorem proving.
Clarity on Quantum Enhancements:  Section 3.2.2 seems to lack depth in the explanation of how the quantum correlations are calculated and utilized within the graph transformers.,Does the review address Presentation?,TRUE,FALSE,It criticizes the clarity of the explanation.
"Mainly, Table 4 provides understandable results showing that multi-turn specifications achieve better performance compared to single-turn specifications.",Does the review address Result?,TRUE,FALSE,It refers to performance outcomes shown in Table 4.
"Yet it seems inconsistent at times whether this is a formal definition of the concept or a necessary condition obtained from some other (unprovided) definition, as Proposition 1 suggests.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,It questions the clarity and consistency of the formal definition.
The new established benchmark is another good contribution.,Does the review address Contribution?,TRUE,FALSE,Calls the benchmark a contribution.
More discussion is required on a) what are the reasons of loss in comprehensibility in this case (it is briefly mentioned in the intro) b) why their individual design choices and how they handles the different reasons c) some evaluation to verify this 2.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,Asks for further discussion and explanation.
"Moreover, the authors better answer questions in 2 so I can gauge if their hyper-parameters were chosen in the principled ways.",Does the review address Experiment?,FALSE,TRUE,"Concerns hyperparameter choices, not experiment details."
Perhaps the authors can consider adding them to setup a more comprehensive benchmark.,Does the review address Data/Task?,TRUE,FALSE,Refers to establishing a comprehensive benchmark (dataset/task).
The same applies to Table 3: it is unclear to me why or how the baseline T5 model has been chosen.,Does the review address Presentation?,TRUE,FALSE,Highlights lack of clarity in presenting baseline selection.
The description of how you compare your invariants to those inferred by Daikon is not clear unless all relevant cases related to (pre)conditions on method parameters.,Does the review address Presentation?,TRUE,FALSE,Points out that the description is unclear.
Can PACT be applied to simpler theorem provers like MetaMath where there are no tactics?,Does the review address Methodology?,TRUE,FALSE,Questions the method's applicability to other systems.
"This work tries a single pruning rate and finds it significantly degrades, rather than improves results: for both active learning and random selection.",Does the review address Result?,TRUE,FALSE,It discusses the observed outcomes (performance degradation) of the pruning rate.
"According to the description, the fact units are constructed using the dependency parser.",Does the review address Methodology?,TRUE,FALSE,It describes a design detail—the use of a dependency parser—to construct fact units.
"For a fair comparison, I think the baseline should add those methods as claimed in the introduction (Lee et al., 2019; Child et al., 2019; Sukhbaatar et al., 2019; Beltagy et al., 2020, inter alia), (Kitaev et al., 2020; Wang et al., 2020; Roy et al., 2020, inter alia) and let us know how badly they performed under the short sequence.",Does the review address Methodology?,FALSE,TRUE,"It recommends including additional baselines for a fair comparison, which is a comparison issue rather than a methodological detail."
"- Extensive ablation studies that showcase specific abilities of the model (types of OOD generalization), investigate the role of the foundation models and study the importance of the components of the prompt.",Does the review address Presentation?,FALSE,TRUE,"It describes experimental ablation studies, not issues of clarity or organization."
The proposed method is reasonable and moderately novel.,Does the review address Methodology?,FALSE,TRUE,"It evaluates the method's overall quality and novelty, not the technical details or approach used."
It seems like more quantitative analysis would be needed to determine how much the LM's attention is correlating empirically to factual knowledge or if there are other factors that are affecting the downstream improvements.,Does the review address Methodology?,FALSE,TRUE,"The comment calls for more quantitative analysis, which relates to analyzing results rather than detailing the method's approach or process."
"* Even though this paper proposes a new efficient transformer, the evaluation does not focus on computational efficiency aspects and comes across as incomplete.",Does the review address Methodology?,FALSE,TRUE,"The comment criticizes the evaluation focus, not the method's techniques or processes."
I would encourage the authors to do this comparison to show how LTU could be a more generic model which can be super useful for users to interact with an audio language model through natural text.,Does the review address Significance?,TRUE,FALSE,"The comment stresses the practical impact and usefulness of LTU, highlighting its broader significance."
"The only advantage of using two is an increase of model capacity, i.e. Furthermore, what are the hyper-parameters / size of the baseline neural networks?",Does the review address Methodology?,TRUE,FALSE,"It raises questions about design choices and details such as hyper-parameters, which are central to the methodological aspects of the study."
"Compared with commonsense and entity-relation knowledge, the fact units are more informative to each specific question.",Does the review address Comparison?,TRUE,FALSE,"The comment directly compares different sources of knowledge, addressing the comparative aspect."
"-----Weaknesses----- I'm not very convinced by the empirical results, mostly due to the lack of details of the baselines.",Does the review address Result?,TRUE,FALSE,"The comment addresses empirical results, criticizing them due to missing baseline details."
It paves the way for more widespread application of VIP in scenarios where interpretable-by-design approaches are critical.,Does the review address Significance?,TRUE,FALSE,"The comment outlines the broader impact and potential application of VIP, relating to the significance of the work."
"Footnote 2 -- ""the tensor version"" - needs citation to explain what's being referred to.",Does the review address Related Work?,TRUE,FALSE,"The remark calls for a citation, aiming to connect the content to prior literature, which falls under related work."
My main problem with this paper at the moment is that it could be much better written: The overall narrative of the paper is unpolished and it’s hard at first to understand the contributions of the paper.,Does the review address Contribution?,TRUE,FALSE,"The review mentions ""contributions"" directly, although it criticizes the clarity in communicating them."
"There is no comparison with other public masking methods in Table 2, such as whole-word-masking, span masking, etc.",Does the review address Methodology?,FALSE,TRUE,"The comment points out missing comparisons among masking methods, which pertains to comparative analysis rather than the methodological approach."
"It requires more analysis about experimental results, such as Figure 1 and tables in Section D.",Does the review address Presentation?,FALSE,TRUE,"The statement calls for more analysis of experimental results rather than addressing issues like clarity, organization, or overall presentation style."
"I look forward to seeing the authors discuss a comprehensive comparison of DeFo's training time and other methods, such as CoOp and CLIP-adapter.",Does the review address Comparison?,TRUE,FALSE,"The comment calls for a side-by-side comparison with other methods, which directly addresses the comparison of approaches."
"Second, the authors neither 1) evaluate their model on another dataset or 2) evaluate any previously published models on their dataset.",Does the review address Methodology?,FALSE,TRUE,The comment criticizes the scope of the experimental evaluation rather than detailing the employed methodological techniques.
"Strengths: * Novel method of using emergent language for pre-training (as opposed to transferring an entire artificial agent) * Some good ablations to identify what contributes to successful transfer * A new evaluation metric (emergent --> NL translation performance) that best correlates with fine-tuning performance  Weaknesses: * Some parameter choices and the design of some ablations are not completely justified * Some additional related works could be included   # Minor comments / questions  * ""However, this metric is too rigid in its definition of compositionality, ignoring aspects like argument structure, context or morphology which play a key role in determining the combination of word semantics (Goldberg, 2015).""",Does the review address Evaluation?,TRUE,FALSE,"The remark scrutinizes the design and adequacy of an evaluation metric, directly relating to the evaluation aspect."
"The paper proposes a novel task, text-to-audio storytelling.",Does the review address Data/Task?,TRUE,FALSE,"The comment highlights a new task introduced by the paper, which pertains to the dataset/task aspect of the study."
"Given a sentence $x$ to be translated, they first retrieve a $(tx, ty)$ sentence pair from the training set through ``SEGMENT-BASED TM RETRIEVAL’’ defined in Section 4.1, where $tx$ and $ty$ are from source and target languages respectively.",Does the review address Methodology?,TRUE,FALSE,explains a retrieval process (SEGMENT-BASED TM RETRIEVAL)
"The authors provide OTTER using hard labels (InfoNCE) as a baseline, but ZSL methods are sensitive to hyper-parameters and training sets.",Does the review address Comparison?,TRUE,FALSE,compares a baseline (OTTER with hard labels) and discusses the sensitivity of ZSL methods
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Data/Task?,FALSE,TRUE,discusses a theoretical guarantee regarding performance on natural tasks rather than addressing the specific dataset or task setup
It is not clear how the proposed method considers the correlations among the retrieved data points.,Does the review address Methodology?,TRUE,FALSE,raises a concern about how the method handles correlations among retrieved data
"Generally speaking, this paper puts forward a universal retrieval scheme, and achieves good results, the specific advantages are as follows:  (1) The sparse alignment of multi-vector retrieval is a good solution to solve the retrieval effect and efficiency.",Does the review address Presentation?,FALSE,TRUE,outlines the advantages of the proposed universal retrieval scheme
* There are some points in the paper that could be made clearer.,Does the review address Presentation?,TRUE,FALSE,mentions that some points could be made clearer
"Regarding the proof, the notations in Section 3 are quite loose, especially for Section 3.1.",Does the review address Presentation?,TRUE,FALSE,discusses the clarity and consistency of notation
"Unfortunately, as the paper overall does not seem to contain significant novelty, neither in methodology nor in results, I cannot recommend acceptance at this point.",Does the review address Result?,TRUE,FALSE,highlights that the paper lacks significant novelty in both methodology and results.
"## Logical Flow of Main Results and Relation to Prior Work Should be Clarified  The paper defines T-LLMs as general learners if ""the expressive power of realistic T-LLM model class can cover universal circuits for all circuits of polynomial size"" and says that:  > It is unknown whether the realistic Transformers are expressive enough to be general learners   In fact, it seems that Theorem 3 essentially follows from the TC0 upper bound in previous work.",Does the review address Related Work?,TRUE,FALSE,references previous work regarding the TC0 upper bound to explain Theorem 3's foundation.
"Given that there is a wealth of existing work that performs the same task and the lack of novelty of this work, the authors need to include experiments that demonstrate that their technique outperforms others on this task, or otherwise show that their dataset is superior to others (e.g. since it is much larger than previous, does it allow for better generalization?)",Does the review address Experiment?,TRUE,FALSE,requests additional experiments to demonstrate improved performance compared to existing methods.
Reducing it to 80% seems to be a sweet point with the best balance between performance and efficiency.,Does the review address Result?,TRUE,FALSE,discusses the optimal performance outcome at 80%
"They show that, especially in small-data regimes, pre-training on an emergent language can yield significant performance boosts in both tasks.",Does the review address Methodology?,TRUE,FALSE,discusses pre-training on an emergent language
"- The authors have evaluated their models on multiple settings, proving that their models trained on Wikipedia can potentially generalize to multiple downstream tasks.",Does the review address Evaluation?,TRUE,FALSE,models are evaluated across multiple settings
"**Technical contribution** Codegen for program synthesis seems effective, especially when the user wants to generate pieces of code from input/output examples or natural language descriptions.",Does the review address Contribution?,TRUE,FALSE,highlights the technical contribution by noting the effectiveness of Codegen for program synthesis
The related work section does not connect this paper to specific prior work (only citing two survey papers).,Does the review address Related Work?,TRUE,FALSE,the related work section only cites two surveys and does not link the paper to specific prior studies
One may also refer to https://opencompass.org.cn/leaderboard-llm for the performance of LLMs (I acknowledge that the performance of ChatGPT on GSM8K from that website is possibly still underestimated).,Does the review address Related Work?,TRUE,FALSE,points readers to an external leaderboard for LLM performance
"With these two elements, the approach performs on par with recently proposed GECA (where the data is not augmented via a neural generator) on two datasets.",Does the review address Result?,TRUE,FALSE,compares performance with GECA and mentions performance on datasets
This paper focuses on improving the dialogue policy together with the responses by utilizing a pre-trained language model and offline RL.,Does the review address Result?,FALSE,TRUE,outlines the focus of the paper
See section-2.6 of this tutorial for more details about using neural models to rank: https://www.microsoft.com/en-us/research/uploads/prod/2017/06/INR-061-Mitra-neuralir-intro.pdf.,Does the review address Methodology?,TRUE,FALSE,points to a section with details about using neural models for ranking
The authors also seem to have carefully designed their experiments.,Does the review address Experiment?,TRUE,FALSE,refers to the experiments and their design
Questions & Comments: • It is stated that the performance is sensitive to epsilon in AdamW.,Does the review address Result?,TRUE,FALSE,highlights the model's performance sensitivity to a parameter in AdamW
"Also, can you add a column where a dense linear model over p_f(s) is used?",Does the review address Methodology?,TRUE,FALSE,addition of a column using a dense linear model
"It considers the training direction to be ""first to perceive, and then comprehend the sound"" so that the training starts from using close-ended datasets to open-ended datasets.",Does the review address Data/Task?,TRUE,FALSE,differentiates between close-ended and open-ended datasets
"Intuitively, this parameter arises from translating the ""natural"" task assumption, which only guarantees transfer on average to the downstream task.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,uses intuitive reasoning to explain the parameter's origin
"-----Post-rebuttal----- The authors did not address my main concern, which is whether the baselines (e.g. TreeRNN) are used to compute substructure embeddings independent of the sentence embedding and the joint tagger.",Does the review address Methodology?,TRUE,FALSE,questions a key methodological detail regarding how the baselines compute substructure embeddings relative to sentence embeddings and the joint tagger
"As, deep recurrent neural networks are already used in keyphrase extraction (shows very good performance also), so, it will be interesting to have a proper motivation to justify the use of  RNN and Copy RNN over deep recurrent neural networks.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,asks for motivation and justification for choosing RNN and Copy RNN over deep recurrent neural networks
"However, there is no discussion on the latency in the proposed method and experiments.",Does the review address Experiment?,TRUE,FALSE,issues in the experiments
(Current experiments only include the results of models that are free from this issue.),Does the review address Methodology?,FALSE,TRUE,describes an experimental inclusion criterion
An additional experimental results with multi-task finetuning should also be added.,Does the review address Experiment?,TRUE,FALSE,adding additional experimental results with multi-task finetuning
"Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",Does the review address Result?,TRUE,FALSE,several tests and observations about model performance and robustness
The second major concern I have with this paper is the small dataset they are using.,Does the review address Data/Task?,TRUE,FALSE,highlights concerns regarding the small dataset used
- Extensive results show improvements over a base model and a larger model across a range of tasks.,Does the review address Data/Task?,TRUE,FALSE,"mentions ""a range of tasks"""
Perhaps the biggest reason is I can’t seem to understand what is novel about the system.,Does the review address Novelty?,TRUE,FALSE,directly questions the novelty of the system
"I thought that this paper was very thought-provoking, and I appreciated the attempts to better understand what is going on with pre-trained language models, why they work well, and what might we be able to improve from theses insights.",Does the review address Result?,FALSE,TRUE,praises the paper for its thought-provoking nature and its exploration of pre-trained language models rather than detailing performance outcomes or experimental results.
The paper then does a good job of showing how using one-hot encodings compared to SCS change the problem definition leading to a difference in performance on the same task.,Does the review address Result?,TRUE,FALSE,the change in encoding leads to differences in performance
The idea of analyzing the gap to variational posterior lower bound for different dropout inference model is interesting.,Does the review address Methodology?,TRUE,FALSE,analytical approach related to dropout inference models
"We observe empirically that if pruned globally, the attention heads in some layers may be completely removed, making the network un-trainable.",Does the review address Presentation?,FALSE,TRUE,describes an empirical observation about model pruning rather than addressing any aspects of the paper's clarity
It is therefore not surprising that multi-task learning should help these tasks.,Does the review address Result?,TRUE,FALSE,implies that the observed benefit of multi-task learning on the tasks is a result
"Specifically, is there any feed-forward computation involved and how many layers of the models used in comparison.",Does the review address Methodology?,TRUE,FALSE,asks for technical specifics about model architecture details
"From what I can tell, Appendix C on prompt tuning (which is very interesting) is maybe the primary evidence the instructions are important.",Does the review address Methodology?,TRUE,FALSE,prompt tuning
"While it is also true that corpus transfer _enables_ this divergence in model types, to really test whether transferring the whole model versus using the corpus works or not, I would think you would want to compare fine-tuning the sender GRU on the LM data vs. starting from scratch _with a GRU of the same type_ and pre-training on the EC corpus before fine-tuning.",Does the review address Methodology?,TRUE,FALSE,a specific alternative approach to fine-tuning and pre-training
"They train low resource NMTs using 4 different tokenization strategies, to show that their proposed tokenization method leads to the best NMT results by several metrics.",Does the review address Result?,TRUE,FALSE,the proposed tokenization method leads to the best results
- Many interesting robustness capabilities of VL models only emerge when trained with hundreds of millions of samples.,Does the review address Result?,TRUE,FALSE,"robustness capabilities was mentioned, related to result"
An ablation analysis would be most appropriate for quantifying this.,Does the review address Comparison?,FALSE,TRUE,conducting an ablation analysis rather than comparing the proposed method to other methods
"I.e., Figure 1 should be your results table, and figure 2 should be the examples for us to see.",Does the review address Result?,TRUE,FALSE,refers to a results table
The show improved performance in MultiWoz dataset.,Does the review address Data/Task?,TRUE,FALSE,mentions the MultiWoz dataset
"As shown in Figure 6, when more than 12 facts are constructed, the performance becomes worse.",Does the review address Result?,TRUE,FALSE,references the performance outcomes
"For example, you explained why ADJ is not used in your mapping, but ADJ does appear in this UD treebank.",Does the review address Comparison?,TRUE,FALSE,It draws a direct comparison between the author’s mapping and the existing UD treebank’s tag usage
"However, there are insufficient experiments and comparison to previous work to convince me that the paper’s contributions are novel and impactful.",Does the review address Significance?,TRUE,FALSE,questions whether the contributions are impactful
This paper is an interesting application of a data augmentation or self-supervised learning type of approach for tactic based theorem proving.,Does the review address Methodology?,TRUE,FALSE,mentions data augmentation and self-supervised learning approaches
The method can select appropriate batch sizes by assessing the working memory requirements per token during benchmarking.,Does the review address Data/Task?,FALSE,TRUE,focuses on selecting batch sizes by assessing memory requirements not data or task
The question about whether realistic transformers can represent any polynomial-time-computable function is interesting.,Does the review address Methodology?,FALSE,TRUE,statement is about the theoretical capacity of transformers not approach
"For fine-tuning, the authors run their model for 2.2 epochs, while their baseline model runs for 3 epochs, roughly 30% more which accounts for much of the reduction observed in Table 2.",Does the review address Comparison?,TRUE,FALSE,contrasts the authors’ model with the baseline model’s training setup
"The authors start with some good motivation for building more intimate interaction between vision and language, but it finally becomes the emphasis of the benefit of scaling up.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,explicitly refers to good motivation
"* page 3: s/""It has also been previous observed""/""It has also been previously observed""",Does the review address Presentation?,TRUE,FALSE,comment addresses a grammatical correction
Another major concern is the use of two separate RNNs which gives the proposed model more parameters than the baselines.,Does the review address Methodology?,TRUE,FALSE,criticizes the design choice of two separate RNNs
Detailed comments: - There already is a small UD treebank for Thai: <https://github.com/UniversalDependencies/UD_Thai-PUD/>   How does your mapped tagset compare to the annotation scheme chosen there?,Does the review address Comparison?,TRUE,FALSE,specifically asks how the authors’ tagset compares to another annotation scheme
"There is a lack of experimental analysis supporting the source of the observed improvements, which is crucial for substantiating the paper's main claims.",Does the review address Experiment?,TRUE,FALSE,refers to experimental analysis
"The paper only performs some finetuning on GLUE tasks, which is significantly less interesting given that it is comparatively cheap and FP8 speedups thus not so crucial while, in many cases, even more affordable finetuning techniques like QLoRA also work well.",Does the review address Methodology?,TRUE,FALSE,critiques the approach of using finetuning on GLUE tasks
"The closest baseline is simply a comparison against a CLIP(image, concept) similarity score.",Does the review address Comparison?,TRUE,FALSE,directly references a comparison to a baseline
"Where the paper does get technical is in a discussion of the differing difficulties of speech recognition for different languages, providing a useful case study to demonstrate that one-size technology approaches are not necessarily universal stand-alone solutions.",Does the review address Presentation?,FALSE,TRUE,focuses on the technical content
"The experments are fairly convincing, although it is not entirely surprising that this approach works, and to repeat, the basic idea of extracting additional training data in this way is not entirely new.",Does the review address Novelty?,TRUE,FALSE,notes that the approach is “not entirely new
"It would be useful if following the suggestions of [2,3] the authors could present results in settings with low data regimes and with significant distribution shift with respect to the pre-training set, which represents a more realistic application setting.",Does the review address Result?,TRUE,FALSE,calls for additional results in different settings
The results demonstrated in the experiments show an improvement over previous models.,Does the review address Result?,TRUE,FALSE,"refers to the outcome (“results”) and how they compare to previous models, which falls under Result."
"See Rives et al, 2020, ‘Biological structures and functions emerge…’, section 5.2, and Vig et al, 2020, ‘Bertology’ section 4.2.",Does the review address Related Work?,TRUE,FALSE,specific references to prior studies
"Thus, the experiment could answer questions such as:     - Does compositionality emerge at the same rate in continuous- and discrete-channel games?",Does the review address Experiment?,TRUE,FALSE,"refers to “the experiment,” indicating the experimental aspect"
Is it possible to import a public SOTA implementation and conduct comparisons based on that?,Does the review address Methodology?,TRUE,FALSE,suggests a methodological approach
The proposed method also extends this to multilingual evaluations.,Does the review address Evaluation?,TRUE,FALSE,mentions multilingual evaluations
Ablation studies show that the model achieves good performance on more complex questions.,Does the review address Ablation?,TRUE,FALSE,mentions ablation studies
"Theoretically, it shows that language models which are close to the “true” language model are guaranteed to attain strong performance on natural tasks.",Does the review address Result?,TRUE,FALSE,strong performance
"In general, the paper is well written and describes the work clearly.",Does the review address Presentation?,TRUE,FALSE,praises the paper’s writing and clarity
L680-683: This needs more examples or explanation of what it means to judge the polarity of a peak.,Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,request for more examples and explanation directly pertains to Elucidation
"So, In this case, it will be interesting to see the results (or will be helpful in evaluating ""absent type"" keyphrases): if we identify all the topical phrases of the entire corpus by using tf-idf and relate the document to the high-ranked extracted topical phrases (by using Normalized Google Distance, PMI, etc.).",Does the review address Evaluation?,TRUE,FALSE,refers to an approach for evaluating keyphrases
"For example, Figure 4 validates Assumption 4.1 (log-partition function is roughly quadratic in theta), and Table 1 shows many real tasks are approximately “natural”.",Does the review address Methodology?,FALSE,TRUE,The statement focuses on validating a log-partition function and reporting on task properties.
"I would like to have seen qualitative examples of model predictions, and more examples from the dataset.",Does the review address Data/Task?,TRUE,FALSE,calls for more examples from the dataset
"For example, if for the baseline model, we also only use one data sample and apply different masks, will there be improvement?",Does the review address Methodology?,TRUE,FALSE,"discusses an approach (using different masks for the baseline model), which falls under Methodology"
- Performance with relatively little finetuning data are encouraging.,Does the review address Result?,TRUE,FALSE,"The statement refers to performance, which falls under Result"
"It's important to discuss why these improvements are non-trivial and how they advance the field, considering the rapidly evolving landscape of both quantum computing and graph analysis.",Does the review address Definition/Description/Detail/Discussion/Explanation/Interpretation?,TRUE,FALSE,"calls for a discussion/explanation of the improvements, which corresponds to Elucidation."
It seems completely unnecessary to me to have separate weights for the two RNNs.,Does the review address Methodology?,TRUE,FALSE,"critiques the design choice regarding separate RNN weights, which pertains to the methods used in the study, hence Methodology."
The authors should conduct experiments beyond English-to-French.,Does the review address Experiment?,TRUE,FALSE,"explicitly suggests conducting additional experiments, thus mentioning the experimental aspect."
Is Theorem 2 a stronger version in some sense because it applies for polylog input size?,Does the review address Theory?,TRUE,FALSE,"references a theorem and its theoretical implications, addressing the paper’s theoretical foundations."
Theorem 2 is presented with no intuition and the proof in the appendix is only for a special case.,Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"points out the absence of intuition, which is related to the aspect of intuition/justification/motivation/validation"
- The ablation study would be better if specific numbers were provided.,Does the review address Ablation?,TRUE,FALSE,It explicitly refers to an ablation study.
"Even though the results don’t show that the proposed loss function and proposed “conditional mean features” give improvements over baselines, the empirical results show that the basic assumptions and definitions in the theoretical analysis are relatively realistic.",Does the review address Analysis?,TRUE,FALSE,directly references the theoretical analysis and discusses how the empirical results relate to it.
"By converting the logic forms to natural languages, the authors can leverage paraphrase datasets and pre-train the critic as a paraphrase model.",Does the review address Data/Task?,TRUE,FALSE,"It references “paraphrase datasets,” which relates directly to data usage"
"Nonetheless, the current paper leaves too many open questions regarding the validity of the experiments.",Does the review address Intuition/Justification/Motivation/Validation?,TRUE,FALSE,"The review explicitly questions the validity of the experiments, thus referencing the validation aspect."
"There are various weaknesses of the MID data, but the evaluation approach needs to be discussed or justified.",Does the review address Data/Task?,TRUE,FALSE,The comment explicitly refers to the weaknesses of the MID dataset.
"While it is also true that corpus transfer _enables_ this divergence in model types, to really test whether transferring the whole model versus using the corpus works or not, I would think you would want to compare fine-tuning the sender GRU on the LM data vs. starting from scratch _with a GRU of the same type_ and pre-training on the EC corpus before fine-tuning.",Does the review address Comparison?,TRUE,FALSE,suggests comparing different approaches for testing model transfer effectiveness
"This is not new (see Rives 2020 and Vig 2020) and does not fit well to the rest of the paper, which is about contact prediction.",Does the review address Novelty?,TRUE,FALSE,critiques the lack of originality and relevance to the rest of the paper
I find the analysis presented in the paper very interesting and insightful - and distinguishes it from previous work in this area.,Does the review address Analysis?,TRUE,FALSE,Comments on the interesting and insightful analysis presented in the paper.
"It is reported that current system uses 527,830 documents for training, while 40,000 publications are held out for training baselines.",Does the review address Data/Task?,TRUE,FALSE,Mentions the dataset used for training and the publications held out for baselines.
Audio Instruction Generation (AIG) is also quite nice and interesting.,Does the review address Novelty?,FALSE,TRUE,The comment describes the work as “nice and interesting” but does not specifically address originality or innovation.
There are several such insights in the experiments section that will be helpful to the community.,Does the review address Experiment?,TRUE,FALSE,Refers to insights from the experiments section.
"Questions:   - Previous work has tried to combine both language-specific and shared parameters (Wang et al 2018), rather than making a binary choice between these.",Does the review address Methodology?,TRUE,FALSE,Refers to combining language-specific and shared parameters in previous work.
"- Table 5 the VAE(32) method performs the best overall in ""Wiki section"" although the TC (16) method has been highlighted as the best.",Does the review address Presentation?,FALSE,TRUE,"The comment only focuses on the methods' performance, not on clarity, structure, or any other presentation aspect."
