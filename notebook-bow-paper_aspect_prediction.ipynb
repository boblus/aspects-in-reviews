{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095ef75-3910-4fdf-9ebb-a1e0838bd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98df52-b2fd-4703-b285-0617b45bb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88515c54-a963-4de9-a6aa-f884d948bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_labels = 'coarse'\n",
    "column_name = 'COARSE'\n",
    "if type_of_labels == 'fine':\n",
    "    column_name = 'FINE'\n",
    "\n",
    "category_to_aspect = pd.read_csv(f'aspects - {type_of_labels}.csv')\n",
    "aspect_to_category = defaultdict(set)\n",
    "for i in range(len(category_to_aspect)):\n",
    "    if (type_of_labels == 'fine' and category_to_aspect[column_name].to_list()[i] not in ['Contribution', 'Definition', 'Description', 'Detail', 'Discussion', 'Explanation', 'Interpretation', 'Intuition', 'Justification', 'Motivation', 'Validation', 'Novelty', 'Clarity', 'Confusion', 'Figure', 'Grammar', 'Notation', 'Presentation', 'Table', 'Terminology', 'Typo', 'Related Work', 'Impact', 'Importance', 'Significance']) or (type_of_labels == 'coarse' and category_to_aspect[column_name].to_list()[i] not in ['Contribution', 'Definition/Description/Detail/Discussion/Explanation/Interpretation', 'Intuition/Justification/Motivation/Validation', 'Novelty', 'Presentation', 'Related Work', 'Significance']):\n",
    "        aspect_to_category[category_to_aspect['LLM annotation'].to_list()[i]].add(category_to_aspect[column_name].to_list()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb519a-3d13-410d-b8a4-a4b03c7db67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict()\n",
    "for venue in ['iclr20', 'iclr21', 'iclr22', 'iclr23', 'iclr24']:\n",
    "    with open(f'data/{venue}.json') as file:\n",
    "        data[venue] = json.loads(file.read())\n",
    "\n",
    "annotation = pd.read_csv('annotation - llm.csv')\n",
    "result = defaultdict(list)\n",
    "for venue in ['iclr20', 'iclr21', 'iclr22', 'iclr23', 'iclr24']:\n",
    "    with open(f'preprocessed/preprocessed-{venue}.json') as file:\n",
    "        preprocessed = json.loads(file.read())\n",
    "    for paper_id in preprocessed:\n",
    "        with open(f'data/papers/{paper_id}.txt') as file:\n",
    "            paper = file.read()\n",
    "        aspects = []\n",
    "        for item in annotation['annotation_1'][(annotation['venue'] == venue) & (annotation['paper_id'] == paper_id)].tolist():\n",
    "            aspects.extend(merge_synonyms(str(item).replace(' and ', ', ').split(', ')))\n",
    "        result['venue'].append(venue)\n",
    "        result['paper_id'].append(paper_id)\n",
    "        result['abstract'].append(data[venue][paper_id]['Abstract'])\n",
    "        result['keywords'].append(', '.join(data[venue][paper_id]['Keywords']))\n",
    "        result['title'].append(data[venue][paper_id]['Title'])\n",
    "        result['paper'].append(paper.split('\\nREFERENCES\\n')[0])\n",
    "        result['aspects'].append(list(set(aspects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d806b1-0650-42b8-aaef-e52e1f37b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = result['title']\n",
    "labels = result['aspects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a1f28-0836-4255-82d2-709e7d2bdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "for aspect, category in aspect_to_category.items():\n",
    "    categories.extend(list(category))\n",
    "categories = list(set(categories))\n",
    "labels_one_hot = []\n",
    "for item in labels:\n",
    "    output = np.zeros(len(categories))\n",
    "    for aspect in item:\n",
    "        if aspect in aspect_to_category:\n",
    "            for category in aspect_to_category[aspect]:\n",
    "                output[categories.index(category)] = 1\n",
    "    labels_one_hot.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa558d-295c-4b39-94dd-56918d964faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0471444-88d6-4cbc-9826-0727d010b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_data = int(len(texts)*0.9)\n",
    "train_texts = X[:number_of_data]\n",
    "train_labels = labels_one_hot[:number_of_data]\n",
    "eval_texts = X[number_of_data:]\n",
    "eval_labels = labels_one_hot[number_of_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465f896-742a-4c65-86e0-50784301ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2266\n",
    "classifier = OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=seed))\n",
    "classifier.fit(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3525852-c2c5-44cf-b30c-2e3f0d3c2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_one_hot = classifier.predict(eval_texts)\n",
    "print(classification_report(eval_labels, predictions_one_hot, target_names=categories, zero_division=0))\n",
    "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(eval_labels, predictions_one_hot, average='weighted', zero_division=0)\n",
    "print(round(precision_weighted, 4), round(recall_weighted, 4), round(f1_weighted, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35d68c-0aab-4e6e-b265-a39932393848",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals, predictions = [], []\n",
    "for item in eval_labels:\n",
    "    actual = []\n",
    "    for i in range(len(item)):\n",
    "        if item[i] == 1:\n",
    "            actual.append(categories[i])\n",
    "    actuals.append(actual)\n",
    "\n",
    "for item in predictions_one_hot:\n",
    "    prediction = []\n",
    "    for i in range(len(item)):\n",
    "        if item[i] == 1:\n",
    "            prediction.append(categories[i])\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "similarity = calculate_jaccard_similarity_for_lists(actuals, predictions)\n",
    "round(sum(similarity) / len(similarity), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a2622-f29d-4d60-a866-cb05c40fbeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
