{
    "9JQtrumvg8": {
        "tE1mdCrUjm": {
            "0": "Overall the reviewer found the experiments are well designed in supporting their claims of 1) the overall methods is much better than using a single LLM and 2) the HTML-T5 is an advance by itself.",
            "1": "The most recent models are included in the experiments, and the evaluation datasets (mind2web and miniwob++) are used in training of both the proposed HTML-T5 and the baseline model long-T5.",
            "2": "Therefore, the reviewer has no concerns of unfair comparisons.",
            "3": "The presentation can be improved.",
            "4": "Please consider revise the writing to avoid the questions below."
        },
        "tBq0fKvsxm": {
            "0": "This work is making a significant contribution to the field by providing two models: one encoder-decoder that reads, understand and summarizes HTML pages: HTML-T5; and one WebAgent that combines the previous model with a code generation model (Flan-U-PaLM) to act and follow instructions on synthetic and real websites.",
            "1": "Some notable strengths of the proposed architecture are:\n- To capture long-range dependencies in long documents, HTML-T5 uses both local and transient global attention similar to Long-T5.",
            "2": "In addition it is pre-trained on various long-range denoising objectives.",
            "3": "- To be able to execute actions on real websites, WebAgent produces executable Python code instead of discrete and non-generalizable HTML actions.",
            "4": "This allows the agent to handle any action space present in real HTML pages instead of being limited to a set of fixed actions.",
            "5": "Experimental results show that WebAgent is able to solve tasks in real websites.",
            "6": "Overall, this is a strong paper, however, one weakness of this work is the lack of baselines to compare results against in real-world tasks.",
            "7": "Table 1 provides good ablation study insights into the proposed WebAgent but there are no other Agents to compare to.",
            "8": "Similarly in Table 3, HTML-T5 is only compared against MindAct on Mind2Web.",
            "9": "Are there any other agents that could be used on this benchmark?",
            "10": "---\n\nAnother weakness of this work is its clarity and ease of comprehension.",
            "11": "Some aspects of the paper were not entirely clear, in particular how was HTML-T5 trained to predict sub-instruction plans and HTML summaries?",
            "12": "What data supervision was used for that?",
            "13": "Similarly, it is not entirely clear what HTML-T5 produces: Figure-3 indicates \"HTML-snippets\", but the paper mentions multiple times that it \"summarizes\" HTML pages (so it should produce a summary?",
            "14": "), and in Section 3.2 the paper states that it predicts ``_the corresponding data-ref attributes_''.",
            "15": "If the model outputs only data reference IDs (like suggested also with Figure 6) then this is not summarization but more like information retrieval and the paper should reflect this.",
            "16": "In addition, if object references are what is really being predicted, then it is not clear how Flan-U-PaLM make use of that information without having access to the raw HTML containing these objects.",
            "17": "Another confusion is the window size of HTML-T5: in Section 3.1 it is mentioned that the input sequence length of HTML-T5 is 4096, but in section 4.2 it uses 16k tokens for the context window.",
            "18": "Which one is it?",
            "19": "16k tokens seems more likely overall since the model is supposed to take as input instruction, previous sub-instructions, and raw HTML.",
            "20": "Just the raw HTML would overflow the 4096 context size as mentioned in the paper and illustrated by Figure 2.",
            "21": "After reading 4096 in Sections 3.1, it was hard to understand how all inputs of HTML-T5 would fit in such a small window (especially after seeing Figure 2).",
            "22": "---\n\nEventually, one important thing that the paper should discuss is the difference between train and test settings.",
            "23": "It seems like WebAgent was trained on all domains individually.",
            "24": "What precautions were made to ensure that the testing tasks do not overlap with the ones used during training?",
            "25": "---\n\nMinor: some syntactic mistakes make the paper hard to read sometimes."
        },
        "hzzmAausZD": {
            "0": "The model's usage of HTML-T5 for planning and summarization is effective and novel, and the overall performance is good.",
            "1": "Especially on Mind2Web, it significantly pushes the upper bound of performance.",
            "2": "Because the model relies on Flan-U-PaLM with 540B parameters, it's difficult to judge how reliant the method is on the ability of this particular model to generate executable code.",
            "3": "The organization of the paper could be improved, including more details about how feedback was acquired and finetuning was done to enable planning and summarization (i.e.",
            "4": "Fig 6 in appendix)"
        },
        "MujrL4V6CP": {
            "0": "The paper has several strengths:\n\n----\n1.",
            "1": "Unlike prior works, there is a focus on real world application.",
            "2": "Demonstrating success in real-world web navigation tasks provides a strong case for the practical application of this research.",
            "3": "This has implications for the usability and deployment of AI systems in everyday tasks.",
            "4": "----\n\n\n2.",
            "5": "The collaborative approach, where different models work together to complete tasks, showcases a novel use of ensemble techniques in a practical setting, which encourages more research in model collaboration.",
            "6": "There is also additional benefits of such a modular approach, in that scalability and error analysis becomes easier.",
            "7": "The use of an ensemble of specialized models to address specific aspects of the problem space, is a departure from the trend of using a single generalist model for all tasks.This specialization can lead to performance improvements and more efficient computation.",
            "8": "1.",
            "9": "Especially for this kind of work, the broader impacts section should be in the main text and should be fully fleshed out.",
            "10": "This is a significant weakness in this work.",
            "11": "-----\n\n2.",
            "12": "It would be good to have a baseline comparison comparing what performance looks like with model scale.",
            "13": "Flan-U-PaLM is a 540B parameter model which puts it at a scale inaccessible to many researchers.. it would be good to benchmark how this approach scales from small accessible open source models, to the large ones used in this work.",
            "14": "----"
        }
    },
    "BrtOzgElD7": {
        "wkP9AJALaG": {
            "0": "This paper provided a game model to study the alignment problem of LLMs.",
            "1": "Through the Nash equilibrium, experiments show that the proposed approach improved the security of LLMs.",
            "2": "*It is not clear to me why RTG is a team game.",
            "3": "For example, as shown in Figure 2, it is enough to model the game as an RLM and a BLM.",
            "4": "*This work assumes a team of RLMs, but some sentences are confusing: “It is worth noting that red team can be expanded to consist of multiple RLMs in RTG.",
            "5": "In this work, we mainly discuss the red teaming task of single RLM.”\n\n*This paper aimed to establish a rigorous mathematical model named RTG (Red Teaming Game) for the red teaming task of language models.",
            "6": "However, the game is not formally defined.",
            "7": "In the main text, the strategy space and utility function are not defined.",
            "8": "Some symbols are not defined as well, e.g., \\pi.",
            "9": "The concept of Nash equilibrium is not formally defined.",
            "10": "*It is unclear how the proposed algorithm guarantees an \\epsilon-approximate Nash equilibrium.",
            "11": "That is, no theoretical results are provided.",
            "12": "*Without formally defining the game and the problem, it is hard to follow the experiment part.",
            "13": "*RLM is a bad guy, but this paper ‘aim to maximize the utility for RLMs and minimize the utility for BLM in multi-turn dailogue.’\n\nTypo:\n“illustrates The variation”\nCaption (e) is missing in Figure 3\n “forms.",
            "14": "topics”"
        },
        "nWwhA5QnsH": {
            "0": "I like how the experiments are divided into many different categories of harm.",
            "1": "I think it adds thoroughness and clarity.",
            "2": "1.",
            "3": "“Existing work rely solely on manual red team designs and heuristic adversarial prompts for vulnerability detection and optimization.” is not true.",
            "4": "There are many examples of automated black and white-box attack methods for LLMs.",
            "5": "2.",
            "6": "The key to the paper’s contribution seems to be about using RL to train a population of adversarial LMs.",
            "7": "I don’t see much value in how the paper wraps this process up in a game theoretic framework.",
            "8": "Moreover, if a classifier for toxicity is already available, why not just perform adversarial training on examples that are selected by the classifier or optimized to elicit responses deemed toxic by it?",
            "9": "These would seem to be strong baselines.",
            "10": "3.",
            "11": "Relatedly, what is the purpose of using a population of red LLMs to each produce different turns in the conversation instead of a single one?",
            "12": "4.",
            "13": "I find the presentation overall to be very poor and confusing.",
            "14": "Much more than usual, I find myself struggling to understand parts of the paper after reading them multiple times.",
            "15": "Algorithm 1 is an example of this.",
            "16": "For example, it is not clear how the RLM and BLMs are initialized, whether exploitability is computed from individual turns or entire conversations, what the difference between the RLMs and policies are, what a “strategy” is (it is never defined at any point in the paper), what it means to compute a meta strategy (is this RL?",
            "17": "), how a meta strategy can be computed insider the loop from U which seems to be initialized outside the loop and never updated, what the relationship between a strategy and a nash equilibrium is, what an oracle is, what a “missing entry” is, what a “diversity measure of semantic space” and what the star notation means.",
            "18": "I simply do not think I can properly review this paper given how it is written.",
            "19": "5.",
            "20": "There is no comparison to a baseline or benchmark.",
            "21": "6.",
            "22": "Casper et al.",
            "23": "(2023) is incorrectly described.",
            "24": "It does not involve manual design of adversarial prompts.",
            "25": "It involves using human feedback to develop a contextual measure of the harmfulness of text."
        },
        "VVhJFGdM81": {
            "0": "Strengths:\n- The paper is topical and interesting to read, but I have some concerns about the current presentation of the results, as written in the next comment section (weaknesses).",
            "1": "- To my understanding, game-theoretic approaches to red teaming / adversarial attacks have not been extensively studied in the literature on LLMs.",
            "2": "Furthermore, much of the literature on red teaming and adversarial attacks focuses on \"single turn\" prompting, which doesn't capture sequential nature of dialog interactions.",
            "3": "I think this is an important research direction, and the results of this paper provide an interesting starting point.",
            "4": "- The set of results suggest that the dialog meta-games, as formalized in this work, can improve the alignment of language models, making them less susceptible to jailbreaking attacks, and can be used as an oversight technique, indicating potential vulnerabilities or LLMs.",
            "5": "Weaknesses: \n- As I mentioned in the previous section, the presentation of this paper could be improved.",
            "6": "I find it strange that the formal setting is provided only in the appendix.",
            "7": "Given that one of the main contributions of this work is a game theoretic framework, this formalism should be provided in the main part of the paper.",
            "8": "Another important contributions, a measure of diversity in semantic space is also only explained in the appendix.",
            "9": "At the moment, the main part of the paper doesn't look self-contained, and doesn't adequately explain relevant information.",
            "10": "There are also quite a few typos in the paper, the font in some of the figures is too small, some of the figures take too much space (Fig 4a and 4d), and I generally believe that the clarify could be improved.",
            "11": "- The approach is grounded in the set of techniques previously considered in multi-agent reinforcement learning, but adapted to LLM dialog scenarios.",
            "12": "From a technical point of view, the proposed approach appears to be a direct application/extensions of DO or PSRO to LLMs.",
            "13": "That said, the application scenario is novel, and the paper considers a novel metric for semantic diversity.",
            "14": "- Generally, I found the set of experimental results somewhat limited, as explained below.",
            "15": "- The experiments focus on one model with 3B parameters: a) it's not clear whether the approach would scale to larger model sizes, given the complexity of the setting, b) it would be much more interesting to see whether weaker RLMs can perform red teaming of BLM that uses a different/larger LLM.",
            "16": "- The paper does not consider any baselines.",
            "17": "Given that prior work has considered red-teaming with LLMs (e.g., (Perez et al., 2020)), one would expect some comparison to these approaches, e.g., in 1 turn scenarios.",
            "18": "- The paper limits the interaction scenario to 3 turns.",
            "19": "It's unclear why this hyper-parameter was set to this specific value.",
            "20": "It would be useful to see if the performance of RLMs/BLM would degreade for larger number of turns.",
            "21": "- It's not clear why existing classifiers for hate speech were not used as an independent measure for toxicity.",
            "22": "It's also not clear some other measures of diversity were not used in the evaluation, e.g., those based on Self-BLUE (e.g., as in Perez et al.",
            "23": "2020)).",
            "24": "- There are no ablation studies.",
            "25": "The experimental results don't demonstrate the importance of having a population of RLMs."
        },
        "iN3ESsXUig": {
            "0": "I appreciate the author's efforts in formulating red teaming from a game-theoretic perspective.",
            "1": "- Presentation is unnecessarily complex.",
            "2": "Too many unnecessary acronyms harm readability.",
            "3": "The value of formulating red-teaming as a game is unclear.",
            "4": "In the introduction, the author said the drawback of prior works is the requirement of manual annotations, but the proposed method also requires manual annotation on the reward function.",
            "5": "I agree the proposed method doesn't require humans to design the toxic or harmful prompts.",
            "6": "But still, this doesn't directly lead to formulating red teaming as a game.",
            "7": "I suggest the author focuses on explaining why game-theoretic formulation can mitigate the issue of red teaming instead of diving into a dense explanation of \"how red teaming is formulated as a game.\"",
            "8": "This is one of the major weaknesses of this paper that makes me give strong rejection.",
            "9": "- Presentation is poor.",
            "10": "Figure 3 is extremely dense and can clearly be split into more figures.",
            "11": "Also, the figures are barely visible.",
            "12": "- Diversity metric should be presented in the main paper, given that this is important in the proposed method.",
            "13": "Similar for reward function definition, I found the definition of reward function in appendix but that is still far from clear.",
            "14": "How you define reward is important in red teaming so I would suggest the author elaborate the definition of rewards.",
            "15": "- The presentation of experimental results in Section 4.1 is hard to follow.",
            "16": "First, I cannot get the main idea and the purpose of this section in the first place.",
            "17": "I can see the author is trying to explain how the evolution between RLM and BLM matches the formulation and arrives at Nash Equilibrium, but the presentation needs improvements.",
            "18": "Also, the fact that BLM doesn't respond toxic text at prompts given by RLM doesn't imply that BLM won't generate toxic responses in other prompts.",
            "19": "It's necessary to evaluate the safety of BLM in other prompts.",
            "20": "- There are several diversity metrics in NLP.",
            "21": "What's the difference between the author's diversity metric and NLP?",
            "22": "The motivation for developing a new diversity metric needs to be justified.",
            "23": "-  How natural or fluent is the generated text?",
            "24": "One concern when optimizing LLM with a reward model is that the RL policy can hack the reward model and generate unnatural text to get high rewards.",
            "25": "Unnatural text are undesired in red teaming as red teaming is purposed for simulating interactions with human users, and humans won't generate that text.",
            "26": "The requirement of generating natural text is the major distinction to adversarial attacks.",
            "27": "I suggest the author conducts a human study to evaluate the naturalness of text.",
            "28": "If the generated text are not natural, it would be a critical flaw that has to be fixed.",
            "29": "- Lack of baseline comparison.",
            "30": "If the author wants to argue that the proposed method is a better automated red-teaming method, the author should compare with the existing red-teaming method to show the significance.",
            "31": "For example, the baselines proposed in Perez et al.",
            "32": "2022 are valid baselines to compare with.",
            "33": "This comparison is necessary to show the significance of this method."
        }
    },
    "ecbRyZZmKG": {
        "QAMswUDWgw": {
            "0": "1.",
            "1": "The article is well-structured, starting with a thorough discussion on the shortcomings of naive backdoor-type watermarking methods before delving into their novel DOUBLE-I WATERMARKING FRAMEWORK.",
            "2": "This logical progression effectively addresses the challenges initially posed.",
            "3": "2.",
            "4": "The authors introduce a BACKDOOR DATA PARADIGM that aptly fulfills the requirements for Uniqueness and Imperceptibility in watermark embedding.",
            "5": "The overall problem is framed as a judgment question, further enhancing the method's Uniqueness and Efficiency.",
            "6": "3.",
            "7": "The paper features extensive experiments that convincingly validate the effectiveness of the proposed method.",
            "8": "Beyond this, the authors conduct a multifaceted set of tests, including a non-harmful test to ensure that the watermark embedding does not significantly degrade model performance, robustness tests against second-time fine-tuning and model quantization, and an ablation study concerning the reference set to further substantiate the rationality of their backdoor data framework design.",
            "9": "1.",
            "10": "As pointed out by the authors in section 3.3.1 \"TRIGGER IN 'INPUT' KEY,\" decorations can utilize specific keywords or phrases that are rare in regular instructions.",
            "11": "Such rarity, however, could potentially be a drawback for these types of watermarking methods.",
            "12": "Given that the target environment is cloud-based LLMs, providers could preprocess user inputs to filter out these decorations and triggers, thereby causing erroneous verifications.",
            "13": "The design of triggers, in this context, warrants a more nuanced discussion by the authors.",
            "14": "2.",
            "15": "In section 3.3.3 \"THE MIX-UP OF MULTIPLE TYPES,\" the authors mention that \"it is possible to embed multiple Double-I watermarks in a model, which theoretically has the potential to enhance the robustness of our watermarking technique.\"",
            "16": "The theoretical substantiation for this claim is lacking, especially considering that multiple types of watermarks could interact and affect each other.",
            "17": "More theoretical proofs or appropriate literature citations are needed to validate this assertion."
        },
        "C7DaMdAJsg": {
            "0": "Here are some potential strengths discussed in the paper: \n1.",
            "1": "Robustness Against Removal Attacks: The proposed \"Double-I watermark\" method has been designed to be robust against attacks aimed at removing the watermark, ensuring that copyright protection remains intact even under adversarial conditions.",
            "2": "2.",
            "3": "Imperceptibility and Uniqueness: The watermark introduced by the method is imperceptible, meaning it doesn’t affect the model's normal functionality or output, and it is unique, allowing for clear identification and copyright protection of the customized LLMs.",
            "4": "3.",
            "5": "Comprehensive Evaluation: The paper includes a thorough evaluation of the proposed method, assessing various aspects such as harmlessness, robustness, uniqueness, and efficiency, demonstrating the method’s practical viability and effectiveness in real-world scenarios.",
            "6": "1.",
            "7": "Limited Exploration of Attacks: The paper primarily focuses on second-time fine-tuning and model quantization as watermark removal attacks.",
            "8": "The exploration of other potential attacks,such as pruning, that might be used to remove or alter the watermark seems limited.",
            "9": "2.",
            "10": "Dependency on Specific Paradigms: The watermarking method relies on specific paradigms for embedding the watermark, and its effectiveness might be influenced by the choice of these paradigms, limiting its flexibility and adaptability.",
            "11": "3.",
            "12": "Uniqueness Challenges: The paper mentions challenges in ensuring the uniqueness of the watermark, particularly in distinguishing whether certain behaviors stem from the model’s inherent traits or the embedded watermark."
        },
        "fVWfHdqiw4": {
            "0": "1.",
            "1": "The design of reference set to complement the trigger set is interesting.",
            "2": "2.",
            "3": "The overall presentation is easy to follow.",
            "4": "1.",
            "5": "Lack of teachnical contribution.",
            "6": "This method is an improvement of the naive judge question based watermarking.",
            "7": "The overall process is still naive, which lacks theoretical or technical contents.",
            "8": "2.",
            "9": "Lack of introduction of related work.",
            "10": "Various black box model watermarking schemes have been proposed recently, including LLM watermarking, while the most recent model watermarking scheme cited in this paper is published in 2019.",
            "11": "3.",
            "12": "Since the authors mention several times regarding the efficiency, it should be evaluated to justify the advantage of the proposal.",
            "13": "This is unfortunately not seen in the experiments.",
            "14": "4.",
            "15": "There is no quantitative comparison against the naive approaches or the existing black box LLM watermarking schemes."
        },
        "onuF5gdmQx": {
            "0": "- The paper is well written and comprehensible, with nice formulation that is easy to understand.",
            "1": "- Innates difficulty of watermarking finetuned LLMs are discussed, which are important for building an algorithm.",
            "2": "- The algorithm is simple and effective, experimental results demonstrate its watermarking capability in five essential properties.",
            "3": "- Extensive experiments are conducted to study the effectiveness of the method in many practical usecases.",
            "4": "- Related works should be discussed in more detail, there are many recent watermarking techniques for LLM in the literature.",
            "5": "- The strategy is applicable for instruction tuning only, whereas there are other ways to finetune LLM with a service provider, restricting the utility of the method in practice.",
            "6": "- The paper should briefly introduces Fisher’s exact test, show its results and how we accept or reject a hypothesis.",
            "7": "For example, in Table 2, the distributions on trigger set and reference set of clean model finetuned with LORA are quite different."
        }
    },
    "s4mPCrSNUZ": {
        "1gzlmrx71L": {
            "0": "## Improved empirical performance\nThe authors have demonstrated improved empirical performance, which is commendable.",
            "1": "## Not open-source\nThe absence of open-source code hampers follow-up studies and comparisons, thereby limiting the community contribution.",
            "2": "## Limited technical advancement\nIt sounds like the primary distinction of SPDesign from earlier methods appears to lie in the feature input to the model, aligning the contribution more with traditional bioinformatics through feature engineering, rather than advancing machine learning techniques.",
            "3": "Furthermore, as acknowledged by the authors, leveraging historical analogs for modeling guidance is a well-trodden idea in this field[1], which suggests a constrained conceptual contribution.",
            "4": "## Ill-defined task\nIt is noteworthy that the task of predicting protein sequences given a backbone structure is ambiguously defined.",
            "5": "Conventionally, in protein design, the backbone and sequence are designed concurrently, underscoring a more common practice in the field[2].",
            "6": "## Lack of Accessibility to a General AI Audience\nThe manuscript employs certain acronyms such as USR-V and TM-align without elucidation, which may impede comprehension for a general ICLR audience.",
            "7": "Reference:\n[1] Song, Y., DiMaio, F., Wang, R. Y. R., Kim, D., Miles, C., Brunette, T. J., ... & Baker, D. (2013).",
            "8": "High-resolution comparative modeling with RosettaCM.",
            "9": "Structure, 21(10), 1735-1742.",
            "10": "[2] Watson, J. L., Juergens, D., Bennett, N. R., Trippe, B. L., Yim, J., Eisenach, H. E., ... & Baker, D. (2023).",
            "11": "De novo design of protein structure and function with RFdiffusion.",
            "12": "Nature, 620(7976), 1089-1100."
        },
        "v3sV8l8Gkb": {
            "0": "Paper demonstrates that the combination of several existing ideas (addition of sequence profile information, pretrained models and GNNs for protein design) allows to improve over several state-of-the-art methods across investigated quality metrics.",
            "1": "Additionally authors provide an ablation study allowing for deeper understanding of how each of the individual components affects final performance and verify their predictions in silico with orthogonal folding method.",
            "2": "USR-V similarity search method described by the authors is a moderately small extension of the original papers (Ballester et al, 2007, J. Comput.",
            "3": "Chem and Guo et al.",
            "4": "2022, Bioinformatics).",
            "5": "Overall the paper is well written, structured and easy to follow.",
            "6": "It touches on one of the fundamental problems in computational biology and research in this direction may have potential to enable accurate and rapid design of functional protein molecules for use in medicine or green industries.",
            "7": "- As one of the contributions of the paper authors mention an \"improved ultrafast shape recognition algorithm (...), facilitating the efficient search for structural analogs\".",
            "8": "I believe that this statement is not properly supported by the data, in particular:\n\na) It's not clear how the method speed compares to state-of-the-art tools like FoldSeek (van Kempen et al, 2023, Nat Communications), 3D Zernike approach used in the PDB structural searches (Guzenko et al, 2020, Plos Comput Biol).",
            "9": "b) It's also not clear how efficient the method is compared to e.g.",
            "10": "FoldSeek in extracting analogous structures.",
            "11": "The pre-alignment step relies on global shape comparison which can prohibit from detection of some of sub-domain sized analogous fragments or fail to work with multidomain proteins (I also miss discussion of this in limitations of the authors approach).",
            "12": "I believe that extra experiments and comparisons are required to support the statements for this part or the text should be rewritten.",
            "13": "- SPDesign workflow is compared to the methods that do not take advantage of sequence profiles.",
            "14": "I agree with authors that combination of sequence profiles and GNNs for protein design can be considered as novel and interesting but there are already several available design methods that rely on the MSAs or PSSMs - e.g.",
            "15": "Sgarbossa et.",
            "16": "al, 2022, Elife or traditional Rosetta(Scripts) FavorSequenceProfile mover, to name a few.",
            "17": "I believe that statements in the paper could be more convincing if authors add more MSA-related baselines.",
            "18": "Also, to large extent, authors fail to discuss these more traditional but still large and meaningful body of work in the related work section.",
            "19": "- Lack of diverse metrics & analyses.",
            "20": "Protein design is a complex problem and frequently multiple solutions are equally good / stable for a given input backbone structure.",
            "21": "Native sequence recovery is an important metric but doesn't tell the full story about the method properties and performance.",
            "22": "I think it'd be valuable to understand e.g.",
            "23": "how diverse are the sequences generated by the SPDesign for a given backbone, how closely designs resemble the natural sequence profiles, is the performance equal or better / worse for particular secondary structure elements or surface / buried residues?",
            "24": "(see e.g.",
            "25": "Ó Conchúir et al, 2015, Plos One, Ollikainen et al, 2013 Plos Comput Biol, Castorina et al, 2023, Bioinformatics for more examples of metrics / analyses)"
        },
        "UZQvWAWgTG": {
            "0": "In addition to improved accuracy, the paper highlights two strengths.",
            "1": "1.",
            "2": "It utilizes ultrafast shape recognition vectors (USR-V) for efficient searching of similar protein structures, significantly reducing computational time compared to TM-align.",
            "3": "2.",
            "4": "The proposed method is applicable to orphan proteins and de novo protein design, making it suitable for practical design applications.",
            "5": "3.",
            "6": "The paper is well-written and easy to follow.",
            "7": "The paper incorporates sequence profiles from similar analogs, but the network structure lacks novelty compared to recentworks.",
            "8": "Additionally, the comparison of orphan protein and de novo protein experiments using box-whisker plots lacks specification on the datasets being compared."
        },
        "SAjRtfAj5h": {
            "0": "(+) Novel concept of creating sequence profiles from analogs to provide guidance\n\n(+) Significant performance gains demonstrated on benchmark datasets\n\n(+) Ablation studies confirm value of sequence profile.",
            "1": "(-) More analysis is needed on the quality and diversity of analog structures found, and how this impacts performance.",
            "2": "Are certain analog types more useful than others?",
            "3": "(-)  The search process for analogs seems computationally expensive.",
            "4": "Can this be made more efficient?",
            "5": "How sensitive is performance to the analog search parameters like number of clusters, analogs etc?",
            "6": "(-) Writing of the manuscript could be largely improved.",
            "7": "The presentation could be tightened up and made more concise in places to improve clarity and flow."
        }
    },
    "zEHGSN8Hy8": {
        "TDT0xBIy0x": {
            "0": "- The paper proposes a novel and simple method to fine-tune existing pre-trained embeddings to be fit to set-based operations.",
            "1": "- The results in the artificial setting show the feasibility of the method for several different sentence embedding\n- The case studies show interesting results that present the method's potential.",
            "2": "- Representing set operation with embedding is not novel, but the comparison and discussion compared with existing methods are missing.",
            "3": "- Vitalii Zhelezniak, Aleksandar Savkov, April Shen, Francesco Moramarco, Jack Flann, Nils Y. Hammerla Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors.",
            "4": "ICLR 2019.",
            "5": "- Siddharth Bhat, Alok Debnath, Souvik Banerjee, and Manish Shrivastava.",
            "6": "Word Embeddings as Tuples of Feature Probabilities.",
            "7": "RepL4NLP.",
            "8": "2020.",
            "9": "- Shib Dasgupta, Michael Boratko, Siddhartha Mishra, Shriya Atmakuri, Dhruvesh Patel, Xiang Li, and Andrew McCallum.",
            "10": "Word2Box: Capturing Set-Theoretic Semantics of Words using Box Embeddings.",
            "11": "ACL2022.",
            "12": "- The set operation presented in the paper does not satisfy the commutative law, and it orders the elements in the first set.",
            "13": "This is not the usual set theory, and the users may be confused if they use the method that supports usual set operations, but the limitations are not discussed in detail.",
            "14": "- The quantitative evaluation is performed only in artificial settings, and there are only case studies for the application results.",
            "15": "It is unclear how the method can be stably used for the application."
        },
        "t3JC5HiNpK": {
            "0": "1.",
            "1": "The paper formulates the sentence retrieval problem as a combination of sentence-set similarity and set operations, which is novel for the community.",
            "2": "2.",
            "3": "The paper provides a comprehensive set of experiments, introducing two new settings: set intersection and set differences.",
            "4": "It uses multiple baselines to demonstrate the robustness of the framework.",
            "5": "The paper also offers sentence embedding visualizations to illustrate the improvement in sentence representations.",
            "6": "Additionally, the paper presents detailed hyperparameters and offers quantitative justification for the proposed framework\n3.",
            "7": "The paper provides three different downstream applications.",
            "8": "Each is paired with background papers and results to show the effectiveness of the proposed methods.",
            "9": "1.",
            "10": "The paper would benefit from an additional experiment on sentence retrieval, similar to the one in Section 6.1.",
            "11": "In this setting, the paper could compare its performance against traditional retrieval-based methods such as DPR and BM25 to better illustrate the model's improvements.",
            "12": "Furthermore, in Table 2, certain baseline models do not show significant improvements with SetCSE.",
            "13": "For instance, the improvements for SGPT are marginal when compared to other baselines.",
            "14": "The paper should include an analysis explaining the variations in improvements among different models\n2.",
            "15": "The core concept is to create clusters of sentences with semantic meaning, and this can limit the generalization ability of the proposed framework.",
            "16": "In comparison to other baselines, the incorporation of semantic meaning within sets naturally provides additional information for training.",
            "17": "3.",
            "18": "The paper fails to provide code."
        },
        "OecP3CIS1V": {
            "0": "The idea of this paper is really clever, simple and straightforward.",
            "1": "The motivation is there, provide a LLM with notions of set theory to improve it in terms of search capabilities.",
            "2": "Experimentation seems reasonable and enough.",
            "3": "Proves the point authors want to provid\n\nThe authors make a good point to show the capabilities brought by the new training regime.",
            "4": "However, there is no analysis on capabilities that are lost because of it.",
            "5": "Do the models train with this regime underperform on sentence similarity or information retrieval datasets."
        },
        "NduXqt9Rba": {
            "0": "1.",
            "1": "Provides a well-defined and practical framework that enables complex information retrieval tasks which are not possible with current search methodologies.",
            "2": "2.",
            "3": "Applies contrastive learning to sentence embeddings in a unique way, emphasizing contextual differentiation between sets of sentences.",
            "4": "3.",
            "5": "Offers compelling real-world applications, such as parsing nuanced topics like ESG stances from earnings calls, highlighting the framework’s potential for practical deployment.",
            "6": "1.",
            "7": "There is no mention of an error analysis which would be beneficial in understanding the limitations of SetCSE in certain scenarios.",
            "8": "2.",
            "9": "The applications of complex semantic search, data annotation, and new topic discovery are very cool with the detailed examples, but there is not quantification here or comparison with others with existing set methods from the literature (same with Table 1 and 2 as well).",
            "10": "Do you have comparisons with other methods from the literature on this topic?",
            "11": "Typos:\nSection 7 \"DISUCSSION\""
        }
    },
    "V4fyVlX13y": {
        "vppGXj6LIe": {
            "0": "1.",
            "1": "While minimum Bayes risk (MBR) training is a well-known method for ASR, it has not received adequate attention for MT, perhaps because it is hard to agree upon a good definition of “risk” for this task which is efficient to compute.",
            "2": "As such, this paper should fill this gap.",
            "3": "Since MT can have multiple correct “alignments”, the authors define a segment-level Levenshtein distance function (sMED) for this task.",
            "4": "2.",
            "5": "Section 2 is effective (at the cost of being a little too verbose) in explaining the discrepancy between training and evaluation metrics, in terms of Hamming distance and Levenshtein distance.",
            "6": "3.",
            "7": "The proposed MED training gives small BLEU score improvements on IWSLT data, and significant WER improvements on LibriSpeech (100h).",
            "8": "The two main weaknesses in the paper are novelty and empirical results, which I will describe in detail below.",
            "9": "### MBR training is well known\n\nMinimum edit distance training is essentially a form of minimum Bayes risk (MBR) training where the risk function is Levenshtein distance between the reference and predicted sequences.",
            "10": "MBR training has a long history in ASR, with instantiations in minimum phone error (MPE) [1], state-level minimum bayes risk (sMBR) [2], and MED training.",
            "11": "In fact, the authors have cited [2] in the “Related Works” section (which is unfortunately delegated to the Appendix), but they fail to make the connection.",
            "12": "Instead, they have strangely focused more on “scheduled sampling,” which is just a training hack to reduce overconfidence in models trained with teacher forcing.",
            "13": "Aside from choices of the risk function, MBR training has been explored in the context of hybrid HMM-based models [2], RNN-transducers [3], and attention-based encoder-decoders [4].",
            "14": "The last one, in particular, uses MED training for the same type of models as proposed in the paper.",
            "15": "The main difference between the strategy proposed in the paper versus these in literature is that the authors compute the risk against a single sequence obtained using autoregressive decoding.",
            "16": "I would argue that this is, in fact, a weaker version of traditional MBR training, which computes the “expected” risk.",
            "17": "Even in machine translation, MBR has a rich history.",
            "18": "It has been primarily used for decoding [5] but has also seen use in training of statistical MT models [6].",
            "19": "The authors have not situated their paper against any of these well-known works, which comes across as ignorance of prior work.",
            "20": "Once we take into account all these existing (but not cited) work, the remaining contribution of the paper is two-fold: (i) segment-level edit distance for MT, and (ii) using MED training for the calibration function.",
            "21": "In my opinion, while (i) is a clever idea, it stands against the original motivation of reducing discrepancy between training and evaluation metrics — for example, [6] performed MBR training using BLEU score and showed that it improved BLEU metrics most, compared to edit distance based metrics.",
            "22": "This only leaves (ii) — it is interesting to see improvement in calibration errors, but this is not sufficient by itself considering lack of novelty in the main training method.",
            "23": "[1] Povey, Daniel and Philip C. Woodland.",
            "24": "“Minimum Phone Error and I-smoothing for improved discriminative training.” 2002 IEEE International Conference on Acoustics, Speech, and Signal Processing 1 (2002): I-105-I-108.",
            "25": "[2] Veselý, Karel et al.",
            "26": "“Sequence-discriminative training of deep neural networks.” Interspeech (2013).",
            "27": "[3] Weng, Chao et al.",
            "28": "“Minimum Bayes Risk Training of RNN-Transducer for End-to-End Speech Recognition.” Interspeech (2019).",
            "29": "[4] Cui, Jia et al.",
            "30": "“Improving Attention-Based End-to-End ASR Systems with Sequence-Based Loss Functions.” 2018 IEEE Spoken Language Technology Workshop (SLT) (2018): 353-360.",
            "31": "[5] Kumar, Shankar and William J. Byrne.",
            "32": "“Minimum Bayes-Risk Decoding for Statistical Machine Translation.” North American Chapter of the Association for Computational Linguistics (2004).",
            "33": "[6] Och, Franz Josef.",
            "34": "“Minimum Error Rate Training in Statistical Machine Translation.” Annual Meeting of the Association for Computational Linguistics (2003).",
            "35": "### MT results show only minor BLEU improvements\n\nThe experimental results section is rather sparse, and the provided MT results do not suggest significant improvements.",
            "36": "From Table 1, on most test sets, the BLEU score only improves by 0.5-1.0, with the relative improvement only about 2% in most cases.",
            "37": "Furthermore, the relatively simple “scheduled sampling” already recovers 50% of this improvement in most cases, so I don’t see why practitioners would implement MED training at all.",
            "38": "### ASR experiments are done on a “toy” task\n\nASR results are only shown on the 100h subset of LibriSpeech, which is almost a toy task at this point.",
            "39": "The authors should perform training and evaluation at least on the full 960h LibriSpeech.",
            "40": "In Appendix A, they have mentioned that they used 4 A100 GPUs for the MT experiments — this hardware should be quite sufficient to conduct experiments also on the full LibriSpeech.",
            "41": "Otherwise, readers may wonder whether these results were not shown because MED provided no improvement in this setting (which may very well be the case from my experience).",
            "42": "Besides the above limitations, I think it may be useful to reduce the space given to Section 2 (Background), since the train-eval discrepancy is already well known, and instead conduct more thorough evaluation."
        },
        "BXf8k5YEFg": {
            "0": "Interesting approach which should help for regularization and better generalization.",
            "1": "A lot of mathematical formulations are introduced, which are rather confusing and distracting from the method, and also have some problems (see details for an example).",
            "2": "The method could be explained in a much simpler way.",
            "3": "The Optimal Completion Distillation (OCD) conceptually leads to a very similar loss.",
            "4": "The Optimal Completion for any given prefix should be exactly what any possible Levenshtein alignment would give as the next possible targets for a given prefix.",
            "5": "The Optimal Completion even solves the problem of ambiguity when there are multiple targets possible, by mapping that to a target probability distribution instead of having a single target.",
            "6": "Given that this method is so similar, even looks almost the same (not taking the derivation/formulation into account, but just what you actually do in the end), this should be directly compared to, when presenting the method, to see the actual differences, and also in the experiments.",
            "7": "This is missing here.",
            "8": "The novelty is also limited, given that OCD is so similar.",
            "9": "The ASR experiments are only done on the Librispeech 100h subset, which is way too small to be relevant.",
            "10": "The whole Librispeech 960h should be used.",
            "11": "MBR training and OCD should be done for comparisons.",
            "12": "I.e.",
            "13": "not just citing results from another paper, but this should be done on the exact same model, within the same software, such that we really have a direct comparison.",
            "14": "No code is published?",
            "15": "ASR baseline is not good.",
            "16": "(I did not really check the translation baseline too much.",
            "17": "Maybe also not good.)",
            "18": "Many details missing."
        },
        "YfABJ47LZN": {
            "0": "1.",
            "1": "The paper is well-written and easy to follow.",
            "2": "2.",
            "3": "The empirical results show the usefulness of the approach.",
            "4": "3.",
            "5": "The calibration results are useful.",
            "6": "1.",
            "7": "Lack of comparison with minimum edit distance based training in ASR systems.",
            "8": "The idea of using the edit distance criteria for training the ASR model is quite well explored [1,2].",
            "9": "References:\n\n[1] Prabhavalkar, Rohit, et al.",
            "10": "\"Minimum word error rate training for attention-based sequence-to-sequence models.\"",
            "11": "2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).",
            "12": "IEEE, 2018.",
            "13": "[2] Tian, Jinchuan, et al.",
            "14": "\"Integrating lattice-free MMI into end-to-end speech recognition.\"",
            "15": "IEEE/ACM Transactions on Audio, Speech, and Language Processing 31 (2022): 25-38."
        },
        "u7Z67so9qh": {
            "0": "- The proposed idea is a new approach to mitigate the exposure bias issue, and optimize sequence level evaluation metric.",
            "1": "- The proposed method is intuitive and technically sound.",
            "2": "- It is a relatively straight-forward change in the training implementation.",
            "3": "- Consistent improvement over the MLE approach across all NMT and ASR tasks in the experiments.",
            "4": "- Calibration function performance also benefits from the proposed minimum edit distance loss, which in turn helps reduce WER as well.",
            "5": "- The analysis showing the proposed approach reduces the accumulated errors due to exposure bias, especially for longer sequences, is promising.",
            "6": "- Presentation is clear.",
            "7": "- There are already many methods to optimize the evaluation metrics in the sequence-level training, as the authors mention some of them.",
            "8": "E.g.",
            "9": "there are minimum WER and MBR based approaches for ASR, see some examples below.",
            "10": "But they are not compared in the ASR experiments in the paper.",
            "11": "The proposed method was mainly compared to MLE, which is a weaker baseline.",
            "12": "Even for NMT, only one task shows MBR result.",
            "13": "This seems to be a major drawback of the paper.",
            "14": "Prabhavalkar et al., Minimum Word Error Rate Training for Attention-based Sequence-to-Sequence Models, 2018\nShannon, Optimizing expected word error rate via sampling for speech recognition, 2017\nKingsbury, Lattice-based optimization of sequence classification criteria for neural-network acoustic modeling, 2009\n\n- Table 2 shows the results for different calibration functions.",
            "15": "It seems they are all done in the ASR model that was trained with MLE.",
            "16": "Can the same comparisons be done in the ASR model trained with MED as well?",
            "17": "Would the MED trained calibration still improve the MED trained ASR model performance further?"
        }
    },
    "wabp68RoSP": {
        "v1nJAage4i": {
            "0": "1.",
            "1": "Combining active learning with the selection process of prompt exemplars is a very intriguing and novel perspective.",
            "2": "2.",
            "3": "Experimental results from multiple datasets, coupled with comprehensive analysis, demonstrate the effectiveness of Active Prompt from various angles.",
            "4": "3.",
            "5": "In Section 5.3, the authors' experimental results indicate that uncertain exemplars are transferable, showcasing the superior generalization capability of the method.",
            "6": "1.",
            "7": "Need for Additional Corpora: One significant advantage of CoT is its ability to leverage the model's generalization capabilities, requiring only a minimal number of task-related samples to teach the model the paradigm for solving tasks.",
            "8": "In scenarios without corpora of the same distribution, such as ASDiv, SVAMP, and SingleEq, Active Prompt still needs to capitalize on the model's generalizability.",
            "9": "However, it struggles to achieve the same performance boosts as datasets with training corpora like GSM8K and AQuA.",
            "10": "2.",
            "11": "Differences in Uncertainty Measurement Methods: The authors introduced four methods of uncertainty measurement but did not delve deep into their differences.",
            "12": "It appears that “Entropy” has better generalizability on datasets like StrategyQA compared to “Disagreement”.",
            "13": "However, “Disagreement” outperforms on datasets like SVAMP and CSQA using code-davinci-002, as discussed in Question 2.",
            "14": "3.",
            "15": "Concerns Over Costs: Active Prompt seems to require an additional 1000*k API calls.",
            "16": "Given the recommended value of k = 10, an extra 10,000 API calls seems to be a considerably high cost.",
            "17": "Additionally, there's the cost associated with extra data annotation, as outlined in Question 3."
        },
        "Ffyp2oEkpM": {
            "0": "- Overall the paper is written clearly and proposes an approach for example selection for chain-of-thought prompting.",
            "1": "The method uses existing approaches from active learning and shows improvements over baselines.",
            "2": "- The authors evaluate their approach on a range of mathematical and commonsense reasoning tasks, and conduct ablations to understand the effect of different factors.",
            "3": "- The approach seems to have limited applicability as it requires the existence of either large enough datasets for a particular task or similar task to sample from.",
            "4": "The authors also report variations between different annotators, further attesting to the difficulty of the task.",
            "5": "- Some details in the paper are missing.",
            "6": "For example, how is the variance based approach applied to textual answers?",
            "7": "There are no results presented with the self-confidence approach and only an example is given, etc."
        },
        "7npC6M6GGh": {
            "0": "The idea is straightforward and the motivation is clear.",
            "1": "The method makes sense.",
            "2": "1.",
            "3": "**Baselines are too weak, leading to a misunderstanding of the effectiveness of the proposed method.",
            "4": "** I would like to urge the authors to include more powerful baselines in the experiment rather than hide them.",
            "5": "ALL the reviewers are experts in this domain and familiar with the state-of-the-art performance of LLMs on these benchmarks in this domain.",
            "6": "In the experiment section, the authors only include the CoT annotations from [1] as the most important baseline.",
            "7": "It is widely acknowledged and studied that the complexity (i.e., the length or reasoning steps of the CoT annotations) significantly influences the performance of the LLMs.",
            "8": "The annotations from [1] are very simple and short, only including some easy examples as in-context examples.",
            "9": "In comparison, if we look at Page 17, the actual annotations from the authors are very long and detailed.",
            "10": "Previous work [2] has already shown that by selecting the most complex examples from the training dataset, the performance can be largely improved compared to the original annotations from [1].",
            "11": "For example, by selecting the most complex examples, the performance of ChatGPT (i.e., gpt-3.5-turbo) can easily achieve more than 80% accuracy (without self-consistency) compared to the number 77.1% in Table 1.",
            "12": "One may also refer to https://opencompass.org.cn/leaderboard-llm for the performance of LLMs (I acknowledge that the performance of ChatGPT on GSM8K from that website is possibly still underestimated).",
            "13": "Without comparison with SOTA's performance, I will try my best to reject this paper.",
            "14": "Please do not try to hide the best baselines.",
            "15": "2.",
            "16": "**More ablation study is required.",
            "17": "** Again, the performance improvement may come from two aspects.",
            "18": "The first is selecting the most uncertain examples, and the second is making the CoT annotations longer.",
            "19": "The annotations in baseline [1] are much shorter compared to the annotations by the authors.",
            "20": "Without the ablation studies on these two aspects, we cannot determine whether the performance improvement truly comes from the author's contribution or just longer CoT annotations.",
            "21": "3.",
            "22": "**The method is simple with limited contribution, while performance improvement is not significant.",
            "23": "** The method is quite intuitive and can be regarded as an in-context example selection method (followed by annotations).",
            "24": "The authors should discuss the relationship with other in-context example selection methods and compare the performance.",
            "25": "Existing performance improvement is quite limited.",
            "26": "Once more baselines are included, it is very possible that the performance will be surpassed.",
            "27": "[1] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou.",
            "28": "Chain-of-thought prompting elicits reasoning in large language models.",
            "29": "In NeurIPS, 2022b.",
            "30": "[2] Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot.",
            "31": "Complexity-based prompting for multi-step reasoning.",
            "32": "In ICLR 2023"
        },
        "Q9hhaYKQsD": {
            "0": "- Combining active learning with prompt construction is interesting and novel to me\n- With the extensive experiments and analysis, the execution is definitely above average\n- Writing is clear\n\n- [Major] An important and very relevant baseline is missing: https://arxiv.org/abs/2210.00720.",
            "1": "Their method is very similar to Active Prompt and simply selects the longest training instances.",
            "2": "I would be curious to see how it compares to this work.",
            "3": "- [Major] One can imagine that if the model is reasonably good, the demonstrations selected by Active-Prompt will be more useful.",
            "4": "I wonder whether this is still the case for “weaker” models.",
            "5": "If the model does not know too much about the task, will the prompts selected by its uncertainty still be useful?",
            "6": "This can be tested out by trying Active-Prompt on, e.g., one of the smaller Llama models.",
            "7": "- [Major] The conclusion drawn on the transferability of prompts found by Active-Prompt in 5.3 needs more evidence.",
            "8": "All the models tested are from the GPT-3 family, which are finetuned from the same base model.",
            "9": "It is unclear whether, e.g, the prompts found by GPT-3.5 perform well for Llama.",
            "10": "This concern is important since it directly determines how useful Active-Prompt is in practice.",
            "11": "If the prompts do not transfer across different model families, it will have a huge overhead annotating a new set of instances for a different model.",
            "12": "Besides, it makes it impossible to do fair comparisons among models controlling the prompts.",
            "13": "I suggest adding an experiment studying the transferability between GPT and Llama models.",
            "14": "- To draw conclusions on the transferability of the prompts, Table 3 should compare, e.g., CD-002->TD-002 (SC) with TD-002->TD-002 (SC), instead of the non-Active-Prompt baseline.",
            "15": "- Some of the wordings are confusing, even misleading.",
            "16": "Please see the details below.",
            "17": "- A clear limitation of Active-Prompt is the high cost associated with doing inference runs over the training set.",
            "18": "A discussion about this would be nice."
        }
    },
    "LlG0jR7Yjh": {
        "NiRtlJqDT3": {
            "0": "(1) The paper presents an approach for the automatic generation of model-specific hallucination datasets through the utilization of existing fact-checking datasets.",
            "1": "(2) The paper is well-written with clarity and comprehensibility.",
            "2": "(1) The authors place considerable emphasis on the model-specific nature of the automatically constructed hallucination datasets.",
            "3": "It is unclear why the creation of such datasets is necessary, as they may not be applicable for evaluating other models due to their model-specific attributes.",
            "4": "Furthermore, the paper does not propose a method for leveraging these datasets to mitigate the generation of hallucinatory content by the models.",
            "5": "(2) The paper lacks a clear and coherent explanation of the interrelation between the two methods presented, namely hallucination dataset construction and hallucination detection.",
            "6": "(3) The paper's reliance on the concept of self-contradictions as a novel approach for detecting hallucination in LLMs is questionable.",
            "7": "Several prior studies have explored similar methodologies in hallucination detection, raising concerns about the novelty of the proposed method."
        },
        "5BhhmZ1SnB": {
            "0": "* This paper offers a nice way to repurpose existing datasets to test for hallucination\n* The detection results seem encouraging, especially over other methods.",
            "1": "* The hallucination this paper tests for could be out-of-distribution for the hallucination we care about in practice.",
            "2": "For example, hallucinations measured by AutoHall could be failures of the LLM classifier (for detecting whether something is supported).",
            "3": "Even generating supportive content for statements seems like a task these LLMs are rarely used for in practice.",
            "4": "* One selling point of AutoHall is that it's automatic, but it requires relying claims and ground-truth evidence from fact checking datasets, which were curated by humans.",
            "5": "* The reported hallucination numbers, where Llama and ChatGPT produce similar hallucination rates, are very different than the numbers reported in https://arxiv.org/abs/2305.14251where ChatGPT is nearly twice as factual as fine-tuned versions of Llama (though it's LLama 1 instead of 2, I'd be surprised if Llama 2 closes the gap), raising questions about the fidelity of the generated datasets."
        },
        "FdwyIhwMWh": {
            "0": "* This paper took a step towards addressing a significant and interesting problem, the hallucination evaluation of LLMs with no assumption of external resources, which is more suitable for real scenarios.",
            "1": "* The automatic data creation method is well-motivated by timeliness and transferability problems of current model-specific and manually created datasets.",
            "2": "* The authors demonstrated the effectiveness of their framework by comparing several previous baseline models and also gave some analysis of the properties of hallucinatory references, which would benefit future research in this direction.",
            "3": "Though this paper is well-motivated, there are three main problems:\n\n* Some designs of the data generation and detection methods are questionable.",
            "4": "In detail:\n  1.",
            "5": "The method to classify the generated references is unreasonable since the two-phase pipeline brings much noise and accumulates errors.",
            "6": "In Step 2, LLMs take the risk of producing wrong answers from factual references and vice versa.",
            "7": "2.",
            "8": "The problem caused by model randomness in the data generation process has not been considered.",
            "9": "For example, for a given (claim, reference) pair, the LLM’s label prediction could be influenced by sampling-based decoding and the form of instructions, as LLMs are sensitive to different instructions (Zhou et al., 2023).",
            "10": "3.",
            "11": "The necessity of model-specific generation has not been verified.",
            "12": "This motivation makes sense, but the authors should also justify it by testing the transferability of datasets generated by different models.",
            "13": "* The proposed pipeline lacks novelty.",
            "14": "1.",
            "15": "The method of automatically generating hallucinated references was proposed by (Agrawal et al., 2023).",
            "16": "The only difference lies in that the authors generated references from existing fact-checking claims instead of topic words.",
            "17": "2.",
            "18": "The proposed self-contradiction-based hallucination detection method has also been proposed in previous work (Mündler et al., 2023; Manakul et al., 2023; Cohen et al., 2023), among which Mündler et al., and Cohen et al., both utilized LLMs as the contradiction judge.",
            "19": "Besides, the design of self-contradiction detection in $(Y,Y^{'}_k)$ pair seems meaningless.",
            "20": "Since the generation process of $Y$ is the same as that of $Y^{'}_k$, $Y$ can be considered one of $Y^{'}_k$.",
            "21": "The claim `*avoid the problem that SelfCheckGPT incorrectly identifies the conflicts in the K sentences generated*' was not verified.",
            "22": "* The experimental settings are not sound enough, making results unconvincing.",
            "23": "1.",
            "24": "As mentioned above, the quality of generated datasets is not guaranteed, and hence the conclusion is also questionable.",
            "25": "2.",
            "26": "Some essential baselines are not compared.",
            "27": "For example, (Mündler et al., 2023), which also uses LLMs as the contradiction judge in an NLI manner.",
            "28": "3.",
            "29": "Since the contradiction judge based on LLMs also introduces randomness and noise, human evaluation is needed for further guarantee.",
            "30": "* Some essential designs need more in-depth analysis.",
            "31": "a) Why did self-check perform worse in the few-shot setting than the zero-shot setting with ChatGPT in Table 3?",
            "32": "b) Why was 1gm worse than the few-shot with LLaMa2-7B?",
            "33": "Refs:\n* Zhou et al., Large Language Models Are Human-Level Prompt Engineers.",
            "34": "ICLR 2023.",
            "35": "* Agrawal et al., Do Language Models Know When They’re Hallucinating References?",
            "36": "2023.",
            "37": "* Cohen et al., LM vs LM: Detecting Factual Errors via Cross Examination.",
            "38": "2023.",
            "39": "* Manakul et al., SELFCHECKGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models.",
            "40": "2023.",
            "41": "* Mündler et al., Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation.",
            "42": "2023."
        }
    },
    "Spp2i1hKwV": {
        "YL5i5ek55P": {
            "0": "The paper introduces a novel approach to improving in-context learning, which is an important problem with a myriad of strategic practical application.",
            "1": "The works appears to be original and the.",
            "2": "empirical evaluation suggests that this work could have major impact (also see comments below on how to make a stronger case along these lines).",
            "3": "The paper is reasonably well-written and organized; see below suggestions on how to further improve it.",
            "4": "The most improvements could be achieved by tightening up the Empirical Evaluation section:\n- ideally, rather than (arbitrarily?)",
            "5": "choosing k = 18 & k = 100, you should provide an automated approach to AUTOMATICALLY assess the smallest amount of annotations that leads to the best possible performance; you only introduce Auto-IDEAL in \"4.4\" but you do not seem to claim it as a major contribution.",
            "6": "Why?",
            "7": "- in Table 2:\n   a) please add an additional row that shows the best-known performance on each dataset; without it, it is impossible to quantify the practical impact of IDEAL (i.e., is \"just\" improving on Vote-k, or does it come close to the best-known performance?)",
            "8": "b) please also add to the Table results for k = 1,000 and even k = 10,000.",
            "9": "How big are these improvements, if any?",
            "10": "c) please explain why do we see IDEAL(100) < IDEAL(18) on RTE.",
            "11": "Is there a general lesson worth sharing?",
            "12": "d) similarly, why does Vote-k outperform IDEAL(100) on GeoQ (Tables 2 & 8).",
            "13": "In particular, given that Table 8 suggest that there is a fair amount of variability among the various trials, ideally you should increase the number of trials to 10 or even larger.",
            "14": "In the current setting, according to Table 8, for \"100\" Vote-k and IDEAL obtain the same best result (60.5) on GeoQ; similarly, for \"18\", there is a similar \"tie\" on HellaSwag, and Vote-k gets a better max on GeoQ.",
            "15": "- section 4.3.1 should cover all datasets, not only two; worst case scenario, if space is an issue, you can summarize the results on all datasets here, and refer the reader to the appropriate appendix\n- same as above, section 4.3.1 should cover all datasets, not only three of them.",
            "16": "Also: (i) why have Table 2 for \"18\" rather than \"100,\" when IDEAL(100) outperforms IDEAL(1*0 on all datasets, and (2) similarly to the above comment on stability, you should use at least 10 randomized trials.",
            "17": "- same as above, section 4.4 should cover all datasets, not only five of them\n\nOTHER COMMENTS:\n1) please add early-on (e.g., in the Introduction) a few illustrative examples.",
            "18": "For one or two of your application domains, you should show:\n- an un-annotated example that IDEAL selects for annotation\n- the annotated version of that example\n- the answer of the LLM w/o that annotated example used as a prompt\n- the answer of the LLM w/o that annotated example used as a prompt\n- explain and/or discuss the difference between the two answers above  \n\n2) please add to the paper a paragraph or two about the actual/expected cost of annotation for the various domains in the empirical evaluation.",
            "19": "3) please intuitively explain the \"end-to-end\" term that you are using in the Abstract, Introduction, and later on in the Appendices, but nowhere else in the rest paper.",
            "20": "If it is an important concept, it should also appear in the \"meat\" of the paper; if it is not, you should remove all references to it as it is distracting to see it mentioned early on, never clarified, and then simply ignored.",
            "21": "4) both in Fig 3's caption and in the abstract, please summarize the running time improvements of IDEAL vs Vote-k.",
            "22": "The current \"largely reduces the time cost\" is simply too vague.",
            "23": "Ideally, the last sentence of the abstract should end something like this: \"... improving the performance by X% while reducing the running time by Y%\"\n\n\nNitpicks:\n- p 1: \"pretty performance\" --> \"strong performance\"\n- p 1: please add a reference and /or brief summary for \"requires substantial manpower and financial resources\"\n- p 2: \"Vote-k devoids theoretical guarantees\" --> \"Vote-k lacks theoretical guarantees\"\n- p 2: please explain why \"the algorithm does not need a delicate trade-off between diversity and representativeness\"\n- p 2: last paragraph of the Intro: please also quantify the performance improvement, not only the gains in speed\n- p 3: for Fig 2, please explain if/why the iterations start at (d).",
            "24": "- p 5: probably the theorem should be called \"Theorem 1\" (or else the reader expects to see a Theorem 1 before it)"
        },
        "q0uAAtoxUY": {
            "0": "- The selective annotation is a meaningful research problem, since in reality LLMs need to to generalize to novel tasks without the existence of large amount of labeled data.",
            "1": "- The previous Vote-k method needs to get the uncertainty from LLM predictions which incurs large computation time consumption, while the proposed method bypasses such need and considers from the perspective of data influence in the corpus.",
            "2": "Also, this method reduces the LLM sensitivity on in-context examples, such as the order, which increases the robustness of in-context learning.",
            "3": "- The experiments is conducted on different LLMs and various tasks, showing its effectiveness.",
            "4": "- This paper is related to \"Li et al., Finding Support Examples for In-Context Learning\", which also adopts the idea of coreset selection in in-context example selection, and \"Diao et al., Active prompting with chain-of-thought for large language models\", It is suggested to include discussion with these papers in the related work.",
            "5": "- The theoretical analysis is about the influence lower bound.",
            "6": "How the influence score relates to better diversity and representativeness needs further illustration, since it is the major consideration of the proposed method.",
            "7": "- A minor suggestion is that the experiment datasets can also include some novel LLM benchmarks that are probably not trained on the experiment LLMs."
        },
        "ovc9Odrp0e": {
            "0": "1.",
            "1": "Investigating the demonstration selection task from the influence perspective is very interesting.",
            "2": "2.",
            "3": "It is great to have a theoretical analysis of the property of the influence function.",
            "4": "3.",
            "5": "Overall, this paper is well written.",
            "6": "1.",
            "7": "There is no time complexity in the proposed method, which is very crucial if it needs to run for every inference.",
            "8": "2.",
            "9": "It is not clear how the proposed method considers the correlations among the retrieved data points.",
            "10": "3.",
            "11": "It is better to compare with more demonstration selection methods such as similarity-based and diversity-based methods which are widely used in practice."
        },
        "HnozqYKCnu": {
            "0": "* S1: The influence-based greedy method can effectively and efficiently help find the right prompts from the large corpus.",
            "1": "* S2: Experimental results show improvements over Random and Vote-K.\n* S3: The authors provide some preliminary theoretical proofs.",
            "2": "* W1: Some state-of-the-art studies like MDL [a] TopK (Liu et al., 2022) are not cited and/or compared in the experiments.",
            "3": "* W2: The rationales behind some experimental results are not explained, such as the reverse performance of MNLI in Table 5.",
            "4": "* W3: Lack of analysis on how the proposed method \n\n\n\n[a] Wu, Z., Wang, Y., Ye, J., & Kong, L. Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering, ACL 2023."
        },
        "fcaU0vANCb": {
            "0": "1.",
            "1": "In-context learning is an important and swiftly advancing research area, capturing significant attention from both the ICLR and NLP communities.",
            "2": "This paper conducts comprehensive evaluations on the influence of selecting specific examples for inclusion in the prompt.",
            "3": "The findings illustrate the substantial impact this choice can have on the final model's behavior.",
            "4": "2.",
            "5": "The paper is well-structured and easily comprehensible.",
            "6": "Within the evaluation section, there are numerous intriguing findings that hold significant value for dissemination within the wider research community.",
            "7": "Besides, the source code is provided to ensure the reproducibility of the empirical findings.",
            "8": "3.",
            "9": "The proposed method is simple and relatively straightforward to implement.",
            "10": "Consequently, there is a possibility that it could be utilized in real-world applications of in-context learning.",
            "11": "4.",
            "12": "Theoretical analysis is provided to demonstrate the effectiveness of the proposed method under a greedy search algorithm.",
            "13": "1.",
            "14": "There are some unclear expressions and inconsistent explanations.",
            "15": "Some polishes are needed.",
            "16": "2.",
            "17": "Some experimental settings only include the baselines Random and Vote-k. More methods as mentioned in 4.3.2 can be also included.",
            "18": "More questions about weaknesses can be checked below."
        }
    },
    "ruQkcBfzpm": {
        "gnYiDn43at": {
            "0": "1.",
            "1": "The proposed method is quite affordable, in that the training only takes a few days on a few GPUs.",
            "2": "The method overall is adaptation cheap thanks to the limited amount of trainable parameters in Q-former, and the LoRA tuning of LLMs.",
            "3": "2.",
            "4": "This paper tackles an important problem of multilingual vision language models, that enables wider accessibility of the vision language models especially for non-English speakers.",
            "5": "1.",
            "6": "One weakness is to name a translated dataset as a multilingual dataset, which doesn't cover the real benefits of multilingual at all (i.e.",
            "7": "multiple cultures, examples from different locations from local people speaking those languages).",
            "8": "This is misleading as the future work will use the translated dataset which will reinforce the emphasis of English centric research, under the translated \"multilingual\" directions.",
            "9": "2.",
            "10": "The idea of applying Q-Former to LLMs is not novel and has been explored by the previous BLIP papers.",
            "11": "I have not found BLIP baselines reported (at least on EN) in the paper (except for the right sub-table of Table 1).",
            "12": "More comparisons with BLIP baselines, especially on the impact of multilingual data to the original English tasks would be nice to show the impact of this paper."
        },
        "skrmqT5KIe": {
            "0": "- The work proposes a dataset (if will be released) with image-text pairs coming from 96 different languages, which could be useful for future research.",
            "1": "- Experiments are decent.",
            "2": "The work also covers some important ablation studies.",
            "3": "- The major concern is the novelty.",
            "4": "In short, the work can be summarized as (1) using machine translation to translate image-text pairs (in English) to different languages, and (2) replace the language decoder in BLIP2 with a multi-lingual one and train the model with translated dataset.",
            "5": "- The mixture of task highlighted in the paper as a contribution to the success of the model, although not considered in BLIP2, was actually explored in PALI.",
            "6": "This fact further deteriorates the novelty of this work.",
            "7": "- It's not a surprise that task mix helps most in VQA and VNLI tasks because such an objective in included in the pre-training stage.",
            "8": "The mixture of task actually hurts the captioning performance.",
            "9": "- The model can be trained on 4 cheap RTX-3090 GPUs, which is great.",
            "10": "But this claim in the conclusion has nothing to do with the contribution of the work, i.e., any similar models will enjoy the speed-up with 8-bit quantization and LoRA PEFT."
        },
        "sX03T6iaPn": {
            "0": "mBLIP is created using only about 2.5 million images and training 124 million parameters on consumer hardware to convert high-quality English data into 95 languages for training.",
            "1": "The contribution of this paper is to presents a cost-effective approach to developing multilingual vision-language models with broad language coverage and strong performance.",
            "2": "There are still big differences of accuracy between English and other languages on XM3600 and xFlickerCo testing.",
            "3": "In addition, Table 2 is not so clean to understand."
        },
        "Cp5UCCt7C3": {
            "0": "The approach is interesting in the sense that it covers a reasonable use case, that of multi-lingual LVLM by aligning frozen models.",
            "1": "It seems like the authors found a good space where a solution did not exist in the literature.",
            "2": "The proposed approach seems technically reasonable.",
            "3": "The paper is mostly clear, the target application is clear and the explanations are usually clear (although some issues are flagged later on).",
            "4": "Results are positive, although there isn't a lot to compare against.",
            "5": "The paper does not seem to have a strong technical contribution.",
            "6": "On the pro side, I like the application, and there's some analysis of the impact of the different pieces in Table 3, which offsets somewhat the lack of technical contribution.",
            "7": "I am a bit unsure about the impact of LoRA.",
            "8": "A task prompt has much lower capacity to adapt to any downstream task compared to adding LoRA (especially if LoRA adapters are added to every 1x1 layer).",
            "9": "So I'm wondering if part of the performance is due to LoRA vs no LoRA.",
            "10": "Also, if there is enough data to train LoRA adapters, why then there is no data to train a task prompt?",
            "11": "is \"re-aligning\" actually fine-tuning?"
        }
    },
    "d98CzL5h0i": {
        "IlRNAIQK7Q": {
            "0": "- Clear explanation of both the algorithm and the key intuitions\n\n- The basic idea is definitely worth pursuing—using a guide for rolling out possible scenarios in order to ensure some coverage of the space of near-optimal policies is clearly something that might benefit current RL methods in LLMs.",
            "1": "- The study of reward optimization tradeoff is interesting and very welcome.",
            "2": "It’s pretty clear that our metrics only work under “normal conditions” where complete gibberish isn’t being measured, so using the KL divergence as the other axis shows a potential pareto frontier that we’re working with in these problems.",
            "3": "- The fact that the proposed technique seems to generalize slightly better than previous techniques to harder examples (with less train-test overlap) on CommonGen is interesting, and does validate the technique to some extent, though the margin is relatively small.",
            "4": "- The benchmarks used are somewhat lacking.",
            "5": "For text generation in 2023, most comparisons for state of the art methods are made by comparisons to other LLMs because fixed metrics have been found to be lacking.",
            "6": "A comparison using a framework like Chatbot Arena (Zheng et al.",
            "7": "2023).",
            "8": "would have made the results significantly more convincing.",
            "9": "These often use GPT-4 as an evaluator, which has now been shown to be provisionally better than traditional metrics (Liu et al 2023, Min et al 2023, Zhou et al 2023, inter alia).",
            "10": "- Even with these quite simple benchmarks, the resulting differences on metrics are small for the task where control is more significant, CommonGen.",
            "11": "In IMDB the task-specific metric really only checks if the sentiment score is correct, which is very little information to be using to validate outputs.",
            "12": "- The fact that perplexity goes up but output perplexity goes down on IMDB is worrying.",
            "13": "I can understand why perplexity would go up: the model is likely collapsing onto a smaller subspace of possibilities, which may still be higher quality.",
            "14": "However, the fact that the output perplexity also goes down is worrying: it indicates that after optimization the resultant model is more predictable to LMs which is usually not a good sign for tasks that LMs are bad at in the first place.",
            "15": "The results on TL;DR are similarly quite small.",
            "16": "- I’m disappointed to see there’s no study of how this technique scales across model sizes: one could imagine doing this for smaller models, incurring relatively low compute expenses, but no such experiments were conducted.",
            "17": "As it is, it is not clear how much these results will generalize to the ever-growing zoo of LLMs.",
            "18": "Works Referenced\n\nLiu, Yang, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu.",
            "19": "2023.",
            "20": "“G-Eval: NLG Evaluation Using GPT-4 with Better Human Alignment.” arXiv [cs.CL].",
            "21": "arXiv.",
            "22": "http://arxiv.org/abs/2303.16634.",
            "23": "Min, Sewon, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-Tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi.",
            "24": "2023.",
            "25": "“FActScore: Fine-Grained Atomic Evaluation of Factual Precision in Long Form Text Generation.” arXiv [cs.CL].",
            "26": "arXiv.",
            "27": "http://arxiv.org/abs/2305.14251.",
            "28": "Zheng, Lianmin, Ying Sheng, Wei-Lin Chiang, Hao Zhang, Joseph E. Gonzalez, Ion Stoica.",
            "29": "“Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings.” 2023. https://lmsys.org/blog/2023-05-03-arena/.",
            "30": "Zhou, Xuhui, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, et al.",
            "31": "2023.",
            "32": "“SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents.” arXiv [cs.AI].",
            "33": "arXiv.",
            "34": "http://arxiv.org/abs/2310.11667."
        },
        "gulWihU3qP": {
            "0": "- The idea is simple and interesting.",
            "1": "It could easily lead to others building on the core concept and approach.",
            "2": "- The paper reviews a line of literature on imitation learning and presents a connection between those and the proposed framework.",
            "3": "- The motivation is not clear.",
            "4": "Why guide policy should be integrated into RL finetuning especially in text generation?",
            "5": "How the rollin & rollout scheme leads better text generation than PPO?",
            "6": "- The theoretical justification section of the paper does not self-contained enough for readers.",
            "7": "- Performance gain seems marginal compared to PPO.",
            "8": "- Lack of ablation study for the mixing parameter $\\beta$ which might be crucial in the framework."
        },
        "c3GAiqCIvh": {
            "0": "1.",
            "1": "The method looks novel and presents a good extension to PPO.",
            "2": "2.",
            "3": "The theoretical justification look rigorous.",
            "4": "1.",
            "5": "Experimental results on both the sentiment sentence generation and TLDR dataset do not show that the proposed methods can outperform PPO, let alone significantly.",
            "6": "2.",
            "7": "I am wondering what is the difference between the LLM policy \\pi_\\{theta} and the guide policy \\pi_g.",
            "8": "It is said that \\pi_g is the SFT+nucleus sampling.",
            "9": "But in PPO, the LLM policy model should also be a fine-tuned LLM on some tasks.",
            "10": "In this case, what is the difference between the two policy models?"
        },
        "YyPl6alOiU": {
            "0": "1.",
            "1": "The paper manages to combine a diverse set of ideas from prior RL research and formulate multiple algorithms within the 9 page limit, which is no small feat.",
            "2": "2.",
            "3": "Authors conduct comprehensive evaluations with multiple realistic tasks and near-SoTA language models.",
            "4": "The experiments are using standard llm fine-tuning best practices and report multiple seeds (in most cases).",
            "5": "While this is not outstanding, many recent papers do not pass this bar, therefore it feels like a strength.",
            "6": "3.",
            "7": "For a paper about so many different ideas and algorithms, this one is reasonably well written and easy to follow.",
            "8": "My main concern is the choice of baselines.",
            "9": "While authors compare against SFT and basic PPO, prior research developed alternative algorithms for fine-tuning LLMs on human feedback that also claim superiority to PPO and SFT.",
            "10": "Authors even cite some of those works in the paper.",
            "11": "Some of those algorithms are: DPO[1], APA[2], P3O[3], SLiC-HF[4] though there may be more.",
            "12": "* [1] https://arxiv.org/abs/2305.18290\n* [2] https://arxiv.org/abs/2306.02231\n* [3] https://arxiv.org/abs/2310.00212 - note: this was published after the paper submission and authors should feel free to ignore it\n* [4] https://arxiv.org/abs/2305.10425v1\n\nThese works adopt different means to learn from human feedback: some of them compatible to RLGF while others can only be used as competitors.",
            "13": "I believe that the paper would be improved if, for each competitor, authors either compare against it in the experiments or prove that it has no chance of outperforming RLGF algorithms or, if authors claim that RLGF algorithms are orthogonal, demonstrate how it performs in combination with those approaches.",
            "14": "Another, less important concern is about the paper structure.",
            "15": "Authors manage to cram multiple algorithms (PPO++, AggreVaTeD, LOLS in Appendix B, D2LOLS) and evaluate all of them within the few allowed pages.",
            "16": "As a result, the paper fills \"crammed\" despite authors' considerable effort.",
            "17": "Perhaps it would be better to explore one or two of those algorithms **in more detail** and leave the rest to appendix?",
            "18": "Though, I will understand if authors deliberately choose otherwise.",
            "19": "For the last (and least) of issues, the idea of guiding the search for optimal policy is technically not novel outside the LLM fine-tuning domain, and the same can be said about other ideas presented in the paper.",
            "20": "To reiterate, it is not a \"problem\" to be solved, and a good practical adaptation of existing methods is valuable in and of itself."
        }
    },
    "8TAGx549Ns": {
        "qBHRqqDfjA": {
            "0": "- The paper explores a very relevant topic that is less looked at, which is the exploration problem in reasoning tasks.",
            "1": "- The paper is easy to read, explains their method well\n- The motivation of exploration and exploitation is clear and is a topic that needs attention in LLM-based reasoning/agents\n\n- The evaluation is somewhat lacking, only evaluated on blocksworld and GSM8K, and ablations were missing (only statistics of # of actions were given), no intuition on how to tune the hyperparameters B,K,C\n- Baselines is missing, see question 1\n- some implementation details are missing, see question 2\n- needs more intuition/analytics for how REX works, which one is better in what situation, when to use it, see question 3 & 4"
        },
        "LTQHoaJ2zs": {
            "0": "# originality\nCombining search techniques with LLMs is an emerging area.",
            "1": "MCTS is only recently being studied in this context, making the work original in that respect.",
            "2": "# quality\nThe proposed algorithms are evaluated on two different domains with varying size and reasoning requirements.",
            "3": "Both accuracy and time complexity are compared.",
            "4": "# clarity\nThe figures and algorithm listings help clarify the core algorithms.",
            "5": "# significance\nEnabling LLMs to incorporate feedback into reasoning is a crucial capability for amortizing expensive inference and coping with partially unknown application domains.",
            "6": "This is an important problem and new techniques to address this problem - like using MCTS to structure search and track action quality and uncertainty - are important.",
            "7": "The work aims to leverage MCTS while reducing the number of LLM invocations needed compared to prior work (RAP).",
            "8": "# originality\nThe MCTS formulation is similar to RAP in some ways, but differs in many key details, particularly around how the world modeling is done, where RAP explicitly models the world but REX uses the implicit model of the LLM.",
            "9": "Augmenting LLMs with search techniques is not itself novel, but this is not a substantial lack of originality per se either.",
            "10": "# quality\nEvaluation results only weakly support the REX models.",
            "11": "The performance improvements are primarily for (some) small Blocksworld domains, with comparable performance on GSM8K.",
            "12": "This makes it unclear to what degree the algorithm is an improvement over existing methods.",
            "13": "Benchmarking is only done on relatively simple example tasks, making it difficult to assess how well these results translate to real world use cases.",
            "14": "Evaluation does not match techniques on the number of tokens they generate or evaluation calls they make.",
            "15": "This makes fair comparisons impossible, as the different methods are afforded different computational budgets for the same objective.",
            "16": "# clarity\nThe text can be hard to follow.",
            "17": "Partially this is due to framing the technique as reinforcement learning, despite the lack of a policy being learned (though presumably the MCTS count tables could be preserved and treated as a learned policy of sorts).",
            "18": "The core algorithm description was difficult to follow and the main figures did not support understanding this algorithm.",
            "19": "# significance\nThe results do not show substantial improvements over prior efforts, limiting the significance attributable to the technical novelties."
        },
        "TBUFObnmyf": {
            "0": "Overall the paper is well motivated and well written.",
            "1": "Proposed mechanisms such as integration of rewards into the prompt are novel.",
            "2": "The approach seems to be limited to problems with discrete actions, and assumes the scores can be mapped to HIGH/LOW which may not always be possible."
        },
        "hFoPeiZmCr": {
            "0": "- Important and timely topic\n- Nice connections between RL/bandit literature and LLM\n- I agree with the authors that MCTS is a promising approach to combine with LLM; hence, the authors try to make progress in a good direction.",
            "1": "- Regarding experiments, I have several concerns.",
            "2": "First, I consider that the authors should compare of the performance of their LLM-based approaches with SOTA methods that are not based on LLMs.",
            "3": "Second, the authors state that \"RAP is not compatible with OpenAI APIs; therefore, we have exclusively focused on evaluating the time complexity of RAP, without delving into its accuracy\", but I do not think that this is a good reason why the authors do not have to empirically evaluate RAP.",
            "4": "If the authors emphasize the better computational complexity of their proposed method, they may want to add rigorous theoretical analysis.",
            "5": "- The ideas presented in this paper are quite similar to Tree-of-Thoughts (Yao et al., 2023).",
            "6": "Though this is a recent work, but uploaded on arXiv on May 17, 2023; hence, this cannot be regarded as a concurrent work unless I misunderstand the ICLR rule.",
            "7": "I would recommend the authors to at least the similarities and differences and compare the authors' proposed method with Yao et al.",
            "8": "(2023) in same benchmarks.",
            "9": "- Yao, Shunyu, et al.",
            "10": "\"Tree of thoughts: Deliberate problem solving with large language models.\"",
            "11": "arXiv preprint arXiv:2305.10601 (2023).",
            "12": "- Maths are sometimes weird to me.",
            "13": "For example:\n    - Algorithm 1, line 3: $\\forall (s,a) \\in Q$.",
            "14": "$Q$ is not a set of state-action pairs.",
            "15": "This part should be $\\forall (s,a) \\in S \\times A$.",
            "16": "- Algorithm 1, line 14: $\\forall (s,a) \\in H$.",
            "17": "$H$ is a time step.",
            "18": "- The overall alogrithmic flow is not clear to me.",
            "19": "I guess it is mainly because \"AGENT.FUNCTION()\" (FUNCTION = {SOLVE, VALIDATEACTION, CALCULATEUCB}) is not explained.",
            "20": "In addition to the math problems mentioned earlier, the algorithmic flow in this paper is hard to follow."
        }
    },
    "g9diuvxN6D": {
        "iOWmzrnXnG": {
            "0": "This paper provides a thorough comparison of LLM's instruction robustness across various models and sizes.",
            "1": "Although the finding—that LLMs are not robust to varying instructions—is anticipated, this paper presents compelling empirical evidence.",
            "2": "Additional analysis in the embedding space of the instruction is interesting.",
            "3": "Furthermore, the study suggests an elegant solution to narrow the performance disparity between familiar and unfamiliar instructions.",
            "4": "The proposed solution could benefit from more details.",
            "5": "Exploring the soft-prompt size (i.e., the variable N) would be nice.",
            "6": "The N used is not specified in the main text either, which I believe is an important detail.",
            "7": "They provide synthetic instruction, and one of the baselines is to fine-tune normally with this new instruction.",
            "8": "Interestingly, there is a noticable degradation in performance, yet there's no explanation as to why.",
            "9": "Usually, continual fine-tuning on the same data should not damage performance (significantly so).",
            "10": "My guess is that the quality of the synthetic prompt is not very good.",
            "11": "If so, this raises a question: what if we spend more effort on generating better synthetic instruction beforehand?"
        },
        "7iw6UIIDCQ": {
            "0": "- The paper performs experiments on various tasks including reasoning benchmarks (MMLU and BBL) and NLG benchmarks.",
            "1": "- The paper provides the experimental setting of evaluating the robustness of LLMs on different instructions by releasing various instructions collected from NLP researchers, which might facilitate further research.",
            "2": "- In Tables 3 and 7, compared to the performance difference, the variance is very large, questioning the significance of the difference between observed and unobserved instructions.",
            "3": "A significance test should be conducted to test the significance of the difference.",
            "4": "- Although the title, abstract, and motivation of the paper mention that the paper tries to evaluate the zero-shot robustness of instruction-tuned language models generally, it only focuses on models up to 11B.",
            "5": "The tendency is likely to be unpredictable for state-of-the-art LLMs such as GPT-3.5 or GPT-4.",
            "6": "- How does PT+KL on Table 7 perform on negated instructions?",
            "7": "The alignment stage might make the LLM insensitive to most instructions even though the instructions are not relevant or negated, which is a similar finding for instruction-tuned LLMs for Webson & Pavlick (2022) \n\nWebson & Pavlick (2022) - Do Prompt-Based Models Really Understand the Meaning of their Prompts?"
        },
        "cU1wpQX4pv": {
            "0": "- The experiments are clear and well-thought-out, and the results are solid and interesting, affecting many current popular models (Llama finetunes), and holding for different model families.",
            "1": "- The observed correlations between performance and instruction similarity (in representation space) are interesting (even if the correlation is somewhat weak).",
            "2": "- The proposed fix method is well-motivated, and the results seem reasonable, especially for the Alpaca-7B model.",
            "3": "- The robustness of models to different prompts is an important and interesting area of study, especially considering current difficulties with LM evaluations.",
            "4": "- The novelty of the robustness experiments is somewhat limited, as there is prior work that has observed variance based on prompt formatting (discussed in the work itself).",
            "5": "Considering this work seems to examine more modern models such as Alpaca, and considers a different set of tasks, I think this is a minor weakness - the work does add a number of interesting insights, especially around representation distance.",
            "6": "- The claim that models perform worse at novel phrasings of tasks seems a bit strong compared to the results: examining Table 3, the variance of performance on unobserved phrasings often is greater than the difference in average performance, suggesting that the difference in performance may not be significant (although the large increase in variance is certainly not desirable and interesting to see).",
            "7": "- While the proposed method seems strong, examining the results in Appendix B.3 seems to show that in many cases, prompt-tuning alone performs within one standard deviation of the PT+KL results (e.g., for BBL unobserved and average).",
            "8": "As such, the proposed method might not be significantly different from just prompt tuning.",
            "9": "Overall, I think this paper is okay, and the robustness results are interesting and useful to see, along with the representation alignment results.",
            "10": "However, the novelty of the robustness experiments is a bit limited, and it’s not clear the proposed method for improving this is significantly better than baselines."
        },
        "P5UjYIQS75": {
            "0": "- This seems like a significant result overall, and explicitly shows an important weakness in IT models\n- In general, this kind of work (exploring what \"success on a benchmark\" really means) is extremely important for the field.",
            "1": "You are raising a really important issue with fine tuning, and this is impactful.",
            "2": "- The experiments in the paper are well-executed, well-presented, and broad across models and datasets.",
            "3": "- It's interesting to explicitly introduce the rephrasing invariance into the fine tuning data-- it's sort of an  equivalent of regularization, I think?",
            "4": "- Thanks for including figure 4!",
            "5": "It helped a lot with the intuition in that section.",
            "6": "- nit: \"instruction-tuned models are not especially robust to instruction rephrasings\" → this is very clear, say it first.",
            "7": "Better yet, make it the title :) \n- I don't know if just releasing prompt rephrasing is a significant enough contribution-- https://openreview.net/forum?id=9Vrb9D0WI4 and others also have datasets of different rephrasing of prompts for the same task."
        }
    },
    "nqlymMx42E": {
        "bS40PzdxX2": {
            "0": "- Technical Soundness: The paper demonstrates a high level of technical rigor.",
            "1": "It conducts extensive experiments that compare various design choices (such as problem representation, neural architecture, pretraining, etc.)",
            "2": "within the realm of string-based reinforcement learning for molecular discovery.",
            "3": "Moreover, the paper offers a comprehensive discussion of the results and imparts valuable insights and recommendations for future research.",
            "4": "- Clarity and Organization: The paper is well-written and organized, making it easy to understand and follow.",
            "5": "It effectively motivates the reader and provides a solid introduction to the field of string-based reinforcement learning for molecular discovery.",
            "6": "- Significance: The paper makes a substantial contribution to the field of molecular discovery.",
            "7": "It offers a comprehensive comparative study of diverse design options (problem representation, neural architecture, pretraining, etc.)",
            "8": "within the domain of string-based reinforcement learning for molecular discovery.",
            "9": "- Table 1 provides a nice summary of the different algorithms for text-based molecule design.",
            "10": "- Originality: While the paper offers a thorough numerical comparison of different design choices (problem representation, neural architecture, pretraining, etc.)",
            "11": "in the context of string-based reinforcement learning for molecular discovery, its originality is somewhat constrained."
        },
        "f1EDHV3cdr": {
            "0": "Promising approach for the molecular generation.",
            "1": "Experiments are conducted using three different datasets and impact of each of them is shown.",
            "2": "Good ablation study includes the design choices, different models architectures and even other RL algorithms beside REINFORCE are tested.",
            "3": "**Relevant work**\n\nSome relevant works seem to be missing: \n\n* MolGPT (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10232454/) also uses Transformer for molecular generation but without RL.",
            "4": "* Taiga (https://pubs.acs.org/doi/10.1021/acs.jcim.1c00600) uses Transformer and REINFORCE algorithm for the molecular generation with different properties optimization.",
            "5": "* Please also consider citing the relevant parallel work which applies offline RL for the similar problem: https://www.biorxiv.org/content/10.1101/2023.11.29.569328v1 (once it is public)\n\nThe second work seems to be very similar in terms of approach and I'm not sure about the novelty of the approach itself.",
            "6": "** Results presentation **\n\n* I haven't noticed the comparison against any other methods.",
            "7": "* From the plots I couldn't understand what \"Div.\"",
            "8": "and \"Red.\"",
            "9": "columns stand for.",
            "10": "* I couldn't find reported scores for different tasks (e.g., similarity, QED or SA).",
            "11": "It would be nice to see them.",
            "12": "* There are no samples of generated molecules.",
            "13": "RL could hack reward functions and generate molecules which make no sense.",
            "14": "Reward hacking is mentioned by the authors but including resulting molecules is essential."
        },
        "7Kyx94iXss": {
            "0": "1.",
            "1": "The problem is of high importance\n1.",
            "2": "The paper is well-written\n1.",
            "3": "The numerical results are well documented and contain ablation studies\n\n1.",
            "4": "Some of the design choices seem to be dated.",
            "5": "For example, \n    * it is not clear why REINFORCE is used as the policy learning algorithm, as opposed for instance to PPO.",
            "6": "* there is no automatic entropy tuning for exploration.",
            "7": "* Reinforcement Learning with Human Feedback can be also an interesting approach to try\n1.",
            "8": "The details for the backbone language model as scarce.",
            "9": "It would be also interesting to discuss the design choices for language modeling, e.g., pretraining architecture (BERT vs GPT),  tokenizer etc\n1.",
            "10": "It would be good to see if increasing the transformer size would lead to performance improvement.",
            "11": "If I am not mistaken increasing the RNN size could lead to issues while training and therefore this could potentially become the strength of the paper."
        },
        "6ERUYhkHAV": {
            "0": "1.",
            "1": "The paper addresses an important problem in the field of molecular design, which has significant implications for society.",
            "2": "The potential of RL methods to discover new, high-value molecules could have a major impact on drug discovery, materials science, and other fields.",
            "3": "2.",
            "4": "The paper presents a new RL-based molecular design algorithm called ChemRLformer, which achieves state-of-the-art performance while being more straightforward than prior work.",
            "5": "The authors provide unique insights into the application of RL to molecular design and highlight the importance of careful search space structuring and algorithm design.",
            "6": "3.",
            "7": "The paper is well-written and easy to understand, even for readers who may not be familiar with RL or molecular design.",
            "8": "The authors provide clear explanations of their methods and results, and use visual aids to help illustrate their points.",
            "9": "4.",
            "10": "The authors conduct extensive experiments and analysis using 25 molecule design tasks, including computationally complex protein docking simulations.",
            "11": "They explore how different design choices for text grammar and algorithmic choices for training can affect an RL policy’s ability to generate molecules with desired properties.",
            "12": "1.",
            "13": "It is confusing why the authors assume a discount rate of 1 in Section 4.1.",
            "14": "Even with a finite trajectory, a discount rate smaller than 1 is not obligatory, it can also help.",
            "15": "A discount rate of 1 can prevent the agent from learning and executing long-term tasks, as it won't appropriately discount long-term returns, leading it to prioritize immediate rewards and neglect long-term benefits.",
            "16": "It is suggested to justify this setting.",
            "17": "2.",
            "18": "REINFORCE is a very classic yet old algorithm.",
            "19": "It is highly recommend to try more recent algorithms, e.g., TROP or PPO.",
            "20": "I am not an exert in RL for molecular optimization, but I doubt whether it is the state-of-the-art RL algorithm in this field.",
            "21": "For example, (i) due to its reliance on stochastic policies and simple optimization methods, REINFORCE can be more susceptible to getting stuck in local optima, making it less effective in complex and high-dimensional environments; (ii) due to its on-policy mechanism, REINFORCE requires a large number of samples to estimate gradients accurately.",
            "22": "This can make it computationally expensive and slow for complex tasks and environments.",
            "23": "3.",
            "24": "It would be more convincing if domain experts can help to judge the effectiveness of ChemRLformer from molecular's perspective."
        }
    },
    "LixtB4TYY2": {
        "JANH2xxHeV": {
            "0": "* The idea of evaluating VLIT datasets is novel and well-motivated, which can facilitate our understanding of the quality of emerging VLIT datasets.",
            "1": "### The rationality of the proposed evaluation paradigm and metrics is questionable.",
            "2": "* Since most ground-truth responses of the VLIT datasets are generated by ChatGPT/GPT4 without manual verification, they are not reliable for evaluation.",
            "3": "It is acceptable to include some noisy examples in the VLIT training set, but the quality of the evaluation dataset should be very high.",
            "4": "* In the **tune-cross-evaluation** setting, the tuning dataset is not included in evaluation, which may neglect a certain aspect of ability for all-powerful VLIT model.",
            "5": "A more reasonable setting is to exclude the specific tuning datasets in evaluation but include data samples with the corresponding ability.",
            "6": "* According to Eq.3, SD prefers samples on which VLIT models perform well.",
            "7": "This may exclude some noisy samples but could also exclude some challenging but meaningful samples.",
            "8": "* Adding the constant 1 in Eq.2 seems unnecessary.",
            "9": "### The experiments are insufficient to support some of the claims\n* Section 2.2 argues that: (1) MME involves human subjectivity in the data collection process (2) ChatGPT-based evaluation is inaccurate, which is not supported by any evidence and there is no comparison with the proposed evaluation method in these two aspects."
        },
        "BIgXxlaJvC": {
            "0": "1.",
            "1": "The motivation of the proposed method is sufficient and interesting.",
            "2": "It could benefit current VLM research.",
            "3": "2.",
            "4": "The proposed metric considers both the sample-wise and dataset-level aspects.",
            "5": "3.",
            "6": "The whole method is simple with a clear presentation.",
            "7": "1.",
            "8": "The proposed method aims to construct the evaluation metric for the vision language dataset.",
            "9": "Therefore, an important target is to reflect the quality of each dataset and to select a high-quality subset that avoids noise and improves the performance.",
            "10": "However, according to the experiments in Table 5, the scores of different portions are very close.",
            "11": "And the selected split is not able to improve the whole performance.",
            "12": "2.",
            "13": "Because this work claims the strategy can help performance with reduced data, it's important to compare with the original dataset that uses the same portions in Table 5.",
            "14": "This makes the contribution more clear.",
            "15": "3.",
            "16": "Whether the selected dataset using QFormer can be generalized to other frameworks, like LLaVA?",
            "17": "This experiment should be added to show the generality of the proposed method."
        },
        "6ASboB2X81": {
            "0": "Mentioned in the summary\n\nMentioned in the summary"
        },
        "tzmE8il3VE": {
            "0": "1.",
            "1": "There are several concurrent vision-language instruction tuning datasets constructed, and it is good to compare and evaluate them in depth.",
            "2": "2.",
            "3": "They demonstrate that their proposed evaluation metric can be used as a good data selection strategy.",
            "4": "1.",
            "5": "There lacks a good meta-evaluation framework that evaluates whether their evaluation strategy is good or not.",
            "6": "While they have demonstrated that training models with half of the data selected by their metrics can achieve comparable performance with training models with all the data, this is an indirect evaluation and it is unclear whether this means their metrics make sense, and it is hard to quantify this.",
            "7": "2.",
            "8": "Their \"Meta Quality\" score is based on statistical evaluation metrics such as BLEU and METEOR.",
            "9": "They have mentioned in the paper that  these metrics can be ineffective and outdated in the LLM/LVLM era, and I am not convinced that their paradigm can justify the use of such metrics for reliable evaluation.",
            "10": "3.",
            "11": "As in Table 1, different datasets serve different purposes and are in different sizes, thus it is hard to use s scalar value to quantify the quality and it would be good to have a fine-grained evaluation paradigm for these datasets."
        }
    },
    "JtKGkz9fAe": {
        "LWpiXLdFJW": {
            "0": "This is a thoughtful paper that poses a well-defined, tightly circumscribed problem and addresses it in a creative and successful way.",
            "1": "Assuming we are working with models with small window sizes, this seems to be a good way to handle lots of context.",
            "2": "It's also valuable to have additional evidence that retrieval (in the form of additional similar examples) helps even for tasks like the ones addressed here.",
            "3": "1.",
            "4": "The argument for keeping prompts short is growing less compelling as models can handle more and more context.",
            "5": "The other savings from the current approach seem to be small, since we still need to create representations for every contextual element.",
            "6": "2.",
            "7": "In terms of clarity: overall, the paper is good, and the methods are mostly easy to follow, but I am not sure how the architecture search works.",
            "8": "Section 3.3.1 creates on set of expectations, and section 3.3.2 does not seem to meet those expectations, or even respond to them directly.",
            "9": "In particular, we are led to believe that the search module will decide what method to use on a per-layer basis, but then it seems to turn out to be a global choice.",
            "10": "But I many well simply not be understanding the description and its connection to the experimental results."
        },
        "p7Anttsz1i": {
            "0": "- The authors illustrate the effectiveness of the proposed model on 15 NLU tasks.",
            "1": "- The proposed model is technically sounding.",
            "2": "Injecting retrievals via representation fusion is reasonable.",
            "3": "- Experimental settings are well listed out for reproducibility\n- Appendix covers meaningful discussions, such as the effect of retrieval with different k\n\n- Some terms are confusing.",
            "4": "The authors use the term \"neural architecture search\" for the search module, but rather, the search module simply performs hard gate operation among the fusion modules.",
            "5": "- Notations can be improved.",
            "6": "When the authors write \"h_y_{<cls>}\", this seems like the output of the final layer.",
            "7": "However, the authors perform fusion at every layer.",
            "8": "Therefore, I suggest the author to denote layer with superscript l. \n- The authors stress \"computation-efficient\" part, but it would be interesting to see the actual throughput and speed compared to other baselines methods as the proposed method brings in multiple modules.",
            "9": "- The authors should add information on the number of parameters.",
            "10": "It is not clear whether the empirical gains are obtained by simply adding more learnable parameters compared to that of LM-BFF."
        },
        "pSbEjvG1Xc": {
            "0": "1.",
            "1": "ReFusion introduces a novel approach to combining retrieval information with model representations, which is a step forward in prompt-based learning.",
            "2": "2.",
            "3": "The experimental results indicate that ReFusion achieves superior performance over other models, suggesting a better understanding capability of the language models.",
            "4": "3.",
            "5": "Evaluation comprehensivenss: The paper conducts a series of experiments on 15 different natural language understanding (NKI) tasks, which is a broad evaluation of the ReFusion method.",
            "6": "1.",
            "7": "Scope of Experiments: The research confines its experimentation to masked language models, leaving the effectiveness of the proposed ReFusion method on populr autoregressive language models unexplored.",
            "8": "Clarification on its adaptability to such models would be beneficial for broader application.",
            "9": "2.",
            "10": "Performance on Knowledge-Intensive Tasks: While the paper presents improved results for non-knowledge-intensive tasks using ReFusion, it remains unclear how this method stacks up against others in knowledge-intensive scenarios.",
            "11": "Given that retrieval-augmented language models are often specifically leveraged for their prowess in knowledge-intensive tasks, a direct comparison in this primary use case would be valuable.",
            "12": "3.",
            "13": "Compatibility with Current Language Models: Modern language models, such as GPT-4 and LongChat, are designed to handle extended sequences, which facilitates the use of context augmentation methods.",
            "14": "However, the representation fusion approach proposed by ReFusion necessitates fine-tuning of language models.",
            "15": "This requirement may not be compatible with the current trend of employing language models as 'black-box' functions, where fine-tuning is either not possible or practical due to access or resource constraints."
        },
        "2DMn7Rp9AD": {
            "0": "1.",
            "1": "The authors claim to be the first to propose fusing the representations of retrievals directly into models to solve the performance and efficiency bottleneck of prompt-based techniques.",
            "2": "2.",
            "3": "Ranking-based weighted representations are fused to LMs to enhance their performance over NKI tasks, which helps to overcome the issue of LMs' inability to handle long sequences during the retrieval-based augmentation processes.",
            "4": "1.",
            "5": "The fusion of representation directly to LMs' layers is based on top-k sentence retrieval based on similarity.",
            "6": "However, the authors need to study the impact of some more metrics while retrieving top-k similar sentences.",
            "7": "2.",
            "8": "This approach is suitable for situations where adaptability is more important than time constraints."
        }
    },
    "lCxic1APct": {
        "9DGwtUvjyl": {
            "0": "1.",
            "1": "The paper focuses on a critical and urgent issue, the training and inference efficiency of LLMs.",
            "2": "2.",
            "3": "The paper provides an image on GCP to reproduce their partial results.",
            "4": "### Major issue 1\nThe paper \"**theoretically**\" analyzes the hyper-parameter selection process in Section 3.1 and provides experimental\nvalidation in Section 5.1.",
            "5": "However, Section 3.1 cannot demonstrate effective theoretical information.",
            "6": "1.",
            "7": "The paper recommends a minimum batch size for achieving high throughput, and caching will not be employed if this threshold cannot be met.",
            "8": "Is this threshold a hyper-parameter need to be configured?",
            "9": "The threshold is definitely related to hardware specifications and model architectures.",
            "10": "It is hard for other users to apply this technique.",
            "11": "They have to tune this parameter empirically instead of configure it theoretically.",
            "12": "2.",
            "13": "The method can select appropriate batch sizes by assessing the working memory requirements per token during benchmarking.",
            "14": "It is unclear for readers the details of the selection.",
            "15": "3.",
            "16": "The paper propose to to retain only one layer on the accelerator at any given time during inference, for checkpoint selection.",
            "17": "Is this strategy guaranteed optimal theoretically?",
            "18": "I think the setting of checkpoint depends on the hardware specifications and model architectures.",
            "19": "I think the proposed is not optimal at all times.",
            "20": "Hyper-parameter balancing strategies in Section 3.1 is not a solid theoretical analysis.",
            "21": "It seems a case study for a specific hardware/software settings and it is difficult to transfer to other settings.",
            "22": "Users cannot follow their strategy to set hyper-parameters in an optimal way.",
            "23": "### Other major issues\n1.",
            "24": "The paper claims that Balance Beam is \"an workflow to optimize the trade-off between latency and throughput performance of LLMs\".",
            "25": "However, there is no discussion on the latency in the proposed method and experiments.",
            "26": "From my understanding, the column-wise traversal of Figure 1.a will increase the latency significantly compared to the row-wise traversal.",
            "27": "2.",
            "28": "The evaluation results are based on the authors' implementations, for both baseline and the proposed method.",
            "29": "However, the baseline may be much weaker than the current SOTA solution.",
            "30": "Is it possible to import a public SOTA implementation and conduct comparisons based on that?",
            "31": "3.",
            "32": "The paper use FLOPS to quantify the arithmetic intensity.",
            "33": "FLOPS is a measure of computer performance, while arithmetic intensity is the ratio of total floating-point operations to total data movement.",
            "34": "They do not match.",
            "35": "### Minor issues\n1.",
            "36": "It is not clear whether the proposed method can be applied to other hardware settings, such as other GPUs, TPUs and large scale.",
            "37": "2. the FlexGen proposed in (Sheng et al., 2023) have showed -> has shown\n3.",
            "38": "Table 2.",
            "39": "Optimal -> Ours"
        },
        "A67WO693nw": {
            "0": "The main strength of this paper is that the newly invented FlexGen approach can be applied to training scenarios, providing less data traffic.",
            "1": "It has been impossible to scale batch size due to memory capacity in previous offloading training scenarios.",
            "2": "The paper introduces new hyperparameters into offloading, so tuning hyperparameters (KVcache, batch size, and gradient checkpoints) looks important for better utilization.",
            "3": "For OPT-175B, turning off KVcache shows optimal performance, which is especially interesting.",
            "4": "Providing real value for the experiments make it easy for comparing with different papers.",
            "5": "In addition, if the codes are contributed to popular framework, it would be very helpful to apply common system optimization methods to derive higher throughput with newly invented methods.",
            "6": "I have concerns on aspects of novelty, practicality and evaluation.",
            "7": "### Novelty\n- The main contribution of the paper is in providing a tunable hyperparameter space.",
            "8": "However, the proposed hyperparameters are not newly discovered, but already existing knobs.",
            "9": "Personally, I find it interesting that the popularly used KV caching can be a new hyperparameter, and that putting it together with other parameters is a meaningful work.",
            "10": "However, I don't think the novelty is enough to be published in ICLR.",
            "11": "- The techniques provided from section 3.2 are mostly what's commonly used, especially in ZeRO-offload.",
            "12": "Even though the paper does not strongly claim those as the contribution, it is not okay to introduce them in the methods section, without any citations.",
            "13": "### Practicality\n- This paper suggests the batch size and sub batch size as the key hyperparameter.",
            "14": "However, unlike inference, changing the batch size has impact on the final accuracy.",
            "15": "Because of this, it shouldn't be tuned just for the throughput.",
            "16": "In addition, I was a little disappointed that the paper just provides the results from various tuning points.",
            "17": "At first, I was expecting a systematic/automatic tuning software or a policy, or at least a guideline on how to achieve the goal.",
            "18": "Without them, the contribution is quite limited.",
            "19": "### Evaluation\n- The authors seem to acknowledge that there is accuracy impact on using large batch sizes for training (from section 6.1), but there is no evaluation on the accuracy.",
            "20": "- Some experiments can be misleading.",
            "21": "For training, ‘with optimal hyperparameter settings’ seems to use different effective batch sizes, and only FLOPS results are given.",
            "22": "If effective batch size is different, the throughput difference would come from additional update steps, and this should be considered.",
            "23": "### Writing\n- It's relatively minor compared to other issues, but the writing needs some improvements.",
            "24": "For example, the paper does not clearly distinguish the training and inference.",
            "25": "Even though they share a lot in common, some guide is needed for the readers.",
            "26": "In addition, the description of generative inference with KV-cache is not enough to understand this work.",
            "27": "Even though the KV cache is getting its popularity, this paper lacks enough information to understand the key aspects, such as why utilizing KV-cache is good for transformer inference.",
            "28": "There are some ambiguities and minor mistakes in this paper.",
            "29": "If Fig.1-(b) is placed next to Fig.3, it could be better to see with Sec.3.2.",
            "30": "In Sec.1, ‘5000’ and ‘s’ are placed in different lines, which makes it confusing.",
            "31": "In Sec.1, Insert ‘and’ between ‘batch size’ and ‘number of gradient checkpoints.’ \nI can’t find any references for gradient checkpoints and recompute."
        },
        "ZONnBICcDv": {
            "0": "$\\mathtt{+}$ The results are promising and cover both inference and training of LLMs across a range of benchmarks.",
            "1": "$\\mathtt{+}$ The framework seems to be straightforward to use.",
            "2": "$\\mathtt{-}$ The contribution of the paper is limited and it is not clear whether the presented results are generalizable to other networks and setup.",
            "3": "$\\mathtt{-}$ The majority of presented techniques are already explored and the paper mainly focuses on changing to system hyperparameters for a particular setup.",
            "4": "$\\mathtt{-}$ The choice of the baseline is not well-supported and it is not clear whether the baseline implementation was also fully optimized for the target platform."
        }
    },
    "PDct7vrcvT": {
        "xwss6kfEZc": {
            "0": "* The paper tackles an increasingly important problem of adapting pretrained LLMs to align with shifting legal and ethical expectations, without prohibitively expensive retraining.",
            "1": "The proposed technique offers a feasible solution.",
            "2": "* The proposed methods, e.g., \"reinforcement bootstrapping\" and \"anchor term\" method, are simple and novel.",
            "3": "Besides, Leveraging GPT-4 to generate substitutions is clever, improving sample richness and efficiency.",
            "4": "* The work could have significant implications for improving the ethical use of LLMs, especially concerning data governance.",
            "5": "* The paper's focus on Harry Potter as the sole test case limits its generalizability.",
            "6": "The method itself seems tailored to the specific characteristics of Harry Potter content, raising questions about its applicability to other types of data.",
            "7": "* The evaluation approach is simplistic, relying on a basic ask-answer test.",
            "8": "This is not robust enough to convincingly demonstrate that the target data has been forgotten.",
            "9": "More sophisticated methods like Membership Inference Attacks (MIA) have been used in relevant papers and could strengthen this work.",
            "10": "* The paper does not adequately cite related work, particularly in the area of concept erasure in NLP (like, 1,2,3), which is highly relevant to the paper's focus.",
            "11": "* The paper suffers from several writing issues, including unclear terminology (e.g., inconsistency between 'llama2' and 'llama'), grammatical errors, and improper use of quotations.",
            "12": "1.",
            "13": "Shauli Ravfogel, Francisco Vargas, Yoav Goldberg, Ryan Cotterell.",
            "14": "Adversarial Concept Erasure in Kernel Space.",
            "15": "EMNLP 2022\n2.",
            "16": "Shauli Ravfogel, Michael Twiton, Yoav Goldberg, Ryan Cotterell.",
            "17": "Linear Adversarial Concept Erasure.",
            "18": "ICML 2022\n3.",
            "19": "Nora Belrose, David Schneider-Joseph, Shauli Ravfogel, Ryan Cotterell, Edward Raff, Stella Biderman.",
            "20": "LEACE: Perfect linear concept erasure in closed form."
        },
        "QmOZahhmf3": {
            "0": "1.",
            "1": "The paper presents an interesting and timely topic to study unlearning for large language models.",
            "2": "The paper is well-written and clear to follow with many good motivating examples.",
            "3": "2.",
            "4": "The design choices and various proposed components are reasonable and shown to be useful.",
            "5": "1.",
            "6": "The paper deals with a rather simple and easy scenario of unlearning, which might be hard to adapt to more general setting.",
            "7": "2.",
            "8": "Although the authors claim to open-source the model, it would be still useful to adversarially probe the finetuned model to see how much knowledge about Harry Potter it still contains.",
            "9": "It has been shown that many language models can be jailbroken and outputs undesirable output even when they are RLHF'ed.",
            "10": "3.",
            "11": "The paper also has a few typos scattering around (\"falls short of producing generic predictions is all cases\", \"completions specific to the target text already have a very probability\").",
            "12": "In general, it also misses many references on related work and datasets.",
            "13": "4.",
            "14": "Simple prompting baseline was not compared."
        },
        "4gDqHH2NLq": {
            "0": "Unlearning is a topic of great practical and theoretical interest.",
            "1": "The authors present an unlearning algorithm, show that it works on a nontrivial example, and provide good intution as to why it works.",
            "2": "They are also upfront about some of the limitations of their approach (e.g.",
            "3": "that Harry Potter uses highly distinctive terms).",
            "4": "The paper is also engagingly written and motivates its arguments well.",
            "5": "First, I found the definition of unlearning essentially ad hoc.",
            "6": "As the authors note, unlearning is an essentially adversarial task.",
            "7": "But the evaluation they engage in is not adversarial in any significant way.",
            "8": "I raise this concern not because I ask them to anticipate future attacks -- that would properly be a matter for future work -- but because it shows the inadequacy of their conceptualization of what unlearning *IS*.",
            "9": "A more comprehensive definition of unlearning would be a modification to a model that makes the model _as if_ it had never been trained on the removed data in the first place.",
            "10": "A definition of this sort could be formalized, and would provide strong theoretical guarantees that the model would not -- even under adversarial attack -- produce generations strongly influenced by the unlearned data.",
            "11": "(Indeed, this is the kind of approach taken in differential privacy and in near-access-freeness, both of which provide theoretically coherent accounts of non-learning.)",
            "12": "I am not saying that the authors need to embrace this kind of definition.",
            "13": "But without *some kind* of general theory of what unlearning is, there is no good reason to be confident that the evaluation measures actually capture it.",
            "14": "My second concern is that this kind of token-level replacement does not convince me that unlearning really has taken place.",
            "15": "As I understand it, the evaluation prompts are specific to the Harry Potter novels, and the test is whether the outputs use Harry Potter-specific terms or ideas.",
            "16": "But given the kind of dictionary-based training involved, it's not clear to me whether the associations have actually been unlearned, or just translated into different terms.",
            "17": "Has the fine-tuned model now learned that students at \"the mystic academy\" play \"skyball\"?",
            "18": "If so, this might just be a thinly disguised version of Harry Potter, and the whole novel is still lurking in the model's weights, ready to emerge.",
            "19": "Maybe it will still write fiction that imitates the stylistic features of the Harry Potter novels.",
            "20": "Both of these are the kind of things that copyright law could treat as infringing similarities, since similarity is not confined literally to the text."
        },
        "s1zN5Bc5yb": {
            "0": "-  The problem statement of unlearning copyrighted content in LLMs without retraining from scratch is very timely and significant.",
            "1": "- The focus on the specific case study of unlearning Harry Potter series and the discussion of learnings in arriving at the proposed solution approach while also discussing solutions that dont work is very useful for the readers.",
            "2": "- The main shortcoming of the proposed approach which the paper mentions is that the unlearning approach heavily depends on the fiction content having identifiable anchor terms that are different from natural language.",
            "3": "This makes the approach harder to generalize across a variety of copyrighted content including textbooks."
        }
    },
    "JWpil30sQG": {},
    "nBZBPXdJlC": {
        "WHL1hg7nOW": {
            "0": "- OpenAQA-5M is a good contribution to provide open-ended question answering in audio domain, especially it is verified with human evaluation.",
            "1": "- Ablation study shown in table 5 provides good insights for choices of LoRA params and the benefit of curriculum in staged training.",
            "2": "- For the open-ended questions, this work seems to focus mainly on solely LLMs assisted question answer generation.",
            "3": "It is not intuitive to understand to what extent the model relies on the input audio versus on the common sense knowledge that is already encoded in the LLMs.",
            "4": "It would be great to define and identify beyond current close-ended tasks with new lower level tasks which really require using the audio, such as counting sound events, ordering of events, etc.",
            "5": "These type of questions might already exist in the proposed dataset, it would provide more insights to dive deeper into those.",
            "6": "- Table 5 on the right for the training curriculum, it would be great to also include the language instruction following rate.",
            "7": "And further discuss the correlation between the classification performance and the instruction following rate, if there is any insights that can be drawn."
        },
        "YJekjxGWUE": {
            "0": "1.",
            "1": "This paper claims that it is the first time designing a reasoning comprehension-capable model.",
            "2": "2.",
            "3": "Details of training and dataset are logical and delicate.",
            "4": "It handles the hallucination problem of LLM by training close-ended dataset and then non-answerable question-answer pairs.",
            "5": "It considers the training direction to be \"first to perceive, and then comprehend the sound\" so that the training starts from using close-ended datasets to open-ended datasets.",
            "6": "The paper shows the reasonable claim that it is necessary to gradually train the model from close-ended datasets to open-ended ones because if the open-ended dataset is trained first, the model is heavily dependent on language capability so it is hard to train the audio representation.",
            "7": "3.",
            "8": "The paper is clear and easy to understand.",
            "9": "1.",
            "10": "There seems to be a lack of thought about model structure and loss.",
            "11": "It is just a combination of the strong pretrained LLM and the existing audio encoder, AST.",
            "12": "Utilizing strong pretrained LLM with multimodal inputs has an alignment issue.",
            "13": "Thus, while concatenating the audio feature and the text feature can introduce desired performance, there could be some advancements not just combining pretrained audio model and LLM.",
            "14": "For example, BLIP-2 [1] solves misalignment between text and image using 3 losses: 1) Image-Text matching, 2) Image-Grounded Text generation, and 3) Image Text Contrastive Learning.",
            "15": "The simple combination of the audio model and LLM does not seem to be novel.",
            "16": "2.",
            "17": "The concurrent works show higher performances.",
            "18": "Compared to Pengi, the closed-ended audio task performances are lower.",
            "19": "I understand that the proposed paper is focusing on the open-ended problem, but it would be better to elaborate more in detail that the proposed paper is competitive compared to the concurrent works.",
            "20": "[1] Li, Junnan, et al.",
            "21": "\"Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.\"",
            "22": "arXiv preprint arXiv:2301.12597 (2023)."
        },
        "TxHUyhSEJ5": {
            "0": "Originality:\n1.",
            "1": "The idea, at the time the paper was originally written, was indeed very novel as there were not many audio language models around back in May.",
            "2": "The idea makes a lot of sense.",
            "3": "2.",
            "4": "Audio Instruction Generation (AIG) is also quite nice and interesting.",
            "5": "3.",
            "6": "The curriculum learning is yet another contribution which makes a lot of sense and the authors have proposed an intuitive curriculum and backed it up with apt ablation study to show its utility.",
            "7": "4.",
            "8": "The Human evaluation study adds a ton of value in judging LTU in my perspective.",
            "9": "Quality:\n1.",
            "10": "A high quality manuscript with sufficient experimental details.",
            "11": "2.",
            "12": "I thoroughly enjoyed reading the full paper including all the Appendix sections.",
            "13": "Very thoughtfully done experimental ablation study.",
            "14": "Clarity: \n1.",
            "15": "Very well written manuscript with clear non-monotonic description of details.",
            "16": "Significance: \n1.",
            "17": "In my opinion this is a significant paper as it explores one of the straight-forward ways to couple an audio encoder with a trained LLM and carefully examines this coupling from several different viewpoints and contributes the OpenAQA dataset which can be a useful public resource for future research.",
            "18": "The curriculum training is yet another aspect that makes this effort worthy as it shows that a brute force approach to just wrap in all possible audio-text paired data may not be as good overall.",
            "19": "1.",
            "20": "It is not clear to me what the value of OpenAQA dataset is on top of of the textual metadata available with most of these datasets.",
            "21": "It would have been fascinating if the authors were to do an ablation study to train their model in the format of (Audio, Text) --> Text format - something similar to what PENGI does.",
            "22": "Use the text data that comes with each dataset as is and compare this with :\n  a) Using OpenAQA (current setting)\n  b) Augmenting the original audio text pairs with OpenAQA\n\n2.",
            "23": "It might be valuable to evaluate PENGI on Open ended tasks.",
            "24": "My hunch is LTU would be far better than Pengi in open ended tasks although Pengi might be better on Close-ended tasks.",
            "25": "This would probably highlight LTU significantly as the two approaches are contemporary in many ways and are very similar in the overarching goal.",
            "26": "However the approaches taken are different.",
            "27": "I realize that PENGI's checkpoint was probably not available when this paper was submitted but it is now.",
            "28": "I would encourage the authors to do this comparison to show how LTU could be a more generic model which can be super useful for users to interact with an audio language model through natural text."
        },
        "YRcGQDk46L": {
            "0": "1.The paper introduces for the first time a large language model that combines both general audio perception capabilities and language reasoning abilities, along with the datasets used for training.",
            "1": "It is highly innovative and holds significant importance for the development of general artificial intelligence.",
            "2": "2.Through a significant number of ablation experiments, this paper extensively researched the model's hyperparameter configurations and training strategies, offering highly instructive guidance for related work.",
            "3": "3.The model excels in various audio-related tasks and open-ended question answering, demonstrating its outstanding performance.",
            "4": "1.The performance of this model is closely related to both the AST encoding frontend and the LLaMA model's performance.",
            "5": "Ablation studies on the varying parameter counts of these two components would be valuable, if possible.",
            "6": "2.The authors may add subjective evaluations to the ablation experiments to better demonstrate that the LoRA fine-tuning strategy mitigates catastrophic forgetting issues."
        }
    },
    "ZG3RaNIsO8": {
        "KbreIurx0g": {
            "0": "- The proposed EVOPROMPT framework is innovative, combining the language processing capabilities of LLMs with the optimization performance of EAs.",
            "1": "This approach allows for the simultaneous leveraging of the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs.",
            "2": "- The paper provides a comprehensive review of related works, including prompt engineering, discrete prompts, and LLMs with optimization algorithms.",
            "3": "This review helps readers understand the context and contributions of the proposed method.",
            "4": "- The experiments conducted on 31 datasets demonstrate the effectiveness of EVOPROMPT compared to crafted prompts and existing methods.",
            "5": "The results show consistent performance gains over both manual instructions and existing methods.",
            "6": "- The paper could benefit from more detailed explanations of the implementation details for each type of EA (GA and DE) used in EVOPROMPT.",
            "7": "Providing more information on the specific steps and instructions for each algorithm would help readers better understand the proposed method and its connection to LLMs.",
            "8": "- The paper could include more ablation studies to better understand the impact of different components of the proposed method.",
            "9": "For example, analyzing the effect of different population sizes, mutation rates, or selection strategies on the performance of EVOPROMPT would provide valuable insights into the method's robustness and generalizability."
        },
        "fFaWdYiZ7Q": {
            "0": "* The combination of LLMs with EAs as presented is novel to me, providing insights for future LLM research.",
            "1": "* I liked the design of using the LLM itself to iteratively refine candidate prompts, which harnesses the natural linguistic strengths of LLMs.",
            "2": "This ensures that the generated prompts are coherent, readable, and well-constructed sentences.",
            "3": "* The authors have conducted extensive experiments on benchmark datasets and the discussions on different designs and hyperparameters are commendable.",
            "4": "* The paper is well-written and easy to follow.",
            "5": "It offers useful examples and LLM templates.",
            "6": "* EvoPrompt's performance appears to be influenced by the quality of the initial prompts (initial population), which may limit its applications.",
            "7": "While the paper emphasized the DE version's superior exploration over the GA, a deeper analysis would be beneficial.",
            "8": "* Further discussion and evaluation of the diversity of the prompts produced by EvoPrompt would be beneficial.",
            "9": "* The EA optimization for a single prompt involves iterations.",
            "10": "However, the search doesn't appear to converge in Figure 6.",
            "11": "Is it possible to illustrate the effects of more iterations?",
            "12": "It's unclear if these 10 iterations are conducted within a single LLM session or if each iteration starts with a new session.",
            "13": "Besides, more details should be provided regarding the runtime, and resources for running the GA.\n* It would be beneficial if the authors could present negative examples where EvoPrompt failed, as this could inspire direction for future research.",
            "14": "Moreover, the limitations of this approach should be discussed."
        },
        "n0FgyX0C5A": {
            "0": "First of all, I find the paper well written.",
            "1": "The motivation is clearly explained, the context is well introduced and the authors do a great job in the literature review part.",
            "2": "The method is also clearly explained and detailed which makes it easy for the reader to understand what is going on and which might help to reproduce the work as well.",
            "3": "I also really enjoyed Figure 1 and 2 which are very clean, colorful and do a great job at illustrating the method.",
            "4": "The method itself is sound and I agree that Evolution Strategies make a lot of sense for this problem for all the reasons mentioned.",
            "5": "I mainly like the way crossover and mutation is implemented by querying an LLM.",
            "6": "I find this idea very powerful as indeed, in most cases the main challenge in using EAs lies in defining operators that can stay in the data distribution when perturbing samples.",
            "7": "I also find the experimental setup convincing as the authors performed a large number of experiments and compared to several relevant baselines.",
            "8": "The fact that the method was illustrated both on an open-source and on a proprietary model also strengthened that part and I also like that the authors illustrated how to apply their method and LLM-based evo operator with two different types of Evolution Strategies.",
            "9": "While I really appreciate the evo operator that leverages LLMs, I have more doubts about the relevance of the considered application.",
            "10": "I feel like there are more interesting applications for this method than prompt engineering which I believe will soon not be a thing anymore as we see the latest language models becoming more and more robust to the prompt that is used.",
            "11": "However, I acknowledge that there are ongoing efforts in that field and while I personally don't find it very exciting or relevant, this work contributes efficiently to this research track.",
            "12": "I also have some doubts about the relevance of this work to ICLR.",
            "13": "In my opinion, the main contribution of this work is this LLM-based mutation/crossover operator which would make more sense in an evolutionary algorithms conference such as GECCO than at ICLR.",
            "14": "Finally, I think that this work would strongly benefit from a study of the computational cost of the approach in the main core of the paper.",
            "15": "I saw some elements that could help towards this end in the supplementary, but I would like to see an analysis of the computational cost / financial cost and time needed to perform this optimization.",
            "16": "It would be interesting also to add similar analysis for the baselines.",
            "17": "I think this would be very useful to the readers to evaluate to what extent they could apply that to their research if they have either to serve themselves Alpaca on an accelerator or to query the OpenAI API after connecting their credit card."
        },
        "9xBcn7NzUJ": {
            "0": "The paper is well organized and clearly written.",
            "1": "The paper's attempt to introduce EVOPROMPT as a groundbreaking framework for discrete prompt optimization feels uninspired due to its reliance on established evolutionary algorithms (EAs) rather than innovating with novel approaches.",
            "2": "While the study showcases the ability to optimize prompts for language models like GPT-3.5 and Alpaca, this contribution doesn't significantly advance the state of the art, particularly given the use of well-known evolutionary operators of DE and GA.",
            "3": "Designing prompts for language models, although important, might not meet the level of substantial novelty expected at a conference like ICLR.",
            "4": "This approach, while showing performance enhancements, might not present a substantial leap forward in the field of language model optimization, especially considering the expectations of innovation and original contributions at such academic conferences.",
            "5": "I think this paper would be better suited in a conference like IEEE CEC or PPSN."
        }
    },
    "nAR9xu8WM6": {
        "7KIDub2F8r": {
            "0": "- The literature of DP in multi-modality is lacking, and therefore the work could be interesting\n\n- There are several factually inappropriate usages of the notion of DP.",
            "1": "DP is not \"incorporated\" in a model or multimodality (as the authors mention in different ways a few times throughout the paper), DP is a property of a randomised algorithm (in this context, the training algorithm that produces the distribution of models, not the model).",
            "2": "- Proposition 3.1 is a trivial consequence of the basic theorems of DP, and Algorithm 1 is a simple modification of DP-SGD (that is already available in standard DP-training libraries).",
            "3": "The only interesting aspect is adapting the training procedure to contrastive learning, which is trivial.",
            "4": "Therefore the novelty of these components of the paper is negligible.",
            "5": "- It is unclear why the zero-shot prediction of CLIP is not used as a baseline (as it would be equivalent to epsilon = 0).",
            "6": "Furthermore, the authors are neglecting parameter efficient fine-tuning baselines, for instance like [1].",
            "7": "The description of the baselines is lacking and quite confusing: it's not clear why the authors have two DP-SGD baselines, and what they're exactly updating during training.",
            "8": "- The experimental analysis focuses exclusively on known computer vision datasets that do not differ from the training distribution of CLIP.",
            "9": "It would be useful if following the suggestions of [2,3] the authors could present results in settings with low data regimes and with significant distribution shift with respect to the pre-training set, which represents a more realistic application setting.",
            "10": "Furthermore, the authors deliberately avoid settings where DP is known to be hard due to the relatively low amount of training data per class (e.g.",
            "11": "CIFAR-100/ImageNet).",
            "12": "- Not accounting for the privacy loss incurred in tuning the hyperparameters is a problem.",
            "13": "Simply because baselines have done that, it doesn't justify the authors from reporting inflated numbers.",
            "14": "I would recommend the authors to at least assume the availability of some public data that is kept out of training and evaluations and to run all the baselines fairly in this setting.",
            "15": "- BLIP is definitely no more state-of-the-art as the authors claim.",
            "16": "Several more sophisticated VLMs have been released since BLIP, e.g.",
            "17": "LLaVa 1.5.",
            "18": "- There are several grammatical errors and typos, and the overall presentation is a bit poor.",
            "19": "Sections 5 onwards feel disconnected from the rest of the work.",
            "20": "[1] https://arxiv.org/pdf/2110.05679.pdf\n[2] https://arxiv.org/pdf/2212.06470.pdf\n[3] https://arxiv.org/abs/2306.03962"
        },
        "RML0pqp9Xf": {
            "0": "**significance** The paper studies an important problem of privacy in multi-modal learning with the widely-used CLIP loss and proposes a novel method to make the training DP.",
            "1": "The proposed method shows promising privacy-utility trade-off empirically.",
            "2": "**originality** The proposed method and theoretical results in the paper are both novel.",
            "3": "The bound derived in section 5 seems to be non-trivial given that the loss is not smooth.",
            "4": "**quality** The proposed method and the presented theoretical results are sound.",
            "5": "**clarity** The paper is well-written and easy to follow.",
            "6": "The comparison in table 2 seems to be unfair.",
            "7": "I assume the competitive methods does not use any pre-trained model so I'm not sure how to read the results.",
            "8": "Perhaps one should use the same pre-trained models and then apply the corresponding DP-method for fair comparison."
        },
        "bJWqvYKOxh": {
            "0": "1) The paper is the first to apply differential privacy approaches to multimodal training in the context of vision-language tasks, which is a much needed effort in enhancing privacy protection for such models.",
            "1": "2)  The paper conducts extensive experiments on different vision-language tasks, including image classification and image captioning, to evaluate the effectiveness of DP-CLIP across diverse datasets and privacy parameters.",
            "2": "The paper provides a thorough comparison with related work in the field of differential privacy and vision-language tasks, ensuring that the contributions of DP-CLIP are well-placed \n2) Paper is very well written and easy to follow.",
            "3": "1) The paper employs smaller classification datasets such as MNIST, Fashion-MNIST, CIFAR-10, and SVHN.",
            "4": "It would have been preferable to observe results at the Imagenet scale, but I understand that the computational resources required for such experiments would have been substantial.",
            "5": "2) No comparison with real-world threat models has been provided.",
            "6": "Epsilon-utility trade-offs can be misleading without testing them against actual attacks, as epsilon guarantees are built upon numerous assumptions, as indicated in [1].",
            "7": "Refs \n----- \n[1] A Critical Review on the Use (and Misuse) of Differential Privacy in Machine Learning (https://arxiv.org/abs/2206.04621)"
        },
        "LPDa7JVwu0": {
            "0": "- Studying the privacy risks in multimodal learning is a relevant and important research topic\n- It is nice to a see a formal characterization of the utility-privacy trade-off\n\nI found the experimental section to be very problematic.",
            "1": "Specifically, \n- Framing the algorithm as \"DP-CLIP\" is very misleading.",
            "2": "You didn't train a CLIP model from scratch using DP-SGD, but rather continue pretraining a **well-trained** model in a privacy-preserving manner.",
            "3": "This is not mentioned in the abstract, and is not made clear until the experimental section.",
            "4": "As a side note, the comparison with Yu et al.",
            "5": "(2023) is unfair: 1) there are obviously no \"two stages\" in your algorithm since you only performed continued pretraining; 2) Yu et al.",
            "6": "(2023) only pretrained on synthesized textures to speedup the DP training process, while the starting point of your DP training is already a very strong model.",
            "7": "- The classification tasks are too simple given the power of the pretrained model.",
            "8": "It might not be necessary at all to perform private continued pretraining; plus I found pretraining on datasets such as MNIST and CIFAR-10 to be super weird.",
            "9": "Two critical baselines are currently missing: the accuracy of the vanilla CLIP model (without continued pretraining), and the accuracy of $\\varepsilon=\\infty$ (non-private continued pretraining).",
            "10": "- The comparison with other baselines in Section 4.2 is arbitrary and careless.",
            "11": "The authors didn't evaluate the same set of methods on all datasets, and didn't report whether the results for other algorithms are based on their own implementation or directly copied from prior works.",
            "12": "The accuracy of DP-Sinkhorn on Fashion-MNIST does not match the one reported in the original paper.",
            "13": "It is also unclear whether these algorithms are indeed the state-of-the-art methods in image classification.",
            "14": "Finally, DP-Sinkhorn is not even a DP image classification method -- while it is capable of performing such task, it is essentially an algorithm of DP data synthesis (take a look at [1] if you are not familiar with this concept).",
            "15": "It is unbelievable that the authors chose this method for comparison.",
            "16": "- I didn't buy the results from Section 4.3; particularly, I have never seen using $\\varepsilon = 1e-4$ in the privacy literature, and it is hard to believe that such privacy budget could still lead to a meaningful model (in the extreme case $\\varepsilon=0$, the model will become completely random).",
            "17": "On the other hand, the authors seemed to suggest that the model's performance is mostly unaffected even in this extreme case.",
            "18": "I insist: 1) report the $\\sigma$ (the noise multiplier), and check the SNR to see whether the results make sense; 2) use $\\varepsilon=1e-8$ and see whether the results are still consistent; 3) use the vanilla CLIP model (without any further continued pre-training) and see whether the results are already very good.",
            "19": "Other issues in this section: 1) there is no description of the non-private model, I have completely no idea what \"IBM Research AI\" is and whether the comparison with DP-BLIP makes sense at all; 2) it is unclear why a baseline of non-private BLIP is missing.",
            "20": "Minor:\n- The experiments should be running over multiple random seeds, and please include the standard deviations in the tables\n- The dataset paragraph should be revised.",
            "21": "The descriptions of the datasets are way too long yet important details are missing (e.g., the dimensionality of each dataset).",
            "22": "The metrics used in image captioning are not explained.",
            "23": "- \"TensorFlow Privacy\": which privacy accountant did you use exactly?",
            "24": "As a side note, RDP and PRV accountant are the go-to choices nowadays.",
            "25": "- The paragraph below Table 2: \"which is not present for DP-SGD\" -- please note that the pretraining and extra caption data are not used in other baseline methods as well\n- Various grammatical issues, included but not limited to: \"while a smaller or equal $\\varepsilon$\" -> \"with a smaller or equal $\\varepsilon$\"; \"allow our private approach to achieving\" -> \"to achieve\"; \"Apart from their work\" -- I don't understand what you meant here; \"requires... should be indistinguishable\" --> \"to be indistinguishable\".",
            "26": "Please do a professional proofreading before submitting your work.",
            "27": "In light of the major issues in the experimental section, this paper is clearly below the bar of ICLR and I will strive for a rejection.",
            "28": "Reference\n\n[1] Hu et al.",
            "29": "\"SoK: Privacy-Preserving Data Synthesis.\"",
            "30": "2024 IEEE Symposium on Security and Privacy (SP).",
            "31": "IEEE Computer Society, 2023."
        }
    },
    "rTDyN8yajn": {
        "wuGqdG5Qlh": {
            "0": "1.",
            "1": "The work adopts a simple but effective gate routing scheme allowing sparsely-activated LoRA modules to learn task- and modality-specific knowledge as an independent expert.",
            "2": "2.",
            "3": "The work can address various 2D/3D vision and language tasks, and conduct various experiments to validate the effectiveness and versatility with a few trainable parameters.",
            "4": "1.",
            "5": "The work focuses on SFT, whether it can be generalized to pre-training on massive data.",
            "6": "2.",
            "7": "Lack of evaluation on some of the latest MLLM Chat evaluation, such as MMBench, MME, SEED-Bench, etc.",
            "8": "3.",
            "9": "Lack of comparison with some classic and latest methods, such as MiniGPT4, mPLUG-Owl, LLAVA-1.5, Qianwen-VL, etc."
        },
        "rxV7rmhbzf": {
            "0": "- This paper constructs Octavius by collecting better detection annotation, combing multiple modality data and propose a novel MoE architecture.",
            "1": "- The authors provide a throughout discussion between related works.",
            "2": "- The proposed method is relatively simple but with strong performance.",
            "3": "- About the tug-of-war problem:\n  - The authors demonstrate the existence of this problem simply by optimization 2D detection and VQA simultaneously.",
            "4": "- Considering the authors also include multi-modality, it would be better to include preliminary also in this direction (e.g., 2D & 3D captioning).",
            "5": "- About the router input:\n  - As shown in Fig.",
            "6": "2, the input consists of the system prompt, modality embedding and the question embedding, which contradicts wit Tab.",
            "7": "5.",
            "8": "Would you mind clarifying how exactly to construct the router input?",
            "9": "- Also how to get the question embedding?",
            "10": "Do you utilize other embedding model or just do that on-the-fly?",
            "11": "- About the MoE deployment:\n  - Do you adopt LoRA-MoE in each Transformer block?",
            "12": "- Do you adopt LoRA only for the MLP, similarly with the original MoE?",
            "13": "- About zero-shot evaluation:\n  - According to Sec.",
            "14": "4.1, the zero-shot evaluation conducted in this paper is only about zero-shot evaluation on novel datasets of the training tasks (e.g., ScienceQA for evaluation and VQA for training).",
            "15": "- Therefore, I wonder how it works if you have not seen any QA tasks during training, since it is difficult to understand a specialized architecture like MoE can generalize well to totally unseen tasks during pre-training.",
            "16": "- Moreover, if you still train with VQA, but change the prompt template of ScienceQA during testing, will the MoE router be robust to this kind of OoD generalization?",
            "17": "- Overall, I think this is an interesting paper, but still with some problems to convince me about the effectiveness of the proposed method.",
            "18": "I would consider increasing the score if my questions are well addressed."
        },
        "gMKs5GShFT": {
            "0": "- The paper is well-motivated -- MoEs have been shown to be useful for distributing the different types of knowledge that are required for multi-task learning, and VL instruction tuning is a good application of this insight.",
            "1": "- The experiments are performed on both 2D image and 3D point cloud tasks, both individually and with the two datasets combined.",
            "2": "- I am primarily concerned by the analysis in Figure 5 -- it seems that all the 2D tasks are using only two experts!",
            "3": "This makes me skeptical about the utility of MoE at all.",
            "4": "Could you run the ablation in Table 5 with 2 experts?",
            "5": "so these two experts will get selected each time and there in routing involved, but the model has the capacity to learn with 2 LoRAs at once instead of one (which is what it seems to be doing in Fig5)\n\n- An additional analysis that is needed is how the gate routing is distributed between 2D and 3D tasks, for the model that is trained on the combined LAMMv2+ScanNet instruction tuning dataset.",
            "6": "Given the result in Figure 5, I am not convinced about the utility of MoE with routing, when it doesn't seem that different experts are even used.",
            "7": "- I am not sure what the non-MoE baseline in Tables 2-3 is -- is it merely training the frozen model minus the LoRA parameters?"
        },
        "CfVkOUtLd7": {
            "0": "- The idea of MoE with sample routing to mitigate task interference for MLLMs is novel.",
            "1": "- The author conducted thorough experiments to validate the framework on a diverse set of 2D and 3D tasks.",
            "2": "The gains are substantial.",
            "3": "- The framework is modular and extensible to incorporate more modalities and tasks.",
            "4": "- There is no analysis on how the routing among experts actually works.",
            "5": "It would be great if the authors can provide some qualitative study of the predictions from sample-based gating network as responses to the input task, to show how the routing mechanism work.",
            "6": "I wonder whether the gating network will simply act like a task classifier, or it's not the case.",
            "7": "- The scaling behavior as more modalities and tasks are added is not studied.",
            "8": "There may be limitations in very high multi-task settings."
        },
        "XxemJdLl39": {
            "0": "This method is straightforward but powerful, capable of integrating numerous vision tasks within this framework.",
            "1": "Its adaptability is showcased as it seamlessly operates with both 2D images and 3D point clouds.",
            "2": "Ultimately, the integration of LoRA with MoE for PEFT proves to be highly efficient.",
            "3": "Given our awareness of each example's task, an important baseline involves employing a dedicated LoRA for each task individually.",
            "4": "Additionally, conducting an ablation study on the impact of top-k would be informative."
        }
    },
    "Q3YaCghZNt": {
        "SGybkF6N0J": {
            "0": "1.",
            "1": "This is a very well-written paper and presents a nice, clean formalization of the guess-and-check style of program reasoning via the Lemur calculus.",
            "2": "2.",
            "3": "The algorithm that operationalizes the calculus is elegant and easy to understand.",
            "4": "3.",
            "5": "Use of LLMs to suggest candidate program invariants is an obvious idea but it has been very well manifested into practice, both mathematically and algorithmically,  by this work.",
            "6": "4.",
            "7": "Some of the prompting tricks used to get the invariants from the LLM, such as placeholder lines, are interesting in their own right.",
            "8": "5.",
            "9": "Most importantly, the empirical results are very promising and suggest that LLMs and verification tools can be fruitfully combined.",
            "10": "1.",
            "11": "This is a relatively minor comment but the formalization and the algorithm seem geared towards imperative languages where the notion of associating a property/invariant with a line number makes natural sense.",
            "12": "It would be helpful to acknowledge that the proposed calculus might not necessarily be applicable to all programming languages.",
            "13": "2.",
            "14": "There has a large body of literature on data-driven techniques for learning loop invariants [1,2].",
            "15": "Unlike Code2Inv and Lemur, these past works use dynamic values of loop variables.",
            "16": "Adding references to this body of work would help paint a fuller picture about this area.",
            "17": "[1] Garg, P., Neider, D., Madhusudan, P., & Roth, D. (2016).",
            "18": "Learning invariants using decision trees and implication counterexamples.",
            "19": "ACM Sigplan Notices, 51(1), 499-512.",
            "20": "[2] Sharma, R., Gupta, S., Hariharan, B., Aiken, A., Liang, P., & Nori, A. V. (2013).",
            "21": "A data driven approach for algebraic loop invariants.",
            "22": "In Programming Languages and Systems: 22nd European Symposium on Programming, ESOP 2013, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2013, Rome, Italy, March 16-24, 2013.",
            "23": "Proceedings 22 (pp.",
            "24": "574-592).",
            "25": "Springer Berlin Heidelberg."
        },
        "jcLqjgbfJm": {
            "0": "- Clear presentation\n- Reachability is a pivotal problem in program verification\n- Promising preliminary results\n- (To the best of my understanding) Lemur's calculus and template algorithm can accomodate different combinations of invariant generators and verifiers\n\nMy main concerns are related to the empirical evaluation of Lemur.",
            "1": "The combination of LLMs and standard verification procedures is indeed promising, but I am left wondering how much the results are reliant on the specific LLM GPT4.",
            "2": "This is particularly important considering the economic cost of reproducing the experiment, which can be prohibitive for some.",
            "3": "If I understand correctly, Lemur is a template algorithm.",
            "4": "I would then expect to see results for LEMUR(X, Y), where X = {GPT4, other free LLMs, other invariant generation techniques (Code2INV maybe?",
            "5": "), and Y = {UAUTOMIZER, ESBMC}."
        },
        "R9iz9PBTtx": {
            "0": "The main strength of the paper are the results in Section 5\\\n\n.",
            "1": "Presentation\n\nOnly good results are shown?",
            "2": "How likely is the fail case?",
            "3": "ChatGPT seems a magic box, Above al, the way you present your work makes it unnecessarily hard to understand ypur ideas."
        },
        "r1KgNecjeF": {
            "0": "The paper is clearly written, modulo some typos.",
            "1": "This helps in taking the reader along with the flow of the presentation.",
            "2": "The core ideas are illustrated with a running example -- this helped me follow the ideas without much difficulty.",
            "3": "The idea of using an LLM to propose assumptions that can then be used to simplify a verification task is promising and the experiments demonstrate this.",
            "4": "Being able to out-perform the winning entries in SV-COMP is a significant achievement, and I believe this sufficiently demonstrates the promise of the approach.",
            "5": "The set of rules formulated by the authors doesn't add much value to the paper.",
            "6": "Algorithm 1 could itself have been presented directly, with explanations for the different steps.",
            "7": "In my opinion, the rules are kind of a force-fit to the paper.",
            "8": "It is good that the authors try to show that the proof rules are sound; however the soundness proofs are simple and not very insightful.",
            "9": "Indeed, finding a sound set of rules for simplifying/decomposing program verification is often not the difficult part of the process.",
            "10": "The more technically challenging part is to have completeness results for some subclass of programs/properties.",
            "11": "Unfortunately, the authors don't even try to do this.",
            "12": "Since there are practical limits to prompt lengths for an LLM like GPT or GPT-4, this sets limits to how large a program can be verified using the proposed technique.",
            "13": "This is highly undesirable.",
            "14": "It would have been better if the authors attempted decomposition of the problem (perhaps guided by an LLM) and then applied the proposed technique to each decomposed part, and then stitched the results back together.",
            "15": "Unfortunately, the authors completely avoid any such attempt/discussion.",
            "16": "SV-COMP has several tracks for verification.",
            "17": "The total count of programs in SV-COMP is significantly larger than that reported by the authors.",
            "18": "It is not clear whether some cherry-picking was done in selecting the examples.",
            "19": "An LLM like GPT-4 makes use of immense computational power at the server end to come up with proposals/suggestions quickly.",
            "20": "It is not fair to discount this computational effort completely when comparing with the performance of other solvers that do not make LLM calls.",
            "21": "As a consequence, I believe the time comparison is not fair.",
            "22": "A method like the one proposed, without any considerations of how the LLM is trained, may give dramatically different results based on what LLM is being used.",
            "23": "Therefore, a discussion on training the LLM should have been included."
        }
    },
    "JzG7kSpjJk": {
        "PQdb6eWCrb": {
            "0": "The numerical results suggest that this quantization framework can help reduce the loss of accuracy from quantization.",
            "1": "- First, I think the presentation of the paper is very hard to follow.",
            "2": "The authors choose to write a paragraph rather using mathematical notations that can make the paper easier to follow.",
            "3": "At core, given the activation as $WX$ with $W\\in R^{q\\times p}$, they propose to have $p$ quantizers where quantizer $i$ corresponds to column $i$ of $W$, rather than having $q$ of them each corresponding to a row of $W$.",
            "4": "Other examples include using the term \"Activation\".",
            "5": "Is activation referring to $WX$ or $X$?",
            "6": "Or $W$ which are the weights?",
            "7": "Isn't this work trying to circumvent outliers in $W$?",
            "8": "Then why they talk about activation outliers in page 3?",
            "9": "The method does not even seem to detect outliers, then why talk so much about outliers?",
            "10": "Overall, I find the paper confusing and hard to follow.",
            "11": "- It seems transposing the direction of quantization helps with accuracy.",
            "12": "But then what happens in terms of implementing this method in practice?",
            "13": "Note that this per-IC quantization method is not a drop-in replacement for per-OC, or at least if it is, that requires to be substantiated with experiments.",
            "14": "As far as I could tell there are no experiments on hardware implementation and inference time performance of the proposal.",
            "15": "The hardware implementation is very briefly mentioned in Section 3.2, but the explanation actually creates more questions than answers, as it contain a bunch of new notations that are never properly defined.",
            "16": "The authors say \"With per-IC quantization, we can maximize the performance of the GPTQ algorithm by using reordering for free without the static groups constraint.\"",
            "17": "which again I don't think is numerically supported.",
            "18": "Overall, I think the paper needs some rewriting to make it easier to understand, and several experiments to show the benefits of per-IC in inference time."
        },
        "c2ZJq23jIs": {
            "0": "1.",
            "1": "The analysis on input/output channel sensitivity is very interesting (figure 2 and 9).",
            "2": "2.",
            "3": "Performance improvement on WizMath and WizCoder is pretty impressive (Table 4).",
            "4": "3.",
            "5": "While input channel quantization isn't new (weakness 1), AdaDim is novel.",
            "6": "1.",
            "7": "Exploring non-output channel quantization isn't new.",
            "8": "See [1] that explores input-channel and arbitrary combination of row and column groups for quantization.",
            "9": "2.",
            "10": "All evaluations in this paper use sub-channel quantization with group size of 128.",
            "11": "While this is the SOTA configuration, I suggest authors to compare per-channel quantization (without groups) which might better demonstrate the advantage of input channel quantization over output channel quantization for certain layers.",
            "12": "This is because the analysis was compare channel-wise sensitivity instead of sub-channel sensitivity.",
            "13": "[1] Yuan, Z., Chen, Y., Xue, C., Zhang, C., Wang, Q. and Sun, G., 2021.",
            "14": "Ptq-sl: Exploring the sub-layerwise post-training quantization.",
            "15": "arXiv preprint arXiv:2110.07809."
        },
        "1EIB0qowI9": {
            "0": "1.",
            "1": "The high-level idea is good.",
            "2": "The idea of \"per-IC quantization\" is clear and effective solution.",
            "3": "2.",
            "4": "This paper is well-written and organized.",
            "5": "3.",
            "6": "I agree the issue that accelerating the memory I/O is important in some scenes, and solving this challenge is very valuable in the industry.",
            "7": "1.",
            "8": "The experiment results with activation quantization is expected, and more compared methods such [1] are necessary.",
            "9": "2.",
            "10": "The result of A.3 is important, more detailed analysis with diagram is expected.",
            "11": "[1] Smoothquant: Accurate and efficient post-training quantization for large language models"
        }
    },
    "e5lR6tySR7": {
        "XQth6f9GdS": {
            "0": "The discussion on the implication of the limitations of Transformers in only expressing functions in $TC^0$ is interesting.",
            "1": "Studying the actual limitations of Transformers in terms of their capabilities, and not just in terms of function class approximation, is important.",
            "2": "While the premise of the paper seemed interesting, I find that the paper does not give a proper discussion of some relevant aspects of Transformer-based LLMs.",
            "3": "First, the discussion on the effect of using Chain-of-Thought (CoT) and the relation to the negative result is not clear.",
            "4": "The authors do acknowledge that CoT with auto-regressive inference allows Transformers to compute functions beyond $TC^0$, but claim that this somehow does not apply to their setting.",
            "5": "The authors need to clarify whether their results cover Transformer used for decoder-like auto-regressive inference, where in each iteration the Transformer is used to generate the next token.",
            "6": "If so, why does CoT not solve the limitation of computing functions in $TC^0$?",
            "7": "While every iteration is \"in $TC^0$\", the overall function computed by the Transformer can go beyond this limitation.",
            "8": "If this is because the Transformer cannot output tokens that are \"ignored\" during the computation, I believe this does not capture properly the behavior of Transformer-based LLMs, which clearly can utilize CoT in a way that overcomes this limitation.",
            "9": "Second, it is not clear which results are novel contributions (on the technical level), and which results are just \"rehashing\" of known results.",
            "10": "As the limitation of Transformers in only expressing functions in $TC^0$ has already been established, what results are novel to the paper?",
            "11": "Is the analysis of limitations of $TC^0$ functions in expressing universal circuits new?",
            "12": "I think that the authors should clarify whether they are just stating known facts about the limitation of $TC^0$, whether they are proving new results on the capabilities of $TC^0$ functions, or whether the setting of language-modeling with $TC^0$ generates new theoretical results that are not already studied in the classical circuit complexity literature.",
            "13": "Some minor comments:\n- I believe that the term \"general learner\" is confusing, as the discussion in not about what functions can be learned by Transformers (i.e., given training samples), but rather what functions they can approximate.",
            "14": "- The claim that \"LLMs can solve complex tasks by memorizing some instances\" is somewhat problematic.",
            "15": "The fact that Transformers are able to memorize inputs does imply that this is how complex tasks are solved.",
            "16": "- The beginning of Remark 1 is confusing, and should be rewritten."
        },
        "zXOkT8AvZ3": {
            "0": "1.",
            "1": "I really like the research question and goals of this work, as it draws an interesting connection between transformers' ability to execute instructions (posed as circuits) and existing results analyzing transformers via circuits and classical work on universal circuits.",
            "2": "2.",
            "3": "The work successfully leverages the framing of general learners in terms of circuits to conclude that transformer LMs are not universal learners.",
            "4": "If the authors can adequately address the following issues around presentation and the interpretation of Theorem 5, I would be satisfied raising my score, as I value the research question raised by the paper and believe the conclusions are valid.",
            "5": "## \"General Learner\": Missing Formal Definition and Misleading Name\n\nThe \"general learner\" concept used in the title and throughout is named in a somewhat misleading way, as the results here have to do more with *expressive power* than learning.",
            "6": "That is, by \"general learner\" the authors mean a model that can *express* a universal circuit.",
            "7": "This is a bit confusing and I would suggest either changing the terminology or explicitly clarifying that you are talking about expressive power and not learning (which is fine, limitations on expressive power translate to limitations on what can be learned).",
            "8": "More of an issue is that the fact that the definition of general learner in Section 2.2 is not clearly structured.",
            "9": "After reading it several times, I get the idea that the authors view a model as a general learner if it can simulate a universal circuit for all poly-size circuits.",
            "10": "Yet it seems inconsistent at times whether this is a formal definition of the concept or a necessary condition obtained from some other (unprovided) definition, as Proposition 1 suggests.",
            "11": "I would suggest rewriting Section 2.2 in one of two ways:\n1.",
            "12": "Provide a formal definition for \"general learner\" before stating the proposition.",
            "13": "2.",
            "14": "Leave \"general learner\" imprecise but reframe proposition 1 as your formal definition attempting to capture it: you view an LM hypothesis class is a general learner if it can express a universal circuit family for all poly-size circuits.",
            "15": "You can then argue informally for why you think this definition makes sense, akin to, e.g., the Church-Turing thesis.",
            "16": "## (Minor) Imprecise Claim about Poly(n) Size\n\nIn Theorem 1, the authors claim:\n> We consider log-precision, constant-depth, and polynomial-size Transformers: for Transformers whose input is of length n, the values at all neurons are represented with O(log n) bits, the depth is constant, and the number of neurons is O(poly (n)).",
            "17": "This setting captures the design and the hardware restriction of realistic T-LLMs and is common in the literature on the theoretical power of T-LLMs (Hahn, 2020; Hao et al., 2022; Merrill et al., 2022; Merrill & Sabharwal, 2023).",
            "18": "This is almost correct, but largely these papers consider a slightly different setting where the number of neurons is O(1), and all other complexity measures are as described.",
            "19": "However, it should be straightforward to extend the results from these papers to the poly(n) case, at least in the nonuniform setting considered here.",
            "20": "It would be good to make this more explicit here though.",
            "21": "## Logical Flow of Main Results and Relation to Prior Work Should be Clarified\n\nThe paper defines T-LLMs as general learners if \"the expressive power of realistic T-LLM model class can cover universal circuits for\nall circuits of polynomial size\" and says that:\n\n> It is unknown whether the realistic Transformers are expressive enough to be general learners \n\nIn fact, it seems that Theorem 3 essentially follows from the TC0 upper bound in previous work.",
            "22": "Here's how I would reconstruct the proof of Theorem 3:\n\n*Proof.",
            "23": "* Assume T-LLMs are general learners by contradiction.",
            "24": "Take any P-complete problem p. p has a poly-size circuit by membership in P, and thus T-LLMs must be able to execute some circuit to solve p. But then there is a threshold circuit with input size n + poly(n), constant depth, and size poly(n + poly(n)) that solves p. This means that p is in TC0, which results in contradiction unless TC0 = P (conjectured false).",
            "25": "Thus, it seems to me that you are essentially applying past results to answer a specific question you have (which is still a valuable contribution).",
            "26": "However, it is confusing to me how this interacts with the prior results in the paper.",
            "27": "How does Theorem 2 come into play when proving Theorem 3, if Theorem 3 can be proved independently?",
            "28": "Is Theorem 2 a stronger version in some sense because it applies for polylog input size?",
            "29": "Another question: does \"prompts of complexity n\" mean prompts of length n?",
            "30": "If so, does this follow from Theorem 2?",
            "31": "This isn't clear from the current structure if so, since it's stated as a corollary of Theorem 3.",
            "32": "In general, it may help to reorder some of these results, add forward references to the proofs, and indicate how different results depend on one another.",
            "33": "## Claims about Instance Memorization are Very Speculative\n\nThe authors show that a poly(n)-size transformer can in principle memorize poly(n) instances, but it is quite a jump to the idea that this instance-based memorization is what explains the success of T-LLMs in practice.",
            "34": "There is a lot missing to actually justify this claim:\n1.",
            "35": "For one, it would require doing some experiments with trained LMs and finding evidence of memorization.",
            "36": "In fact, empirical evidence suggest that LMs do memorize n-grams from their training data somewhat, but not full examples (see [McCoy et al.",
            "37": "](https://arxiv.org/abs/2111.09509))\n2.",
            "38": "There are theoretical reasons why it would be difficult for a T-LLM to learn to memorize instances from single examples.",
            "39": "T-LLMs are trained with huge batches, and it can be hard to pick out all the information about one example from a batch.",
            "40": "This idea has been used to show lower bounds on the learnability of functions like sparse parities for feedforward neural networks (see [Barak et al.",
            "41": "](https://arxiv.org/abs/2207.08799))\n\nThe authors have already hedged the claim that memorization is responsible for the success of T-LLMs, but I think it could be toned down further and, if the authors would like to engage in speculation, it would be good to integrate some of this related work and its implications into the discussion (e.g., memorizing full instances from a single occurrence doesn't seem to happen in practice and there are theoretical arguments against it)."
        },
        "aBsY6MMlXO": {
            "0": "--\n\nI had trouble following the paper as the definitions and claims have not been presented well.",
            "1": "It is really hard to find the main technical claim of the paper, and the introduction was of little help.",
            "2": "The paper essentially argues that not having the ability to solve \\textit{all} problems, raises doubts on LLM capabilities.",
            "3": "It is not clear why it can't just be \\textit{most} problems, or most instances of most problems.",
            "4": "Although the paper reduces the problem to a well known results, it can still be worthwhile to provide a single example of a problem that cannot be solved to get an idea of what falls outside the purview of current models."
        },
        "Q2eWk5YENJ": {
            "0": "This work has the potential to set a precedent in the fusion of quantum computing with graph transformers.",
            "1": "Enhancing the paper with the aforementioned suggestions could substantially improve its impact and reception by the research community.",
            "2": "Definition of Variables and Positional Encodings:\n\nThe paper would greatly benefit from a more detailed explanation of the positional encodings used.",
            "3": "Terms such as θ, t, δ, and especially the adjacency matrix A, which are crucial for understanding the method, require clear definitions and contextual usage within the proposed quantum framework.",
            "4": "Furthermore, an explicit definition of the feature matrix X of the nodes would help in understanding how these features interact with the quantum-inspired positional encodings.",
            "5": "Clarity on Quantum Enhancements:\n\nSection 3.2.2 seems to lack depth in the explanation of how the quantum correlations are calculated and utilized within the graph transformers.",
            "6": "Providing a more comprehensive elucidation of these processes would aid in bridging the gap between classical and quantum approaches.",
            "7": "A layman's explanation or intuitive reasoning behind the adoption of quantum features and their computational advantages in graph analysis would be invaluable for the reader's understanding.",
            "8": "Theoretical Advantages and Theorem Justification:\n\nWhile you mention that quantum features are theoretically more expressive, the paper falls short of explaining the underlying intuition and proof for this assertion.",
            "9": "Elaboration on Theorem 1, with an intuitive breakdown of its implications, would significantly enhance the readability and credibility of the results.",
            "10": "Comparative Analysis and Benchmarking:\n\nThe comparisons presented in Tables 1 and 2 focus solely on the improvements over one reference work (Ma et al., 2023).",
            "11": "For a more comprehensive analysis, it would be instructive to see how the approach compares with a broader spectrum of state-of-the-art methods.",
            "12": "Additionally, the rationale for choosing (Ma et al., 2023) as a benchmark, along with the significance of the improvements observed, even if minute, should be clearly articulated.",
            "13": "It's important to discuss why these improvements are non-trivial and how they advance the field, considering the rapidly evolving landscape of both quantum computing and graph analysis."
        },
        "ymuy3iepHc": {
            "0": "The question about whether realistic transformers can represent any polynomial-time-computable function is interesting.",
            "1": "All of the results in this work seem to be previously known:\n* Theorem 1 is general to any polynomial-size circuit -- there is nothing special about Transformers.",
            "2": "It proves that not all functions are polynomial-time computable via a counting argument, which is previously known.",
            "3": "* Theorem 2 is a restatement of past work, showing that transformers lie in logspace-uniform TC^0\n* Theorem 3 assumes TC^0 \\neq P / poly, and then derives that transformers cannot simulate any poly-time circuit.",
            "4": "This is immediate from Theorem 2, and this kind of separation appears to have been the implicit the point of Merrill and Sabharwal 2023\n\n* This statement seems overly strong and minimizes prior work: \"This work takes the first step towards rigorously answering the fundamental question by considering a theoretical boundary of model capacity to be general learner\" \n    * e.g., \"Saturated Transformers are Constant-Depth Threshold Circuits\" shows that transformers lie in TC^0 under a saturation condition\n    * e.g., \"The Parallelism Tradeoff: Limitations of Log-Precision Transformers\" shows that log-precision transformers lie in log-space-uniform TC^0"
        }
    },
    "owokKCrGYr": {
        "0Zvt3CAbtX": {
            "0": "1.",
            "1": "The authors have proposed a novel and effective quality-diversity algorithm that leverages the latest developments in AI feedback, demonstrating superior performance compared to existing alternatives.",
            "2": "2.",
            "3": "The paper features a comprehensive set of experiments focused on creative writing, supported by a thorough analysis of the results, showcasing the practical applicability of the proposed method.",
            "4": "1.",
            "5": "The presentation, particularly in the experimental section, could benefit from clarification and better organization to enhance readability and comprehension.",
            "6": "2.",
            "7": "The paper occasionally employs exaggerated language and makes promising claims that seem to lack sufficient empirical backing.",
            "8": "For example, the paper states “providing a recipe that seemingly generalizes to many domains and modalities” and “it is often easier for a model to evaluate the quality of a generation than to generate the same high-quality text.” These claims would be more convincing if supported by concrete evidence or reference or discussion."
        },
        "Nzfrx51xAO": {
            "0": "Strength: \n* The paper addresses an interesting problem in the creativity domain, namely, generating solutions that are both diverse and of high quality.",
            "1": "The integration of AI feedback and the existing QD algorithm seems to be novel and interesting\n\nWeakness\n* One key motivation of the paper using AI feedback seems to bypass the necessity to articulate a set of criteria.",
            "2": "However, the prompt strategies still resort to specified diversity and quality criteria\n* The evaluation result seems to be a bit confusing; for example, in Table 1, one of the methods is LMX, Fitness-only, then in section 4.3 when it explains the method, there is LMX Quality-only.",
            "3": "Is that the same method as LMX, fitness-only\n* It would be interesting to see ablation analysis to compare with the QD with and without AI feedback (not sure if LMX fitness-only or quality only serves the baseline) \n* QD metric is used throughout, which is the “sum of highest quality value found in each bin” - it seems to only focus on quality rather than diversity.",
            "4": "For readers not familiar with QD metrics, some explanation/justification of why QD measures Quality and Diversity will be helpful"
        },
        "qAhfpw7Kld": {
            "0": "- A combination of simple ideas that allow to generate diverse high-quality outputs\n- Strong performance in the experiment section\n- The paper is well written\n\n- The lack of strong baselines\n- More datasets for the experiments would be appreciated"
        },
        "Fa6AiDZ4fz": {
            "0": "1.",
            "1": "QDAIF presents a novel approach to discover diverse and high-quality solutions in qualitative domains by leveraging AI feedback, which contributes to the development of AI systems.",
            "2": "2.",
            "3": "The paper thoroughly discusses limitations and potential future work, offering some insights for further research in this area.",
            "4": "1.",
            "5": "QDAIF still requires researchers to define the axes of diversity they are most interested in, which may limit its autonomy in creative search.",
            "6": "2.",
            "7": "Could we have a detailed comparison with other AI feedback methods or discuss how QDAIF specifically addresses their limitations?",
            "8": "3.",
            "9": "The generalizability of QDAIF to other domains and tasks beyond creative writing is not extensively discussed."
        }
    },
    "wXpSidPpc5": {
        "EwKZv5BgPu": {
            "0": "* CLEX demonstrates strong length extrapolation results (evaluation length > train length) compared with prior PE scaling methods such as Position Interpolation,YaRN, and CodeLLaMA.",
            "1": "* When the evaluation length is smaller than the train length (i.e.",
            "2": "finetuning length), CLEX exhibits a better performance compared with prior PE scaling methods.",
            "3": "* The ablation includes a few useful topics such as continuous vs. discrete dynamics, sampling strategy, and log-scaling.",
            "4": "* Despite a strong extrapolation performance, the motivation for adopting continuous modeling is a bit unclear.",
            "5": "It seems that the continuous model has to be somehow discretized on a few points (e.g.",
            "6": "evaluating the integral of equation 12).",
            "7": "If this is true, doesn't this imply an equivalent discrete modeling?",
            "8": "* CLEX is adopting YaRN in equation 13, so it seems some part of the performance of CLEX is due to YaRN.",
            "9": "An ablation of CLEX without YaRN is needed.",
            "10": "* CLEX is based on PE scaling, which requires a finetuning dataset.",
            "11": "However, non-PE scaling methods (e.g., ALiBi and RandomPos) don't require finetuning.",
            "12": "So it doesn't seem fair to compare CLEX with non-PE scaling methods.",
            "13": "* The author mentioned that CLEX is computationally demanding due to the evaluation on the integral.",
            "14": "Maybe the author can comment more on the training time.",
            "15": "* The author claimed that AliBi-like methods (attention biasing) struggle in practical tasks requiring long-context dependency; however, the cited evidence is on AliBi.",
            "16": "Among the author-cited AliBi-like methods, there are attention-biasing methods that achieve better long-context dependency than Alibi.",
            "17": "Maybe the author can clarify on this.",
            "18": "* The notations are confusing sometimes.",
            "19": "For example, $\\lambda$ is supposed to be an amplification factor but is missing in equation 13."
        },
        "tQOrD3xgEy": {
            "0": "1: The theory part is closely combined with practical part.",
            "1": "And the performance of the proposed method also aligns with the theoretical derivation.",
            "2": "2: The performance of the proposed method is good.",
            "3": "And the experiments are comprehensive.",
            "4": "3: Besides the main results, this paper also provided some insightful observations about LLMs' length generalization.",
            "5": "Please check the question section"
        },
        "f6l7I0yaNS": {
            "0": "I think the proposed method has some value.",
            "1": "It sticks to a well established PE scheme, and then proposes a way to update its parameters that is _trained_ to be good, instead of just wishing it will be based on some assumptions.",
            "2": "For this reason, the paper definitely deserves consideration in my opinion.",
            "3": "The proposed method moreover seems to be providing good performance for extrapolation, which was the intent.",
            "4": "* Not much details is provided in the main text regarding how we train such a beast.",
            "5": "I must say this looks quite daunting to me how I would train a NODE along my transformer model.",
            "6": "I guess it would help to have some explanations to it.",
            "7": "* I am missing some exploration of what the model is producing regarding the frequencies for ROPE.",
            "8": "As I understand, it boils down to being able to produce a new set of frequencies for ROPE to use for any input lengths.",
            "9": "This would have been feasible to actually display that.",
            "10": "Since many people have played with the idea of manually setting such parameters, I am curious whether a trained method could give us insights as to what good frequencies actually look like.",
            "11": "Are we observing high frequencies to disappear to favor long term dependencies?",
            "12": "Such things."
        },
        "v87GFNqqNZ": {
            "0": "Originality:\nContinuous PE scaling is introduced as a RoPE embedding scaling method.",
            "1": "Clarity:\nThe paper is easy to follow and understand.",
            "2": "Significance: \nLong-sequence modeling is important for many downstream applications.",
            "3": "- The work is built upon RoPE, which limits its application to other models that don't use RoPE.",
            "4": "- According to Table 1, the models still do not perform \"real\" length extrapolation.",
            "5": "The PPL results become worse when the length is increased.",
            "6": "If PPL becomes worse, why not directly use window-based methods in practice?",
            "7": "The real-world value of the proposed method is questionable.",
            "8": "- Straightforward method (such as https://arxiv.org/abs/2309.16039) works well in practice.",
            "9": "It also challenges the value of research on length extrapolation, as long as we finetune the models.",
            "10": "So the evaluation setting can be improved.",
            "11": "- Fig 5 indicates that different models perform similarly across tasks, despite GPT.",
            "12": "The significance of the method is not clearly demonstrated."
        }
    },
    "B6pQxqUcT8": {
        "w9ZRGgs4Pm": {
            "0": "* Clarity: The paper is well-written and easy to follow.",
            "1": "* Novelty: The proposed tree-search-based method is novel (see footnote) and uses a simple but effective cost-function design that helps in better decision-making.",
            "2": "* Significance: The experiments adequately justify the superior performance of their proposed method, both empirically and qualitatively.",
            "3": "The use of heuristics for LLM planning is appealing to the LM planning & reasoning community and could be a potential research direction for the future.",
            "4": "Footnote: Note the work \"SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge, Hazra, et al., 2023\" which also proposes heuristic planning with LLMs.",
            "5": "However, given its recency, I have considered it as a concurrent work, and therefore have not compared them despite their overlapping contributions.",
            "6": "I did not find any major weaknesses in the paper.",
            "7": "However, it would be nice to have some clarifications regarding the proposed heuristic functions (see Questions)."
        },
        "lHo2aXqeGP": {
            "0": "- A firm contribution of the reasoning framework using LLMs inspired by the MCTS and search algorithm.",
            "1": "- Extensive experimental evaluations show the effectiveness of the concept.",
            "2": "- Posiblly handcrafted the two important components (g(n) and h(n) in the A* search) for the problem."
        },
        "z4Ipb97v0o": {
            "0": "+ The paper tackles an interesting and important research question with potentially large impact.",
            "1": "+ The paper proposes a simple and intuitively clear best-first search approach to construct an improved LLM-based planning agent.",
            "2": "The heuristic function seems novel with potential for broad use across tasks.",
            "3": "+ The proposed method outperforms a number of strong baselines.",
            "4": "The experiments include ablations, computational costs and other forms of analyses making it easier to evaluate.",
            "5": "The experimental section and appendix has a good amount of detail, aiding reproducibility.",
            "6": "+ The paper is reasonably well-written.",
            "7": "The use of illustrative examples made it very easy to understand.",
            "8": "- Some of the implementation details of the four components of the heuristic function are not clearly explained.",
            "9": "These are central to evaluating the algorithmic contributions of the paper and reproducibility so a clearer description would be very useful.",
            "10": "I found it particularly difficult to understand the implementation details of the \"imagination score\".",
            "11": "See the questions for details.",
            "12": "- Although the experiments have a good amount of detail including ablation experiments, the paper does not clearly identify the main sources of performance improvement.",
            "13": "For example, how much does a better scoring function matter compared with a better LLM or search procedure?",
            "14": "How does performance depend on the prompt and other hyper-parameters of the algorithm (heuristic score implementation, dataset size and quality, etc.)?",
            "15": "What happens if we use non-LLM versions of the scoring function?",
            "16": "The paper mentions the importance of the cost function (\"this efficiency gain may stem from the proposed superior cost function\") but does not investigate deeper.",
            "17": "As a result, it becomes difficult to clearly identify the overall impact and broader utility of ToolChain*, especially compared to similar search-based ideas proposed in Tree-of-Thought."
        },
        "vYnNEAo9eS": {
            "0": "1) Novel formulation of LLM planning as tree search using A* search algorithm is intuitive and elegant.",
            "1": "Allows structured exploration of expansive action space.",
            "2": "2) Task-specific cost functions g(n) and h(n) provide a principled way to guide search and prioritize promising branches.",
            "3": "3) Strong empirical results demonstrating improved success rate and efficiency over competitive baselines on diverse tasks.",
            "4": "1) Cost functions rely on heuristic components like long-term memory, self-consistency sampling, and LLM imagination which may not always be accurate.",
            "5": "2) Still trails open-loop systems in efficiency, albeit outperforming other tree search methods.",
            "6": "There is a tradeoff between search depth and solution quality.",
            "7": "3) Limited analysis on how the approach generalizes to even more expansive action spaces and longer planning horizons.",
            "8": "However, I think that the above weaknesses are some hard open questions in NLP with LLM."
        }
    },
    "vE8Vn6DM0y": {
        "hPd1d0jaom": {
            "0": "The combination of utilizing Large Language Models (LLMs) and the Shared Response Model (SRM) to explore common information spaces in human brain processing seems to be a novel approach.",
            "1": "The significant improvements in encoding performance and the ability to denoise individual responses using shared space, are noteworthy.",
            "2": "The paper lacks clarity regarding whether it introduces new methods or replicates Goldstein et al.",
            "3": "'s (2022) approach.",
            "4": "This ambiguity hampers a clear understanding of the paper's contributions.",
            "5": "The paper misses an opportunity to explore the impact of scale by not conducting the study on smaller auto-regressive models.",
            "6": "With the vast parameter difference between GPT-2 XL and GPT-4, assessing the performance of smaller models would provide valuable insights into scalability and generalizability.",
            "7": "The impact of findings or what they entail in this field of study is not clearly described.",
            "8": "For example other works have been carried out studying shared response for fMRI."
        },
        "l4l76kxjw7": {
            "0": "1.",
            "1": "Clear description of background knowledge and motivations needed to understand the study.",
            "2": "2.",
            "3": "Clear exposition of the proposed model.",
            "4": "3.",
            "5": "The paper demonstrates that aligning brain responses across subjects into a shared space significantly enhances the encoding performance.",
            "6": "4.",
            "7": "Experimental demonstrates that the SRM model is generalizable to new subjects suggesting the model's robustness and adaptability.",
            "8": "1.",
            "9": "The paper lacks implementation details under the Shared Response Model (SRM).",
            "10": "How were S and W jointly estimated?",
            "11": "What method was used to estimate W?",
            "12": "Was it solved under the orthogonal Procrustes problem?",
            "13": "2.",
            "14": "Could the experimental results be compared against other baselines?"
        },
        "OBzzjqg6jv": {
            "0": "1.",
            "1": "The idea of shared response model is a well-known technique and authors demonstrate that aligning brains into a shared space significantly improves the encoding performance.",
            "2": "2.",
            "3": "Additionally, the authors' examination of their encoding model's performance on ECoG recordings is intriguing, considering that prior studies predominantly concentrated on fMRI.",
            "4": "1.",
            "5": "The novelty in the paper is somewhat limited as it primarily delves into a comparison between shared responses, original responses, and denoised responses.",
            "6": "Notably, the shared response model itself isn't a new concept.",
            "7": "2.",
            "8": "The implications of this paper are unclear to me.",
            "9": "Given the authors' emphasis on shared responses rather than original neural responses, the role of contextual word representations remains ambiguous.",
            "10": "If the authors intended to present findings related to Large Language Models (LLMs), they could have explored a comparison of different word embeddings such as GloVe or Word2Vec alongside word representations from LLMs to assess their performance.",
            "11": "However, the authors solely utilized word representations from LLMs and concluded that LLMs performed better.",
            "12": "3.",
            "13": "Similarly, authors can explain what the percentage of shared information across subjects across regions is.",
            "14": "Also, the comparison of estimated noise ceiling vs. shared responses is more interesting.",
            "15": "4.",
            "16": "The authors concentrate solely on contextual word representations from LLMs, but it's worth noting that there exists a rich language-hierarchy across layers, and layer-wise representations contain a wealth of information (such as POS tags, NER, and dependency tags) that may also be pertinent to neural brain responses.",
            "17": "These findings provide substantial evidence across various types of information and shared responses among individual subjects.",
            "18": "5.\tthe clarity can be improved:\n6.",
            "19": "Figure 6 result is difficult to parse because it contain a lot of information.",
            "20": "Also, check the typo in Figure 6: Relaive -> Relative, Predictibility -> Predictability"
        }
    },
    "7UhxsmbdaQ": {
        "f0qvSXTECm": {
            "0": "- The authors provided the codebase.",
            "1": "- The writing is easy to follow.",
            "2": "The concept figure aids the understanding.",
            "3": "The main weaknesses of the paper are that the contribution (both conceptual and technical) is marginal and the proposed method is heuristic rather than machine learning-based (and thus seems out of scope for ICLR) and lacks a mathematical basis.",
            "4": "The proposed method relies primarily on Augmented Memory [1], and the methodology outside of Augmented Memory (*Beam Enumeration* ~ *Self-conditioned Generation* paragraphs in Section 3) are short and seems like an additional trick.",
            "5": "I will combine the *Weaknesses* section and the *Questions* section.",
            "6": "My concerns and questions are as follows:\n\n- What is the difference of the generation scheme in Figure 1a with that of Augmented Memory?",
            "7": "- The *Autoregressive Language-based Molecular Generative Model* paragraph in *Proposed Method* section should be moved to *Related Work* section as that part is not proposed by this paper.",
            "8": "- Are there any ablation studies that quantify the effects of Augmented Memory?",
            "9": "Are there experiments that quantify the effects of the combination of Beam Enumeration and other generative models?",
            "10": "- The method description seems a bit vague.",
            "11": "I recommend to explain the self-conditionining scheme in paragraph *Self-conditioned Generation* more concretely.",
            "12": "---\n\n**References:**\n\n[1] Guo et al., Augmented memory: capitalizing on experience replay to accelerate de novo molecular design, arXiv 2023."
        },
        "tbzAz4lPpj": {
            "0": "## Importance of the problem\nThe paper delves into oracle-agnostic molecular optimization, which holds significance in the realm of AI-driven de novo drug design.",
            "1": "## Solid empirical performance\nA marked improvement in empirical performance has been observed.",
            "2": "## Open-sourced code\nThe authors have made the code available, facilitating comparisons and further research.",
            "3": "## Ambiguity in Methodology\nThe methodology entails several phases, namely training RNN agents, beam enumeration, and resampling based on substructures.",
            "4": "From the manuscript, it appears that only beam enumeration does not invoke the oracle while the others do.",
            "5": "The allocation of the oracle budget across these stages is unclear.",
            "6": "A comprehensive pseudo-code encompassing the entire algorithm, rather than just the beam enumeration, would be beneficial.",
            "7": "## Exaggerated Claims\nThe assertion that this is the \"first method to concurrently address explainability and sample efficiency\" is overstated.",
            "8": "Guo et al.",
            "9": "[1] have put forth a concept strikingly akin to the one proposed here, where they too derive interpretable substructures and then generate novel molecules.",
            "10": "Likewise, Fu et al.",
            "11": "[2] have purportedly tackled both interpretability and enhanced sample efficiency.",
            "12": "## Potential nomenclature confusion\nBeam search is a well-established technique within the NLP community.",
            "13": "I would recommend revisiting the nomenclature for the proposed method.",
            "14": "### Reference\n[1] Guo, M., Thost, V., Li, B., Das, P., Chen, J., & Matusik, W. (2022).",
            "15": "Data-efficient graph grammar learning for molecular generation.",
            "16": "arXiv preprint arXiv:2203.08031.",
            "17": "[2] Fu, T., Gao, W., Xiao, C., Yasonik, J., Coley, C. W., & Sun, J.",
            "18": "(2021).",
            "19": "Differentiable scaffolding tree for molecular optimization.",
            "20": "arXiv preprint arXiv:2109.10469."
        },
        "AHm58kD6cK": {
            "0": "Overall, this is an excellent paper that is very well written.",
            "1": "The proposed idea is relatively simple but well-motivated, intuitive, and generally applicable to various generative molecular design models based on language models.",
            "2": "Beam Enumeration, proposed in this paper, has been applied to a state-of-the-art generative language model for molecular design - called Augmented Memory - and results demonstrated that the incorporation of Beam Enumeration was able to further enhance the performance of the Augmented Memory algorithm, which was already shown to outperform other existing methods.",
            "3": "Notably, the proposed scheme enhances the sampling efficiency significantly and the extracted top-k substructures during the generation process are shown to provide additional sources of explainability - by connecting the presence of most likely substructures in full molecules with high rewards.",
            "4": "Throughout the paper, the authors provide ample intuition and novel insights regarding not only \"how\" the proposed Beam Enumeration scheme works but also \"why\" they may lead to improved sample efficiency and also contribute to better explainability.",
            "5": "The overall paper is written very clearly and easy to follow.",
            "6": "Throughout the paper, the authors distill intuitive explanations and derive meaningful insights, conclusions are drawn with sufficient evidence to back them up, and hypotheses/speculations are made in a reasonable and logical manner.",
            "7": "As a result, I do not have any major concerns but have a number of mostly minor remarks to improve the presentation even further.",
            "8": "1.",
            "9": "There are additional results in the appendix regarding the impact of the proposed Beam Enumeration scheme on reducing diversity.",
            "10": "While the main text briefly mentions such diversity reduction is expected, the paper would benefit from having (at least some) further discussion (in the main text) on this effect and its extent.",
            "11": "2.",
            "12": "There should be further investigation of the impact of k (i.e., the number of top substructures) on the performance of Beam Enumeration.",
            "13": "The authors hypothesize that a low top k would be optimal, but wouldn't the use of small k potentially lead to molecules with repetitive substructures and undesirably limit the molecular diversity?",
            "14": "3.",
            "15": "Similarly, the manuscript could benefit from having further discussion on the optimal choice of the \"Structure Minimum Size\" - currently set at 15 in the experiments - and its impact on the overall performance.",
            "16": "It is mentioned that \"larger substructures ... improves performance\" but what is the best minimum size to use?",
            "17": "Increasing it beyond some number would certainly degrade the performance of the molecules and also limit the diversity of the generated molecules significantly.",
            "18": "4.",
            "19": "The multi-property optimization (MPO) aspects will need to be discussed in further details.",
            "20": "Currently, the MPO appears to completely rely on the baseline algorithm (e.g., Augmented Memory or REINVENT) to be extended with the Beamn Enumeration capability.",
            "21": "But since different substructures might be associated with different properties, incorporation of Beam Enumeration for MPO would have to consider the impact of self-conditioned molecular generation when used with a specific baseline algorithm and a specific number of properties for optimization.",
            "22": "For example, one may expect that when optimizing a large number of properties, then using a very small k may be detrimental as the selected substructures may be associated with only some of the properties of interest.",
            "23": "5.",
            "24": "Finally, while the paper focuses on language models for molecular generation and uses Beam Enumeration for self-conditioning the generative process by filtering the most probable substructures, it would be great if the authors could discuss how similar ideas may be used to extend other types of popular generative molecular design models (e.g., latent space models based on VAE, JT-VAE).",
            "25": "Especially, models like the JT-VAE optimize molecules by sampling & assembling substructures (in the form of junction trees), which - at least at a conceptual level - *may* be related to the core \"self-conditioning\" idea in Beam Enumeration, to prioritize certain substructures.",
            "26": "While this may be beyond the scope of the current work, having at least some high-level discussion might benefit the readers."
        },
        "mrLiGRFcBz": {
            "0": "- The paper is well-written, well-organized, and easy to follow.",
            "1": "- The idea is quite intuitive and straightforward.",
            "2": "It is based on the state-of-the-art language model--augmented memory.",
            "3": "- The paper also emphasizes sample efficiency, which is an essential problem in practical molecular design.",
            "4": "It does not only require the optimization ability but also the oracle efficiency.",
            "5": "The oracle can be computationally expensive and the bottleneck of the modern molecular design.",
            "6": "- The whole setup is realistic.",
            "7": "Novel Oracle efficiency-based metric is designed.",
            "8": "- Code is easy to read and is public, guaranteeing the reproducibility.",
            "9": "- The experimental results are thorough and solid.",
            "10": "The proposed beam enumeration significantly outperforms REINVENT (the strongest baseline in the existing benchmark).",
            "11": "It also exhibits explainability during the generation.",
            "12": "- It would be great if authors could incorporate more baseline methods.",
            "13": "- Some minor issue, e.g., repetitive statements, like \n\"To address this, Gao et al.",
            "14": "(Gao et al.",
            "15": "(2022) proposed the Practical Molecular Optimization (PMO) (Gao et al.",
            "16": "(2022) benchmark.\"",
            "17": "Too many \"Gao et al\".",
            "18": "- Do you use the same setup with PMO?",
            "19": "If not, it seems unfair to compare with PMO's best baseline REINVENT."
        }
    },
    "UVSKuh9eK5": {
        "lo6OmS3vso": {
            "0": "+ This paper proposes an interesting approach to measure the compositional capabilities of large-scale VL models, by leveraging a text-to-\nimage model to generate new images with specific attributes.",
            "1": "+ The authors provide a large set of experimental results in the supplementary materials, showing that CLIP models struggle with their proposed dataset\n\n+ This paper is well-structured, easy to read and follow.",
            "2": "+ There is no description or motivation for the attribute selection, are those attributes randomly selected or generated?",
            "3": "How do the authors guarantee that those attributes are not present or co-occur less in the training data?",
            "4": "+ The human validation seems crucial in generating the proposed benchmark; however, there is no detailed description of how this was performed.",
            "5": "+ In section 1, the authors claim: \"By assessing the captions in the training sets, we guarantee that none of the captions in our test dataset or similar captions are included in the CLIP training data.\"",
            "6": "-- however, I couldn't find any empirical or theoretical evidence, nor existing reference for this claim.",
            "7": "+ The human validation only asses for the plausibility of the noun-adjective composition, but are the images generated by DALLE following those compositions?",
            "8": "Prior work has shown that Diffusion models \"struggle to understand the composition of certain concepts, such as confusing the attributes of different objects or relations between objects\"[1].",
            "9": "It is unclear if the generated dataset follows the attribute-noun composition, or falls into this category.",
            "10": "See also [2].",
            "11": "+ Most of the conclusions are prevalent in the literature (e.g., the diversity of training captions promotes compositionality [3]), and the mutual information analysis does not seem to provide additional insights [4, 5].",
            "12": "[1] Liu, Nan, et al.",
            "13": "\"Compositional visual generation with composable diffusion models.\"",
            "14": "European Conference on Computer Vision.",
            "15": "Cham: Springer Nature Switzerland, 2022.",
            "16": "[2] Park, Dong Huk et al.",
            "17": "“Benchmark for Compositional Text-to-Image Synthesis.” NeurIPS Datasets and Benchmarks (2021).",
            "18": "[3] Doveh, Sivan, et al.",
            "19": "\"Dense and Aligned Captions (DAC) Promote Compositional Reasoning in VL Models.\"",
            "20": "arXiv preprint arXiv:2305.19595 (2023).",
            "21": "[4] Radford, Alec, et al.",
            "22": "\"Learning transferable visual models from natural language supervision.\"",
            "23": "International conference on machine learning.",
            "24": "PMLR, 2021.",
            "25": "[5] Oquab, Maxime, et al.",
            "26": "\"Dinov2: Learning robust visual features without supervision.\"",
            "27": "arXiv preprint arXiv:2304.07193 (2023)."
        },
        "oRBTd3XYGq": {
            "0": "- The experiments are well-designed \n- Conclusions drawn are very interesting and insightful \n- The dataset ImageNet-AO can be helpful for future study as well\n\n- \"*the training dataset of the OpenAI CLIP has not been released, which makes designing a test set that has a truly different distribution from the training one challenging.",
            "1": "We aim to address these issues in this paper, by focusing our attention on the compositional generalization\nin the single object setting, and designing an authentic test dataset to assess the training data characteristics and mechanisms in the models that lead to the OoD generalization.",
            "2": "*\" -- This contradicts the following statement where the authors claim that they verify that the ImageNet-AO images are not a part of several CLIP training dataset -- \"*To ensure these combinations were not present in the CLIP training set, we conducted a thorough search and removed any combinations that were found.",
            "3": "*\"\n- \"*By assessing the captions in the training sets, we guarantee that none of the captions in our test dataset or similar captions are included in the CLIP training data.",
            "4": "*\" \n    - Is this check done for all the other datasets considered in the paper as well (LAION, YFCC15m, CC12m, and DataComp)?",
            "5": "-  A similar check should be done on images as well, it is possible that such images with different captions are present in the training set.",
            "6": "Usually, captions from web sources are not exactly descriptive of the image.",
            "7": "- \"*We also found that the CLIPs that show higher OoD generalization typically exhibit strong disentangled text representations.",
            "8": "Furthermore, such CLIPs also enjoy a more disentangled image representation with respect to the attributes and objects as well.",
            "9": "*\" -- the experiments in the paper do hint at the above statement.",
            "10": "But this does not necessarily imply the following: \"*Specifically, a dataset with diverse compositions of attribute-objects facilitates a more disentangled text representation, which in turn induces a disentangled image representation through contrastive learning.",
            "11": "*\" It could be possible that diverse images lead to disentangled image representations as well.",
            "12": "- \"*To evaluate the degree of disentanglement in the training captions utilized by the CLIP, we conducted an analysis by measuring the normalized mutual information (NMI) between the object class and attribute tokens, whose domains are defined based on the captions in our generated dataset.",
            "13": "*\" -- Could the authors explain how the domains are defined based on the captions in the generated dataset?",
            "14": "More details on how the NMI is measured would be helpful.",
            "15": "- Fig.4 - It is not clear how the disentanglement metrics are computed for the image encoder.",
            "16": "- \"*We aimed for a diverse set of class names to enhance the complexity of the generated images.",
            "17": "*\" -- It is not clear if all 1000 classes were used or only a subset.",
            "18": "If a subset was used, how was this chosen?",
            "19": "- \"*This dataset was produced by creating compositional images via a text-to-image model, using an Attribute+Object template.",
            "20": "*\" -- could the authors give more details/ a citation for the Attribute+Object template?",
            "21": "- Could the authors provide details on where the 30 adjectives were chosen from?",
            "22": "- \"*Lastly, human evaluation was used to validate the generated images, with images not closely aligning with their prompts removed.",
            "23": "After this process, around 12000 combinations remained, for which we successfully generated near 50000 accurate, high-quality images.",
            "24": "*\" - The order of the two statements may have to be swapped?",
            "25": "Could the authors provide details on how this human evaluation was done?",
            "26": "- \"*For the test sets, all 1000 classes of ImageNet were used as the in-distribution set and expanded the number of classes to approximately 12000 for the OoD set.",
            "27": "*\" -- could the authors share how the captions were created for the OOD set?",
            "28": "Sharing some examples would be helpful.",
            "29": "I believe the 80 captions are used only for the ID set, and single relevant captions are used for the OOD set?",
            "30": "- In Fig.1, for a more fair comparison, the image-only models such as DINO-v2 and BEiT-v2 should also be trained on the datasets that were used for training CLIP (by using only the images, and ignoring the captions).",
            "31": "Without matching at least the image datasets, there is not enough evidence to support the following statement - \"*We interpret these findings as strong evidence that the inclusion of language supervision, particularly during CLIP training, positively impacts the model representation quality, hence making it possible to generalize to unseen compositions, despite the absence of such compositions in their training data.",
            "32": "*\"\n\nNitpicks -\n\n- citation format seems non-standard - (x) vs. [x]\n- inline citations should use the format xyz et al., rather than [x] \n- A citation for the work that defines \"compositional OOD generalization\" would be helpful"
        },
        "AUeGBXg0Pe": {
            "0": "1.",
            "1": "This paper propose a high quality test set measuring compositional generalization with generative model.",
            "2": "This benchmark provide a simply and more straightforward measurement for compositional generalization of Top1 accuracy for synthetic dataset, over prior measurement like using Visual Genome, or captions perturbation.",
            "3": "This could be significant to the community exploring model generalization.",
            "4": "2.",
            "5": "Author have conducted various analysis over the relationship between compositionally and feature disentanglement, demonstrate the potential influence of the proposed dataset at a large scale.",
            "6": "1.",
            "7": "In 3.2, the statement 'We interpret these findings as strong evidence that the inclusion of language supervision, particularly during CLIP training, positively impacts the model representation quality' might be too strong of a claim.",
            "8": "As explored in prior work(\"Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP)\") , language supervision might not be the sole reason for model generalization.",
            "9": "There're multiple variance between VLM and other modality and author should not attribute such improvement solely on language supervision.",
            "10": "2.",
            "11": "Conclusion are less convincing due to the limited candidate in each experiment.",
            "12": "For instance, in Table 1, it will be interesting to shows the NMI for a subset of LAION with the same number of data to other dataset.",
            "13": "Also in table 2, there's only 4 results, please consider adding more variance of dataset and CLIP architecture .",
            "14": "3.",
            "15": "The narrative after section 4 is a bit too rush, it's hard to follow the method and results.",
            "16": "For instance, what is 'dimensions' in 4.1 stands for?",
            "17": "And more context over 'switching dimension' would be helpful.",
            "18": "Moreover, I cannot tell how the conclusion of 'A higher level of accuracy in the image retrieval task indicates that the model embeddings are more disentangled.'",
            "19": "can be drawn from experiment in 4.2.",
            "20": "4.",
            "21": "There's some grammar and formatting issue, for instance in section 4, spaces were missing between sentences."
        }
    },
    "NMPLBbjYFq": {
        "d7dx0snd8Z": {
            "0": "The idea of using games to using LLMs is promising.",
            "1": "There are certain flaws of the approach.",
            "2": "Particularly on the point of using stage Nash equilibrium to evaluate LLMs in a repeated game setting."
        },
        "UUm3zEpRXv": {
            "0": "1.",
            "1": "The paper is well-written and organized, making it easy to follow.",
            "2": "2.",
            "3": "Investigating the capability of strategic reasoning in LLMs is important.",
            "4": "3.",
            "5": "The choice of using the second price auction and beauty contest game as an evaluation arena for LLMs is novel.",
            "6": "1.",
            "7": "The significance of this paper appears to fall short of the standard of ICLR.",
            "8": "As acknowledged by the authors, there are already a few related works that explore the performance of LLMs in economic games with different settings, including various game classes and information provided to LLMs.",
            "9": "It is already known that LLMs can exhibit some degree of rationality and strategic reasoning.",
            "10": "Although this paper evaluates LLMs under specific new settings, it does not significantly advance our understanding of LLMs in economic games.",
            "11": "2.",
            "12": "As a paper that selects \"dataset and benchmark\" as the primary area, the experiments are not thorough enough to support the main claims and reproducibility is questionable.",
            "13": "Most importantly, the prompts which are central for reproducibility are not presented.",
            "14": "Moreover, only multiple versions of GPT are considered, neglecting other commonly used LLMs (e.g., Claude 2 or LLama 2) which have been shown to have quite different performances in games compared to GPT, and only the results of average values are reported (e.g., Figure 2 and Figure 4).",
            "15": "Additionally, the paper claims that they have varied the prompts to show the robustness of their results, but these experiments are not presented."
        },
        "APQU7InhH6": {
            "0": "This paper proposed to explore competitive games as an evaluation of the rationality and strategic reasoning ability of LLMs.",
            "1": "They can be used to test the abilities of LLMs, i.e., rationality, strategic reasoning ability, and instruction-following capability.",
            "2": "Competitive games exist in the literature.",
            "3": "This paper just shows how to design experiments to test the ability of LLMs.",
            "4": "That is, this paper did not provide any dataset or benchmark, and then it should not be added to the primary area of datasets and benchmarks as well.",
            "5": "This paper is not a technical paper on learning representation.",
            "6": "Thus, it is not related to ICLR."
        },
        "glv7J3ivSt": {
            "0": "* Arguing about metrics that associate with the Nash Gap is a systematic approach.",
            "1": "This is indeed a straightforward metric to evaluate rationality.",
            "2": "* The use of self-computing beauty contest games to assess LLMs is an interesting one, compared to having different models in the same auction.",
            "3": "* The methodology includes running multiple runs and account for the LLMs not responding correctly, an inherent pitfall of their architecture.",
            "4": "* The paper acknowledges the importance of prompt sensitivity but fails to provide a detailed account of prompt structures, limiting the reproducibility of the experiments.",
            "5": "It does not investigate different methods of prompting or incorporating historical data into prompts.",
            "6": "* There is no discussion on whether the stability of outputs in the homogeneous model setting correlates with a consistent strategy distribution between all agents, nor is there an exploration of how the model's temperature setting influences strategy uniformity.",
            "7": "* The methodology is unclear on whether different rounds were obtained by a chat-based model instantiation, where there are affecting subsequent decisions, or if the models were independently assessed in varied historical contexts, simulating different rounds.",
            "8": "* The experiments lack scenarios where LLMs interact with actual strategic agents, which would test the models in more realistic strategic environments.",
            "9": "Miscellaneous:\n* The font size in Figure 1 is difficult to read."
        },
        "8GcX7szGS6": {
            "0": "This is a really great direction, and I am very excited about the direction of this paper which seeks to bring game-theoretic tools to the study of LLMs.",
            "1": "I hope the authors pursue these directions further!",
            "2": "The main assumption of the paper, namely that rational agents play a Nash equilibrium, is in my opinion incorrect.",
            "3": "More generally, rational agents play a rationalizable action, i.e., the solution concept of interest is rationalizability [1].",
            "4": "In fact, rational agents might not be compelled to play a Nash equilibrium as summarized by following quote from Luce and Raiffa [2, page 63] regarding Nash equilibrium and rationality here is relevant:\n\n> Even if we were tempted at first to call a (Nash) non-conformist 'irrational', we would have to admit that (his opponent) might be 'irrational' in which case it would be 'rational' for (him) to be 'irrational'-to be a (Nash) non-conformist.",
            "5": "The set of experimental settings are relatively standard, and do not add significantly to the existing literature."
        }
    },
    "CeJEfNKstt": {
        "fJauhqDto7": {
            "0": "The motivation is good.",
            "1": "Interpretability works often suffers from weak generalization and undetermined thresholding on generalization.",
            "2": "This paper steps in this problem by observing the conditions of generalization.",
            "3": "The takeaway is unclear.",
            "4": "The beautify linear separability could be because of the simplicity of the text in the curated dataset.",
            "5": "In reality, this could be a luxury to have.",
            "6": "Then, the usefulness of the proposed probe and establishment of the observations need to be re-examed.",
            "7": "Another thing is, what can people do with this problem is unclear.",
            "8": "Can folks use the observation, say, inject a loss to improve LLM's factuality during pretraining or fine-tuning?",
            "9": "There are some interesting discussions could happen, but not appeared in this paper.",
            "10": "The causal interference happens at hidden level instead of word/token level.",
            "11": "Roughly saying, most probes can have a hidden interference to revert the binary output.",
            "12": "But what's is more direct/interpretable is make it also work on text level."
        },
        "HD0KELwY8x": {
            "0": "- Identifying the knowledge held by LLM and discovering the correspondence between its internal representations and world knowledge is crucial for realizing a trustworthy LLM.",
            "1": "Particularly, the identification of the truth values of declarative plain sentences related to world knowledge aligns well with fundamental paradigms in semantics within NLP, such as truth-conditional semantics.",
            "2": "The theme of the paper is likely to be well-received within the community.",
            "3": "- Controlled datasets created to measure only specific aspects of meaning will likely be useful for researchers studying the truthfulness of sentences.",
            "4": "The experimental setup appears arbitrary and limited, diminishing the persuasiveness of the authors' general claims.",
            "5": "For instance, despite the availability of numerous pretrained language models, experiments were conducted solely on LLaMA, making it unclear whether the findings apply generally to LLMs.",
            "6": "The authors explicitly mention this as a limitation, which should be acknowledged for its intellectual honesty.",
            "7": "However, it is hard to deny that the verification is lacking when considering the subject of interest stated in the main claim (Large Language Models).",
            "8": "If the focus was merely on the \"Linear Structure in LLaMA\", the experiments would suffice.",
            "9": "Yet, in that case, it might not be deemed impactful enough for acceptance at ICLR.",
            "10": "Furthermore, although there are numerous internal representations available for sentence representations, experimental results are provided only under very specific settings: a specific layer, specific parts of the network (after the residual stream), and right after period characters.",
            "11": "Additional settings, such as the utilization of top principal component directions and connecting centroids, also follow specific configurations.",
            "12": "Taking into account that multiple options exist for each of these aspects, it becomes somewhat challenging to dispel concerns that the reported results might be cherry-picked."
        },
        "hhsMySnYaZ": {
            "0": "- Detailed analysis of whether an LLM can learn to distinguish true and false data within and across tasks.",
            "1": "- Good use of synthetic and natural data for this purpose.",
            "2": "- Mass-mean probing seems to be an effective method for inducing probes _without training_ and could be more broadly applicable.",
            "3": "- Causal intervention on the model's representations using the probes shows that the truth vectors are \"active\" and not \"inert\".",
            "4": "(This also demonstrates the importance of working with open models, where such interventions can be done.)",
            "5": "- The paper has so many experiments and results that it could benefit from a richer discussion of how to interpret all of the results.",
            "6": "- Only tests one model, so it's unclear how generalizable the findings are (the authors, of course, acknowledge this).",
            "7": "- I would have also appreciated a bit more detail about the datasets and how they were generated to be in the body of the paper instead of appendices."
        },
        "y4Lt3MW5CF": {
            "0": "1.",
            "1": "A new alternative to regular logistic regression probing is proposed, which overcame the problem of logistic regression where the truth direction may be interfered with by an independent feature.",
            "2": "Mass-mean probes show significant improvements in causal interference.",
            "3": "2.",
            "4": "Clear visualization of the separation of True/False statements.",
            "5": "3.",
            "6": "A new dataset to train such linear probes.",
            "7": "1.",
            "8": "The majority of the conclusions and claims are not unique.",
            "9": "For example, from Li et al.",
            "10": "and Burns et al.",
            "11": "(which the paper cites), we already knew that such truth representation is linearly separable and one can apply casual intervention to such representation.",
            "12": "2.",
            "13": "Lack of model variances.",
            "14": "The experiments are only conducted on LLaMA-13B.",
            "15": "As a result, we don't really know the effects of scale or the effects of the pretraining paradigm on such representations.",
            "16": "3.",
            "17": "Mass-Mean probe doesn't really improve generalization accuracy over some of the other methods that much."
        }
    },
    "l5rEkR8OgU": {
        "w1DigYUnj6": {
            "0": "1.",
            "1": "This is an interesting work on the investigation of learning effects with a mix of tasks.",
            "2": "Some theoretical and empirical evidence is shown for the learning effect.",
            "3": "The results on a mixture of the Parity/Sum task are interesting \n\n2.",
            "4": "They also empirically show that it is easier and faster for the learner if the signals from easily inferred labels to learn target are provided.",
            "5": "Experiments on LEGO and code interpretation task are done.",
            "6": "3.",
            "7": "Their findings on learning complex tasks contribute to the understanding of large language model learning and provide valuable insights for future related work on efficient training.",
            "8": "1.",
            "9": "The theoretical results on the Parity/Sum task reply to some strong assumptions: bilinear parameterization, some initialization (for example, v = 0).",
            "10": "Under these assumptions, the gradient over the parity distribution samples is zero.",
            "11": "The assumption looks a little strong.",
            "12": "2.",
            "13": "It would be to show more experiment results for some settings, for example, performance on Sum task when training with a mixture distribution, or more Sum task samples and fewer Parity task samples ( p range from 0.5 to 1.",
            "14": "In Figure 1, results with p ranges from 0.1 to 0.5 are shown."
        },
        "jxAzrXSLVi": {
            "0": "1.",
            "1": "It is novel that the paper pays attention implicit intermediate supervision instead of explicit supervision to solve intricate tasks in language modeling, and it provides detailed proof of the notion.",
            "2": "2.",
            "3": "The paper could also contribute to the understanding of how large language models learn complex tasks and may facilitate research on more efficient and effective training methodologies.",
            "4": "1.",
            "5": "There is something wrong with the structure of this paper, for example, section 1.2 is named as Related Work, which is usually a separate chapter.",
            "6": "Moreover, this paper losses the Conclusion part.",
            "7": "2.",
            "8": "This paper does not contain an example to show the advantages of implicit supervision over explicit supervision, or an example that demonstrates how the implicit supervision work.",
            "9": "So can the authors provide a figure in Section 1 that can make readers get your innovation quickly?",
            "10": "3.",
            "11": "The authors point out that explicit intermediate step-by-step supervision is time consuming compared to the implicit supervision in abstract, but they do not provide experimental results to verify this view."
        },
        "ECdIR3b0RI": {
            "0": "1.",
            "1": "The paper explains implicit intermediate supervision, which may help understand the large language model's capability of solving complex problems.",
            "2": "2.",
            "3": "The paper provides both theoretical understanding and empirical justification.",
            "4": "The experiments show the observation also applies to the Transformer architecture.",
            "5": "1.",
            "6": "The theory is a bit limited to the specific synthetic task.",
            "7": "Are there possibilities to extend the idea to support a more general case?",
            "8": "2.",
            "9": "The experiments are based on synthetic datasets without realistic datasets.",
            "10": "I think datasets that can be used in curriculum learning can be used here too, to justify the applicability of the proposed approach.",
            "11": "I would currently put my score to 5 but may change my score based on the authors' rebuttal."
        },
        "g1VMaetcGb": {
            "0": "* They include both interesting theoretical and convincing empirical results\n* Many of their tasks show a dramatic difference between with/without additional supervision, potentially making these tasks a good source for future work to further study\n* Their results seem to hold across several tasks and on full transformer language models\n* The paper is overall well presented\n\n* The tasks they study are a little bit toy, which makes them easy to study, but it is a little bit unclear if these findings transfer cleanly to the LM pretraining setting.",
            "1": "* They frame this as a replacement for chain of thought, and state that it saves on collecting full reasoning chains for supervision.",
            "2": "However chain of thought prompting (the predominate way to get LM to output intermediate reasoning) only requires a handful of examples that can usually be written by a single person in a few minutes.",
            "3": "Whereas their method would require collecting or synthesizing large datasets.",
            "4": "I feel that a potentially more interesting framing could be around understanding how large scale pretraining (multitask) can enable LMs to learn tasks which are typically challenging for neural networks to learn on their own."
        }
    },
    "LajkZlgD83": {
        "yfh6wJjcqE": {
            "0": "- The method not only improves latency as it originally sets out to, but also seems to improve accuracy.",
            "1": "This is fascinating (though I have my reservations about this fact)\n- The system design seems simple, yet quite elegant (assuming all the claims are true)\n- Even HybridRag \"w/o FT\" beats the baseline RAG model.",
            "2": "This shows great promise (though it also warrants more investigation)\n\nI have some general reservations about the claims, the most important of which concerns the validity of the dataset and metrics used:\n1. the first and main dataset used for evaluation is the WikiText-103 dataset.",
            "3": "As the authors also mention, it's highly likely that both the OPT and GPT-3 models have been trained (directly or indirectly) on this or similar data.",
            "4": "As such, this makes it an odd choice for a \"RAG\" method, where the main value prop is improving the model when the base knowledge is lacking.",
            "5": "To further support this claim, we also see that \"GPT-3 zero-shot\" is highly competitive and beats all the models in many of the metrics.",
            "6": "2.",
            "7": "GPT-3 is in some sense being used both as the evaluator, the trainer, and the memory generator.",
            "8": "The concern with this is the possible bias towards its own results.",
            "9": "I believe all the metrics used, e.g.",
            "10": "BLEU, ROUGE, BERTScore, etc, are highly susceptible to such bias as they cannot fairly compare two correct solutions that are worded differently.",
            "11": "Here are a set of other more minor issues:\n3.",
            "12": "HybridRAG w/o finetuning seems pretty much just as good as the finetuned version.",
            "13": "So I'm surprised that the authors are actually recommending the finetuned version at all.",
            "14": "Also, the fact that this model does so much better than vanilla RAG generates a lot of questions.",
            "15": "I would have expected more ablations to get to the bottom of this disparity.",
            "16": "Are the summaries really that much more effective?",
            "17": "Or is it the FIFO memory mechanism?",
            "18": "Why?",
            "19": "Looking at the summary samples, they do not look that much more concise.",
            "20": "Do you have comparisons on the average length of the documents vs the summarized version?",
            "21": "4.",
            "22": "In comparisons (e.g.",
            "23": "Table 2), it's not obvious how much \"edit distance\" or how asynchronous actually are the HybridRAG models.",
            "24": "In the absence of this info, makes me believe that they are being compared in the \"idealized\" scenario, which then makes all latency claims highly unfair.",
            "25": "5.",
            "26": "For a method that claims reduced latency as their main benefit, I find the latency comparisons to be not enough, and the existing results seem to be hastily put together.",
            "27": "6.",
            "28": "Though I find this point to be slightly unfair, but using the OPT and GPT-3 models seems slightly outdated by now and makes the results less relevant.",
            "29": "7.",
            "30": "Lastly, I want to mention that since most of the improvements are on the systems side, I'm not sure if ICLR is the correct venue for this work.",
            "31": "I am by no means giving a diminished value to the contributions in this point"
        },
        "uBkkN8qbQz": {
            "0": "1.",
            "1": "The proposed framework facilitates real-time text generation on client devices, harnessing the power of cloud-based retrieval augmentation.",
            "2": "1.",
            "3": "Limited Novelty: The system's enhancement relies on using an LLM to distill essential information from retrieved documents into concise bullet points.",
            "4": "Hence, it's unsurprising that HybridRAG performs better given that (1) the LLM effectively stores content into memory and (2) knowledge from the LLM is distilled into smaller models.",
            "5": "2.",
            "6": "Restricted Testing Scope: The evaluation is confined to only two datasets - WikiText and Pile.",
            "7": "The absence of tests on knowledge-intensive NLP tasks, such as open-domain QA and fact verification, limits its broader applicability.",
            "8": "Moreover, the exclusive testing on the OPT model fails to demonstrate the framework's generalizability across other models like LLaMA."
        },
        "ROUwJUTWqh": {
            "0": "- Retrieval augmented generation is an effective method to improve the performance of LLMs but suffers from inefficiency due to the additional retrieval process.",
            "1": "Thus the goal of this paper to improve the efficiency of retrieval augmented generation is well-motivated.",
            "2": "- The proposed method is intuitive and easy to understand.",
            "3": "- The model and baseline used in the paper are slightly outdated.",
            "4": "It would be meaningful to see how the proposed method behaves with more recent LLMs and other RAG methods (e.g., LLaMA[1] and RETRO [2], respectively) \n- In the paper, the authors claim that the proposed framework can be used for real-time generation.",
            "5": "However, the definition of real-time is not clear here and as the context retrieved from the cloud becomes longer, how will this impact the claim on the real-time generation still lacks of evaluation.",
            "6": "- The presentation of the paper can be improved, for example in Fig.",
            "7": "3, there is some overlapping between subfigures, blocking some characters in the label.",
            "8": "[1] Touvron, Hugo, et al.",
            "9": "\"Llama: Open and efficient foundation language models.\"",
            "10": "arXiv preprint arXiv:2302.13971 (2023).",
            "11": "[2] Borgeaud, Sebastian, et al.",
            "12": "\"Improving language models by retrieving from trillions of tokens.\"",
            "13": "International conference on machine learning.",
            "14": "PMLR, 2022."
        },
        "5tG8fKh4ev": {
            "0": "The paper describes and focuses on a interesting problem: text completion in the context of edge devices is very practical and intuitive.",
            "1": "The approach is straightforward and novel.",
            "2": "Combining different scales of LLMs for any application is timely with the growing popularity of both open and enterprise LLMs.",
            "3": "I particularly find the use of the cloud model to enhance the training of the small model to be particularly compelling.",
            "4": "I like the use of summarized RAG techniques to improve text generation.",
            "5": "The experiments are reasonable and show the approach is promising.",
            "6": "The ablated models as baselines clearly show the complexity of the approach is necessary for improved performance.",
            "7": "I have two main issues with the paper: presentation and evaluation.",
            "8": "In general, the paper is bit a difficult to follow.",
            "9": "I had an idea what the paper was trying to propose, but it wasn't until I reached the dataset section that the problem, next word(s) completion, became clear.",
            "10": "The intro reads more like a conclusion, as it uses concepts that aren't defined until later.",
            "11": "One example: the word memory is used dozens of times before it's defined in section 3.2, and I what memory was in my head didn't quite match the details in that section.",
            "12": "Additionally, it seems the goal (enhancing text prediction) should be a larger focus on the intro.",
            "13": "The figures and algorithm need more surrounding text to gently introduce a reader: the captions (of all figures too) should be substantially filled out to explain what is in the figure.",
            "14": "For figure 1, I think a general workflow (step 1. user inputs this text, step 2. the augmentation coordinator ....) needs to be added, as the current figure is useful only if you already understand the methods.",
            "15": "The evaluation suffers from an important caveat: OPT is trained on wikipedia and thePile.",
            "16": "This issue is not a showstopper for me, but it does cast some doubts on the generalizability of the method.",
            "17": "I realize that LLMs are now being trained on the literal entire internet, so finding unseen datasets is non-trivial.",
            "18": "I do agree, however, with the conclusions of the paper that HybridRAG is better than the baselines.",
            "19": "Minor:\n* section 3.3, it would be nice if the full training dataset was explicitly defined as a variable\n* training/test sets should be defined for the evaluation"
        }
    },
    "X2gjYmy77l": {
        "kdJvKihxjy": {
            "0": "## Originality\nThis work appears relatively novel, considering the important problem of LLM controllability and bringing insight from dynamical systems literature to characterize controllability.",
            "1": "## Quality\nFor the most part, this is a very carefully written theory paper that lays out important assumptions and characteristics for notions of controllability.",
            "2": "## Clarity\nThe paper was largely clear.",
            "3": "I tend to favor figures or diagrams, but the first figure (which I found helpful) only appears in the appendix.",
            "4": "I confess that I am typically more of an empiricist than a theorist, but I am familiar with LLMs, dynamical systems, and the math presented in the paper, which I was able to follow.",
            "5": "## Significance\nI am undecided about the significance of this work for one particular reason: Postulate 1.",
            "6": "The authors are considering a very important problem that many people care about - if a paper can establish that real-world LLMs that we use are controllable, that would be an extremely important paper.",
            "7": "The problem, in my mind, is that to reach this conclusion, the authors make a very big assumption about well-trained LLMs in Postulate 1.",
            "8": "To their credit, the authors note this limitation, both in the main text and Appendix 1.",
            "9": "Overall, I fear that the strength of the assumption in Postulate 1 could significantly limit the significance of this work.",
            "10": "## Postulate 1: \nAs noted earlier, the biggest weakness of this work is the strong assumption in Postulate 1 about the bijective/invertible nature of the map $F_w$.",
            "11": "To me, this assumption almost gives away the controllability conclusion: if there is an invertible map, then it at least intuitively follows very clearly how such a system would be controllable.",
            "12": "## Presentation of results:\nI recognize that the primary contribution of this work is theoretical, rather than empirical, in nature.",
            "13": "However, the authors do conduct experiments and present results in Appendix A.",
            "14": "Even while keeping results in appendices, I would encourage the authors to at least provide a sentence or two in the main paper highlighting high-level trends of the experiment results.",
            "15": "I wish to emphasize again that I traditional study more empirical AI methods and analysis.",
            "16": "Thus, if other reviewers find that this work would contribute to the more theory-focused community, I am happy to change my mind."
        },
        "m1zIjTo4mC": {
            "0": "The paper sets out to formally characterize controllability of LLMs which is an important issue in preventing adversarial attacks on language models and preventing LLMs from producing undesirable content.",
            "1": "It's unclear what the contribution of the paper is.",
            "2": "The related work section does not connect this paper to specific prior work (only citing two survey papers).",
            "3": "Then, most of the paper is spent discussing preliminaries and introducing notation and definitions.",
            "4": "The first use of the proposed definitions to make a non-trivial claim is in Section 5 with Postulate 1, but this claim is not justified.",
            "5": "Theorem 1 in Section 5 seems to follow directly from the proposed definition of controllability.",
            "6": "Theorem 2 is presented with no intuition and the proof in the appendix is only for a special case.",
            "7": "It's also not explained how Theorem 2 justifies the main conclusion: that \"a prompt engineer aided by enough time and memory can force an LLM to output an arbitrary sequence of ℓ tokens.\""
        },
        "FSyiyTpPn3": {
            "0": "I appreciate the effort to formalize controllability of LLMs as a generic question.",
            "1": "This is an interesting topic that can spur further research and help predictability and understand the LLM's behaviours in general.",
            "2": "However, the presented theory suffers from various core issues.",
            "3": "- Definition of equivalence seems to be insufficient and lacks important components.",
            "4": "- Definition of meaning seems to defeat the whole purpose of this paper, as it allows for any gibberish/random sequence of tokens to still induce a meaning and possibly a set of many other gibberish sequences to be in their equivalent class.",
            "5": "- How to find a discriminant for meaning is left out as the authors explicitly assume that “the mechanism is provided by human annotators and other providers of training data.” While the authors emphasize in the introduction that such information can be used in the LLM training without external reward model: “This observation shows that sentence-level annotations can be incorporated directly into the trained model without the need for any external reward model nor external policy model, simply by sentence-level feedback,” I do not see the advantage of this approach over using the very same data to train a reward model and use that either during the training (as in RLHF) or as an augmentation (as in Rectification method), the latter indeed provides quite strong theoretical guarantees.",
            "6": "If this secondary goal is valid, the paper requires sufficient reasoning for why the presented approach is superior.",
            "7": "If not, the presentation requires to change and reflect only the controllability analysis."
        },
        "oQNHMmOuRz": {
            "0": "The paper is very original, and presents some unique idea on how to determine the controllability of \"well-trained\" LLMs.",
            "1": "Connecting LLMs with control is definitely interesting.",
            "2": "A new theoretical perspective is developed.",
            "3": "This paper may also inspire more researchers to think about the fundamental theory of LLMs.",
            "4": "1.",
            "5": "The characterization of meanings seems quite subjective.",
            "6": "The authors mentioned that their characterization of meanings is compatible with the deflationary theories in epistemology.",
            "7": "It seems that this explanation itself does not justify why such a characterization is meaningful for studying the controllability of LLMs in general.",
            "8": "2.",
            "9": "The authors claim that their conditions are largely met by today’s LLMs.",
            "10": "More justifications are needed.",
            "11": "This also seems a hand-waving statement.",
            "12": "\"Largely met\" means \"not always met\"?",
            "13": "3.",
            "14": "Many of the equations are quite difficult to understand.",
            "15": "I have tried very hard to follow the theoretical arguments in this paper.",
            "16": "However, I still feel very confused in the end.",
            "17": "I will ask some questions in the \"Question\" section."
        }
    },
    "9bmTbVaA2A": {
        "4zbVe48Iji": {
            "0": "- The paper is easy to follow.",
            "1": "The authors explain their proposed method and give background knowledge about V-IP in an easy-to-follow way.",
            "2": "More technical details are also explained and provided in the appendix.",
            "3": "- The designed experiments indeed show that the proposed Concept-QA helps the whole V-IP improve interpretability and results in a shorter query chain compared to the CLIP baseline.",
            "4": "- Fig 4 illustrates how using the proposed Concept-QA improves the interpretability of query chain.",
            "5": "- The major (if not the only) competitor of the proposed Concept-QA is CLIP baseline.",
            "6": "It would be good to include other baseline methods for comparison.",
            "7": "- What the quality of the pseudo-label when evaluated on the Table 1 experiment?",
            "8": "- Since there exist many vision language models (commercial or open source), there might be other easier and more effective ways to generate pseudo-labels for training the Concept-QA model.",
            "9": "For example, prompt a LLaVA or InstructBLIP model.",
            "10": "The authors should compare to other pseudo-label generation methods as this is part of the major contribution of this paper.",
            "11": "- What's the correlation between the performance of the QA model and the final V-IP system?",
            "12": "In the paper, the authors $\\textbf{imply}$ that a better QA model leads to better overall V-IP performance, without supporting experiments and evidence.",
            "13": "This weakens the connection between the results in Table 1 and the overall V-IP problem setting.",
            "14": "For example, the author may show that using BLIP2 on Places 365 or CIFAR-100 brings better V-IP performance (improved interpretability of query chain, shorter query chain, etc).",
            "15": "The reviewer is aware that the computation of BLIP2 is much more expensive than that of Concept-QA.",
            "16": "The point here is to build the connection between QA model performance and V-IP performance.",
            "17": "- It would be good to come up with a way to quantify the interpretability and the length of query chain so that the reader can be more confident that the proposed Concept-QA indeed improves over CLIP baseline in these two aspects.",
            "18": "For example, a few qualitative results in Fig 4 and the appendix might not be representative enough and might be cherry-picked."
        },
        "dmvezA5oxj": {
            "0": "1.",
            "1": "Performance: Concept-QA appears to perform well when evaluated along multiple axes.",
            "2": "The results are highly correlated with concepts that are actually present in the images; i.e., there seems to be very little confabulation (often called “hallucination”).",
            "3": "In addition, the explanations (query-answer chains) are shorter and more human-interpretable.",
            "4": "2.",
            "5": "The key contribution of the paper appears to be the formulation of the Concept-QA model based on query information and answers from GPT + CLIP.",
            "6": "The paper demonstrates that naively using CLIP-score between (query-concept, image) does not work well out-of-the-box, and proposes learning a new light-weight network based on pseudo-labels.",
            "7": "3.",
            "8": "Impact: The labeling requirement was a huge bottleneck.",
            "9": "With this approach, that requirement doesn’t exist anymore.",
            "10": "It paves the way for more widespread application of VIP in scenarios where interpretable-by-design approaches are critical.",
            "11": "However, we should credit the core idea and (part of the implementation) to the earlier work on label-free CBMs.",
            "12": "1.",
            "13": "The framework of Variational Information Pursuit is quite similar to the Concept Bottleneck Models.",
            "14": "The main difference is the sequential selection of informative queries (concepts) in VIP.",
            "15": "The key contribution of the paper is the approach to overcome the limitation of annotating  query sets and labels.",
            "16": "However, this was already proposed and implemented by an earlier paper (Oikarinen et al.).",
            "17": "2.",
            "18": "Sec.",
            "19": "3.2.2 presents the observation that choosing a set of queries from the dataset a-priori (agnostic to the image), does not result in either an optimal or interpretable query set.",
            "20": "This is understandable, since two main information sources are ignored — the image content, and taking advantage of the answers to the queries.",
            "21": "Considering the actual experimental setting is significantly different from the VIP setting, the title “Answering Queries with CLIP Adversely affects VIPs explanations” and the conclusions seem a bit misleading.",
            "22": "While floating-point-dot-product-scores from CLIP might also be a problem (as discussed in Sec.",
            "23": "4.1), the more obvious problem in this setting appears to be the query selection strategy.",
            "24": "Please let me know if I have misunderstood something.",
            "25": "3.",
            "26": "The proposed ConceptQA architecture is intuitive and quite straightforward.",
            "27": "While this is not a downside by itself, it is probably something that one implement as a baseline.",
            "28": "It is a bit hard to identify the interestingness or novelty in the approach.",
            "29": "The closest baseline is simply a comparison against a CLIP(image, concept) similarity score.",
            "30": "References:\n- Oikarinen et al.",
            "31": ": Label-Free Concept Bottleneck Models; ICLR 2023."
        },
        "ZEGegJRgpA": {
            "0": "1.",
            "1": "This is an interesting take to use VIP / sequential QA for image classification and the experiments demonstrate the effectiveness of this method for interpretability/explanations.",
            "2": "2.",
            "3": "In general the idea could be useful beyond image classification for other tasks with data-scarce settings, especially unlabeled datasets, where language models can help to create pseudo labels.",
            "4": "3.",
            "5": "The paper put together (main + appendix) is well written and explains the preliminaries, proposed method, implementation, and experiments in good detail.",
            "6": "1.",
            "7": "Comparisons to vision-only models are missing: it would be useful to know how much of a gap there is between supervised as well as self-supervised vision models trained on these datasets.",
            "8": "This comparison would tell us how much performance is being sacrificed for interpretability.",
            "9": "Comparisons in terms of #parameters are also important in this regard.",
            "10": "2.",
            "11": "The method only uses OpenAI's GPT models (which are not open-source but only accessible via API calls -- i.e.",
            "12": "need an internet connection and OpenAI account for inference) -- it would have been better to also implement the method with a local language model -- it is understandable that the performance could potentially be lower than GPT.",
            "13": "3.",
            "14": "A human study could have helped to supplement the study on explanation length.",
            "15": "See Q2 and Q3 below.",
            "16": "4.",
            "17": "Useful details and useful visualizations are relegated to the appendix -- for instance Fig 9 could be moved to the main paper, some of the details on query set generation (App C) and training process (App D) could be briefly added in the main paper to improve the flow/readability of the paper."
        },
        "mZsQGulbci": {
            "0": "- This paper introduces a methodology for training Concept-QA that doesn't require manually annotated training data, reducing the burden of data annotation.",
            "1": "- Experiments on multiple datasets demonstrate the proposed method's effectiveness.",
            "2": "- This paper is well-written and easy to follow.",
            "3": "- It would be better to try more LLMs to show the generality of this idea.",
            "4": "- Limitations could be discussed.",
            "5": "Is there anything about **the proposed method itself** that fails in certain scenarios or falls short compared to prior work?",
            "6": "- While the paper mentions the use of pseudo-labels from GPT and CLIP, it could discuss the interpretability and potential biases associated with these labels.",
            "7": "Are there instances where the pseudo-labels might lead to incorrect or biased answers?"
        }
    },
    "4bLXfRd0CX": {
        "8wUoPIKgar": {
            "0": "This paper is easy to follow.",
            "1": "The presentation is mostly clear.",
            "2": "1.",
            "3": "**There are significant concerns regarding the evaluation methodology in this paper.",
            "4": "Comparing MLE and EMO based on outputs generated by unbiased sampling is unfair, as the two objectives result in considerably different model distributions.",
            "5": "** The expected MLE loss is minimized when the model distribution Q matches the data distribution P. As mentioned in the paper, the expected EMO loss is $E_{v_i ~ Q}[\\sum_{j=1}^{|V|}P(v_j)C(v_i, v_j)]$, which is minimized when the model distribution Q is a one-hot distribution that only outputs the token i that maximizes $\\sum_{j=1}^{|V|}P(v_j)C(v_i, v_j)$.",
            "6": "Consequently, models trained using EMO will predict a much sharper distribution, leading to higher-quality but lower-diversity outputs when sampling from EMO.",
            "7": "The evaluation methodology in this paper, i.e., comparing the sampling results of EMO and MLE, is therefore like comparing the output quality of greedy decoding and unbiased sampling, which is inherently unfair.",
            "8": "The fair way is to compare their decoding results of greedy/beam search, necessitating further experiments to establish the effectiveness of EMO.",
            "9": "2.",
            "10": "Based on the above analysis, the authors' motivation appears to be flawed.",
            "11": "Under ideal circumstances, MLE trains the model to conform to the data distribution.",
            "12": "In contrast, EMO results in a one-hot distribution, which is recall-prioritization and negative diversity ignorance.",
            "13": "3.",
            "14": "The proposed EMO loss is very similar to the word embedding-based loss [1].",
            "15": "The only difference lies the choices of distance mertics (Cosine distance in EMO, Euclidean distance in [1]).",
            "16": "[1] https://arxiv.org/pdf/1807.11219.pdf"
        },
        "ymzpfZWBLq": {
            "0": "1.",
            "1": "This paper is well-organized and well-written, so it is generally easy to follow.",
            "2": "2.",
            "3": "The intuition of the idea makes sense, and it is good that the complex earth mover distance loss can be reformulated into the cosine similarity dot probability.",
            "4": "3.",
            "5": "The author(s) conducted extensive and detailed experiments, encompassing different model sizes, data scales, and evaluation metrics (which is very important).",
            "6": "The thorough and detailed experiments show the advantages of EMO, adding to the soundness of the paper.",
            "7": "I have two concerns here.",
            "8": "1) Originality of the method.",
            "9": "In my view, the final loss function is very similar to the d2gpo loss, the authors did cite the d2gpo paper, but they ignored the methodology comparison and they should add d2gpo as a baseline.",
            "10": "2) Why Cosine Similarity?",
            "11": "Using cosine similarity is a choice, but may not be the best choice.",
            "12": "The cosine similarity relies on the pre-trained llm head embedding, which makes it not unbiased.",
            "13": "And through the 3.3 section, the gradient of the proposed EMO is very similar to the REINFORCE with cosine similarity as the reward, so maybe RLHF/RLAIF will be a better reward model?"
        },
        "KTCGbptnN5": {
            "0": "1.",
            "1": "The authors propose to apply the Earth Mover Distance to train the language model and establish an upper bound for practical backward propagation training.",
            "2": "2.",
            "3": "The experiments demonstrate promising performance of EMO on various tasks.",
            "4": "1.",
            "5": "The authors argue that MLE exhibits a recall-prioritization behavior, which serves as the primary motivation for introducing their proposed approach, EMO.",
            "6": "The claim appears to be confusing, as MLE is equivalent to minimizing the forward KL-divergence, i.e., $KL(p||q_{\\theta})$.",
            "7": "If the model $q_{\\theta}$ has sufficient capacity, the optimal $q_{\\theta}$ converges to $p$.",
            "8": "Otherwise, $q_{\\theta}$ tends to exhibit a mean-seeking behavior.",
            "9": "Therefore I have doubts about whether \"recall-prioritization\" is proper.",
            "10": "2.",
            "11": "As pointed out in Section 3.3, EMO exhibits a property of harmonizing recall and precision.",
            "12": "A straightforward inference is that EMO is better at handling synonyms compared to MLE, potentially granting EMO-trained models the capability to generate more diverse texts than models trained with MLE.",
            "13": "The authors did not conduct such experiments.",
            "14": "3.",
            "15": "I guess the distribution of model trained by EMO is very different from that by MLE.",
            "16": "However, there's no experiments and analyses regarding that."
        },
        "IUohXjvzQZ": {
            "0": "The paper is overall well written and describes an interesting idea.",
            "1": "The experimental setup is well described and the results look reproducible.",
            "2": "A \"related work\" section is missing, and it could be nice to better discuss the introduction of EMD (and optimal transport in general) in NLP and this kind of task.",
            "3": "The experimental setup focuses on the improvement of MAUVE.",
            "4": "This is a quite recent metric that makes a tradeoff between precision and recall.",
            "5": "While it is interesting to use that metric, it could be nice also to provide also perplexity.",
            "6": "I know MLE optimizes the perplexity so it is not fair for EMO, but it can provides a meaningful comparison point (I mean in table 1)."
        }
    },
    "AIbQ3HDDHU": {
        "ai1U0R8GVC": {
            "0": "This paper is a key piece missing from the large scale FP8 literature.",
            "1": "Figure 1 in particular is presented clearly and contains important details for successful FP8 inference/fine-tuning.",
            "2": "The largest weakness in this paper is in transparency -- it is claimed throughout (e.g., the title) that FP8 training will be demonstrated.",
            "3": "However, results are only provided for fine-tuning.",
            "4": "I would suggest changing the title/intro to be more clear."
        },
        "fTsIIDpUjN": {
            "0": "* The paper goes into great detail on how exactly quantization is carried out and how scaling factors are computed.",
            "1": "* Additional general discussion and statistics studies are presented in the Appendix.",
            "2": "* The paper repeatedly emphasizes \"training\" in FP8 (e.g., in the title, in the abstract, etc.",
            "3": "), yet I could not find any actual training experiments, that is training a large LLM from scratch, in the paper.",
            "4": "The paper only performs some finetuning on GLUE tasks, which is significantly less interesting given that it is comparatively cheap and FP8 speedups thus not so crucial while, in many cases, even more affordable finetuning techniques like QLoRA also work well.",
            "5": "I think significant presentation changes are required to clarify that the paper focuses on inference and finetuning.",
            "6": "* Most of the methodology appears to me like standard low quantized training techniques, e.g., using additional scales that are determined dynamically, adapted directly to FP8.",
            "7": "Could you explain more precisely what exactly is new?",
            "8": "I also did not find a Related Work section discussing this in more detail.",
            "9": "* FP8 inference has been studied extensively by e.g.",
            "10": "[3, 4] and also in the context of LLMs [1, 2].",
            "11": "Further, [5] finetunes (and even trains from scratch) large Transformers in FP8.",
            "12": "Hence, the overall novelty of the work appears very low.",
            "13": "Unfortunately, as the paper overall does not seem to contain significant novelty, neither in methodology nor in results, I cannot recommend acceptance at this point.",
            "14": "[1] ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats, Wu et al.",
            "15": "[2] Integer or Floating Point?",
            "16": "New Outlooks for Low-Bit Quantization on Large Language Models, Zhang et al.",
            "17": "[3] FP8 Quantization: The Power of the Exponent, Kuzmin et al.",
            "18": "[4] FP8 versus INT8 for efficient deep learning inference, Baalen etl a.",
            "19": "[5] FP8 Formats for Deep Learning, Micikevicius et al."
        },
        "pOYj4I8JUT": {
            "0": "1- The paper is well-written and organized.",
            "1": "2- The new methodology for FP8 has been evaluated on various large language models, demonstrating that this approach is generalizable.",
            "2": "1- The paper's contributions and novelty are not immediately clear.",
            "3": "The methodology for calculating the Exponent Bias resembles the asymmetric quantization process for INT8, where the scaling factor is determined using a max operation.",
            "4": "Furthermore, even within the scope of 8-bit floating point representation, determining the exponent bias based on the max operation has been explored in prior research.",
            "5": "The author is recommended to clarify the paper's unique contributions, especially in comparison to the following studies:\n\n[1] Tambe, Thierry, et al.",
            "6": "\"Algorithm-hardware co-design of adaptive floating-point encodings for resilient deep learning inference.\"",
            "7": "2020 57th ACM/IEEE Design Automation Conference (DAC).",
            "8": "IEEE, 2020.",
            "9": "[2] Sun, Xiao, et al.",
            "10": "\"Hybrid 8-bit floating point (HFP8) training and inference for deep neural networks.\"",
            "11": "Advances in Neural Information Processing Systems 32 (2019).",
            "12": "[3] Kuzmin, Andrey, et al.",
            "13": "\"Fp8 quantization: The power of the exponent.\"",
            "14": "Advances in Neural Information Processing Systems 35 (2022): 14651-14662.",
            "15": "[4] Lee, Janghwan, and Jungwook Choi.",
            "16": "\"Optimizing Exponent Bias for Sub-8bit Floating-Point Inference of Fine-tuned Transformers.\"",
            "17": "2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS).",
            "18": "IEEE, 2022.",
            "19": "2- Comparisons with other numerical formats, such as INT8, block floating point, logarithmic number systems, and posit, are not discussed.",
            "20": "For instance, the results in [5,6] indicate that INT8 performance is superior for inference, even for models like the Transformer.",
            "21": "[5] van Baalen, Mart, et al.",
            "22": "\"FP8 versus INT8 for efficient deep learning inference.\"",
            "23": "arXiv preprint arXiv:2303.17951 (2023).",
            "24": "[6] Zhang, Yijia, et al.",
            "25": "\"Integer or Floating Point?",
            "26": "New Outlooks for Low-Bit Quantization on Large Language Models.\"",
            "27": "arXiv preprint arXiv:2305.12356 (2023)."
        }
    },
    "GrgWf0ABUC": {
        "rDtdRRAavY": {
            "0": "1.Compared to traditional NLP encryption methods, this paper considers the approach of simultaneously obfuscating both the user-uploaded prompts and the generated text, which aligns well with the inherent privacy requirements of Large Language Models (LLMs).",
            "1": "2.The paper also addresses potential vulnerabilities by proposing a potential attack method, the beam-search attack, and subsequently introduces a metric for analyzing privacy protection under this attack.",
            "2": "Besides, the clarity of the paper is commendable, with logical flow, well-defined terms, and illustrative examples ensuring accessibility to a broad audience.",
            "3": "The use of figures enhances understanding, making complex concepts more digestible.",
            "4": "1.From a motivational perspective, the necessity of a collaborative and interactive process between the client-side and the server for text generation is questionable.",
            "5": "Often, users utilizing large language models are primarily interested in obtaining results, rather than performing operations on the data.",
            "6": "Moreover, they may not necessarily possess the computational power required for such operations.",
            "7": "2.The authors utilize the metric max-true-ratio to demonstrate how their privacy-preserving mechanism can withstand attacks.",
            "8": "However, it is crucial to acknowledge that a sentence inherently possesses its own structure and semantics, and often, obfuscating just a part of it may not suffice to protect the privacy of the entire sentence.",
            "9": "The authors do mention that there is often a trade-off between privacy and model effectiveness.",
            "10": "In scenarios where not enough words in a sentence are obscured, it raises a concern whether the semantics of the sentence could still be exposed.",
            "11": "This aspect deserves further attention to ensure comprehensive privacy protection."
        },
        "BkEmO4kvD1": {
            "0": "The paper does a reasonably thorough job of considering attacks, granted they are not aiming to be exhaustive as would be very hard for something like this.",
            "1": "The use of lattice techniques for this purpose seems like an interesting idea to me (though I am not an expert by any means) and thus something that was worth exploring.",
            "2": "The intersection of the degradation in quality and the fact that by their own measure the model leaks about 40% of the semantic content anyway makes this not a clearly useful idea.",
            "3": "Whilst I don't know if it would be feasible in the space available tht fact that I can read the paper and not have much idea what a lattice is afterwards does seem unsatisfying as it seems to be the main technique being brought to bear."
        },
        "9dX9TJXnCD": {
            "0": "The problem of keeping generated text private is an interesting one.",
            "1": "The paper contains ideas of how certain elements of an algorithm for this task could be performed.",
            "2": "The paper (and the preliminaries section) don't introduce all terminology and concepts.",
            "3": "While a reader may potentially read all cited work and try to understand in this way the text, the text is insufficiently self-contained to be easily digestible by a non-expert.",
            "4": "For example,\n* The preliminaries section says that a lattice structure is used and cites two papers (which explain different things) but doesn't provide a clean definition of \"lattice\".",
            "5": "As probably \"lattice\" in not meant in the purely mathematical sense (a partial order with least upper bound and greatest lower bound operators), more details are needed.",
            "6": "* The paper doesn't introduce \"transformer\".",
            "7": "* In \"As the name suggests, we conduct a simple linearization operation before feeding it to the LM\" it is unclear to what \"it\" refers, and it is unclear on what object the \"linearization\" operation is performed.",
            "8": "* In Sec 3.1, there is a \"lattice-finetuned LLM\", but the text doesn't explain what this means.",
            "9": "Also at other points, the presentation is hard to follow.",
            "10": "For example, at the bottom of page 3 the text starts to describe an algorithm informally, but there is no pseudo-code or other algorithm formalization which may help the reader to get a more precise view of what is intended.",
            "11": "The text makes no precise formal claims, but mainly describes an approach.",
            "12": "The paper presents a number of experiments, essentially investigating how robust the proposed approach is to a set of attacks the authors have selected (without much motivation on why defending against these attacks is sufficient).",
            "13": "There are quite a few language issues, e.g., missing articles before \"cloud\" (the cloud, a cloud, ...)"
        }
    },
    "8JCn0kmS8W": {
        "0wUfndscxV": {
            "0": "1.",
            "1": "The paper proposes a novel task, text-to-audio storytelling.",
            "2": "The task opens up a huge space for AI-powered general audio creation.",
            "3": "2.",
            "4": "The proposed system outperforms or achieves on-par  performance against previous SOTA methods, i.e., AudioGen and AudioLDM, in both objective and subjective metrics.",
            "5": "3.",
            "6": "The new established benchmark is another good contribution.",
            "7": "4.",
            "8": "The developed prototype and demos look amazing.",
            "9": "1.",
            "10": "The method proposed has limited methodology contribution to the research community.",
            "11": "The system reflects a crafted engineering pipeline by combining several off-the-shelf audio expert models through LLM.",
            "12": "There is limited contribution in terms of machine learning algorithms.",
            "13": "2.",
            "14": "As sort of an ensemble of expert models, the paper does not include any system-level ablation studies by comparing against other design choices.",
            "15": "a.",
            "16": "How much does the system rely on the capabilities of LLMs?",
            "17": "How would it perform if LLM is not GPT-4, but rather those open-source alternatives like Llama.",
            "18": "b.",
            "19": "The script writer acts like an agent.",
            "20": "There are numerous works and existing methods working on connecting LLM to perform various tasks, e.g., AutoGPT.",
            "21": "But the authors didn’t compare against these agent-based system design."
        },
        "d5uLWksw7M": {
            "0": "- The paper proposes an interesting approach for human-machine co-creation specific to audio.",
            "1": "To the best of my knowledge, there is no other system that is leveraging existing LLMs and audio generation models for such a use-case.",
            "2": "The use of a deterministic compiler for generate the exact instructions from the output of the LLM is an interesting choice.",
            "3": "Additionally, the choice to focus separately on foreground and background seems to work quite well in enhancing the quality of the outputs.",
            "4": "- While I am not very impressed with the results especially in terms of naturalness, I can see that such an application might be useful for storytelling.",
            "5": "- There doesn’t seem to be substantial technical contribution in the paper.",
            "6": "The main technical components I can see are: \n  1.",
            "7": "Using the in-context learning capabilities of LLMs to generate well-formatted outputs for audio scripts.",
            "8": "2.",
            "9": "Converting the scripts to calls to 3 different models.",
            "10": "3.",
            "11": "Carefully assembling the generated audio into a single unit.",
            "12": "While I do appreciate the effort it takes to assemble all these components, I am not too sure of their scientific value to the ICLR community.",
            "13": "- Based on the text, it is not clear what the basis of the metrics proposed in Audio Storytelling benchmark is.",
            "14": "There are no references to any studies from the relevant communities which justify the choice of the specific criteria.",
            "15": "I would expect the authors to at least add some information, either in the paper, or an appendix, going into more detail regarding the justification being choosing these metrics.",
            "16": "- The result showing WavJourney outputs to be better than AudioCaps GT audio seems a little off to me.",
            "17": "1.",
            "18": "It’s not clear what the preference test is focusing on: the overall quality, or the adherence to the caption.",
            "19": "2.",
            "20": "I wonder if the authors ran the GT audio through the same audio quality enhancement model for evaluation.",
            "21": "3.",
            "22": "In table 3, the 6th column seems to have the wrong entry bolded.",
            "23": "GT audio has a higher REL score than WavJourney audio.",
            "24": "4.",
            "25": "The fact that the results are so one-sided for Clotho dataset gives the impression that the result is not too signification (even though the statement is true), or that there is something wrong in one of the two datasets.",
            "26": "Based on the samples shared, I felt all the GT audio to be more natural sounding than WavJourney.",
            "27": "I would encourage the authors to also showcase examples where WavJourney was rated higher than GT by the listeners.",
            "28": "- The generated results have pretty severe audio artifacts.",
            "29": "This is not necessarily a weakness of WavJourney itself, but is an issue with the audio generation models themselves."
        },
        "wZJzNWeI6C": {
            "0": "1) The generated samples are well done.",
            "1": "2) The framework is training-free.",
            "2": "3) The framework offers high interpretability and flexible ways to create audio content.",
            "3": "4) A novel subjective evaluation metrics are proposed.",
            "4": "1) While the generated results are impressive, this work focuses more on production than academic research.",
            "5": "It shows how best we can achieve when combining state-of-the-art models, and the contribution is limited from the perspective of technical novelty.",
            "6": "2) Since the SOTA generative models are not perfect everywhere, sometimes those models might not generate the expected content.",
            "7": "It seems like the proposed framework doesn't take it into consideration and may not always be reliable or robust to use.",
            "8": "3) As an AI audio creation tool, it would be nice to enable the editing of existing audio content.",
            "9": "It happens a lot in movie or TV creation.",
            "10": "In this case, the framework needs to take the audio as an input as well.",
            "11": "However, it seems like the current framework cannot support that.",
            "12": "4) The evaluations are limited to audio captioning tasks.",
            "13": "The evaluation of speech and music qualities is missing."
        },
        "I1l2gcjeUo": {
            "0": "The problem is interesting.",
            "1": "1.",
            "2": "The way this paper deals with audio temporal relationships is to generate audio using multiple models and manually connect the generated audio.",
            "3": "However, considering the ambiguity of language and the complexity of natural audio, there may be partly overlap among the generated foreground audio lists.",
            "4": "This method cannot well fit the distribution of natural audio data.",
            "5": "The audio shown in the demo and the mel-spectrogram shown in the article show this shortcoming: there is a clear separation between different audio contents, and there are obvious traces of artificial processing.The author also pointed out this point in the limitations.",
            "6": "2.",
            "7": "The author points out that WavJourney outperforms previous state of the art methods in both subjective and objective evaluations.",
            "8": "However, on the objective indicators of the Audiocaps dataset, WavJourney's performance is lower than AudioGen's.",
            "9": "3.",
            "10": "The experimental part of the article is rather inadequate, The analysis of composite audio generation capabilities of the method is limited to the scene of storytelling, and the analysis of interactive audio creation in multi-round dialogues is also oversimplified, making an inadequate demonstration of the core capabilities of the model."
        },
        "29a6fIyEdE": {
            "0": "The paper focused on a compositional audio content creation, not the end-to-end generation model.",
            "1": "In audio domain, I believe that this kind of compositional audio content creation will be more useful, because audio has specific physically proven time-frequency relationship, and is really weak for noise (in human perception), so that, a compositional creation can be one solution.",
            "2": "And, the paper described one way to do that by tackling in sound types, sounds level, sounds position, etc.",
            "3": "I think this paper is more like a positional paper rather than an experimental paper.",
            "4": "The authors evaluated the proposed methods in two ways.",
            "5": "One for validating the proposed method, they evaluated the proposed method on already established text2audio generation task.",
            "6": "This evaluation showed that the proposed compositional audio generation method is working well within an audio generation task which I think is enough to show the effectiveness of the proposed method.",
            "7": "As a second experiment, the authors further explored audio storytelling creation task.",
            "8": "And, in my opinion, this experiment is more like what we can do more or further use cases rather than a solid evaluation method.",
            "9": "They measured five subjective metrics, however, since the generated audio content contains music, effect, and speech sounds, we are not sure about where the impressions are came from.",
            "10": "Also, baseline is not existed (even though it's not for this task, comparing with audiogen and audioldm might give some baselines)."
        }
    },
    "TjXjkxhSdE": {
        "KTs90LnWPU": {
            "0": "The explanation provided for Figure 3 is compelling and effectively illustrates the effect of the method on model parameters.",
            "1": "Nevertheless, it's worth noting that the visualization in Figure 3 visualizes a small model opt-125m, leaving some uncertainty regarding whether the observed effect would hold the same significance for larger models.",
            "2": "- **Comparing to stronger methods like wandb:** Wandb (Sun et al., 2023) is a method that performs better than SparseGPT on one-shot pruning, and the authors should introduce it as a baseline and add more discussions around it.",
            "3": "I believe that the framework is independent from the base pruning method, thus doing experiments on top of a strong existing method is highly recommended.",
            "4": "- **Performing experiments on stronger base models:** A clear trend that is disclosed by comparing SparseGPT and Wanda in Sun et al., 2023 is that the stronger the base model is, the more the pruning process hurts the performance of the model.",
            "5": "For example, in the SparseGPT paper, pruning retains the model performance on OPT models; however, when Sun et al., 2023 evaluates on LLaMA based models, the performance degradation is way more significant.",
            "6": "Such observations make intuitive sense, as the more stronger the base model is, the more information each parameter carries, and the more the model performance gets hurt when the parameter gets pruned.",
            "7": "Given this observation, I suggest the authors test on stronger base models like LLaMA to give a more accurate account of how practical one-shot pruning is for real applications.",
            "8": "- **The extra step leads to diminishing returns in performance as the model scales up:** From table 2, it’s clear that as the model scales up and becomes stronger, the performance of the the re-dense and r-=prune process leads to minimal improvement compared to simply using one step of pruning."
        },
        "ASqvvckgVA": {
            "0": "- The paper tackles an important problem of sparsity in large language models that can help in reducing the memory footprint and reducing latency during inference for these large models.",
            "1": "- The paper is well written and is fairly easy to follow.",
            "2": "- The empirical results show gains over SparseGPT for the OPT-125m and OPT-350m models and on-par with SparseGPT for the OPT-1.3b and OPT-2.7b models (Table 2).",
            "3": "- Although the results on OPT models look okay on paper, I believe they are not enough to judge the practical relevance of the proposed method.",
            "4": "First of all, how much additional flops are being incurred to prune the models in three stages?",
            "5": "Secondly, the performance of OPT class of models on pre-training and various downstream tasks is itself not good.",
            "6": "So, are the gains reported in the paper statistically significant, or they lie within the standard deviation of the performance of OPT models on these tasks.",
            "7": "- Sparsity and pruning research is more relevant for larger models to reduce their inference time and the GPU/TPU memory footprint.",
            "8": "But the proposed method only matches SparseGPT's performance for the larger models.",
            "9": "Is the further Dense-Sparse pruning even necessary?",
            "10": "- The paper should also report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8)."
        },
        "lwI6fess8r": {
            "0": "- **Better performance than  SparseGPT**: Its performance seems better than SparseGPT.",
            "1": "- **Limited Calibration Samples**: SDS achieves superior results with a limited number of calibration samples, making it a practical and efficient approach for real-world applications where acquiring extensive labeled data might be challenging.",
            "2": "- **Detailed Process Explanation**: The paper provides a clear and detailed explanation of the three-step pruning process, enabling readers to understand the methodology thoroughly.",
            "3": "- It is unknown whether this could be valid for pruning large language models.",
            "4": "For pruning small language models, there are already many solutions.",
            "5": "I wonder the advantage of pruning."
        }
    },
    "JWrl5pJCnl": {
        "oNACfe2nfm": {
            "0": "1.",
            "1": "This system conducts experiments on diverse benchmarks such as VIMABench and the CaP benchmark.",
            "2": "2.",
            "3": "Detailed ablation studies are also provided, highlighting the efficacy of 'Library API Full Examples' and different segmentation methodologies.",
            "4": "1.",
            "5": "Important related work RT-2 [1] is missing, likely because it is too recent to be included and discussed.",
            "6": "2.",
            "7": "The improvement in performance is not robust.",
            "8": "Figure 5 showcases results from evaluations on VIMABench.",
            "9": "However, the baseline VIMA-200 performs slightly better than the suggested approach across all tasks.",
            "10": "Although the authors argue that VIMA requires large-scale pre-training, their proposed method also depends on large-scale pre-trained foundation models, such as SAM.",
            "11": "It would be beneficial for the authors to demonstrate performance gains on tasks where VIMA has not been trained.",
            "12": "Furthermore, the performance gain of 3% over PerAct and 1% over CaP in Table 1, is also not significant.",
            "13": "3.",
            "14": "Although employing cursor clicks to create point prompts and guide SAM’s segmentation is clever, applying this approach for the Pick and Place task seems unnecessary.",
            "15": "If you have the camera extrinsics, you can easily obtain the 3D location of the click by projecting from the image space to the 3D space, given the depth or known height.",
            "16": "In this case, there's no need for SAM.",
            "17": "In fact, other example tasks should be selected to better highlight the advantages of the proposed method.",
            "18": "[1] Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Chen, X., Choromanski, K., ... & Zitkovich, B.",
            "19": "(2023).",
            "20": "Rt-2: Vision-language-action models transfer web knowledge to robotic control.",
            "21": "arXiv preprint arXiv:2307.15818."
        },
        "L4ACqWaj8p": {
            "0": "1.",
            "1": "Instuct2Act represents a whole pipeline from utilizing multimodal instructions to actions.",
            "2": "This is meaningful in embodied ai domain.",
            "3": "2.",
            "4": "It can handle a diverse range of task types.",
            "5": "3.",
            "6": "This paper includes suckers and gripper in simulations, and conducts real-world experiments.",
            "7": "1.",
            "8": "The embodied ai plus LLM develops too fast.",
            "9": "It seems that this paper a little bit lacks of novelty.",
            "10": "Instruct2Act seems like the combination of VIMA and CaP."
        },
        "A3gHHaLomn": {
            "0": "- Well-written.",
            "1": "The paper is very well-written and easy to follow.",
            "2": "The figures very much aid in understanding the paper.",
            "3": "- Ablations.",
            "4": "Ablations are conducted to better understand various design choices of the proposed methodology.",
            "5": "- Unfair comparison to baselines.",
            "6": "- CaP\n    - The proposed work's claimed distinction with CaP is unclear.",
            "7": "The authors write \"Unlike existing methods such as CaP (Liang et al., 2022), which directly generates policy codes, our approach generates decision-making actions that can help reduce the error rate when performing complex tasks.\"",
            "8": "But, the proposed methodology also uses LLMs to generate Python programs, so the distinction is unclear.",
            "9": "Furthermore, about CaP, the authors write: \"However, its capabilities are limited to what the perception APIs can provide, and it struggles with interpreting longer and more complex commands due to the high precision requirements of the code.\"",
            "10": "This seems to be a limitation of the proposed methodology as well, which also relies on a finite number of available APIs.",
            "11": "Hence, again, the distinction between the proposed methodology and CaP is unclear.",
            "12": "- Why is the oracle version of the proposed method used when comparing to CaP, instead of the non-oracle method?",
            "13": "This seems to be an unfair comparison.",
            "14": "- Even then, the performance gap seems trivial.",
            "15": "Is there any evidence to suggest that the gap in performance is non-trivial?",
            "16": "- PerAct\n    - The authors write: \"For simple 3D tasks, such as stacking objects, we introduced an additional parameter to indicate the current occupancy.",
            "17": "For more complex tasks, such as opening a drawer, we added some heuristic movements to ease the execution.\"",
            "18": "PerAct was able to operate without such simplifying assumptions, which makes this comparison unfair.",
            "19": "- Even then, the performance gap is very small.",
            "20": "How do we know this is a non-trivial gap in performance?",
            "21": "Is there a trend of tasks / cases where the proposed methodology succeeds and PerAct fails?",
            "22": "What is the intuition behind the proposed methodology outperforming PerAct, which was trained directly for the task at hand?",
            "23": "- Decision Transformer\n    - How was comparison to DT done, as DT doesn't take in language instructions?",
            "24": "- What is the intuition behind the page gap in performance between the proposed methodology and DT?",
            "25": "- Simplistic Tasks.",
            "26": "- The tasks considered for evaluation seem limited in complexity, e.g.",
            "27": "are simply pick-and-place like tasks.",
            "28": "These are tasks which can be very easily solved.",
            "29": "More complex tasks have not been explored.",
            "30": "- Furthermore, as the \"Generated Policy Code\" in Figure 3 depicts, there is an API for pick-and-place, which the system simply calls upon.",
            "31": "This simplifies the already simple problem quite a bit, by abstracting away the more difficult low-level control.",
            "32": "- Finally, a lot of processing / engineering is done to get the system to work (e.g.",
            "33": "applying a gray threshold filter followed by a morphological closing operation, a morphological opening operation, Non-Maximum Suppression, etc.).",
            "34": "If all of this engineering was required to get a simple task like pick-and-place to work (which is further simplified with the use of a pick-and-place API), then I find it difficult to see how the proposed methodology could be extended to more complex manipulation tasks, thereby limiting its utility."
        },
        "COvLA4Q4C5": {
            "0": "- Extensive ablation studies that showcase specific abilities of the model (types of OOD generalization), investigate the role of the foundation models and study the importance of the components of the prompt.",
            "1": "- Removing the dependence of engineered perceptual models from the CaP method by using foundation models.",
            "2": "- Slight improvements over CaP via the different prompting method.",
            "3": "- The methods and results are presented in an understandable manner.",
            "4": "- Standard Errors: The VIMABench experiments were run over three random seeds for each meta-task but results are reported without any standard errors?",
            "5": "In case of the textual prompts benchmarks its also not clear to me why no standard errors on results are reported?",
            "6": "- Choice of baselines: For the VIMABench I find the choice of baselines not insightful.",
            "7": "On the one hand the baselines make use of a large set of training trajectories, but on the other hand these methods train policies that choose low-level actions.",
            "8": "The presented method chooses action primitives such as \"PickAndPlace\" but does not need much training data (apart from the examples).",
            "9": "I think adapting CaP to the VIMA benchmark would be a more insightful baseline.",
            "10": "- I think it makes sense in the comparison with CaP to compare using an oracle object detector, but one of the main novelties of the work is replacing the perceptual modules of CaP with foundation models.",
            "11": "Therefore it would be interesting to see how this affects performance, i.e.",
            "12": "just run the method on the CaP benchmark without the oracle.",
            "13": "- Too much detail in related work: I think the related work section is too long and just a list of papers rather than helping to place the work in the research area.",
            "14": "I would shorten it and move interesting results from the Appendix to the main paper."
        }
    },
    "c72vop46KY": {
        "65fTVbAa0D": {
            "0": "1.",
            "1": "The proposed method represents a novel approach to multimodal techniques, distinguishing itself from previous Vision-Language Models (VLMs) like Flamingo and PaLI.",
            "2": "The method's innovative and effective feature fusion into the language model sets it apart.",
            "3": "2.",
            "4": "The proposed method has achieved SOTA performance on a range of Vision-Language benchmarks, spanning image captioning, Visual Question Answering, and visual grounding tasks.",
            "5": "3.",
            "6": "The paper meticulously provides all experimental details, and the ablation study helps to validate the design components, enhancing the overall robustness of the research.",
            "7": "Comparing the proposed method to earlier approaches such as PaLI, CoCa, and Flamingo may not be entirely fair.",
            "8": "These prior methods do not incorporate the SFT stage, making it unclear how the model performs before this crucial phase."
        },
        "bQk9tPHaig": {
            "0": "1.",
            "1": "Strong performance on a variety of popular benchmarks, including VQA, Image Caption, Visual Grounding, Document Visual Tasks, and some GPT-4 based evaluation.",
            "2": "2.",
            "3": "One pioneering work to address the shallow alignment problem for cross-modal learning by introducing visual expert module in MLLM.",
            "4": "3.",
            "5": "Open-source MLLM for better promoting the cross-modal research.",
            "6": "1.",
            "7": "The idea is not that novel, compared with BEIT-3 and VLMo, which also introduces different modality expert structures, although this work makes some changes to make it work in the era of LLM.",
            "8": "2.",
            "9": "The VQA/Image Caption model, Visual Grounding model and Chat model are three different models, I am wondering how the performance can be if all these models are a unified one?",
            "10": "Since GPT-4V may be a unified one.",
            "11": "3.",
            "12": "Although I appreciate the excellent performance it achieves, the visual backbone is ViT-e, and the input resolution is 490 * 490, also the parameter size of LLM doubles, which makes the comparason a little hard."
        },
        "MLPcShzvKD": {
            "0": "- Strong performance.",
            "1": "As tables in the submission, CogVLM shows strong performance compared to other models of equal magnitude.",
            "2": "It also exhibits competitive results compared to PaLI-X which has much more parameters.",
            "3": "- Open Source.",
            "4": "Open source multimodal fundation model with strong performance has significant impact on the whole society.",
            "5": "- Extensive experiments from different angles and extensive ablation studies.",
            "6": "The authors evaluate the superiority of CogVLM in various different kinds of benchmarks (e.g., caption, VQA, text-oriented VQA, grounding, instruction following and etc.).",
            "7": "- The perhaps biggest weakness with this paper is the writing.",
            "8": "- This paper starts by raising two possible drawbacks of shallow alignment methods: (i) converge fast but perform worse.",
            "9": "(ii) weak visual understanding ability, expecially hallucination.",
            "10": "However, both these two disadvantages proposed by the authors are just **hypothesises**, not **compelling** nor **conclusive**.",
            "11": "First, the performance gap between BLIP-2 and PaLI-X cames from several possible differences between two framework (e.g., the visual encoder size, the way that visual encoder is pre-trained by).",
            "12": "And both MiniGPT-4 and LLAVA have extremely little trainable parameters in the alignment between visual features and language features.",
            "13": "- Some blanket statements are used.",
            "14": "For instance, the author claims that NLP ability is weakened when jointly train the language model in image-text training.",
            "15": "However, there are some evidences show that jointly training can benefit both vision task as well as language task, at least in some aspect (e.g., [1]).",
            "16": "- The motivations and starting points are inconsistent with the experiments.",
            "17": "In other words, despite the strong performance, the ablation studies cannot demonstrate that two problems of shallow alignment raised by the writers are well resolved.",
            "18": "The ablation studies in Table 6 can prove the effectiveness of CogVLM design.",
            "19": "But these numbers cannot prove that deep alignment is better than and solves the issues of shallow alignment, due to the results of shallow alignment method with larger visual encoder (same parameters as vision encoder + vision adapter) are remain unknown.",
            "20": "- Section 2.2 mentions that CogVLM is trained via two-stage process, with 120K and 60K steps respectively.",
            "21": "The ablation studies in Table 6 are trained for just 6K steps.",
            "22": "However, despite with much fewer iterations, the performance gap between ablation model and the final model is not that significant (e.g., in Table 6, CogVLM achieves 142.8 COCO CIDEr, only ~4 CIDEr score less that the results in Table 3).",
            "23": "So does this phenomenone implies that too much iterations in the two-stage training process are unnecessary?",
            "24": "- The visual expert in CogVLM includes FFNs in both attention block and FFN block.",
            "25": "Which one is more important for better performance?",
            "26": "[1] Tu, Haoqin, et al.",
            "27": "\"Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics.\"",
            "28": "arXiv preprint arXiv:2309.07120 (2023)."
        },
        "DemFI9QbQn": {
            "0": "1.",
            "1": "The authors argued that most of the previous multimodal LLMs used shallow connections between vision and models, and thus proposed a new module called visual expert.",
            "2": "This new module prompts a more intimate interaction between visual and language tokens in LLMs.",
            "3": "2.",
            "4": "The authors curated a large-scale dataset for first-stage pretraining and second-stage instruction tuning.",
            "5": "Based on the large-scale training data and the proposed visual expert module, the proposed method achieves a number of state-of-the-art results across a wide range of vision-language tasks.",
            "6": "3.",
            "7": "Finally, a number of ablation studies are performed and demonstrate the effectiveness of the proposed method to some extent.",
            "8": "The main concern to me about this paper is its limited novelty and scientific merit.",
            "9": "First of all, the dense interaction between vision and language tokens has been heavily studied prior to the so-called multimodal LLM era.",
            "10": "For example, a lot of BERT-style models exploit dense interactions.",
            "11": "Second, it is really hard to capture which part is really making the main contribution to the final performance.",
            "12": "There are many confounding factors such as the number and type of pretraining data, the instruction-tuning data, different architecture designs, and finetuning strategies.",
            "13": "According to Table 6, I can hardly see a clear improvement brought by the introduced new VE modules.",
            "14": "The authors start with some good motivation for building more intimate interaction between vision and language, but it finally becomes the emphasis of the benefit of scaling up.",
            "15": "Another missed piece of this work is what we can learn from this work.",
            "16": "The state-of-the-art performance should be appreciated.",
            "17": "But from the paper, I can hardly tell what the researchers should proceed to further improve the performance.",
            "18": "Do we need better model design, or more data and computations?",
            "19": "As mentioned in the paper, the authors also used some in-house data, which I guess cannot be released to the public.",
            "20": "Given the barrier of reproducing the reported results and also the limited insights delivered by this work, I am sharing a huge concern regarding the current trend of building multimodal LLMs manifested by this work or other related ones."
        }
    },
    "jhCzPwcVbG": {
        "efqsRW0UZR": {
            "0": "- The proposed idea is intuitive and easy to follow.",
            "1": "- Exploring the potential applications of LLMs in compression is a promising research direction.",
            "2": "- The paper is well presented in general.",
            "3": "- The novelty of the LLMZip method seems to be limited.",
            "4": "As mentioned in the introduction, it seems the connection between compression and prediction has been developed decades ago.",
            "5": "Using language models for compression has also been explored before, with LSTM and/or RNN being used.",
            "6": "Therefore, it appears that the sole contribution of this paper is the substitution of previously explored smaller language models with large language models (LLMs)\n- Only Llama2 has been used as the language model in the experiment.",
            "7": "It is unclear how the performance of LLMZip would vary when employing LLMs of different types and sizes.",
            "8": "- LLMs usually require GPUs for execution, whereas traditional compression algorithms can run on CPUs, which are more widely accessible and easier to democratize.",
            "9": "- The LLMZip approach presented in this paper appears to be more suitable for submission to an information theory conference or journal, such as ISIT."
        },
        "orMCeKaOjX": {
            "0": "- The authors improve the text compression performance by combining LLMs and arithmetic coding.",
            "1": "- The paper provides new estimates of an asymptotic upper bound on the entropy of English\n\n- The authors should provide more background introduction about text compression and make the paper more self-contained."
        },
        "A1Q5LpkhER": {
            "0": "Utilizing a state-of-the-art Large Language Model for text compression to attain a higher compression ratio is interesting.",
            "1": "1.",
            "2": "The concept of compressing text with pretrained language models is not groundbreaking.",
            "3": "The paper's attempt to innovate using the advanced LLaMa2 as an LLM seems to lack strong novelty.",
            "4": "2.",
            "5": "Sections 2.1.1 and 2.1.2, which discuss text compression methods other than arithmetic coding, appear superfluous.",
            "6": "3.",
            "7": "The detailed explanation of Arithmetic coding might be redundant; perhaps it would be better placed in an appendix.",
            "8": "4.",
            "9": "In Section 2.2 regarding Entropy bounds, the equation H(S) = H(X) / E[B] does not appear to be a significant finding.",
            "10": "5.",
            "11": "The use of text-summary for compression seems misjudged.",
            "12": "Theoretically, adding bits to describe a summary would only be beneficial if the probability estimation isn't flawless.",
            "13": "6.",
            "14": "The claims about the entropy bounds of the English language are debatable.",
            "15": "For instance, Table 1 lists 0.6936, while Table 2 cites 0.7741 from a different dataset.",
            "16": "The input data chosen for testing does not seem to be a true representation of English text, with entropy rates that fluctuate depending on the input.",
            "17": "7.",
            "18": "Minor Remarks:\n- The use of \"It's\" may not be suitable for a formal paper.",
            "19": "- Terminologies such as $N_{tg}$, $N_{cg}$, and others need clear and precise definitions."
        }
    },
    "94FKDbtTqO": {
        "3owTzhNHcl": {
            "0": "Thorough analytical background on the method\n\nNot much applicable to general machine learning, too specific in bioinformatics\n\n- In the description of Table 2, what are MCC and PCC?",
            "1": "The reviewer is aware that they are later explained in Experiemnt section, but what they are and what they do need to be briefly explained in the description of Table 2 as well for the readers who are not in life sciences field.",
            "2": "- The authors say they progressively expand the masking boundary to prevent easy learning.",
            "3": "Shouldn't it be the other way around?",
            "4": "The reviewer believes that the masking boundary should progressively contract.",
            "5": "What is the point of showing the shorcut first and complicating the learning?",
            "6": "The model would already learn the shortcut if the masking boundary progressively expanded.",
            "7": "An additional experiment on this needs to be conducted.",
            "8": "---\n\n**Post Rebuttal**\n\nWell addressed!"
        },
        "KyfeUtgURB": {
            "0": "[Originality and Significance] The author presented two original findings.",
            "1": "One is that the overlapping tokenization always performs better in the fine tuning stage, regardless of the tokenization method in the pre-training.",
            "2": "This is different from the conventional wisdom and could provide the insights for many related research and applications.",
            "3": "The second contribution is that gradually increasing the complexity during the training could mitigate the overfitting issue and achieve better performance by combining fast convergence and generalizability.",
            "4": "This method could inspire other researchers to consider similar techniques to balance the convergence and generalizability.",
            "5": "The performance of the RandomMask algorithm is better than the precedent algorithms in different tasks, which is a significant result for the DNA sequence analysis.",
            "6": "[Organization] The paper is presented in a well-organized way, from the observations to the new algorithms.",
            "7": "Both the them bring new knowledge to the field.",
            "8": "[Clarity] The experiment and result section is relatively short.",
            "9": "Some more clarifications would be helpful.",
            "10": "For example, (a) when describing the baseline, the author mentioned “All models are trained on human genome and fine-tuned on the benchmark datasets with identical settings.” The “identical” setting does not bring clarity on how the mask is generated.",
            "11": "Does this mean all the algorithms are trained and fine tuned with 15% token masked?",
            "12": "This setting is slightly different than the original setting in the “Nucleotide Transformer” paper.",
            "13": "(b) “Finetuning” section discussed the dataset in a detailed way; however, the details of the algorithm setup in the fine tuning is not discussed.",
            "14": "[Quality] The value of RandomMark (or training with gradually increased difficulty) can be better verified through experiments.",
            "15": "For example, the author presented the result using the training with 5 phases.",
            "16": "It would be great if the author could compare the result with different numbers of phases: one phase with maximum difficulty, two phases with two different difficulties, and etc."
        },
        "fXj1hLDRFX": {
            "0": "* Extensive empirical results and analysis, providing some findings about overlapping strategy in DNA tokenization, could benefit the community.",
            "1": "* The proposed method RandomMask achieves SOTA on various downstream tasks.",
            "2": "* The proposed RandomMask is effective but simple.",
            "3": "It could be easy to be re-implemented and deployed for further research.",
            "4": "While this paper provides extensive empirical results and quantitively demonstrates the effectiveness of RandomMask, there are several areas where it could be further enhanced.",
            "5": "My main concerns are as follows:\n\n1.",
            "6": "The authors might consider refining the focus of this work.",
            "7": "The true contribution appears to be the improvement of the overlapping strategy tokenization for DNA pretraining, which diverges from the broader theme of \"rethinking the pretraining for DNA sequence.\"",
            "8": "1.",
            "9": "The motivation behind the study is somewhat unclear.",
            "10": "Although the authors identify three potential challenges -- rapid convergence, the risk of under-training, and the potential for sparse attention -- they do not adequately explain how RandomMask addresses or mitigates these issues.",
            "11": "1.",
            "12": "There is a lack of experimental analysis supporting the source of the observed improvements, which is crucial for substantiating the paper's main claims.",
            "13": "For example, besides the quantative improvements, does the rapid convergence and under-training still exist after applying RandomMask?",
            "14": "1.",
            "15": "The comparison in Observation 1 does not seem to be an apples-to-apples comparison.",
            "16": "Overlapping represents more patterns and creates longer sequences for the same DNA length.",
            "17": "It would be beneficial to understand if the conclusion holds for different lengths of k-mer.",
            "18": "1.",
            "19": "The paper's presentation could be improved in several ways:\n    1.",
            "20": "The introduction is somewhat verbose, indirectly causing the first two weaknesses and making the paper hard to read.",
            "21": "1.",
            "22": "Placing Figure 1 and Table 1 on page 1 would improve readability, given that the main content describing Figure 1 and Table 1 is in the first page.",
            "23": "1.",
            "24": "The separate table on the left in Table 2 appears to be redundant.",
            "25": "1.",
            "26": "The experimental settings in Section 3 lack detailed descriptions, potentially making reproduction difficult and potentially misleading.",
            "27": "1.",
            "28": "A thorough proofreading could enhance the clarity of writing and word choice.",
            "29": "1.",
            "30": "It would be beneficial to further explore whether sparse attention is indeed a problem for DNA sequence representation.",
            "31": "Sometimes, sparse attention can improve generalization [1].",
            "32": "This might depend on different sub-sequences and the various functions of different layers when modeling cross-attention.",
            "33": "I would appreciate further elaboration on the limitations of sparse attention in DNA sequence representation.",
            "34": "I would appreciate the explanation and further evidence to address these concerns.",
            "35": "[1] Correia, et al.",
            "36": "\"Adaptively Sparse Transformers.\"",
            "37": "Conference on Empirical Methods in Natural Language Processing (2019)."
        },
        "0gERyqV2PL": {
            "0": "The paper is well-written and presents its findings in a clear and logical manner, effectively explaining all observations and results.",
            "1": "I especially like how it points out important observations step by step until it introduces the new technique.",
            "2": "The graphs showing how the model's errors changed during training, attention maps and t-sne plots that help visualize the data made it easier to get what the paper is saying.",
            "3": "The evaluation section is lacking in clarity.",
            "4": "It would be helpful to answer the questions listed below and help readers understand how RandomMask overall improves the performance of downstream tasks."
        }
    },
    "YIWe2amtrV": {
        "VMRvFOYHsk": {
            "0": "The paper has the following strengths:\n\n1.",
            "1": "QAT is a fairly simple procedure that could have benefits beyond just open-endedness of questions posed to the chatbot.",
            "2": "2.",
            "3": "QAT shows improvements over non-QAT in a variety of LLMs (Table 1)\n\nThe paper has several weaknesses.",
            "4": "1.",
            "5": "The labelling of open-endedness itself comes from GPT-4, thus invalidating one of the core propositions that LLMs are not very good at identifiying open-ended questions.",
            "6": "2.",
            "7": "The prompt used to GPT classifies is simplistic and would result in classification based on the overall topic and appearance rather than factual open-endedness.",
            "8": "As an example, consider a question that is open-ended by seemingly about science (eg.",
            "9": "concerned with origin of life or questions about the universe).",
            "10": "These will likely be classified as Highly Accurate by the prompt.",
            "11": "3.",
            "12": "Since the final evaluation is also done via GPT-4 it collapses the evaluation function with the labelling function."
        },
        "PY4amGqsFi": {
            "0": "- This paper calls attention to the ability of question awareness, which is useful in detecting when “hallucination” or creativity is needed, and when factuality is more important when answering user queries.",
            "1": "- This paper use average Kurtosis as a metric to evaluate the “determinacy” of the answer.",
            "2": "I am not fully convinced of whether this metric is reliable and whether it truly reflects determinacy, but it is an interesting choice.",
            "3": "- The paper introduced QAT, an adaptive way to tune the temperature parameter to adjust the output distribution.",
            "4": "- Better definition of question awareness/determinacy: Why does average kurtosis reflect determinacy?",
            "5": "Is determinacy equivalent to “certainty” of the model?",
            "6": "How do these two concepts link together?",
            "7": "I am not convinced by the claim in section 2.4 that LLMs have fundamental question awareness on some scenarios, maybe these tasks are indirectly or directly presented in their training data, and thus not necessarily mean that they know that they need to choose more deterministically.",
            "8": "- QAT has a phase of continual fine-tuning prior to the temperature tuning phase, so I would love to see a comparison with baselines like simply tuning the temperature by hand.",
            "9": "How does the cost differ?",
            "10": "Which one performs better?",
            "11": "Without a comprehensive comparison, and human evaluations for open-ended writing tasks, I don’t know whether QAT truly improves the generation."
        },
        "iLeBsbOzwl": {
            "0": "1.",
            "1": "Novel Focus: The paper tackles the \"question awareness\" in LLMs, exploring their ability to discern between open-ended and non-open-ended questions.",
            "2": "2.",
            "3": "Methodological Contribution: The introduction of the Question Awareness Temperature (QAT) sampling method is novel.",
            "4": "1.",
            "5": "The experimental setting is not clear.",
            "6": "2.",
            "7": "Some benchmarks are missing for evaluation.",
            "8": "3.",
            "9": "Some important implementation details are missing."
        }
    },
    "29pGC6IYaL": {
        "U5tA4soOaW": {
            "0": "- This paper notices that the LLMs' potential in low-resource NMT\n- This paper tries multi-source distillation with RL method, it has somewhat novelty\n\n- This paper is hard to read.",
            "1": "In other words, its presentation is very poor.",
            "2": "It seems that the authors do not spend enough time to prepare such a paper.",
            "3": "Specifically, \"RL\" in the title; what is the test sets and setting on Table 1, why the results of ChatGPT or GPT4 are not presented?",
            "4": "What is the i of M_t^i?",
            "5": "What is the M_y.",
            "6": "What do you mean by \"follow 11\", above Equation 11?",
            "7": "What is \"eq.3\"\n- This paper cannot be viewed as a solid science paper, as I cannot find enough information to ensure their experiments are reasonable and convincing.",
            "8": "What is your test set in Table 2, are they officially released test sets?",
            "9": "Why the student model's lr is lower than the teacher model?",
            "10": "How do you train the LLMs, i.e., the teacher models?",
            "11": "Do you mean that you will SFT them with millions or billions datas?",
            "12": "- The experiments in this paper are not enough, and miss some important baselines."
        },
        "pAw147WVds": {
            "0": "- The paper is easily comprehensible and straightforward.",
            "1": "- The authors conduct an ablation study to systematically assess the contributions of each individual component.",
            "2": "- The observed improvements are relatively marginal when compared to other baseline methods.",
            "3": "- The paper lacks a comprehensive set of experiments to conclusively establish the superiority of the proposed approach over other existing methods.",
            "4": "The performance enhancement is primarily demonstrated through improvements in BLEU scores in various translation directions.",
            "5": "However, I'm hard to find a qualitative assessment of the method's effectiveness and why the proposed techniques are advantageous in enhancing translation models.",
            "6": "Since the authors mentioned that the consideration of dynamic changes in the distillation process is a key contribution of the paper, it would be good to provide additional experiments to demonstrate this."
        },
        "hinWS94HQS": {
            "0": "1.",
            "1": "The authors proposed to use LLMs as the teachter model to distill the task-specific models, this is a promising direction for achieving a balance between performance and efficiency.",
            "2": "2.",
            "3": "Experimental results in multiple translation tasks show the effectiveness of the proposed method.",
            "4": "1.",
            "5": "Why have you selected Llama as one of the teacher models?",
            "6": "Llama has not been trained on the languages referenced in the paper.",
            "7": "2.",
            "8": "I want to know the performance of the reward models.",
            "9": "In recent work, the performance of the reward model determines the final outcome.",
            "10": "3.",
            "11": "Training a model based on Reinforcement Learning (RL) is challenging.",
            "12": "Is it possible to directly use rejection sampling for knowledge distillation?"
        }
    },
    "FiQRgzKl64": {
        "tOxLNuB6XX": {
            "0": "- Successfully applies MoE supernets to both BERT and MT models demonstrating significant metric improvements\n- The work is written in a well structured manner making it easy to follow\n\n---\n### Weaknesses\n\n- **[major]**: As far as I can tell, many of the main contributions are already published in [AutoMoE: Heterogeneous Mixture-of-Experts with Adaptive Computation for Efficient Neural Machine Translation](https://aclanthology.org/2023.findings-acl.580) (Jawahar et al., Findings 2023) for machine translation and the presented work would need to outline how it differs from previous work besides applying it for different tasks.",
            "1": "- **[major]**: Despite WMT'14 being commonly used in the literature, they are now way overhauled in the broader machine translation literature and should be replaced by more recent test sets to put the results into the context of recent research, see **[2]** or **[3]**.",
            "2": "- **[major]**: The presented work should follow the broader machine translation standard to report their evaluation scores using `sacrebleu` and provide the corresponding hash that was used for generating the scores.",
            "3": "This will ensure that scores are reproducible and do not vary across papers by up to 1.8 BLEU points due to varying tokenization and normalization, see **[2]**, **[4]**.",
            "4": "This should replace the metrics reported in the main paper and not only live in the Appendix.",
            "5": "- **[major]**: While BLEU is still commonly used, there are now better metrics that correlate more closely with human judgement **[3]**, specifically I'd additionally report chrF and COMET scores.",
            "6": "- **[major]**: The machine translation experiments are missing a compute-matched dense and mixture of experts baseline trained from scratch without NAS to make results comparable.",
            "7": "---\n### Minor Comments & Typos\n\n- p.2: \"Typically, [the] weight-sharing supernet\"\n\n---\n### Missing References\n\n- **[1]**: [AutoMoE: Heterogeneous Mixture-of-Experts with Adaptive Computation for Efficient Neural Machine Translation](https://aclanthology.org/2023.findings-acl.580) (Jawahar et al., Findings 2023)\n- **[2]**: [Non-Autoregressive Machine Translation: It’s Not as Fast as it Seems](https://aclanthology.org/2022.naacl-main.129) (Helcl et al., NAACL 2022)\n- **[3]**: [Results of WMT22 Metrics Shared Task: Stop Using BLEU – Neural Metrics Are Better and More Robust](https://aclanthology.org/2022.wmt-1.2) (Freitag et al., WMT 2022)\n- **[4]**: [A Call for Clarity in Reporting BLEU Scores](https://aclanthology.org/W18-6319) (Post, WMT 2018)"
        },
        "BQujKnIbwa": {
            "0": "1.",
            "1": "Results of the method show significant speedup versus baseline and non-marginal improvement in the final model accuracy\n\n2.",
            "2": "The method to use Mixtures of Experts (MoE) as a way to perform weight disentanglement is an interesting and novel idea and is backed up by solid quantitative results.",
            "3": "1.",
            "4": "The decision to use MoE as a method for weight disentanglement is not fully justified.",
            "5": "A better explanation and introduction is necessary."
        },
        "hROYUixWdD": {
            "0": "The author introduce a novel method in the form of mixture-of-supernets, blending the mixture-of-experts method to refine the weight-sharing mechanism, which is a novel step in neural architecture search.",
            "1": "The proposed approach is designed to cut down on the need for retraining, which could save significant time and computational resources.",
            "2": "Experimental results show that the method could lead to better-performing machine translation models and more efficient BERT models, indicating an improvement over existing techniques.",
            "3": "The paper presents some areas for potential improvement:\n\n1.",
            "4": "The study concentrates on smaller networks, which may not face the challenges of larger models where memory and computational resources are more critical.",
            "5": "To fully evaluate the method's applicability, incorporating a broader range of network sizes and model families (e.g., BERT, T5, GPT) would be beneficial for assessing its scalability and generalizability.",
            "6": "2.",
            "7": "The absence of FLOPs (Floating Point Operations Per Second) as a performance metric is noticeable.",
            "8": "Including FLOPs would provide a more complete comparison with other methods.",
            "9": "Additionally, the exclusion of the STS-B task, a single regression task in the GLUE benchmark, is not justified; its inclusion could enhance the validation of task generalization.",
            "10": "3.",
            "11": "Although efficiency is purported to be a key advantage of the proposed method, this is not thoroughly discussed in the main body of the paper.",
            "12": "The supplementary comparison of memory efficiency between HAT and the proposed method indicates a significant memory efficiency gap.",
            "13": "Moreover, the improvements in task performance are relatively marginal  and efficiency drop compared to other baselines is significant, suggesting a trade-off that may undermine the method's relative advantage when considering the marginal performance enhancement."
        },
        "A2h6wSYdFu": {
            "0": "- Results seem strong on language modeling and MT.",
            "1": "- Leveraging MoE techniques for modeling is intuitive.",
            "2": "- Paper is hard to follow and took multiple readings to understand the problem setting.",
            "3": "Any reader not familiar with NAS area is likely to feel lost.",
            "4": "I recommend significantly reworking the problem setup for clarity.",
            "5": "This will greatly improve the paper.",
            "6": "(Eg.",
            "7": "Section 2 is confusing, and extra prose to explain what a supernet is informally and why it is used would be helpful).",
            "8": "Connecting each subsection in Section 3 is also needed.",
            "9": "- k-shot NAS is extremely similar to the proposed method, and should not be taxing to reimplement.",
            "10": "Given that this is an intuitive baseline even if k-shot NAS didn't exist, I believe this, or something similar (iterative vs joint training) is an important baseline.",
            "11": "Without this, it is not clear how effective the proposed method is.",
            "12": "- More than training steps, cost (FLOPS and wall clock time) while training both initial model and final model is a more informative metric than what is displayed in Table 3."
        }
    }
}