{
    "EBS4C77p_5S": {
        "n2OLgJ7g5c": {
            "0": "Strength：\n1.",
            "1": "The paper combines the related tasks of sign language translation in a clever way.",
            "2": "It is only necessary to perform different processing on different modalities in the input layer, and then a unified network can be used for subsequent training.",
            "3": "The method is simple and effective and improves performance without significantly increasing model parameters.",
            "4": "2.",
            "5": "This paper has done a lot of ablation experiments, and the experimental details shown in Table 2 can enable readers to understand the improvement brought by each method and enhance the reproducibility of the method.",
            "6": "Weakness:\n1.",
            "7": "There is a little description of the method in this paper.",
            "8": "There is only an illustration chart, and no details of the model are shown.",
            "9": "It is not stated how the different modal inputs are fused at each iteration of the model.",
            "10": "2.",
            "11": "The experimental part of the paper does not highlight its method.",
            "12": "The main innovation of this paper is to use a unified framework for related tasks of sign language translation and expect that multi-task training can improve the performance of the model.",
            "13": "However, there is only a small amount of content about multi-task training in the experimental part of the paper.",
            "14": "3.",
            "15": "The performance metrics in the paper are confusing.",
            "16": "The article discusses the common performance metrics of machine translation and uses two different metrics, tokenized Bleu (B@4) and detokenized Bleu (sBLEU).",
            "17": "However, the values of these two indicators in the experiment of the paper are exactly the same, which is Unreasonable unless a unified Tokenizer is used, namely tokenize13a.",
            "18": "This needs to be explained in more detail in the paper."
        },
        "ZhJ47FIQch": {
            "0": "Strength:\n\n1.",
            "1": "The performance is promising.",
            "2": "The final model does not rely on any pre-trained networks but achieves comparable performance with models with pre-trained networks as initialization.",
            "3": "2.",
            "4": "The multi-task objective is intuitive.",
            "5": "Generally speaking, the size of datasets for sign language-to-text translation is limited compared with text-to-text translation datasets.",
            "6": "Borrowing knowledge from other tasks and external task is a practical solution.",
            "7": "3.",
            "8": "The authors also conduct a comprehensive ablation study to see the effects of model settings to the final performance.",
            "9": "Weaknesses:\n\n1.",
            "10": "Table 2 shows that the multi-task objective improves results from 24 to 25.23, but the settings of other architecture details increase performance from  25.23 to 27.87.",
            "11": "Although experiment highlights are state-of-the-art performance, the contribution of the proposed multi-task objective is limited."
        },
        "EIIqncX6I0I": {
            "0": "Strengths:\nThe proposed approach allows multiple tasks (e.g., such as sign-to-gloss, gloss-to-text, and sign-to-text translation) related to sign language translation to be simulated jointly for enhancing the performance of sign language translation.",
            "1": "Weaknesses:\n\n1.",
            "2": "The existing experiments were insufficient to verify how multiple tasks interact to improve the performance of sign language translation.",
            "3": "2.",
            "4": "In End-to-End: Sign2Text in Table 4, the proposed approach just was comparable to the baseline VL-Transfer model in terms of ROUGE and B@4 on the Test set of PHOENIX-2014T.",
            "5": "3.",
            "6": "One of the claimed contributions is that the set of optimization technologies for SLTUNET was proposed to improve the trade-off between model capacity and regularization.",
            "7": "It was confusing.",
            "8": "Questions:\n\n1.",
            "9": "When there is an imbalance between video and gloss input, what is the result?",
            "10": "2.",
            "11": "Author claimed that the DGS Corpus includes larger\nscale, richer topics, and more significant challenges than existing datasets.",
            "12": "How to evaluate them?",
            "13": "3.",
            "14": "When the proposed approach was applied to multiple tasks, how about the learning curving of CTC and MLE losses?",
            "15": "4.",
            "16": "If there replaced the shared encoder or decoder with a separate encoder or decoder, what about the performance?",
            "17": "5.",
            "18": "In Figure 1 (1), What do the different colors of these modules denote?"
        },
        "fZMdZzUhqo": {
            "0": "Strengths\n- The proposed model is clearly defined and the ablation studies are carefully structured in Table 2.",
            "1": "The detailed discussion of these results is also appreciated.",
            "2": "Weaknesses\n- Design the protocol for Public DGS for an end-to-end SLT setup: It seems that the protocol involved splitting the dataset into train, test, and dev sets.",
            "3": "Was there more to that process?",
            "4": "Furthermore, it would also be useful to include the details of how these splits were conducted.",
            "5": "Do speakers overlap among the splits?",
            "6": "If yes, does the speaker overlap matter?",
            "7": "How does the speaker's identity affect sign language translation?",
            "8": "What is the distribution of text tokens and gloss vocabulary across the splits?",
            "9": "- The back translation losses are not useful for SLT (i.e.",
            "10": "impact of Text2Gloss in Section 5.2.2), but Zhou et.",
            "11": "al.",
            "12": "2021 showed that it was quite useful.",
            "13": "That seems contradictory and some more discussion on this would be useful for the readers.",
            "14": "- The choice of visual backbone could impact the final performance.",
            "15": "Why was the SMKD model chosen?",
            "16": "Chen et.",
            "17": "al.",
            "18": "2022 also uses a visual backbone model which is S3D (i.e.",
            "19": "different from the one used in this paper).",
            "20": "Chen et.",
            "21": "al.",
            "22": "2022 also use CTC losses for training the model.",
            "23": "As their model have some level of similarity to the proposed model, it would be useful to explicitly talk about the differences.",
            "24": "- Especially, as Chen et.",
            "25": "al.",
            "26": "2022 is also similar to the proposed model in terms of performance, it would have been insightful to see its performance on the DGS3-T baseline in Table 6."
        }
    },
    "QwqxO8URJzn": {
        "1IWuJsFdXf": {
            "0": "Strength:\nThe main reason to accept this paper is empirical results and showing performance o various tasks.",
            "1": "The author has provided more quantitative results on various tasks.",
            "2": "Weaknesses:\n\nThe current literature survey does not discuss the advantages and disadvantages of the paper.",
            "3": "The author should validate why I should include this paper in this current work.",
            "4": "How did you get this equation-2?",
            "5": "Is there any intuition of this equation?",
            "6": "The generalization of the method.",
            "7": "The equation-2 is valid for the linear layer.",
            "8": "What happened to the convolution layer?",
            "9": "Is this valuable reparametrization for the convolution network?",
            "10": "The paper does not explain the relation between attention entropy and \\sigma_reparameterisation.",
            "11": "How does this learnable parameter contribute to the stability of the transformer?",
            "12": "Instead of evaluating the proposed method on multiple tasks, the author could have done an ablation analysis on different kinds of networks and various types of transformer architecture.",
            "13": "The author should provide ablation analysis results to clarify the proposed method's work principle.",
            "14": "Why do we need such reparametrization, learning another parameter?",
            "15": "Did you analyze other kinds of techniques to tackle the attention entropy collapse problem?",
            "16": "This requires a substantial literature survey and motivation for the proposed method.",
            "17": "Can you justify this?",
            "18": "How is the attention entropy collapse solved by the proposed reparametrization technique?",
            "19": "The author should compare the stability analysis results of this transformer with the existing state-of-the-art stable transformer.",
            "20": "Also need to add a small paragraph in the related work section about stability/robustness in the transformers.",
            "21": "Can you elaborate on the number of parameters and FLOPS required for this?",
            "22": "What about the complexity of the proposed method?",
            "23": "The name spectral reparametrization in the title makes it confusing here.",
            "24": "It seems it works on frequency domain reparametrization."
        },
        "5dLt90KIiw": {
            "0": "Strength:\n- Somewhat novel reparameterization of the weights.",
            "1": "- Some analysis on attention entropy and its correlation to the training stability.",
            "2": "Weaknesses:\n- Very similar to weight norm, so the novelty is limited.",
            "3": "- No actual comparisons to weight norm?",
            "4": "- Source code not released?",
            "5": "- Results are not good?",
            "6": "- Librispeech train-clean-100 is not representative as a speech recognition task."
        },
        "4q4Q7_4E-g": {
            "0": "Strengths\n+ The empirical results are strong, showing increased robustness to changing hyperparameters and similar or better final performance.",
            "1": "This is a good result for democratisation of ML, since it reduces the amount of time and money that must be spent on fiddly hyperparameter tuning.",
            "2": "Figure 4 is particularly compelling.",
            "3": "+ The method is extremely simple to implement, yet has (to my knowledge) not been proposed before.",
            "4": "+ The experimental results are fairly comprehensive.",
            "5": "Weaknesses\n+ While I believe the final experimental results stand on their own, on a scientific level I am not convinced by the argument relating the failure to train to the collapse of the attention-entropy.",
            "6": "In the case in figure 1, the two phenomena are definitely correlated, but this doesn't appear to continue in figure 2, where the baseline attention entropy 'collapses' but still gives good downstream performance.",
            "7": "Similarly, none of the successful baseline models in figure 3 seem to have this 'dip' phenomenon where the entropy decreases then increases as the model begins to learn properly.",
            "8": "Similarly, the connection between the singular values and attention entropy doesn't seem to hold practically: look at figure 3 where we have the green solid and dotted line have similar singular values but completely different attention entropy.",
            "9": "It seems plausible that the collapse of the attention entropy and the failure of downstream performance could both be symptoms of some other problem, which the $\\sigma$-reparameterisation avoids.",
            "10": "I realise the authors are careful to not say that entropy collapse causes training instability, but I believe it could be possible to get some direct evidence for this claim, which would strengthen the scientific contribution of the paper.",
            "11": "+ Nitpicks:\n    + Could you try a baseline of dividing the initalization by a factor of the spectral norm of a random matrix?",
            "12": "+ In the theory you use $\\|W_KW_Q^\\top\\|_2$, but in the implementation it seems that you apply the reparameterisation on all of the weight matrices.",
            "13": "Did you try only reparameterising the $W_KW_Q^\\top$ matrix directly?",
            "14": "+ How does the overall memory usage compare when using LARS and fp32 on attention compared to adam and full mixed precision?"
        },
        "HU2j0mQEUz": {
            "0": "(-) The readability of the paper needs much to be desired.",
            "1": "It seems that instability is measured by the entropy of the attention head.",
            "2": "Decreasing the learning rate or increasing warmup epoch leads to more stability.",
            "3": "Without providing any explanation, the paper mentions that the training loss decreases with increase in learning rate.",
            "4": "The paper should state whether decrease in training loss comes from stability.",
            "5": "What is the consequence of entropy collapse?",
            "6": "Explain how entropy collapse relates with the stability and accuracy?",
            "7": "Is  stability and accuracy related?",
            "8": "It is not clear how the lower bound of the attention entropy is related to stability.",
            "9": "(-) The paper is proposing a re-parameterization of the weights of the linear layer using a spectral norm.",
            "10": "It is not clear how this is related to regularization and performance increase?",
            "11": "Many normalization methods have been proposed in the past, and it is not clear how the proposed is different previous normalization methods- a table should compare the performance of previous methods."
        }
    },
    "Rkk51I-BpMH": {
        "1SEreR4ZQs": {
            "0": "Strength:\n- Thorough study on the robustness of recent popular VL models vs conventional CE models.",
            "1": "The findings of (2)(3)(4)(5) mentioned in the summary section above are especially interesting and can be helpful to the community when comparing new VL methods with existing methods.",
            "2": "- Many interesting robustness capabilities of VL models only emerge when trained with hundreds of millions of samples.",
            "3": "With the proposed CaptionNet dataset, it is now possible to have a fairer comparison between VL models and CE models.",
            "4": "- Figure 1 is helpful in comprehending the effect of different loss functions vs robustness.",
            "5": "Weaknesses\n- The writing and the paper organization can be improved.",
            "6": "Sec 3.1 contains results on captionnet, Sec 4 also contains results on captionnet.",
            "7": "It’s not easy to follow what the authors try to convey quickly at first glance.",
            "8": "- The authors perform quite a lot of ablation studies.",
            "9": "However, there are many numbers in different tables.",
            "10": "It is also hard to navigate through all the information due to different ablation targets.",
            "11": "The experiments cover loss functions, label noise, caption length, caption quality, VL vs CE etc.",
            "12": "However, the text in the current form does not lead the readers well through different sections and contents.",
            "13": "- There are also many typos in the text, for example page 2: “Our results that when” -> “Our results show that when”, page 5: “CaptionNet subset can be found in Section ?",
            "14": "?” -> missing reference number.",
            "15": "- The captions are too small to read in Figure 2 & 3."
        },
        "zR6KYDFLZE": {
            "0": "**Strengths:**\n\n- The proposed experimental setup is potentially very interesting as it allows to compare different training strategies relatively fairly: using image captions vs. class labels\n- The authors experiment with many different datasets also using combinations of them\n\n**Weaknesses:**\n\n- The paper is not written clearly, creating some ambiguity and possible misunderstandings, also is not self-contained.",
            "1": "To give some examples:\n    - (Section 2, first paragraph) The authors mention using some “subset matching” technique to train models on unlabeled images.",
            "2": "That technique, however, is not properly explained - not even in the sense of how the method itself works but also just what does this technique supposed to do.",
            "3": "The details in the appendix only mention that the method matches samples with classes, but nothing says what this matching is based on.",
            "4": "Only looking at Feng et al.",
            "5": "(2022) that was referred to I can guess that the authors mean “substring matching” (not “subset”) where caption strings are matched to label names.",
            "6": "But as this “subset matching” is an important part to understand for interpreting the results and observations, it should be really clear what this is, limiting the risk of misunderstandings.",
            "7": "- (Table 2) The authors argue that “labeling strategy” is important and choosing different terms for matching has a significant impact on robustness.",
            "8": "However, they do not explain what’s their proposed terms for matching, how they are obtained, what are they based on, etc.",
            "9": "This makes drawing any conclusions from the results difficult.",
            "10": "- (Section 3, beginning) ImageNet-100 explained as a “superset of ImageNet”.",
            "11": "I would suppose it’s a union of samples in ImageNet-Captions and ImageNet-100 + some extra captions for 50,000 samples?",
            "12": "The need for extra captions are motivated for balancing classes - but are they perfectly balanced then?",
            "13": "The number of samples in Table 3 is 124k - shouldn’t that be 130k then?",
            "14": "- “we use SimCLR transformations rather than CLIP transformations for all model training on CaptionNet” - what type of transformations?",
            "15": "Are these transformations for data augmentation?",
            "16": "- Are the evaluation numbers reported in Table 3 computed on the listed datasets for each row or on ImageNet-100 (the last paragraph of the experimental setup seems to mention that)?",
            "17": "This should be clear to the reader without any ambiguities, as it’s very important for interpreting the results.",
            "18": "- (Section 4.1 + Table 3) VL models are referred to as more tolerant of label noise than CE models, where OpenImages-100 is given as an example of a dataset with noisy labels.",
            "19": "However, looking at Table 3, second row (oi100) it seems that it’s VL models that get much lower accuracy and robustness than CE models, which appears to be the opposite of what the authors claim\n- Some of the conclusions and observations are not explicitly justified or informative/clear:\n    - (Section 5, point 1)  The authors say “losses matter“, “can have a substantial effect on model robustness” - however, the exact effect/relation observed is not summarized here, although some of the relations are discussed throughout the paper\n    - (Section 5, point 3) “Length matters” - this is something that I don’t see explicitly discussed in the paper.",
            "20": "It should be clear which specific results indicate that\n\nMinor:\n- The links to figures and tables often don’t work/point to wrong places in the paper"
        },
        "X41w3QZjE6": {
            "0": "Strength:\n- The authors provide discussions on how this paper relates to and differs from related works.",
            "1": "- The authors carefully designed a set of training datasets to study the effect of different factors in vision model training, including losses, label noises, caption quality, etc.",
            "2": "- The authors in the end highlighted a few aspects that can guide future researchers in studying vision language models.",
            "3": "Weaknesses:\n- The paper presentation can be improved.",
            "4": "- There is one missing section link and a few grammar errors.",
            "5": "- The acronyms in100 and oi100 are not been officially introduced.",
            "6": "Similarly, there are many acronyms, for example, in Table 4, are not described.",
            "7": "- The experiment setup is not very clear at first sights, like how the evaluation works.",
            "8": "- The authors use CLIP-loss sometimes and VL sometimes.",
            "9": "- I also feel like the text is too narrative and not very essay-y.",
            "10": "- Although the authors show empirically that CE and VL-loss have different behaviors, there is no theoretical analysis nor any guideline on how to use the lesson to improve the loss.",
            "11": "Can we modify the CE loss for image classification so that it is less prone to label noises, or can we modify the VL loss so that it can learn more from clean data?",
            "12": "- The authors mention in 4.1 that oi100 has 90% label noise; where does this number 90% come from?",
            "13": "- Also for this section, the authors say that the noises are not equal while they are both around 90% accuracy.",
            "14": "I wonder if the authors have looked at top-5.",
            "15": "It is possible that the clip label noises are more reasonable while the subset matching label noises are more wild."
        },
        "x-2dTavKX8B": {
            "0": "Strength:\n\n1.",
            "1": "The authors conduct comprehensive experiments and propose a dataset CaptionNet which is a sub-set of ImageNet and with newly added 50000 images, it is class-balanced and with caption information.",
            "2": "Weakness:\n\nOverall the core contribution of the work is not clearly illustrated, and some key factors, such as subset matching are not well introduced even in the supplementary material.",
            "3": "Also for the proposed dataset CaptionNet, it is not clear how this dataset can be further used for researchers as there are no clearly targetted research topics relating the CaptionNet.",
            "4": "1.",
            "5": "The core statement of the work \"caption supervision enables robust learners,\" seems under-illustrated.",
            "6": "“CNNs trained on a standard cross-entropy loss also benefit from caption supervision.\"",
            "7": "This expression in the abstract is not clear to me.",
            "8": "Does it mean by subset matching labeling on unlabeled data, CE loss could be utilized and achieves similar or higher robustness compared with CLIP?",
            "9": "After reading the paper, I am not sure in which section this point is addressed with deep discussion.",
            "10": "Explanations are welcomed if there are misunderstandings.",
            "11": "1.",
            "12": "In this work, the authors consider comparing the standard supervised training with CLIP model from the perspective of cross-entropy loss and clip-style loss.",
            "13": "I am confused that from this perspective, does it degrade the fundamental difference between supervised and unsupervised learning into a loss comparison?",
            "14": "is it proper to just address this as a difference in loss function?",
            "15": "1.",
            "16": "Key factors are not well introduced in the paper.",
            "17": "For subset matching, although it is used in another paper, it is still a new method that is not widely recognized by the community.",
            "18": "Briefly introducing how it works and how it relates to your method is a necessity.",
            "19": "However, in the supplementary section E, it is still not clear how it works and why the following evaluation in Sec.E matters.",
            "20": "1.",
            "21": "For CaptionNet, the introduction is not related to what the research topics it targets at.",
            "22": "For example, the authors can not only bold/highlight the combination of sub-datasets but also highlight/emphasize the topic that the combination targets to explore.",
            "23": "1.",
            "24": "The \"label noise\" (sec.4.1) and \"captioning strategy\" (sec.4.2),  I feel like the cause for label noise or captioning strategy is the way (subset matching) used in CaptionNet to create caption labels.",
            "25": "However, the authors use the drawback in dataset creation as the topic this dataset is to discuss.",
            "26": "1.",
            "27": "There are quite an amount of unclear abbreviations and references, which makes the paper not easy to follow.",
            "28": "For example, \"in100\", ''in1000\", \"oi100\" are not first introduced as abbreviations for each sub-dataset.",
            "29": "In Table2.",
            "30": "it is not introduced what \"Eff.",
            "31": "Rob.",
            "32": "Acc.",
            "33": "Ratio\" is  , which I am afraid is also not discussed in the paper.",
            "34": "In Table 4, all the abbreviations in the first row (evaluation metrics) and names of the evaluated models are not introduced, which makes the table really hard to read and conveys little useful information currently."
        },
        "Sth5AKAwaTG": {
            "0": "Strength: The paper is clear overall.",
            "1": "It studies an important question in image classification with captioning supervision.",
            "2": "Weakness: The novelty of the paper is limited in my view.",
            "3": "The authors conduct some experiments to show that caption supervisions are helpful to make the model more robust, but this method has been proposed before.",
            "4": "The dataset is interesting, but its contribution may not be enough."
        }
    },
    "bhUPJnS2g0X": {
        "RPgz4v5y2uM": {
            "0": "Strength:\n1.",
            "1": "The improvement of AMA is significant (GPT Neo 6B outperforming GPT-3 175B).",
            "2": "Also, the experiments are extensive, evaluating on various model families such as OPT and BLOOM.",
            "3": "This shows the effectiveness of AMA is universal.",
            "4": "2.",
            "5": "This approach is scalable since AMA uses LLM itself to generate open-ended questions.",
            "6": "Weakness:\n1.",
            "7": "To apply AMA in real use cases, AMA needs 1000 training examples from the training set of the target task (specified in Appendix A.3.).",
            "8": "This is an unrealistic setting because only a few training instances might be present depending on the task.",
            "9": "What if only a few training examples are present for a task (similar to few-shot setting)?",
            "10": "Also, we need to train the probabilistic graphical model for each task.",
            "11": "This introduces additional latency for task adaptation.",
            "12": "2.",
            "13": "For the AMA prompts on Appendix H, it seems that some tasks (DROP, SST, BoolQ, COPA) only do either prompt() or answer() stage, not both.",
            "14": "How can we decide \"automatically\" when to do only prompt() or answer() or both depending on the target task?",
            "15": "3.",
            "16": "This paper is quite unclear on how the predictions are mapped to the output space.",
            "17": "Are the predictions mapped to the output space using a predefined rule?",
            "18": "(ex) no -> False for Figure 1) \n4.",
            "19": "Are there any results on a large-scale LM evaluation (175 OPT, GPT, BLOOM, etc,) comparing using AMA or not on the evaluation setting of Table 1 and 2?",
            "20": "2.",
            "21": "The structure of Section 3.2 and Section3.4 is divided into observation and solution (AMA).",
            "22": "However, the observation experiments are not extensive enough.",
            "23": "Is there a reason for selecting 3 tasks (CB, WSC, RTE)?",
            "24": "Observing the findings on more tasks would make the findings more general and the motivation of AMA stronger.",
            "25": "5.",
            "26": "I think that StoryCloze should be included in Natural Language Understanding instead of NLI for Table 1 and 2."
        },
        "qw1i8LvWaAb": {
            "0": "# Strengths\n\n- Consistent improvements over the base model when using the new aggregation.",
            "1": "- There is useful analysis: the observations related to dependencies between prompts, the diagnostic, etc.",
            "2": "Including many details throughout the methods section motivating the approach.",
            "3": "- The extensive results and appendix will be valuable to others using prompting.",
            "4": "# Weaknesses\n\n- I found the story line a little confusing.",
            "5": "The aggregation based on weak supervision is touted as main accomplishment, but this actually only gives a small improvement in Table 1 (but this small push does give edge over GPT-3 sometimes).",
            "6": "In many of the tasks the 6B model already beats the 175B without weak supervision based aggregation.",
            "7": "Also this table is not really apples-to-apples comparison making it hard to interpret.",
            "8": "Should make it more clear what is the goal in this table --- is GPT-3 simply used more like a reference than a baseline?",
            "9": "Also, is it fair to compare against GPT-3 like this when so many other prompting techniques have been developed since release?",
            "10": "- To explain more previous weakness, I was not clear when reading if it is enough to do prompt re-formatting or aggregation is also necessary.",
            "11": "I think still I am a little not sure, also about whether re-formatting is necessary for aggregation to work well.",
            "12": "In general, it could help to tailor overall story as being primarily about prompt re-formating or aggregation.",
            "13": "- It is well known that aggregating can be effective for prompting, and there are existing techniques like (self-consistency combined with chain of thought) that typically yield good improvements.",
            "14": "Perhaps worth using those as baselines, or mentioning why they weren't used.",
            "15": "Maybe CoT is not effective for smaller models?"
        },
        "-8QB5TXERm5": {
            "0": "Pros:\n-  impressive results (zero shot performance of smaller models is comparable or better than few shot of larger) on context dependent tasks\n- the idea is really neat \ncons:\n- not flashed out enough to allow me to reproduce/code it up (without looking at authors' code)\n- clarity (please see more detailed comments)\n- less impressive results on closed book tasks\n- not sure how much effort/tuning goes into prompt genereation and WS"
        },
        "m4jFIitnjuP": {
            "0": "Strengths:\n- This paper has impressive empirical results in that it up-levels the 6B parameter model to the accuracy of the 175B parameter model for most of the tasks\n- In general, the observation that question-based tasks are much more likely to be answered correctly than other formats of tasks is really interesting.",
            "1": "This is exactly the sort of quantitative/qualitative evaluation of benchmark datasets that the field needs more of: we often take benchmark datasets for granted, and even though we know that they're flawed in various ways, we still use them to define SOTA.",
            "2": "- Similarly, thinking about what sorts of text features and distributions work \"well\" with LLMs  (e.g., formatting a task as a natural language question rather than templating it in less natural ways) is often overlooked, even though it has significant impact on the accuracy.",
            "3": "- The error analysis section in the appendix is good-- much more useful for future work than just presenting a raw accuracy number.",
            "4": "Weaknesses:\n- My main concern is that I'm not sure this is enough for a full paper.",
            "5": "This is a useful analysis and prompt engineering strategy, but I would expect either a deeper analysis of *why* formulating things as Q/A works so much better (e.g., analysis of the training data), or \n- I'm confused about the question() prompt.",
            "6": "I thought these contained \"task-agnostic examples of how to transform statements to various questions\", but it seems like the format is not the same for all tasks?",
            "7": "(Appendix H)"
        }
    },
    "MtGmCCPJD-": {
        "hhWb5DvQ_i_": {
            "0": "Strengths:\n- Addresses an important and novel area of good prompt generation for LLM tasks\n- Approach does not require access to the weights of LLM\n- Suggests and implements prompt generator that uses information from the whole repository.",
            "1": "The prompt generator also uses repository level prompt \"proposals\" (rules/suggestions).",
            "2": "- Using generated prompts significantly improves Codex results\n\nWeaknesses:\n\n- It is not clear whether prompt proposals are really per-repository.",
            "3": "It seems that they will be pretty universal and should not vary much.",
            "4": "So the value of repository-specific prompt proposals is not really established or proven.",
            "5": "This is a minor issue though."
        },
        "ddhYN3Isbv": {
            "0": "Strengths:\n\n- A novel way of generating prompts.",
            "1": "- Extensive experiments.",
            "2": "- RLPG is efficient for both training and inference.",
            "3": "Weaknesses:\n\n- The paper is better for a software engineering/programming language conference.",
            "4": "- Only the structure of the repository and the context from other relevant files are considered in the prompt proposals."
        },
        "-ksgVN5wz7R": {
            "0": "Strengths:\n\n(1) The idea of generating training labels for the correct contexts and training a classifier to predict what the correct contexts should be is novel and interesting\n\n(2) They investigate multiple possible baselines \n\nWeaknesses:\n\n(1) Overlap with pretraining data -- Github is not the only source of training data for Codex (https://openai.com/blog/openai-codex/ -- \"OpenAI Codex is a descendant of GPT-3; its training data contains both natural language and billions of lines of source code from publicly available sources, including code in public GitHub repositories\").",
            "1": "Thus it is very possible that Google Code -- which they use for their test data -- is part of the training data for Codex.",
            "2": "Furthermore, deduping based on just repo name match is highly imperfect.",
            "3": "A much better way would be file level deduping or suffix array based deduping.",
            "4": "Unless there's a better understanding of what the pretraining data consists of, the results might be invalid.",
            "5": "The authors could consider using a model like CodeGen for which the pretraining dataset is known.",
            "6": "Alternatively they could use code published after June 2021 (the training data cutoff for the Codex davinci-002 model), dedupe it against the code data available upto June 2021 and use that as their test data.",
            "7": "(2) The improvements over both right context as well as identifier usage baselines are modest.",
            "8": "(3) They don't explore how different prompt proposals could be combined with each other"
        },
        "bmtUB-Rhu_": {
            "0": "Strength:\n- The paper is well-written.",
            "1": "The method is well explained with examples.",
            "2": "Experiment results are extensive with analysis.",
            "3": "- The paper explores several variants on the prompt sources and prompt types, and made a nice figure to demonstrate which prompt source works the best, though only one is used in experiment at a time.",
            "4": "Weakness:\n- Taking the whole file from the whole import file seems unnecessarily large context.",
            "5": "Rather, if the import statement only imports one class or one function from the module, it makes sense to only consider the function implementation, rather than the whole file where the function resides.",
            "6": "This especially applies to 7) Method Names and Bodies prompt type.",
            "7": "- The paper only considers one prompt proposal, which is a large limitation of the paper.",
            "8": "Why don't the authors take top-k prompt proposals and put into context instead of just one?",
            "9": "Besides, I'm curious whether there is a better choice of prompt proposal, for example, intuitively the function names, docstrings, and variable names of the imported function could help inform the model the functionality of the imported function.",
            "10": "- It seems that, RLPG-H is more like classification, while RLPG-R is more like retrieval.",
            "11": "Would a lexical search method like BM25 could retrieve relevant prompts already compared?",
            "12": "That way no training for the PPC is needed.",
            "13": "And I would expect it works reasonably well."
        }
    },
    "FtOxgKe_Zg2": {
        "KFm3nzXn0m": {
            "0": "Pros:\n\nThe simplicity of this approach is a plus.",
            "1": "The avoidance of label overfitting due to FLIP is also a nice advantage with additional benefits on unseen labels.",
            "2": "Questions:\n- Any additional thoughts on why unlikelihood training is crucial for the success of FLIPPED?",
            "3": "Cons:\n\n- It is not surprising that the meta training done will make 3B model outperform larger models.",
            "4": "The statement that the model performs better compared to 175 or 540B models do not mean much and such statement should be avoided or with caveats mentioned explicitly.",
            "5": "To compare with the larger models, it would be good to see the few-shot results without meta training.",
            "6": "Or is it the case that FLIPPED does not work at all without meta training?",
            "7": "- In approach makes sense, however, I still question the universality of this approach.",
            "8": "The free-form generation of label being one.",
            "9": "- Another strong baseline for tasks with unseen labels is to add label explanation in the instructions.",
            "10": "- Performance gain is observed for some datasets but not overwhelmingly consistent."
        },
        "l6hYVQHjAw9": {
            "0": "### Strength\nComputing the conditional probability of instruction given the concatenation of the input and label has led to strong zero-shot generalization performance.",
            "1": "It is mentioned that this is due to the model’s better generalization to labels that it has not seen before (labels that have different surface form, but similar meaning).",
            "2": "### Weaknesses\nAs the authors mention these as well, their proposed training method is limited to tasks which have label options (vs. free-form generation).",
            "3": "This would limit the approach in both training and inference/evaluation.",
            "4": "It is also not always the case that one could have a task instruction that is easily separable from the input instance."
        },
        "zeXfj7NQLH": {
            "0": "### Strengths\n\n1.",
            "1": "The proposed method is novel and neat\n2.",
            "2": "The empirical results are strong demonstrated by a comprehensive set of experiments.",
            "3": "As a new way of instruction tuning, FLIPPED could be potentially very impactful given that it outperforms much larger models with much smaller training costs.",
            "4": "3.",
            "5": "The analysis is interesting and insightful, revealing that T0-like methods have difficulties generalizing to unseen label options while FLIPPED does a pretty good job.",
            "6": "4.",
            "7": "The paper is well-written.",
            "8": "### Weaknesses\n\nAs mentioned in the Limitation section, FLIPPED is only naturally applicable to classification tasks where the label space is limited, while DIRECT methods appear to be more flexible from this aspect.",
            "9": "### Suggestions\nWhen presenting the main results, I think the authors should clarify FLIPPED outperforms DIRECT on X out of X datasets.",
            "10": "The gains are actually not very consistent in the Tables and the mean accuracy does not tell the full story."
        }
    },
    "VTYvxbr5E-A": {
        "Kvh0tRdMV4S": {
            "0": "A strength of the paper is that it tackles a non-trivial problem by combining recent ideas from different disciplines (e.g., language games, speaker/listener communication architectures, contrastive representation learning, differentiable computer graphics…).",
            "1": "The proposed framework is well-motivated, and the work stimulates further thinking.",
            "2": "At the same time, however, I see several weaknesses that might downplay the significance of the work:\n- Besides an increase in ecological / cognitive realism, it is unclear what could be the advantage of using motor primitives to create utterances in the graphical space, rather than directly optimizing the continuous graphical representation (as done in previous work).",
            "3": "Introducing a “differentiable motor system” might be relevant to better understand how sensory-motor constraints shape our ability to create written symbols, but this aspect has not been investigated in the present work.",
            "4": "- The authors also argue that a possible advantage of exploiting a drawing framework is to increase the interpretability of the emerging lexicon; however, also this aspect has not been emphasized in the simulations (and, in fact, the emergent signs appear quite arbitrary).",
            "5": "- It is not clear what is the relationship between the complexity of the concept space (e.g., similarity between objects and/or number of different objects to represent) and the emerging graphical conventions; further analyses would be needed to clarify this important aspect.",
            "6": "- What is the role of the dimensionality of the graphical space in the emerging lexicon?",
            "7": "I guess this parameter might have a major impact on the type of signs that could emerge, but it seems that the dimensionality was arbitrarily chosen.",
            "8": "- From my understanding, the contrastive learning mechanism should (indirectly) promote an increase in similarity between the referent images and the generated utterances.",
            "9": "However, this does not seem to happen in practice.",
            "10": "Am I missing something?"
        },
        "v-cdBHoDNx": {
            "0": "Strengths:\n* The proposed approach addresses an important and timely problem of agents learning to generate a shared language under realistic sensory-motor constraints.",
            "1": "As discussed in the paper, several approaches have shown promising results without such constraints, but these are not realistic models of human language development because they lack them.",
            "2": "* The proposed problem formulation and framework appear to be well suited to evaluating this problem.",
            "3": "They are simple enough to be tractable, but sophisticated enough to capture the important aspects of the problem.",
            "4": "* The proposed metrics seem reasonable in measuring performance\n* The proposed baseline shows promising results for coherence, but not compositionality.",
            "5": "It shows that solutions to the task are possible and that the metrics can capture the performance of solutions.",
            "6": "* The paper is clearly written and explained.",
            "7": "Weaknesses:\n* The abstract states, \"We show that our method allows for the emergence of a shared, graphical language with compositional properties.\"",
            "8": "I'm not necessarily convinced that this is true.",
            "9": "The proposed solution does not seem to include much in the way of compositionality.",
            "10": "The proposed metrics seem to allow for compositionality, but it is difficult to judge the extent to which they would successfully identify a compositional language if one developed.",
            "11": "This statement also misled me into thinking that the proposed solution was compositional, although on re-reading, it does not actually state this."
        },
        "m9JH13ebqAo": {
            "0": "# Strengths\n- Exploring compositionality using an automatic topographic metric is an interesting idea.",
            "1": "It would be nice to see what this metric gives for real world ideograms/pictograms to get a sense of its trustworthiness and interpretability.",
            "2": "- The continuous setting is a very nice departure from the typical setup\n\n# Weaknesses\n- The setting is limited.",
            "3": "In the single-target case, the alphabet has 5 symbols.",
            "4": "In the joint-target case, there are 5 choose 2 = 10 symbols.",
            "5": "- Studying compositionality in this setting is thus limited to exploring how conjunctive symbols may be encoded, as opposed to studying negation, disjunction, adjectives, adverbs, hierarchy, etc.",
            "6": "- In this work, compositionality is studied by looking at the form of produced symbols.",
            "7": "For instance, to study the compound symbol $u(r_{ij})$, the authors use a topographic score to compare the compound symbol to the corresponding individual constituent symbols.",
            "8": "However, there are many ways for a writing system to distinguish between semantics without dramatically distinguishing between forms and vice versa.",
            "9": "It would make more sense to do this type of analysis in terms of the symbols decodability.",
            "10": "Look at what sort of mistakes a decoding model makes.",
            "11": "If the symbol $u(r_{ij})$ only encodes the joint symbol, and nothing about the constituent pieces, then we would expect no correlation among the incorrectly decoded symbols.",
            "12": "But if compositionality is employed, we would expect to see predictions of the form $u(r_{ik})$ and $u(r_{ki})$ at higher frequency.",
            "13": "- The emergent language is not conclusively shown to be compositional (section 4) using the proposed topographic measure\n- I don't think the setting can be rightly called a \"language game\" in which the speaker and listener are jointly learning to communicate.",
            "14": "From section 3, pgs.",
            "15": "5 and 6, as best I can tell, the listener's loss is directly optimized to learn the association between the ground truth referent and the utterance.",
            "16": "Please correct me if I'm wrong (see clarification question in section below).",
            "17": "I believe the correct thing to do would be for the listener to learn an association between the predicted referent and the utterance.",
            "18": "As it stands, this is information that is typically not available to the listener during the language game"
        },
        "J-tx8Npdy1g": {
            "0": "### Strengths\n- (major) The paper presents a new, well-formulated emergent language environment and learning method.",
            "1": "- (minor) The experiments give an adequate characterization of the empirical behavior of the system.",
            "2": "### Weaknesses\n- (major) The contributions of the paper is introducing a new environment, yet this environment is not strongly motivated.",
            "3": "Simply differing from previous work is not motivation enough.",
            "4": "- (major) The field of emergent language does not stand to benefit that much from new environments if they do not address a relevant issue in the field."
        },
        "zd6Z1AFEoT": {
            "0": "\n*Strengths:*\n- The experiments are well designed (one-hot vs visual-shared vs visual-unshared).",
            "1": "This difference in perspective between the speaker and listener is a nice addition to this game.",
            "2": "- In the main text there is a balanced set of conclusions around compositionality which match the evidence: that the presence/absence of compositionality in the learned language is difficult to assess and conclude anything about.",
            "3": "However (see weaknesses) the abstract makes a different claim.",
            "4": "Weaknesses:\n\n- Despite the lack of clear evidence for compositionality in the main text, the abstract claims in the final sentence “we show that our method allows the emergence of a shared, graphical language with compositional properties”.",
            "5": "This claim is unsubstantiated and should be removed.",
            "6": "- It wasn’t clear to me how the drawn image is actually perceived by the listener.",
            "7": "Is there a CNN in here somewhere to instantiate this perception, that I am missing?",
            "8": "If the listener’s perception happens instead in the action space of the speaker then is it really a continuous signal?",
            "9": "The perception of the image by the listener needs to be clarified in the text.",
            "10": "- Compositionality is a hypothesis which is generally difficult to falsify empirically.",
            "11": "It is not clear what data would have yielded a clear compositional vs not-compositional result either way.",
            "12": "It is therefore not clear what this section of the paper on measuring compositionality contributes to the literature.",
            "13": "- Figure 4 is a bit hard to parse as it has multiple axes going on at the same time.",
            "14": "These results would be clearer if there was another way to present them."
        }
    },
    "hQwb-lbM6EL": {
        "evVp_0hs12": {
            "0": "Pros:\n\nThis paper shows that a simple method works.",
            "1": "Cons:\n\nThere is no baseline against the traditional left to right approach.",
            "2": "That is, with a given amount of data / compute this work uses, what would be the performance if we use these resources for left to right completion alone?",
            "3": "This is important because the amount of data that the paper uses as well as the training resources are slightly different from other papers, therefore, it would be good to see how much this amount of data/compute yield in terms of left to right completion.",
            "4": "Note that this could be different from the left-to-right performance that is obtained from the infilling method proposed.",
            "5": "That goal here would be to compare if this approach results in performance drop due to infilling or not, and if so how much.",
            "6": "A similar work by Bavarian 2022 shows that with a similar approach but only with 1 infilling spot, there seems to be no degradation, but this work is sufficiently different that it is not clear if the results by Bavarian 2022 also applies here."
        },
        "gKGjCGaCmQ": {
            "0": "The paper is well written and easy to read.",
            "1": "The approach described tackles fundamental challenges in autoregressive generation by training  models that are capable of filling the masked regions.",
            "2": "This ability is necessary for tasks such return type prediction and doc string generation where the output depends on both left and right context.",
            "3": "The experimental results are also encouraging as for various tasks shown, the model is able to perform better with less model size (e.g., compared to code-davinci-001).",
            "4": "The paper, however, does not discuss full code generation as it focuses primarily on infilling experiments, so its competitiveness on more challenging tasks is not known.",
            "5": "With the ability of infill and the original motivation that \"Code is seldom written in a single left-to-right pass and is instead repeatedly edited and refined.",
            "6": "\", I'd be very interested to see how the model performs on full code generation as well as devising an ability to detect and re-write portions of the code when solving those tasks."
        },
        "nQ3roIgNaV": {
            "0": "Strength:\n- The paper is well-written.",
            "1": "The method is well explained with examples.",
            "2": "Experiment results are extensive with analysis.",
            "3": "- The proposed method is a simple but effective masking objective.",
            "4": "Zero-shot performance demonstrates the effectiveness for infilling line completion task, as well as other related prediction tasks.",
            "5": "Weakness:\n- From the main text, I cannot infer whether the training is done 100% with mask infilling or there are some probability that normal left-to-right data is used for training without any masking.",
            "6": "If it is 100% mask infilling, it seems surprising to me that left-to-right is not affected at all.",
            "7": "I would expect normal left-to-right data exist in training, like the concurrent work fill-in-the-middle (FIM) training (Bavarian et al., 2022).",
            "8": "- Some training details seem missing, for example, how many training tokens and number of iterations the model has gone through during the training process.",
            "9": "- Though there is an <EOM> token indicating the end of generation, there is possibility that the generated code after <MASK:0> will contain overlapping content as the actual right context.",
            "10": "Did you see any such issue exist?",
            "11": "How do you resolve such issue?"
        },
        "xKRUnqBJkc": {
            "0": "Strengths \nA really good paper\nThe idea is clever, simple and straightforward.",
            "1": "It provides a functionality that general GPT-like or full transformer models don’t.",
            "2": "Experimentation seems appropriate.",
            "3": "Authors make a great effort not sticking with standard benchmarks which might not be the ideal scenario for InCoder\n\nWeaknesses\nThe training regime comes with a cost and the Left to right generation, specifically on Table 11"
        }
    },
    "C8by2OoY6Y2": {
        "DNErHMbcslS": {
            "0": "**Strengths**\n\n- The paper is meaningful in that it shows the combination of dense and hybrid retrieval with an iterative query-expansion method is robust on both in-domain and zero-shot retrieval.",
            "1": "**Weaknesses**\n\n- The proposed method is a combination of the methods of previous works [1] and [2], which limits the technical novelty of the paper.",
            "2": "- While the authors emphasize that the proposed system reranks one order of magnitude smaller number of documents compared to the state-of-the-art [1], pointing out that it is time-consuming to cross-encoder reranking of 1000 documents as in [1], it is unclear whether this leads to actual latency improvement of the proposed system because the authors do not report the end-to-end retrieval latency.",
            "3": "Since the proposed system uses iterative query refinement (five times) which generates the augmented query based on the previous top-ranked documents, the latency of this step would not be negligible.",
            "4": "The authors should report the actual latency in order to show the superiority of the proposed system in terms of time cost.",
            "5": "- While the proposed method achieves near-state-of-the-art zero-shot (BEIR) retrieval performance while achieving much higher in-domain (MS MARCO) retrieval performance, it uses a much more complicated pipeline approach for both training and inference than the state-of-the-art method.",
            "6": "The creation of the training data for T5-Q using Rocchio Session would be time-consuming considering that it requires calculating nDCG on multiple (M=100) candidate augmented queries to generate one label for a query.",
            "7": "Considering this, the gain in retrieval performance seems insufficient to claim a significant advantage over the method of [1]."
        },
        "VSrBP9LyFe9": {
            "0": "Strengths:\n\n1.",
            "1": "The proposed method sounds reasonable.",
            "2": "2.",
            "3": "The proposed method achieved SOTA performance on both zero-shot and in-domain evaluations and keeps the number of documents to rescore low.",
            "4": "3.",
            "5": "The paper is easy to follow.",
            "6": "Weaknesses:\n\n1.",
            "7": "Considering Adolphs et al., 2022, the contribution of the hybrid retrieval environment appears too marginal, especially the simple combination of sparse retrieval and dense retrieval results, which has been explored by many works.",
            "8": "[1] Karpukhin, Vladimir, et al.",
            "9": "\"Dense Passage Retrieval for Open-Domain Question Answering.\"",
            "10": "EMNLP.",
            "11": "2020.",
            "12": "[2] Sidiropoulos, Georgios, et al.",
            "13": "\"Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering.\"",
            "14": "Proceedings of the Second Workshop on Simple and Efficient Natural Language Processing.",
            "15": "2021.",
            "16": "[3] Gangi Reddy, Revanth, et al.",
            "17": "\"Synthetic Target Domain Supervision for Open Retrieval QA.\"",
            "18": "SIGIR.",
            "19": "2021.",
            "20": "[4] Chen, Tao, et al.",
            "21": "\"Out-of-Domain Semantics to the Rescue!",
            "22": "Zero-Shot Hybrid Retrieval Models.\"",
            "23": "ECIR.",
            "24": "Springer, Cham, 2022.",
            "25": "2.",
            "26": "There are many related works on iterative retrieval in the open-domain QA that have not been mentioned and compared, such as:\n\n  [1] Guo, Xiaoxiao, et al.",
            "27": "\"Learning to query, reason, and answer questions on ambiguous texts.\"",
            "28": "ICLR.",
            "29": "2016.",
            "30": "[2] Qi, Peng, et al.",
            "31": "\"Answering Complex Open-domain Questions Through Iterative Query Generation.\"",
            "32": "EMNLP.",
            "33": "2019.",
            "34": "[3] Qi, Peng, et al.",
            "35": "\"Answering Open-Domain Questions of Varying Reasoning Steps from Text.\"",
            "36": "EMNLP.",
            "37": "2021.",
            "38": "[4] Zhu, Yunchang, et al.",
            "39": "\"Adaptive Information Seeking for Open-Domain Question Answering.\"",
            "40": "EMNLP.",
            "41": "2021.",
            "42": "[5] Nakano, Reiichiro, et al.",
            "43": "\"WebGPT: Browser-assisted question-answering with human feedback.\"",
            "44": "arXiv preprint arXiv:2112.09332 (2021).",
            "45": "3.",
            "46": "Some comparisons with the baseline experimental results do not seem to be fair, especially in terms of model size, and it is recommended to provide detailed comparisons of parametric quantities.",
            "47": "Besides, in Fig.",
            "48": "2(b), as far as I know, ColBERTv2 and SPLADE++ are dense and sparse retrieval, respectively, not hybrid retrieval, and in addition, neither of them has re-ranking, so it is not fair to compare them with HRE.",
            "49": "Also, in Table 1, although I believe that iterative agents are better than single-step retrieval environments, the retrieval depth used by the environments is too small to adequately account for this.",
            "50": "It is recommended that the retrieval depth used by the environment be set to 5*k or the average number of doc reranked of the agents."
        },
        "3yldSnINoyn": {
            "0": "## Strength\n\nThe authors present a finding that using the combination of dense and sparse agents in a retrieve-then-rerank setting leads to much better performance than a single agent (with fewer than 100 retrieved documents).",
            "1": "The final model (hybrid search environment + query refinement) leads to a state-of-the-art model.",
            "2": "The ablation study and analysis are comprehensive, showing the strength of the proposed hybrid environment.",
            "3": "## Weakness\n\nIf my understanding is correct, the main contribution of the paper is to propose using sparse+dense retrievers +reranking at the first step.",
            "4": "Though I don’t think previous works have reported this before, either combing sparse and dense retrievers [1] or using rerankers is not new.",
            "5": "The authors also sell the hybrid environment as it does not need to retrieve hundreds or thousands of documents for reranking, compared to state-of-the-art models like MonoT5.",
            "6": "However, it is not fair to only compare the document numbers — first, sparse and dense retrievers have very different efficiencies; second, the proposed model has a multi-step question refinement procedure, which makes it much slower.",
            "7": "To truly show the proposed model’s strength, the authors should really show the retrieval time per query of each model.",
            "8": "[1] Ma et al., 2021.",
            "9": "A Replication Study of Dense Passage Retriever."
        }
    },
    "69MODRAL5u8": {
        "6g96r5LRTFd": {
            "0": "**Strength**\n\nAnalyzing the hardness of equivalence decidability can be an interesting perspective to understand the learning capacity of neural network models, especially for programming language tasks.",
            "1": "**Weakness**\n1.",
            "2": "The theory is ad hoc:\nThe (semantic) equivalence problem is a classical problem and has been studied for decades for different formal systems, for example, automata, regular expressions, and pushdown systems.",
            "3": "They are often at least PSPACE-hard.",
            "4": "These are naturally encountered formal systems.",
            "5": "In this paper, the authors impose assumptions like the (denotational) semantics is from a finite set, the input space is finite.",
            "6": "Those assumptions in general do not hold.",
            "7": "2.",
            "8": "The techniques are elementary:\nThe techniques used to develop the theory are elementary.",
            "9": "With the finiteness and some efficient procedure assumptions, the proofs are usually direct manipulations of definitions and assumptions.",
            "10": "It does not seem that there are useful theoretical or mathematical techniques.",
            "11": "3.",
            "12": "The evaluation is rough:\nThe evaluations are on two toy languages defined in this paper, and the input space size is at most 11.",
            "13": "It is conceivable that modular addition is easier than bitvector arithmetic to learn because the latter is a direct extension of the former.",
            "14": "It is inconclusive to understand model's capacity to learn the semantics just based on this toy evaluation."
        },
        "0PGO1XDduu0": {
            "0": "Strengths:\n\n+ The notion of equivalence-preserving program embedding is new, theoretically formulated, and proven to be satisfied by a simple arithmetic language and unsatisfied by a bit-vector language.",
            "1": "+ The usefulness of equivalence-preserving program embedding is experimentally demonstrated.",
            "2": "+ The documentation is well written and easy to follow.",
            "3": "Weaknesses:\n\n- Little languages have equivalence-preserving program embedding functions.",
            "4": "Theoretically, a tractably embeddable language (i.e., one with an equivalence-preserving embedding function) has a means to determine the equivalence of two programs.",
            "5": "It means that no Turing-complete language is tractably embeddable.",
            "6": "Furthermore, although recognizing the limitation of an approach is crucial in general, even the simple bit-vector language does not have such a function.",
            "7": "Therefore, I am concerned about the practicality of the proposed approach in its current status.",
            "8": "Considering the strictness of equivalence-preserving program embedding, I am not surprised that a machine learning model can learn an embedding for a tractably embeddable language even when the same model cannot learn an embedding for a language that is not tractably embeddable.",
            "9": "- As a minor point, the theory of the paper seems to assume the input space ($I$) is finite, but, in general, one can consider programs with an infinite input space (like list-processing programs)."
        },
        "154Y8MzPwS0": {
            "0": "(+) Code semantics is an important program property, and proposing a theoretical framework to incorporate semantics to embedding is important.",
            "1": "(+) The theoretical foundation is good.",
            "2": "(-) The demonstration is shown on small tiny problems.",
            "3": "(-) I am not sure any general-purpose language can be tractably embedded.",
            "4": "It is not clear how such a definition can be extended to such languages.",
            "5": "(-) If the intention is to use tractable embedding to domain-specific language, I would encourage the authors to show some convincing scenarios."
        },
        "pnPwn-IEoH": {
            "0": "Strength:\n+ Describes an important property of program embeddings: they should remain invariant to semantic-preserving transformations.",
            "1": "+ First theoretical definition of equivalence-preserving program embedding problem.",
            "2": "The paper provides formal conditions under which the programming languages can be tractably embedded.",
            "3": "Weaknesses: \n\n- The empirical study is not convincing by only evaluating BERT-Tiny.",
            "4": "Numerous neural architectures have been used to model programs, e.g., large language models, graph neural networks, etc.",
            "5": "Can the proposed theory help explain some of the successes of one architecture over others?",
            "6": "Can the theory guide how to develop new models to learn program representations?",
            "7": "- The practical implication of this paper is unclear.",
            "8": "While the authors describe two applications (Section 2), these applications often deal with common programming languages that are intractable, e.g., code clones across binary code for vulnerability detection.",
            "9": "Can the proposed theory help explain if the same code modeling task for some languages is strictly easier than the others?",
            "10": "The theory can be more practically useful if it can be extended to quantify the intractability level so the resulting embeddings' error can be bounded or compared.",
            "11": "- Figure 1: unclear why certain input sizes have their accuracy going down, even though they have reached 100% in the earlier epochs.",
            "12": "- There is no discussion on why larger input space sizes need a smaller number of epochs to converge on the tractable language, which contradicts the observation that losses increase monotonically with input space sizes on the intractable language.",
            "13": "- Extensive results and discussions are put in the Appendix, costing great effort in going back and forth.",
            "14": "- The paper uses code clone detection and semantic labeling to motivate their theory, but the theory focuses on characterizing language tractability.",
            "15": "Can the theory extend to cross-language clone detection, e.g., one language is tractable, but the other language is not?"
        }
    },
    "hT4qiZK0Iv": {
        "bjQk9sCzDEc": {
            "0": "Strengths:\n\nThe paper is written clearly and is easy to follow.",
            "1": "The proposed techniques themselves are simple yet effective for getting better discrete representations from speech.",
            "2": "Evaluation is done on a variety of tasks and a significant improvement is achieved on all of them.",
            "3": "Weaknesses:\n\nMy main concern about this paper is how the premise is set.",
            "4": "The main premise in this paper seems to be that spoken language modeling is sensitive to noise and discretized speech representations are not robust to it.",
            "5": "My question is how often is noise a problem in speech generation/synthesis for downstream tasks like end-to-end speech translation.",
            "6": "Maybe I am missing something but it seems that speech processing for spoken LM is not subject to noise from outside as it processes its own generated speech and not human speech.",
            "7": "Also, was there a source of noise in tasks that involve autoregressive generation like E2E S2S translation?",
            "8": "Maybe I am missing something here, but it seems that the UED score analysis does not add anything noteworthy to the paper.",
            "9": "I understand that it shows how a discrete representation of speech may change in the presence of noise but it’s not very surprising that it changes as representations always change in the presence of noise.",
            "10": "The question is how much is the downstream task affected by these noises.",
            "11": "There are no experiments which show the effect of artificial noise on downstream tasks but only UED is used to show the effect which is rather obvious.",
            "12": "The fact that UED improves after a teacher-student like training with CTC loss is also not surprising.",
            "13": "If a UED score is high, does it necessarily mean that one representation is better than the other?"
        },
        "NUPJMqDkrDS": {
            "0": "\nStrength:\n\n- Tests on time-stretch, pitch-shift, additive-noise, and reverberation and how they affect the learned representation.",
            "1": "- Pseudo-labeling using CTC, and an iterative variant improve speech-to-speech translation.",
            "2": "Weaknesses:\n\n- The paper claims to study the self-supervised representation in general for spoken language modeling.",
            "3": "However, in the end it really only tests it for speech-to-speech translation.",
            "4": "This limits the scope of the paper.",
            "5": "I would have expected tests for other downstream tasks as well, to really get an understanding on the robustness of self-supervised representation, as the title says.",
            "6": "- The actual tests on robustness are very limited.",
            "7": "It just has a single experiment on speech-to-speech translation.",
            "8": "I would have expected more experiments to verify the robustness aspect.",
            "9": "Note that this is a separate weak point to the previous.",
            "10": "Here in this point, I specifically mean that the robustness experiments are too limited.",
            "11": "Of course, both are related.",
            "12": "When experiments are done on other tasks as well, this would automatically extend also the actual tests on robustness.",
            "13": "But there are potential other ways to extend such tests as well."
        },
        "GYOjRevjm5v": {
            "0": "Strength: the approach of using augmentation robustness as an objective for improving speech representation in self-supervised learning is well-motivated.",
            "1": "Weaknesses: both the noisy-student learning and the quantization distillation are existing approaches, and the idea of correlating semantics with noise robustness is also well known.",
            "2": "This makes the novelty of the work limited.",
            "3": "The experiments on downstream tasks are also insufficient to demonstrate the benefits of the approach."
        },
        "8ibOlMck3U-": {
            "0": "Strength: Overall, this propose approach is technical sound.",
            "1": "Experiments and analysis are carefully designed for validation, including several widely used self-supervised learning representations.",
            "2": "Weakness: This proposed metric and approach are mostly based on existing technologies (Levenshtein distance, MLP-based module, CTC loss etc).",
            "3": "Also I think more details are needed for explaining design and results.",
            "4": "(See questions in the summary section below)."
        }
    },
    "8taH4yjN62m": {
        "4qODQ5-U5G": {
            "0": "\nStrengths:\n- I find the question they are attempting to ask about the role of position encodings to be an interesting one.",
            "1": "- I have never seen a clear discussion of the symmetry property, although it is evident in attention heat maps in every paper on transformers.",
            "2": "- More importantly, I have never seen a discussion of the potential drawbacks of a symmetry bias.",
            "3": "It’s not something that I had considered before, and it makes me curious about human cognition: are we better able to handle symmetric word swaps than random word swaps, for example?",
            "4": "I expect not.",
            "5": "This is a clear example of cognitively implausible behavior at the position encoding level, although to be fair nobody is claiming any kind of cognitive plausibility in position encoding.",
            "6": "I would like to see the focus on symmetry expanded.",
            "7": "- I was impressed by the incorporation of research in psycholinguistics to discuss word swaps.",
            "8": "I would actually have liked to see a longer discussion of the implications of the different studies, in terms of local and more distant word swaps.",
            "9": "- In future work or versions of this paper, I would be extremely interested to see the symmetry and locality biases treated separately.",
            "10": "- The new method of Sequence Combination as an alternative to adding together position and contextual encodings appears to work well.",
            "11": "Weaknesses:\n- My main problem with this paper is that I do not find the experiments to be particularly convincing evidence of the properties that they discuss.",
            "12": "In particular, they use a new encoding scheme to artificially impose strict symmetry and locality, and find that performance is somewhat damaged but not too much.",
            "13": "I don’t know what result they would consider to be evidence against the importance of symmetry and locality, perhaps some very extreme blow to performance?",
            "14": "In general, I don’t think that the performance of these simplistic position encodings give any particular evidence as to whether their biases are *also* the reason why the original encoding scheme worked.",
            "15": "- I would have liked to see more variety in the position encoding schemes being used, rather than using only BERT’s default position encoding.",
            "16": "- When you set the contextual or position encoding to zero, you create a significant distribution shift in representations.",
            "17": "Perhaps taking an average would be better?",
            "18": "In general, I’m skeptical about these kinds of causal interventions on a fully trained model.",
            "19": "You are changing the expected norm and representational geometry, and that might change to different degrees depending on which component you are removing.",
            "20": "- They seem to be arguing that symmetry in the attention weights means that you can swap the position of different tokens without changing the meaning of the sentence, but that’s not clear to me?",
            "21": "I feel like I need an explanation that either gives the mathematical process or diagrams the reason why this would be the effect.",
            "22": "- I would like to see for learned position encodings whether symmetry is a learned property.",
            "23": "- The experiments on simplistic position encodings bear a significant resemblance to Alibi, and I’m not sure what they contribute over that scheme in terms of understanding https://arxiv.org/pdf/2108.12409.pdf\n- There are nonlinear interactions between the position encodings and the context.",
            "24": "Currently they consider these interactions to be part of the position encoding, but I’m not convinced that that’s appropriate.",
            "25": "It’s possible that some of the bias they are talking about is due to the isolated role of position $\\frac{(p_iW^Q)(p_jW^K)^T}{\\sqrt{d}}$ so I think that experiments should separately consider what happens when interactions are included or removed.",
            "26": "- When you measure the effect of removal, do you just straightforwardly remove it or do you take an average value or do you retrain the network to work without the encoding in question?",
            "27": "There is a big difference between these strategies because you are creating a very large domain shift by removing a component of the representation, but that doesn’t necessarily mean that the information of structure within that component is as important as it seems based on changes effected by the wholesale removal of a component.",
            "28": "- Maybe you should be considering something like shapley values.",
            "29": "- There should be an explicit comparison between their word swap probe and other existing methods for behaviorally testing the role of word order.",
            "30": "Currently I’m not clear on what the new contributions are of this particular experiment.",
            "31": "- Do you have a metric for measuring symmetry?",
            "32": "That would be better than all of the figures.",
            "33": "Even something simple like the matrix norm of the difference between the original attention matrix and its transpose.",
            "34": "- There is a lack of detail about the implementation of sequence combination, although it seems like it should be one of these strongest points in the paper.",
            "35": "Minor/references:\n- This paper needs extensive editing for typos (“encoings”, mismatched subject-object number, etc).",
            "36": "- Probably should add a note as to why autoregressive models aren’t relevant to position encodings research http://arxiv.org/abs/2203.16634\n- Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context https://arxiv.org/pdf/1805.04623.pdf\n- When you describe the symmetry property, make sure to clarify the axis of symmetry.",
            "37": "Even with the example given, which initially just confused me, it took me a while to understand that this was referring to equidistant tokens having the same weight rather than the same weight applying both to both key-query and query-key directions.",
            "38": "- “BEET-A∗-s” I don’t understand what this string means.",
            "39": "- “we adopt widely used 10 probing tasks” — make sure that you actually cite each of the tasks separately, rather than only the benchmark paper that aggregates them.",
            "40": "- “For surface tasks, the surface knowledge is stored more in bottom layer …” I find this a confusing sentence\n- Don’t start a sentence with a variable name if you can help it, as in the paragraph before equation 10 (https://jmlr.csail.mit.edu/reviewing-papers/knuth_mathematical_writing.pdf)"
        },
        "3nHZVo4UOK": {
            "0": "Strength:\n- Some probing experiments are novel and the findings are interesting\n- The proposed methods get good results\n\nWeaknesses:\n- Many details are missed, which makes parts of this paper hard to be understood.",
            "1": "1) what are the learnable form of equations 12 and 13?",
            "2": "A random initialized matrix?",
            "3": "2) What is PA(X)?",
            "4": "Multiply X with the PA matrix?",
            "5": "3) The results of STS and SICK-R seem much better than RoBERTa-large.",
            "6": "What is the metric of STS and SICK-R?",
            "7": "Spearman or Pearson?",
            "8": "STS has 12-16 and STS-B, which one is used in this paper?",
            "9": "4):\n- The proposed method is similar to AliBI, in terms of adding a bias mask to the attention scores.",
            "10": "Is there any discussion of the difference or which one is better?",
            "11": "- The models are all BERT-base trained with 600K steps.",
            "12": "Experimenting with another model can help to support the claims of this paper.",
            "13": "For example, show the BERT-large/RoBERTa can also be improved."
        },
        "kKDukJISkUd": {
            "0": "Strength\n- Comprehensive studies.",
            "1": "Weaknesses\n- There are too many important contents putting in the appendix.",
            "2": "For example, the equation of the proposed encodings should be put in the main context.",
            "3": "- Maybe I misunderstood.",
            "4": "But why the symmetry is inconsistent with the examples “a man playing an electric guitar on stage” is totally different from “an electric guitar playing a man on stage”?",
            "5": "I feel like the symmetry just implies that the attention of the i-th word to the j-th word is almost equally important to the attention of the j-th word and the i-th word.",
            "6": "From my point of view, the locality does capture the meaning change in this case.",
            "7": "- In the original Transformer paper, they also design the positional encodings based on sine and cosine.",
            "8": "It's satisfied the locality and symmetry properties as well and is reported to have similar performance to the learned positional encodings.",
            "9": "So I am not super excited about the experimental results.",
            "10": "Question\n- It's a bit interesting that handcrafted + learnable is better than handcrafted and learnable separately.",
            "11": "Is it because handcrafted provides better initialization?",
            "12": "I suggest to explore this direction more."
        },
        "Fkn3FqP36zE": {
            "0": "In terms of strenghs\n- The paper has a very throughout analysis of different models and positional encodings\n- It proposes several contributions, including a new probing task and several positional encoding methods.",
            "1": "My main problem with this paper at the moment is that it could be much better written: The overall narrative of the paper is unpolished and it’s hard at first to understand the contributions of the paper.",
            "2": "I had to go multiple times back-and-forward in this paper to understand what was new in it.",
            "3": "The introduction of two different positional encoding methods in different sections is confusing (even if one only serves the purpose of understanding the role of positional encodings).",
            "4": "A lot of attention/space is dedicated to locality and symmetry properties of positional encodings, which from my understanding, isn’t very novel and has been explored in previous work."
        }
    },
    "2EFQ_QlcPs8": {
        "OHOcSUaECJ": {
            "0": "Strengths: (1) novel perspective on unifying previous multi-vector document retrieval and build the sparsified end-to-end scheme on top of them.",
            "1": "(2) Good efficiency trade off on the sparsity side\n(3) Good results on the  BEIR benchmark\n\n\nWeakness: (1) entropy-regularized linear programming?",
            "2": "The paper does not explain why  entropy-regularization on the linear programming is a desired choice.",
            "3": "For enabling end-to-end training, a quadratic term would also work?",
            "4": "(2) The paper does not explain why end-to-end training in the  entropy-regularization is necessary.",
            "5": "During training, isn't the  model uses top-1 alignment where the only one document token is activated for each query token.",
            "6": "(3) As the sparsity of the training and test can be different, it is good to investigating optimal training sparsity.",
            "7": "(4) When training with top-1 alignment, the model looks similar to ColBERT except for the unary masking.",
            "8": "It is good to analyze how and why the  unary masking is beneficial"
        },
        "whKTBhKPc1": {
            "0": "Generally speaking, this paper puts forward a universal retrieval scheme, and achieves good results, the specific advantages are as follows:\n\n(1) The sparse alignment of multi-vector retrieval is a good solution to solve the retrieval effect and efficiency.",
            "1": "(2) The new proposed model in this paper has achieved better results than the previous work in many tasks on MSMARCO.",
            "2": "(3) The proposed model in this paper uses sparse alignment matrix to aggregate token-level similarity, where each element represents the alignment of a pair of tokens, which can develop different retrieval models in a unified way and identify the shortcomings of existing models.",
            "3": "However, there is a lack of unified experimental standards and ablation experiments in this paper.",
            "4": "So I also have a few doubts about this article:\n\n(1) This paper uses 6B T5-V1.1, but the previous baseline work only GTRxxl has the same size, while ColBERTv2 using multi-vector retrieval model has only 110m model size.",
            "5": "However, GTR is a single vector retrieval model, so there is no unified standard to show that the effect of the proposed model in this paper is better than the previous model.",
            "6": "(2) In this paper, similarity and alignment structures are proposed, but no ablation experiments have been carried out to prove the effectiveness of the improved model.",
            "7": "(3) This model still needs to calculate the similarity matrix for queries and documents, so the computational efficiency is not improved compared with other multi-vector retrieval models in the training stage."
        },
        "XVPa2Cl8yW": {
            "0": "\nStrengths:\n- Learning the alignement allows to improve results of already successful models such as ColBERT.",
            "1": "- Few-shot learning based on selecting the right alignment improve the results\n- Interesting sparsity regularizer with a target ratio (or number?",
            "2": "This is not really clear) of tokens kept for the index\n\nWeaknesses:\n- The alignement is not learned\n- The sparsity is not really learned since during indexing the ratio is different ($\\beta$ vs $\\alpha$) and more importantly it is fixed - why this discrepancy?",
            "3": "- Novelty is low (pruning has been proposed in ColBERTer)\n- The experimental comparisons lack rigor (compared models have 60x times less parameters, ColBERTer is not included in the experiments, some models could have been tested with the alignement adaptation)\n- No complexity analysis (comparing it to ColBERTv2 or ColBERTer)"
        },
        "1ziDHVa6PY": {
            "0": "Strength\n1.",
            "1": "The authors proposed a new way to learn sparsified pairwise alignments between query and document tokens.",
            "2": "2.",
            "3": "The unary saliences can significantly reduce the document token representations minimal performance loss.",
            "4": "3.",
            "5": "The method can achieve good performance on BEIR benchmark under the zero-shot setting.",
            "6": "Weakness:\n1.",
            "7": "No analysis on retrieval speed and index space.",
            "8": "2.",
            "9": "The size of the datasets seem not large enough.",
            "10": "Most of the datasets have been pre-processed by some existing IR tools.",
            "11": "It would be great if the authors could build index from scratch and compare to the method of \"Dense Passage Retrieval for Open-Domain Question Answering\"."
        }
    },
    "TSqKS0lQQA6": {
        "7UylN_q7n4K": {
            "0": "Strengths:\n\n- The paper is based on a simple and effective idea and is executed well.",
            "1": "- The paper is accurately and clearly written.",
            "2": "- The performance is satisfactory.",
            "3": "Weaknesses :\n- I see a lot of similarities between the proposed method with [1].",
            "4": "If I am not mistaken, the auxiliary loss function prevents forgetting the general knowledge is the same as [1].",
            "5": "However, this paper's gradient projection approach and theoretical analyses are new.",
            "6": "While the authors limit their application to zero-shot learning, I believe the contributions of this paper hold in a general setting where some previous knowledge has to be preserved for training on a new task.",
            "7": "A discussion on the differences with [1] and direct comparisons with their method would be interesting and strengthen the paper, in my opinion.",
            "8": "A quick experiment that can be done during the rebuttal is to show the performance of the proposed method without the gradient projection, i.e.",
            "9": "adding the KL loss to CoOp and optimizing with the standard SGD.",
            "10": "A similar experimental setup as [1] and director comparisons with them would be even more interesting.",
            "11": "[1] Zhizhong Li and Derek Hoiem, Learning without Forgetting, 2016"
        },
        "NGOsv4J0-U": {
            "0": "Strength:\n\n- The work addressed some key challenging in prompt engineering for vision-language models.",
            "1": "- The idea is computationally simple and empirically validated to bring superior performance.",
            "2": "Weakness:\n\n- The proof of generalization bound is not much informative.",
            "3": "It is a direct extension of the theoretical results in prior works (e.g.",
            "4": "Zhang and Ye's 2012 paper).",
            "5": "- More insights are required for the readers fully understanding the empirical superiority of the proposed idea.",
            "6": "In specific,  the \"general knowledge\" induced by standard zero-shot CLIP transfer does not provide ground truth.",
            "7": "The gradient-calculating rule as proposed in Eq.",
            "8": "4 is essentially a fusion of two kinds of cues: one is from zero-shot extension, and the other is data-driven.",
            "9": "The trick is to cleverly choose the way for the fusion.",
            "10": "In the practice of multi-source fusion, the final results tend to be improved given that all sources are informative and complementary to one another.",
            "11": "Section 4.5 provides some analysis on the failure case, which is unfortunately somewhat superficial."
        },
        "WRLpxuRRiT": {
            "0": "###STRENGTHS\n1.",
            "1": "Wide range of experiments\n\n### WEAKNESSES\n1.",
            "2": "Very incremental contribution\n- The delta over CoOP is very small.",
            "3": "Infact the method is a very simple extension of CoOP.",
            "4": "I don't know why the authors made a whole new name.",
            "5": "2.",
            "6": "Results not convincing\n- The reason is that the improvement over CoOP seems very negligible in more important datasets like ImageNet and Table2.",
            "7": "Can you aadd a table which shows results on individual datasets?",
            "8": "- Some tables have ProGrad and others have ProGrad++.",
            "9": "If ProGrad++ is also your method, add it into the method section.",
            "10": "- Standard deviation is missing.",
            "11": "So it is very difficult to draw any conclusion.",
            "12": "0.27 improvement on ViT-B in Table 2 can easily go away with multiple runs.",
            "13": "3.",
            "14": "Not properly motivated\n- The method does not have a sound technical motivation.",
            "15": "It seems like a heuristic.",
            "16": "- Phenomenon shown in Fig.2 is not enough.",
            "17": "It could be a cherry-picked exception.",
            "18": "- Starting of sec3.2 should motivate the challenge with previous methods.",
            "19": "However, it says that it has been discussed in Introduction.",
            "20": "Can you discuss it properly?",
            "21": "4.",
            "22": "Poor Writing\n- Although the method section is decently written, the introduction is hard to follow."
        },
        "wlx2neNTw7x": {
            "0": "**Strength:**\n- Paper is clearly written and organized.",
            "1": "- Theoretical justification and derivation are correct as far as I know unless other reviewers raise important concerns.",
            "2": "For me, this paper address the same question as [2,3] did in order to improve generalization.",
            "3": "I would suggest authors to elaborate these similar papers in their related work.",
            "4": "- The idea is novel in the context of soft-prompt tuning, but it has been already explored in multi-task learning and continual learning [1].",
            "5": "It would be even nice if authors discuss a bit more about this prior work or similar ones in the related work.",
            "6": "- Ablations and experiments are complete in the main body of the paper as well as the appendix part.",
            "7": "**Weakness:**\n\nAccording to my experience working with **CoOp** and **CoCoOp**, the two baselines of this paper, in CoCoOp work, all results are reported on **4 learnable tokens** initialized with \"A photo of a {class}\",  **16 shots** and **ViT/B-16 backbone** on three different random seeds for three different tasks: **base-to-new-generalization**, **cross-dataset transfer learning**, and **domain generalization**.",
            "8": "Regarding this information, I would appreciate if the authors answers following questions:\n\n1.",
            "9": "Do authors train all baseline models themselves or they adopt the results from the main paper?",
            "10": "2.",
            "11": "Are learnable prompts initialized with \"A photo of a {class}\" or they are trained from scratch?",
            "12": "3.",
            "13": "I would ask authors why the number of shots are different in tasks  **base-to-new-generalization** and **domain generalization** in Table 1 and 2.",
            "14": "Are there any specific reasons?",
            "15": "Can they provide the performance with same hyper-parameters?",
            "16": "I would suggest authors to be consistent with the baselines in terms of hyper-parameters to conclude a fair comparison.",
            "17": "To me, Table 1 and Table 2 looks a bit wired as you change the training hyper-parameters.",
            "18": "Maybe for 16 shots, CoCoOp performs better.",
            "19": "4.",
            "20": "I noticed that authors did not provide results for cross-dataset transfer learning (Table 2 of CoCoOp paper).",
            "21": "I would suggest to report these numbers as well since it makes the paper more complete.",
            "22": "5.",
            "23": "Regarding ProGrad++, where authors use the idea of prompt ensemble, would it be possible to clarify how the prompt design changes in terms of number of learnable tokens.",
            "24": "To me, since the input prompts changes, the length of learnable prompt would change accordingly and it is a bit unclear how many learnable parameters exist.",
            "25": "[1].",
            "26": "Farajtabar et al., Orthogonal Gradient Descent for Continual Learning, 2019\n\n[2].",
            "27": "Lu et al.",
            "28": "Prompt Distribution Learning, CVPR 2022\n\n[3].",
            "29": "Derakhshani et al., Variational Prompt Tuning Improves Generalization of Vision-Language Models, Arxiv 2022"
        },
        "sSm91GtNBY": {
            "0": "- Strength\n1.",
            "1": "The proposed method looks novel and makes much sense.",
            "2": "Using a generalizable prompt to regularize the learning of a domain-specific prompt is a simple and effective strategy to avoid overfitting in few-shot learning.",
            "3": "2.",
            "4": "The experiment is comprehensive.",
            "5": "It includes three aspects: standard few-shot image classification, domain generalization, and unseen class classification.",
            "6": "The comparison to KD (Table 4) and the cosine classifier (Table 5) directly support its claims that its regularized gradient direction is the key to improving the results.",
            "7": "- Weaknesses\n1.",
            "8": "The improvement of ProGrad looks marginally better and may be affected by the choice of hyperparameters.",
            "9": "What is the upper bound result this approach can get?",
            "10": "How about simulating the upper-bound case using many training data to get an optimized prompt instead of using the man-made prompt to create G_g?"
        }
    },
    "TqCHPi7xlV": {
        "caAXo_HPtJD": {
            "0": "**--- Strengths ---**\n\nNo particular strengths stood out to me when reviewing this paper.",
            "1": "**--- Weaknesses ---**\n\n**W1.",
            "2": "** The paper claims (e.g., in the abstract and the conclusion) to show that the proposed TTLM is a generalization of 2nd-order RNNs, RACs, and MI-RNNs.",
            "3": "The TTLM model takes the form given in Eq (2).",
            "4": "In order to say that TTLM generalizes another model, that model must be expressible in the form given in Eq (2).",
            "5": "However, according to Claim 4.1 and 4.2, in order to be able to express 2nd-order RNNs and MI-RNNs additional nonlinearities need to be inserted into the formula in Eq (2), therefore yielding a model which is *not* expressible as a TTLM (i.e., as in Eq (2)).",
            "6": "Therefore, it is *incorrect* to say that TTLM generalizes those models!",
            "7": "If TTLM truly generalized these models, there shouldn't be a need to further modify Eq (2).",
            "8": "This is a bit like saying that the set of linear functions (i.e., matrices) generalize functions $f : \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ of the form $f(x) = \\sigma(A x)$, where $A$ is a matrix $\\sigma$ is a non-linear functions.",
            "9": "**W2.",
            "10": "** The paper is full of typos, missing/redundant commas and periods, and notational inconsistencies that a careful proof reading should have caught; there are two inconsistencies already in the first sentence in Sec 1.",
            "11": "**W3.",
            "12": "** On page 1, you say that \"we propose a novel Tensor Train Language Model, as a first attempt to apply tensor networks on language modeling tasks\".",
            "13": "This makes it sound like applying tensor networks, and tensor trains in particular, to language modeling is new.",
            "14": "But that's not the case.",
            "15": "For example, Miller et al.",
            "16": "(2021) use matrix product states (which is the same as tensor trains) with language modeling as a potential application.",
            "17": "Your contribution needs to be clarified.",
            "18": "**W4.",
            "19": "** The paper is difficult to follow in several places.",
            "20": "For example:\n- The discussion in Sec 3.3 doesn't make sense.",
            "21": "You insert Eq (4) into Eq (3) to get Eq (5)---which is the same as Eq (3).",
            "22": "What is the point of this calculation?",
            "23": "- Below Eq (5) you show diagrammatic notation and say that it represents the tensor $A$---but doesn't that tensor network graph correspond to the contraction in Eq (2)?",
            "24": "- The discussion at the start of Sec 4 is difficult to follow.",
            "25": "TNLM is never defined.",
            "26": "- How exactly is the slice operator $T[i]$ defined?",
            "27": "This is unclear below Eq (6).",
            "28": "Is the 2nd or 3rd index kept fixed when slicing?",
            "29": "- In Fig 3: Plot (a) shows that $f_\\theta(x^{(j)})$ is contracted with the tensor $M^{(j)}$.",
            "30": "But then (b) and (c) seem to indicate that $M^{(j)}$ itself is a reshaped version (a matrix, rather than tensor) of a contraction that involves $f_\\theta(x^{(j)})$.",
            "31": "Also, since TTML-Large and TTML-Tiny add additional operations like reshape, it's not immediately clear that they can even be expressed on the form in Eq (2).",
            "32": "Again, if additional functions need to be added into Eq (2) to make the model expressible in that format, then it's not a TTLM.",
            "33": "- In Fig 4: The caption refers to labels (RNNs-100, RNNs-200, etc) that don't appear in the figure.",
            "34": "**W5.",
            "35": "** The experiment results aren't represented properly.",
            "36": "For example, you say that \"TTLM-Large obtains the best PPL among these models,\" but that's not true.",
            "37": "Two of the LSTM-based methods achieve lower PPL in Table 1 (for PTB).",
            "38": "For the PTB dataset, the PPL for TTLM-Large is bolded even though it's not the best number."
        },
        "wyTo_pHN1_i": {
            "0": "Strength\n1. the paper is well written, containing all of the Algebra background of tensor network and tensor train.",
            "1": "2.  they prove that TTLM generalizes Second-order RNNs, RACs and MI-RNNs.",
            "2": "Weakness,\n1.",
            "3": "Applying Tensor Train to RNN is not very new.",
            "4": "For example,\n\nYang, Yinchong, Denis Krompass, and Volker Tresp.",
            "5": "\"Tensor-train recurrent neural networks for video classification.\"",
            "6": "International Conference on Machine Learning.",
            "7": "PMLR, 2017.",
            "8": "Actually, TT is a very common compression technique, and is widely used with CNN, Transformer.",
            "9": "Ma, Xindian, et al.",
            "10": "\"A tensorized transformer for language modeling.\"",
            "11": "Advances in neural information processing systems 32 (2019).",
            "12": "Therefore, the novelty of this work is not very high.",
            "13": "2.",
            "14": "The code is not available, and the reproducibility is uclear due to a lots of details in the proposed framework.",
            "15": "3.",
            "16": "It may be better to compare with the popular Transformer to see more benefit of the TTML"
        },
        "oVwIdY9Y6xe": {
            "0": "+ Giving concrete experimental results in language modeling is an important step for research into the use of TNs in machine learning.",
            "1": "These models have many interesting properties and capabilities that aren't shared by neural nets, but (largely owing to the origins of TNs in physics and mathematics) prior work in this area has skewed heavily towards theory.",
            "2": "I want to stress to other reviewers that even though the empirical results reported are a far cry from that of modern neural language models, the fact that simple recurrent TT models are in the same ballpark as pre-Transformer state of the art RNNs is an important result in itself.",
            "3": "+ The authors prove concrete connections between recurrent TT language models and several prior models, namely recurrent arithmetic circuits, second-order RNNs, and multiplicative integration RNNs.",
            "4": "These connections aren't surprising and the proofs are basic, but it is nonetheless good to clearly state these connections so that they can be appreciated by the broader machine learning community.",
            "5": "- Many important implementational details are unspecified or unclear, and the paper feels hastily written.",
            "6": "I address these points in more detail in the following section, but given that the primary contribution of this work is experimental, ensuring that these experiments are well-explained and fully reproducible should be a priority."
        }
    },
    "OVbY-QCCjAh": {
        "Rvwi1m_yHO-": {
            "0": "**Strengths:**  \nAlthough the use of rule sets is quite common in tabular data, its less prevalent in NLP and I don’t recall seeing the construction of rule set classifiers for explaining sequence level tasks before so its quite novel ( though the authors mention Bayesian Rule Lists which is less efficient method ).",
            "1": "**Weakness: **  \nThe paper's argument could be made stronger.",
            "2": "The baseline they compare against seem pretty weak ( they allude to its limitations in the related work section ) and it seems like comparing SAGE with additional methods such as Decision trees would have more sense as well ( since SP-LIME performs very poorly in the task ).",
            "3": "More robust comparison of baselines/alternative methods  ( bayesian rules, global explain models, decision trees for NLP etc ) would benefit this paper along with some ablations including whether if instead of filtering as aggressively and using all rules if they'd get you 91% F1 on CoNLL?",
            "4": "If so, it seems perfectly acceptable as a solution if only a sparse amount of rules are used at each's instance explanation level.",
            "5": "Discussing what it means for overlapping spans ( unigram, bigram, etc ) of the same word to be present in rules is also important.",
            "6": "Also qualitative analysis of rules extracted including human judgement on whether they are good/interpretable, because the only rules shown in the paper are of simple unigram words/features implying a NORP class.",
            "7": "Finally, the accuracy of the BERT NER system on both tasks should be provided because thats really the upper limit of how well any explanation model could do."
        },
        "5HL3VsSp2Z-": {
            "0": "The authors have provided motivation to the problem, which is certainly important.",
            "1": "They present their algorithm and their experiments on 2 datasets, compared against the SP-Lime baseline model.",
            "2": "The paper could have been improved by comparison to other baselines.",
            "3": "Given that LIME and SP-Lime were released in 2016, more work has gone into the field of XAI.",
            "4": "It is not clear why only LIME was chosen as the baseline."
        },
        "1bWnoxK-bD": {
            "0": "Proposed approach shows its effectiveness in generating a global explanation for the NER model.",
            "1": "I believe this approach can be useful to the future research of weakly-supervised learning and neural-symbolic learning for NER.",
            "2": "However, I have a minor concern that the paper needs more analysis to convince readers.",
            "3": "For example,\n\n(1) Could find that the F1 score between model prediction and rule-based prediction is over 0.4 with only one rule.",
            "4": "It could be good to show qualitative examples of which rules are extracted “globally”, not just for the specific entity type (e.g., NORP).",
            "5": "(2) Comparison of qualitative explanation examples between SAGE and LIME.",
            "6": "Seems the word itself contributes a lot to labeling decision (e.g., Chinese → NORP), compared to the surrounding words or context.",
            "7": "Then, I think word importance generated by LIME can also be a good explanation but it seems not.",
            "8": "It would be good to show qualitative explanation examples between SAGE and LIME to show the effectiveness of SAGE.",
            "9": "(3) How does each semantic/syntactic information (POS tag, entity types, is_digit, … etc.)",
            "10": "contribute to the performance?",
            "11": "Seems entity prediction gives a lot of information to create rules.",
            "12": "(4) What is the performance of the fine-tuned BERT model as it is?"
        },
        "-PmEP2b3Rik": {
            "0": "### Strengths:\n* The proposed method, SAGE, is potentially useful.",
            "1": "### Weaknesses:\n* The paper may need major revision in its writing.",
            "2": "* The paper is not easy to read for me, especially the method section and its notations without complete definitions, e.g., mingensup, mingencon, maxrulelen, maxnrules, SORT-SUPPORT-AND-ABSTRACTION, etc.",
            "3": "I need to guess their meanings.",
            "4": "* The paper can be further proofreading.",
            "5": "For example,\n    * in Section 2, “Finally, Performing…” has a wrong uppercase.",
            "6": "* In Section 3.1, “..explanation method, the In Algorithm 1 the …”\n  * Most of the citations in this paper are not in a correct format.",
            "7": "Please change \\cite{} to \\citep{}.",
            "8": "* The paper lacks discussion about other explanations for NLP works while this paper claims to be a general method for NLP but test on NER, such as (I'm not asking you to cite them but would like to see its position in explanation for NLP field):\n  * David Alvarez-Melis and Tommi Jaakkola.",
            "9": "“A causal framework for explaining the predictions of black-box sequence-to-sequence models.” In EMNLP 2017.",
            "10": "* Hanjie Chen and Yangfeng Ji.",
            "11": "“Learning variational word masks to improve the interpretability of neural text classifiers.” In EMNLP 2020.",
            "12": "* Yi-Lin Tuan, Connor Pryor, Wenhu Chen, Lise Getoor, and William Yang Wang.",
            "13": "\"Local explanation of dialogue response generation.\"",
            "14": "In NeurIPS 2021.",
            "15": "* Hanjie Chen, Song Feng, Jatin Ganhotra, Hui Wan, Chulaka Gunasekara, Sachindra Joshi, and Yangfeng Ji.",
            "16": "“Explaining neural network predictions on sentence pairs via learning word-group masks.” In NAACL 2021."
        },
        "mONXjlug8NL": {
            "0": "Strengths:\n\n\t1.",
            "1": "They support the necessity for each step in the algorithm\n\t2.",
            "2": "They provide global explanations\n\t3.",
            "3": "They are task agnostic , method can be applied to many NLP tasks\n\nWeaknesses:\n\t\n\t1.",
            "4": "In section 3.1 they do not specify what certain notations mean  , eg the difference between the two transaction tables on the right of figure 2.",
            "5": "2.",
            "6": "Jump from section 3.2 to 3.3 is big especially for people who are unfamiliar with algorithms they point to such as FP-growth Han et al.",
            "7": "(2000) and apriori Agrawal et al.",
            "8": "(1994).",
            "9": "They use an example for section 3.1 but then they drop the example for subsequent sections in the algortihm .",
            "10": "3.",
            "11": "Other evaluation metrics employed by other papers eg, fidelity to the model and comprehensibility could have been explored .",
            "12": "Human evaluations might make a more compelling case .",
            "13": "4.",
            "14": "They don’t perform any study about which semantic features help and which harm the f1 score.",
            "15": "5.",
            "16": "Visualizaition is an important part of explainable models which this paper lacks"
        }
    },
    "yKbprarjc5B": {
        "rk2mQ7ui_Mv": {
            "0": "Strengths:\nThe paper presents an interesting idea for Multiple-Choice Question-Answering (using the answer symbol instead of the answer itself), motivates the idea well and does a thorough analysis over multiple datasets, and LLMs to analyze its performance in different settings (including few-shot settings).",
            "1": "Weaknesses:\nThere is no contribution/novelty from the modeling/methods side.",
            "2": "The paper is mainly an empirical analysis of a different way of formulating an existing problem."
        },
        "fg3s5OAzNGd": {
            "0": "Strengths: The authors explain their approach well.",
            "1": "They also discuss the (somewhat surprising) variance between different models in their ability to separate the letter from the answer.",
            "2": "(They call this Multiple Choice Symbol Binding.)",
            "3": "The approach is evaluated on a wide range of (20) datasets.",
            "4": "Weaknesses: The approach is not new, just discussed and evaluated.",
            "5": "The authors differentiate their suggested prompting from “prompt engineering”, which they seem to define as fine-tuning of prompts to increase model performance.",
            "6": "However, I’m not convinced that these are fundamentally different, and would include research such as theirs in the general domain of prompt engineering."
        },
        "_wSHGs29hxY": {
            "0": "Strength:\n\n1.",
            "1": "This paper is well-written and easy to understand.",
            "2": "2.",
            "3": "The authors propose a simple but effective prompting method, which outperforms previous CP methods, approaching or even surpassing SOTA performance.",
            "4": "3.",
            "5": "Experimental results show that the MCQA ability of LLMs has been previously underestimated.",
            "6": "And there is a better way to prompt a single LLM.",
            "7": "The potential of multiple choices prompts can be further tapped.",
            "8": "Future work include prompt engineering is still promising.",
            "9": "Weakness:\n\n1.",
            "10": "The novelty of this paper is limited.",
            "11": "Multiple choices prompting (MCP) has been used in other QA tasks, such as TruthfulQA and RACE.",
            "12": "2.",
            "13": "Although the experimental results prove that the proposed multiple choices prompting (MCP) methods can outperform existing cloze prompting (CP) methods, the reasons behind it are still unclear.",
            "14": "Since the authors have listed several problems within CP methods, I'm curious about whether these problems are all solved or avoided by their MCP methods.",
            "15": "More analysis is needed to show this."
        },
        "SF1Fe9-L9RC": {
            "0": "(Strengths)\n1) Reveals problematic ingredients for likelihood-based answering.",
            "1": "2) Introduce the concept of MCSB and measure it by PPA.",
            "2": "3) Concentrated results that significantly improves QA performance by using multiple-choice prompting.",
            "3": "(Weaknesses)\n1) Individual problematic ingredients are neither being theoretically-proven nor empirically-proven.",
            "4": "2) No novel/brand new ideas.",
            "5": "Mostly empirical analysis based on OpenAI playground.",
            "6": "3) Some major arguments are less supported."
        }
    },
    "KbYevcLjnc": {
        "J6XS2QmyFU4": {
            "0": "**Strengths**\n\nIdea of training LMs to perform collaborative writing is interesting and the application exciting.",
            "1": "Current tools for editing do not support such advanced functionalities and could have large  commercial potential.",
            "2": "Showcases feasibility of collaborative writing with pretrained LMs (proof of concept) and improvements over unsupervised pretrained LMs and LMs that have been trained on a broad set of human instructions.",
            "3": "**Weaknesses**\n\nThe approach requires training different LMs for four functionalities which is not ideal from maintainability and efficiency standpoint.",
            "4": "Discussion about this design choice versus pretraining a single model to perform different actions would be useful.",
            "5": "Assumption is that a large dataset of annotation is available for training and access to citations/documents which are not realistic.",
            "6": "Even though an approach for extending to other domains is proposed, it still relies on annotated data and additional costly steps for data augmentation and training.",
            "7": "This limitation has not been examined or discussed thoroughly in the paper.",
            "8": "Lack of baselines with vanilla in-context learning (ICL) with editing/performing undo/explaining examples.",
            "9": "There have been a number of papers demonstrating that ICL can work surprisingly well.",
            "10": "It would be interesting to compare with simple in-context learning with a few examples of edits for instance."
        },
        "OHmiZQWC27": {
            "0": "S:\n- The idea of controlling the generation of language models step-by-step in a recurred manner is interesting.",
            "1": "- The authors have evaluated their models on multiple settings, proving that their models trained on Wikipedia can potentially generalize to multiple downstream tasks.",
            "2": "W:\n- Human evaluation is missing and could add more insights to the interactive process.",
            "3": "- Even though there is a “explain” component in PEER, it is not evaluated and studied regarding its correctness.",
            "4": "- No error analysis about the generated plans and the edited text.",
            "5": "The authors only put a sentence at the end of the Appendix saying that “we still found PEER to generate false statements or claims not backed up by the provided documents in many cases“, but in the main paper there is no discussion or statistics on this weakness."
        },
        "Yj69ifaHjVy": {
            "0": "Strength:\n- This paper was the first to combine multiple collaborative writing skills together into a language model.",
            "1": "- Solid experiment results show its effectiveness on various editing tasks in a zero-shot fashion and also citing and quoting tasks.",
            "2": "- Enable collaborative editing for generating text as shown in Table 4.",
            "3": "- New datasets: Natural Edits, NE-Cite and NE-Quote are introduced.",
            "4": "Weaknesses:\n- Many of your downstream tasks include Wikipedia, which may be included in the training set of T5.",
            "5": "Is there any way to prevent this issue?"
        },
        "GJgRL221sS": {
            "0": "Strengths:\n\n1) Collaborative language modeling is an interesting and promising direction in NLG, which increases the interpretability and controllability of traditional NLG models.",
            "1": "This direction also connects with the industrial products about writing assistants, making the technique of NLG more applicable.",
            "2": "2) The proposed method based on self-training and instruction tuning is simple and effective, which directly supports the motivation to imitate the collaborative writing process.",
            "3": "3) The experiment part is well organized.",
            "4": "The four research questions are essential for collaborative language modeling.",
            "5": "And the authors provide empirical results on diverse tasks and datasets to successfully answer each question.",
            "6": "Weaknesses:\n\n1) Since PEER contains four different models which infill the missing part of training data, the authors should test the performance of each model (including PEER-Edit, PEER-Undo, PEER-Explain, and PEER-Document) to demonstrate the quality of augmented data.",
            "7": "Especially the performance of PEER-Document should be shown and analyzed, because in my view it’s hard for a pre-trained model with 3B model parameters to generate high-quality knowledge documents only given the texts before / after editing and plans.",
            "8": "2) More baselines should be included in the main experiments of text editing.",
            "9": "For example, Table 1 only contains a copy-based baseline, which may exaggerate the improvement of PEER.",
            "10": "At least the Wikipedia subset which contains the edit histories should have more baselines.",
            "11": "3) In this paper, the plan is just defined as a short text sequence like instructions.",
            "12": "This setting seems a little bit toy because it doesn’t clearly describe which part should be edited.",
            "13": "This may put more burden on the design of instructions.",
            "14": "From Figure 3, I find that the instructions mostly contain the position information, such as “add citation for the model being developed by Meta AI”.",
            "15": "But it’s obviously hard when the text is long and has many objectives to describe.",
            "16": "Thus, the design of plans should be further discussed to make this scenario more realistic.",
            "17": "4) Typo: the second x_t –> x_{t+1} on the right side of Figure 2 (PEER-Document)"
        }
    },
    "I8ly64E5Nt": {
        "McjcFSRDhn": {
            "0": "Strength:\nThe studied topic is at the core of community's interest.",
            "1": "How to scale the large scale language models  with reduced costs is important for many tasks.",
            "2": "The branch, train and merge framework has a clear design and the empirical studies supported the design idea and indicate the problems that the authors has faced.",
            "3": "The proposed method is validated on the large scale datasets and suggest the effectiveness of the paradigm.",
            "4": "Weakness:\n1.",
            "5": "Some of issues still remain unknown and insights behind this design is also lacking.",
            "6": "For example, why the model need to branch from some LMs on the similar domains?",
            "7": "Why does the merging of models trained on different domains lead to better performance rather than the models trained on random splits?",
            "8": "2.",
            "9": "The trained LLMs are not evaluated on the downstream tasks.",
            "10": "The evaluation of downstream tasks are useful to understand the effectiveness of this training paradigm.",
            "11": "GPT style models usually have strong few-shot abilities and strong generation abilities.",
            "12": "Look forward to seeing the corresponding results to support the effectiveness claims."
        },
        "K04aOfMXyx": {
            "0": "**Strengths:**\n-  Interesting approach of learning models in parallel and running on multi-node.",
            "1": "The paper introduces a new learning framework to train multiple models on different domains and merge them.",
            "2": "**Weaknesses:**\n- The evaluation is limited to language model perplexity.",
            "3": "The work would be more complete to have the results on other downstream tasks.",
            "4": "Did you have any chance to evaluate the model on downstream NLP tasks?",
            "5": "And does the model have the same capability as standard GPT models (i.e., in-context learning or generation tasks)?",
            "6": "- The motivation is unclear on why the authors proposed to branch-train-and merge.",
            "7": "Why do you choose to branch the LMs?",
            "8": "How can they be effective?"
        },
        "y7V_XAO6L-": {
            "0": "Strength\n1.",
            "1": "The experiments are very extensive, the ELMforest ensembles outperform baselines at no additional training cost.",
            "2": "Weekness\n1.",
            "3": "The evaluation for the parameter averaged ELMforests seems not fair, given that during evaluation the parameter averaged model can activate domain related experts on the test set.",
            "4": "The hidden assumption is that the consecutive sentences in the test set are from the same domain.",
            "5": "2.",
            "6": "If the parameter average approach doesn't give reasonable performance, the inference cost can be very high if we want to gain good performance."
        },
        "PgL-1jlJip": {
            "0": "The paper proposes a promising modification to the current LLM training scheme.",
            "1": "Specifically, I found the way the authors combine the outputs with domain posterior interesting.",
            "2": "However, I have the following concerns regarding the proposed method and its evaluation:\n\n- The technique of ensemble of many deep learning models is a well-known idea in deep learning.",
            "3": "The paper uses a standard ensemble method with limited algorithmic innovations.",
            "4": "Please highlight the difference between your work and previous works on\n- The results in Table 1 are not fair because different models have different numbers of parameters.",
            "5": "A more meaningful experiment is to compare the accuracy of the ELM model with a Transformer-LM with the same number of parameters and check whether the ELM model can match the performance with less training cost, or can outperform Transformer-LM under the same training budget.",
            "6": "- In addition, one can also ensemble the baseline Transformer-LM across different checkpoints and this can also boost the final inference performance.",
            "7": "How does this baseline compare with the proposed method?",
            "8": "- The study on the speed/efficiency of the proposed method is not complete.",
            "9": "Table 2 only provides the per-step speed during training.",
            "10": "Please provide a more detailed study on the convergence/inference speed of the expert-based LM."
        }
    },
    "wtcud6HroZr": {
        "Qqwij5l5D_": {
            "0": "Strengths:\n1）Prompts Learning is a meaningful direction, and this paper provides a valuable discussion of this direction to some extent.",
            "1": "2) The authors propose a novel and efficient method to address two issues regarding the Clip-like model.",
            "2": "3) The DeFo achieves 73.2% test accuracy on ImageNet with a ResNet-50 backbone without tuning any pretrained weights of both the vision and language encoder, outperforming zero-shot CLIP by a large margin of 15.0%, and outperforming state-of-the-art vision-language prompt tuning by 7.6%.",
            "3": "4）This paper is easy to follow and the motivation is well explained.",
            "4": "Weaknesses:\nThere are some issues that need to be improved: 1) The introduction and related work section lack a detailed discussion of the recent method CoCoOp.",
            "5": "2) A comparison with the SOTA method CoCoOp is lacking in the experimental section.",
            "6": "For example, in Tab1, Tab2, Tab3, Tab4 and Fig2."
        },
        "M0Dm6d93fW": {
            "0": "Strength:\n1.",
            "1": "Good and clear motivation, good paper writing with easy understanding scope&contribution.",
            "2": "2.",
            "3": "Great empirical results.",
            "4": "Weaknesses:\n1.",
            "5": "Limitation of technical novelty but it may not be a big concern from my perspective."
        },
        "jrTfputadJ": {
            "0": "Strength：\n1.",
            "1": "The two problems pointed out by the paper: do exist and deserve the attention of the community.",
            "2": "2.",
            "3": "The authors take time to implement and evaluate several prominent baselines.",
            "4": "Experimental evaluation shows competitive performance.",
            "5": "3.",
            "6": "This paper is well written and easy to follow.",
            "7": "Weakness:\n1.",
            "8": "The paper does not discuss the computational complexity of the proposed methods.",
            "9": "How to efficiently complete the fine-tuning of the pre-trained model is also a direction worthy of attention.",
            "10": "I look forward to seeing the authors discuss a comprehensive comparison of DeFo's training time and other methods, such as CoOp and CLIP-adapter.",
            "11": "2.",
            "12": "Some important ablation study may be missing.",
            "13": "Since the authors point out that using class labels to generate text embeddings may bring challenges with expressive sensitivity.",
            "14": "So a very straightforward idea is that we can directly set an independently learnable parameter as the prototype of each category to calculate the cosine similarity with image embeddings.",
            "15": "or adopt the exponential-moving-average (EMA) manner [3].",
            "16": "These above-mentioned methods do not use text encode.",
            "17": "Therefore, it is not necessary to carry out the forward of the text encoder every iteration during training.",
            "18": "If these method can also achieve very good results, then I feel that the novelty and effectiveness of DeFo may be challenged.",
            "19": "Therefore, I think it is very necessary to supplement this experiment.",
            "20": "Look forward to the author discussing in following version.",
            "21": "3.",
            "22": "The comparison of some other important baseline is missing, such as Tip-adapter [1] and CoCoOp [2].",
            "23": "4.",
            "24": "I look forward to the author's discussion of the additional learnable parameters introduced in addition to CLIP's pre-trained model, and compare the number with other methods.",
            "25": "Because if too many parameters are introduced, the performance improvement may come from overfitting of too many parameters.",
            "26": "If the authors would like to compare the number of additional parameters of DeFo with CoOp and CLIP-adapter, I think it may be very helpful for us to comprehensively evaluate and compare these methods.",
            "27": "5.",
            "28": "We expect that the model can not only achieve good performance on a single dataset, but also have the potential to transfer beyond a single dataset.",
            "29": "I suggest authors to add discussion about the perfomance of DeFo for domain generalization.",
            "30": "Maybe the setting in Section 4.2 of [3] is a good formulation.",
            "31": "This may strengthen the contribution of the paper."
        }
    },
    "UERcQuXlwy": {
        "FEImxIqens": {
            "0": "Although interesting and very well written, this paper does not make major contributions to the field.",
            "1": "The first contribution concerning the pre-training strategy is quite interesting.",
            "2": "The authors propose a strategy based on web pages screenshots that allows to collect quickly and easily a very large amount of data.",
            "3": "Moreover, these data can be quite varied and contain a large variety of elements, which allows to train a model that can work on many tasks.",
            "4": "The second contribution consists in adding modifications to the transformer inputs to handle variable aspect ratios and resolutions.",
            "5": "This strategy, although interesting, brings little gain to the results.",
            "6": "Moreover, it does not constitute a major contribution to the paper.",
            "7": "For the experiments, the following comments should be addressed.",
            "8": "1.",
            "9": "The idea of simplifying the multi-modalities problem is interesting.",
            "10": "However, it could have been nice to compare the method to a standard approach with a modality combination.",
            "11": "2.",
            "12": "The input masking is done using crossed-out opaque bounding boxes.",
            "13": "There is no justification about this choice.",
            "14": "I wonder if this choice has an impact on the results compared to other approaches like removing the boxes or using white bounding boxes.",
            "15": "3.",
            "16": "The authors claim that the changes they added to the standard ViT inputs provide major advantages in terms of robustness to extreme aspect ratios and on-the-fly changes to the sequence length.",
            "17": "However, except for the results presented on Figure 4, there is no experiments showing these advantages.",
            "18": "4.",
            "19": "It is not clear whether the modifications applied to the screenshots and HTML only consist in masking some texts or if other modifications are applied.",
            "20": "5.",
            "21": "I would have appreciated to have the inference times of the base and large models.",
            "22": "6.",
            "23": "The method of Wang et al (2021a) for the Screen2Words task could be more detailed.",
            "24": "7.",
            "25": "It is not said on which task and dataset the ablation study on the inputs resolution is carried on.",
            "26": "8.",
            "27": "13 articles are cited as ArXiv preprints, please update the citations for articles that have been published.",
            "28": "inor comments:\n\n1.",
            "29": "In Table 2, it would make the table clearer to add a line with the metrics.",
            "30": "2.",
            "31": "In Table 2, the value 160.4 should be highlighted instead of 145.0.",
            "32": "3.",
            "33": "The values should be given with the same number of significative numbers:\n    - 11.27 in AI2D\n    - 145 in TextCaps\n    - 40 and 81 in InfographiVQA\n4.",
            "34": "Figure 3 is a table, it should be renamed Table 3.",
            "35": "5.",
            "36": "Typo:\n    - Figure 4 caption: \"Our variable-resolution inputs prevent**s**...\"\n6.",
            "37": "In the appendix\n    - In the fine-tuning section, it is said \"Tables 4 and 4\", it should be corrected to \"Tables 4 and 5\".",
            "38": "By the way, tables 4 and 5 are quite similar, they could be merged into a single table."
        },
        "x9b9XESt2G": {
            "0": "Strength:\n\n1.",
            "1": "Pix2Struct uses a general-purpose pixel-to-text design, which simplifies the model architecture and can be easily applied to multiple domains.",
            "2": "2.",
            "3": "The masked screenshot parsing objective is intuitive and effective.",
            "4": "The pretraining data is easy to obtain from the web.",
            "5": "The warmup stage with an image-to-text curriculum further improves the pretrained model.",
            "6": "3.",
            "7": "The proposed fine-tuning strategy seamlessly integrate language and vision inputs by rendering language prompts on the image, without changing the architecture.",
            "8": "4.",
            "9": "A single pretrained model achieves strong performance on multiple visual language understanding tasks from diverse domains.",
            "10": "Weakness:\n\n1.",
            "11": "The presentation of this paper is easy to follow, but not clear enough.",
            "12": "Many important techniques are described at a high level, for example \n\n    (1) How the proposed variable-resolution input representation is implemented, how to determine the number of patches for width and height, do small and large inputs have the same number of patches?",
            "13": "(2) How the pretraining data is collected and processed, especially for the warmup stage.",
            "14": "(3) How the masked parts are selected?",
            "15": "2.",
            "16": "The authors do not mention if the data/code/model will be publicly available.",
            "17": "It would be difficult for the community to reproduce or follow if they cannot be released.",
            "18": "3.",
            "19": "Some of the designs lack empirical justification.",
            "20": "For example, are there alternative ways to fine-tune the model, such as concatenating image and text?",
            "21": "Does the location/size/font of where the prompt is rendered affect the performance?"
        },
        "nTX6MEbqgNW": {
            "0": "The paper makes a welcomed and impressive empirical contribution, with several nice discussions on certain design choices.",
            "1": "I will note 3 concerning points:\n\n1.",
            "2": "OCR or no OCR?",
            "3": "The paper is in line with the trend of replacing domain-specific components with a general pre-trained neural model, which is generally welcomed.",
            "4": "However, in domains where OCR is cheap and adequate, I am not sure if it is worthwhile to spend so much compute on replacing the OCR with a pixel-only LM.",
            "5": "An ideal solution would be an adaptive model which is pre-trained on such general screenshot parsing task but when adapted to a downstream task, could be fine-tuned to accept domain-specific inputs when there are cheap and easy-to-use solutions.",
            "6": "2.",
            "7": "Scaling up the model parameters seems to only bring marginal performance improvement.",
            "8": "Is there any observation about this?",
            "9": "Is it because the pre-training task is too simple?",
            "10": "It would also be good if the authors could provide evaluations on the pre-training task itself, using some simple metrics such as blue or exact match.",
            "11": "3.",
            "12": "More details on how the pre-training data are extracted and cleaned should be provided.",
            "13": "The authors mentioned that the data are from C4.",
            "14": "Does C4 already provide the cleaned data in HTML?",
            "15": "My impression of C4 was that it was primarily a web-text corpus.",
            "16": "Statistics on the pre-training data should also be provided.",
            "17": "E.g., what’s the lengths distribution of the output strings?"
        }
    },
    "NiEtU7blzN": {
        "_KSoY-JeGZ": {
            "0": "\nStrengths: \n1.",
            "1": "The paper is well written and easy to follow.",
            "2": "2.",
            "3": "Evaluated the approach of a lot of datasets and showed improvements.",
            "4": "3.",
            "5": "Lot of ablations are conducted which are very useful.",
            "6": "Weaknesses: \n1.",
            "7": "The paper presented an approach followed with empirical evidence, but did not provide why such an approach works in the first place (i.e., approach is not backed well enough).",
            "8": "Following are my concerns on the approach:\n   - The approach fine-tunes on the rationale-augmented reasoning paths using self-consistency, which means that self-consistency outputs without LMSI (fine-tuning approach) will be on par with CoT-Prompting with LMSI.",
            "9": "This is more or less consistent with the observations in main Table-3.",
            "10": "- As per my understanding, the model is not learning any new information, the proposed approach is acting like a filtering method where the results achieved by a self-consistency can be achieved by fine-tuned LMSI in CoT setting.",
            "11": "I think the self-consistency results for LMSI can be achieved by using more samples for self-consistency without LMSI.",
            "12": "These experiments are not there in the paper.",
            "13": "2.",
            "14": "Like I said, there were a lot of ablations in the paper where some of them proved some points presented in previous work (like Table-7) and others are new (Figure-3).",
            "15": "On the new ones, the paper failed to provide good discussion on the outcomes/observations.",
            "16": "For example, in Figure-3, both step-by-step and few-shot with step-by-step are converging for total samples at 80.",
            "17": "Why is that the case?"
        },
        "PbXQN07LV0": {
            "0": "### Strengths:\n- The work pushed the state-of-the-art results on multiple datasets including GSM8K which seems to be a challenging dataset even for larger language models.",
            "1": "- Using what the model knows (in this case by predicting multiple answers to the same question, and doing majority voting to estimate the possible correct output) to train the model further can help in adapting LLM to a specific task and can be used in future to train LLMs without any supervision.",
            "2": "### Weaknesses: \n- Prompting is a popular technique for querying LLMs because of their size and training them is not efficient/possible in most scenarios.",
            "3": "Various prompting strategies have been developed in the past that have improved the performance of LLMs significantly, like Chain of thoughts, appending “let's do this step by step”, and so on.",
            "4": "An obvious extension was to generate multiple times using the same/different strategies, and select the one with higher confidence or cluster them or do some majority voting.",
            "5": "This paper uses all the methods of the past and proposes an obvious extension that takes the confident samples and trains over them.",
            "6": "This is not novel at all with many researchers have thought about this but could not execute the idea because of a lack of resources, higher API costs,  and non-availability of open-source LLMs like PaLM.",
            "7": "- Secondly, proposing an approach and claiming that “This is similar to how a human brain sometimes learns: given a question, think multiple times to derive different possible results, conclude on how the question should be solved, and then learn from or memorize its own solution” is just random with not theory or study to back this up.",
            "8": "In other words, it is saying that humans can look at a problem, and think of a solution many times, and the one that humans conclude the most is the most likely output and use that to think and train themselves to memorize that solution.",
            "9": "I don't agree with this point at all (of course I am happy to listen to why authors thought about this).",
            "10": "- Research where such an important claim is being made (LLMs are able to self-improve) needs to be shown on multiple models (small to very large) and just showing the results on a 540B model does not prove the point that large LMs can self-improve by training on the samples that they produced.",
            "11": "When generating outputs with let's say a smaller model like T5-large, where the accuracy will not be that high, the model outputs cannot be used to train them as most of the time, the answers will be incorrect.",
            "12": "So my guess is that this approach only works for PaLM or similar-sized models.",
            "13": "- Finally the limitation of the experiments on one model (and that too not open sourced) is not enough to justify the big claim of \"large language models can self improve\".",
            "14": "The reproducibility of the results is a concern to many."
        },
        "dfWz-9PsvCI": {
            "0": "Strengths: \n1) The empirical gains indicate that the method is effective.",
            "1": "2) The approach is reasonably straight forward, although difficult to estimate the impact of a variety of hyperparameters and choices (some of which are varied and shown in later in the paper) at each stage due to the complexity of fine-tuning such a large model.",
            "2": "3) One-type of distillation, fine-tuning a smaller model from the generations of the 540B model, is effective.",
            "3": "Weaknesses:\n1) The method is only broadly applied to the 540B model that almost no one else has access to/can train or fine-tune.",
            "4": "The distillation approaches show that the method is effective when using the samples from the 540B model.",
            "5": "What happens if you don't have access to such a large model?",
            "6": "Can you apply the entire method to a smaller model say < 10B?",
            "7": "2) It'd be great to see if these approaches can be used with language models that are available to everyone and at scales that most of the community can use.",
            "8": "3) Replicating this is nearly impossible."
        }
    },
    "3oWo92cQyxL": {
        "Bkw7rN3CYw": {
            "0": "Strengths:\n1.",
            "1": "The paper is well motivated and described.",
            "2": "The ideas are clear and experiments are on several large multimodal datasets.",
            "3": "2.",
            "4": "The paper is very clear with clear figures and exposition.",
            "5": "3.",
            "6": "Experiments are comprehensive and results are strong.",
            "7": "Weaknesses:\n1.",
            "8": "The novelty of the paper is limited, since it seems to be a combination of Frozen (Tsimpoukelli et al., 2021) and standard meta-learning approaches to learn the mapping from image representations into language model token space.",
            "9": "2.",
            "10": "There should be more comparisons in both performance and complexity - the proposed method does better but certainly uses more computation so the tradeoff should be analyzed."
        },
        "_5yfpoP27E": {
            "0": "Strength:\n\n+ The main idea of combining soft-prompt tuning and MAML is very straightforward, and novel to some extent.",
            "1": "+ The empirical results are strong, and show that the proposed method outperforms the previous state-of-the-art in multimodal few-shot learning.",
            "2": "+ The ablation studies are quite comprehensive, and most of my questions about the methods was addressed.",
            "3": "Weakness:\n- I don't see very obvious weakness of the methods.",
            "4": "Questions:\n\nOne question I have is about the variance of the model's performance, with respect to the few-shot support examples.",
            "5": "Figure 3 has shown same hints but it could be interesting to more variance analysis on realistic VQA data."
        },
        "EL2G6WfQ64s": {
            "0": "Strengths:\n1.",
            "1": "Thorough and insightful literature survey that provides a sound motivation for the proposed approach.",
            "2": "2.",
            "3": "Clear explanation of both the proposed approach and the experimental results.",
            "4": "3.",
            "5": "Sound technical approach that is computationally lightweight and applicable to multiple multimodal tasks.",
            "6": "4.",
            "7": "Experimental results show clear advance over the state of the art.",
            "8": "5.",
            "9": "Insightful ablation results show the advantage of the proposed approach.",
            "10": "Weaknesses\n1.",
            "11": "No significant weaknesses.",
            "12": "A suggestion - have you thought of how you would bridge three modalities?",
            "13": "That is not required for this paper but I would be curious to know your thoughts.",
            "14": "For example, how would you bridge visual, text and audio modalities?",
            "15": "My guess is that your approach will scale up easily to accomodate more modalities but do think about it."
        },
        "AgeVNcUWskN": {
            "0": "Strength: \n* The idea itself is very simple and easy to understand, for an impactful research direction.",
            "1": "Making use of already pre-trained vision/language models could help save computational cost.",
            "2": "* This paper is very well written and is very easy to understand.",
            "3": "The illustrations of the idea are very clear.",
            "4": "* Good qualitative results and ablation tests.",
            "5": "Weaknesses:\n* It is appreciated to mark both \"episodic\" and \"cross-domain\" in Table 1 and Table 2.",
            "6": "It is clear that the proposed \"episodic\" training helps on the quality significantly on target tasks.",
            "7": "However, \"cross-domain\" leads to unfair comparisons, where the Frozen baseline only reported results with \"cross-domain\" setup while this paper highlights results with non \"cross-domain\" (\"in-domain\") setups.",
            "8": "I am concerned by this point and if we look at \"episodic\" and \"cross-domain\" row in Table 2, this paper falls behind Frozen overall."
        }
    },
    "jNpvW1ozbj3": {
        "2FPiAVvezP": {
            "0": "Strength\n* Clear mathematical extension of the standard GP formulation to train on multiple outputs for a single input.",
            "1": "Weakness\n* Unclear that this improvement is solving a problem.",
            "2": "The speech intelligibility task like many subjective evaluations has substantial uncertainty (noise) in the ratings.",
            "3": "It's unclear what a better measure of uncertainty is important to this task in order to understand the necessity of this improvement\n\n* Limited evaluation.",
            "4": "There are a plethora of approaches to measure, predict and account for noise in subjective ratings.",
            "5": "In Section 6.5 it is not clear how the KL divergence without multiple input samples is calculated.",
            "6": "(Repeated samples from the vanilla GP?)",
            "7": "How would this approach compare to a naive approach using a fixed covariance across the full data set?",
            "8": "Or an only slightly more complicated approach, predicting the variance for each utterance?",
            "9": "The proposed approach still has a Gaussian predictive density function.",
            "10": "This limits the distributions that can be represented by this technique.",
            "11": "How would this compare to a variant whose predictive density function were a mixture of Gaussians similar to \"Gaussian Mixture Modeling with Gaussian Process Latent Variable Models\" (https://arxiv.org/abs/1006.3640)?",
            "12": "* Efficiency Discussion\nGaussian Processes are computationally expensive.",
            "13": "Are there other approaches to density estimation that are less expensive that can be compared to the proposed?",
            "14": "Or that the use of Gaussian Processes can be shown to be more computationally expressive?"
        },
        "Il0q4vhDde": {
            "0": "Strengths:\n\n        - The proposed approach may have the advantage of reducing training cost when compared to considering an extended Gaussian process prior which may lead to a non-invertible covariance matrix.",
            "1": "However, this is not evaluated.",
            "2": "Weaknesses:\n\n        - The paper has a sloppy notation in which several terms are introduced without clarification.",
            "3": "It not clear what Y_ref or y^º_i are.",
            "4": "This makes difficult following the paper.",
            "5": "- The experimental section is weak.",
            "6": "Only two datasets are considered and the baseline the authors compared with is very simple.",
            "7": "- The results show no particular benefit with respect to the simple baseline the authors compare with."
        },
        "dMKlEVRtIZ": {
            "0": "S1.",
            "1": "The authors are trying to solve a spoken language assessment task using a Gaussian process.",
            "2": "The problem addressed herein is important.",
            "3": "W1.",
            "4": "The manuscript is not well organized and the technical contributions are somewhat unclear.",
            "5": "W2.",
            "6": "The proposed model seems incremental.",
            "7": "The proposed model attempts to represent multiple outputs by independent sampling from a single GP.",
            "8": "This does not seem to contain any particular novelty.",
            "9": "W3.",
            "10": "I think it would be better to explain the importance of problem settings more carefully, for example, by drawing an easy-to-understand diagram."
        },
        "IgRkOkTeTDN": {
            "0": "Strength: \n\nThe paper is well-organized and easy to follow.",
            "1": "Weaknesses:\n\nTo be honest, I do not understand why the proposed approach is required.",
            "2": "Although the author mentioned that the stacked kernel approach does not work because eq(13) is not full rank.",
            "3": "However, as far as the noise variance is nonzero \\sigma > 0, the predictive distribution of GPR can be calculated even when (13) is not full rank (inverse is required only for (K + sigma^2 I), not for K).",
            "4": "Obviously, it is usual that, when \\sigma > 0, multiple different observations can be obtained for the identical x.",
            "5": "The standard GPR framework can deal with this situation."
        }
    },
    "qY1hlv7gwg": {
        "0lls2iOtV9q": {
            "0": "Strength:\nThe proposed method is simple yet effective.",
            "1": "The paper is well-written and thus easy to follow.",
            "2": "The empirical studies provide interesting insights about how the method works.",
            "3": "Weaknesses:\nSome important alternatives and baselines are not involved in the comparison.",
            "4": "There is inconsistency in presentation."
        },
        "zgwPPma1DH": {
            "0": "### Strength\n\nThe efficient approach to select a pool of examples to annotate from unlabeled data which are shown to be diverse.",
            "1": "The authors evaluate their method on several tasks including classification, reasoning, dialogue, semantic parsing and generation.",
            "2": "The authors also provide a detailed analysis of their method compared to other baselines.",
            "3": "### Weaknesses\nI have a few comments:\n\n* Do the authors take the cost of encoding every unlabeled training instance using Sentence-BERT into account when comparing methods?",
            "4": "I believe this was not mentioned in the paper.",
            "5": "* In section 2.1, It is not very clear how the first M/10 examples are labeled.",
            "6": "It is mentioned that “the current labeled $\\mathcal{L}$ has M/10 samples” which is used to label other instances.",
            "7": "Are they manually labeled?",
            "8": "* It is stated that the vote-k method encourages diversity.",
            "9": "Since all the labels are removed first, does this method encourage or keep inclusivity of all the classes?",
            "10": "Have the authors looked at whether their method favors examples from certain classes?",
            "11": "* In section 2.1, “we conduct experiments three times and report the average score”.",
            "12": "What/where is the randomness?",
            "13": "Examples selected or model prediction?",
            "14": "* Figure 2 shows a direct comparison between fine-tuned RoBERTa large and models such as DaVinci-002 while it is stated that the authors do not aim to conduct a head-to-head comparison.",
            "15": "What is the comparison the authors are making here and perhaps could it be shown better with another figure?",
            "16": "Results from this direct and not fair comparison are also mentioned in the abstract which could be misleading.",
            "17": "* In section 4.4, I think some more detail is needed as to why the combination of vote-k and similarity retrieval works, but vote-k alone with random selection of supporting examples has almost the same score as random selection."
        },
        "dGEZTIZWEg": {
            "0": "Strengths:\n1.",
            "1": "The authors present a simple technique for in-context learning with large language models that achieves consistently good results across a variety of NLP tasks.",
            "2": "2.",
            "3": "The proposed ideas in isolation do not yield significant improvements.",
            "4": "The authors find that the main ingredients for the success of in-context learning are a combination of selective annotation with similarity-based prompt retrieval.",
            "5": "3.",
            "6": "The experimental section is thorough.",
            "7": "Along with ablations and trying LMs of varying sizes, their technique is compared against many other existing selective annotation approaches and shown to consistently outperform the latter.",
            "8": "Weaknesses: Some of the design choices need to be elaborated on further and additional analysis-based experiments would also be useful.",
            "9": "I elaborate on these further below for the authors to address.",
            "10": "- For the classification tasks, what do the label distributions look like over the labeled subset $\\mathcal L$?",
            "11": "Since the selective annotation is based entirely on similarities derived from sentence embeddings, there is nothing explicit ensuring that the label distribution over the selected subset is not skewed.",
            "12": "Or, is the label distribution on the annotated subsets derived via vote-*k* indeed skewed for some tasks and the performance improvements are mainly coming from improvements on the labels that are well-represented?",
            "13": "Some discussion of this would be useful.",
            "14": "- It seems like the optimal value of $k$ in vote-*k* would depend on the number of instances in the unlabeled set that changes with the tasks.",
            "15": "A single value of $k=150$ was chosen for experiments across all tasks.",
            "16": "Could the authors justify this choice further?",
            "17": "- From the diversity and representativeness measures shown in Table 10 in Appendix F, the difference between Random and vote-*k* does not appear to be very large.",
            "18": "In the least, it's unclear how to assess the differences shown in this table.",
            "19": "A qualitative analysis might be more revealing here.",
            "20": "It might be interesting to see some examples, especially when the annotation budget is 18, of the kinds of instances that get selected depending on the task.",
            "21": "t-SNE plots of these selected examples in the larger context of unlabeled instances might also be a good visualization to show.",
            "22": "Please comment."
        },
        "gRltDu_A77": {
            "0": "## Strengths\n\n1.",
            "1": "In-context learning is a hot, rapidly evolving area of research and of high interest to the ICLR and NLP communities.",
            "2": "This paper presents a thorough set of evaluations of the impact of the choice of examples to include in the prompt, demonstrating that this can have a huge impact in final model behavior.",
            "3": "1.",
            "4": "The paper is clear and easy to read.",
            "5": "The evaluation section contains several interesting results that should be valuable to share with the broader community.",
            "6": "1.",
            "7": "The gains of vote-k over other existing active learning methods presented is quite strong (Section 4.5).",
            "8": "1.",
            "9": "The system proposed seems to be practical and relatively easy to implement in practice.",
            "10": "As such, there is a chance that it could be applied in practice in real world applications of in-context learning.",
            "11": "1.",
            "12": "The idea of automatically constructing graphs of unlabeled examples using similarity measures is relatively old in the label propagation literature.",
            "13": "The proposed use-case in this work is interesting and novel.",
            "14": "## Weaknesses\n\n1.",
            "15": "The main weakness of the paper is the lack of a thorough description and analysis (including ablations) of the vote-k algorithm and its relationship to existing clustering algorithms.",
            "16": "I would have hoped for a more complete discussion in Section 2.1, including the contents of Appendix G which seem important for readers to fully understand the proposed vote-k algorithm.",
            "17": "1.",
            "18": "One particularly confusing part of vote-k: it was not immediately clear to me how this differs or is better than simple k-means clustering to discover centroids?",
            "19": "Once a weighted graph is constructed (as described in Section 2.1, using cosine similarities of sentence-level representations), it should be possible to run any graph-based algorithm for finding centroids.",
            "20": "I think a naive baseline (that does not use model prediction confidence scores) would be to use k-means.",
            "21": "1.",
            "22": "Related to the point above, I would have liked to see more ablations on the vote-k selection process.",
            "23": "How important is it to use the model confidence “stratification” strategy in the algorithm?",
            "24": "This is particularly useful to know since, given a very large set of unlabeled examples `|U|`, it can be costly to run all `u in |U|` model predictions to collect confidence scores.",
            "25": "1.",
            "26": "One source of bias that was not addressed in the paper relates to the choice of unlabeled examples (|U|).",
            "27": "In this study, the unlabeled corpus for all 10 datasets has been extracted from an existing labeled/supervised corpus (that has been previously annotated).",
            "28": "This may not seem like it, but I believe there is huge amount of supervision and work simply *choosing* which examples to label in the first place.",
            "29": "In practice, however, for a new task/dataset, this will not be the case if we want to do only “selective annotation”.",
            "30": "I was quite unsure (maybe a little skeptical) that the proposed procedure would work for a “random” or uncurated corpus of unlabeled examples.",
            "31": "1.",
            "32": "There is also no discussion on label distribution in the vote-k process.",
            "33": "Again, I think the current experimental evaluation is taking advantage of curated training datasets where labels tend to be nicely distributed/represented.",
            "34": "So focusing on performing input similarity and model confidence may be enough.",
            "35": "For example, for some tasks, a fairly random unlabeled corpus may contain a huge number of “negative” examples (say you want to automatically find pairs of sentences for entailment - most random pairs of sentences will be NEUTRAL).",
            "36": "Measuring similarities of inputs alone does not seem to be sufficient to match the expected posterior distribution of labels?",
            "37": "Can you please elaborate on this point?",
            "38": "1.",
            "39": "With respect to the experimental setup, it is a bit jarring the number of combinations of (dataset, model) pairs (Table 1).",
            "40": "I understand that it is expensive/infeasible to run all datasets on all models, and I don’t have a good suggestion to improve on this.",
            "41": "But I fear that the end result is that subsequent/future work that builds on vote-k may need to re-evaluate your implementation on a partial set of dataset/tasks.",
            "42": "## Other questions\n\n1.",
            "43": "Question about potential clarification in initialization of Algorithm 1.",
            "44": "Maybe I did not understand this part of the algorithm, but when running initially |U| contains all examples, and |L| is empty.",
            "45": "My understanding is that the score in line 4 of Algorithm 1 (also equation in Section 2.1) generates score of 0 for every node since no u in |U| are yet connected to a node in |L|.",
            "46": "Is the argmax using some stable ordering when all scores are 0 to guarantee determinism?",
            "47": "Does this choice not influence the final set of examples in |L| ?",
            "48": "1.",
            "49": "Recently, the Chain-of-Thought prompting (https://arxiv.org/pdf/2201.11903.pdf) has been used by many papers using in-context learning, with reported improvements in model performance (the paper seems to have been cited already 100 times since its release earlier this year).",
            "50": "One question this work does not address is whether model sensitivity/variance to retrieved prompts is also present when used in conjunction with chain-of-thought.",
            "51": "And whether the vote-k scheme would be useful to limit the number of chain-of-thought annotations needed to improve in-context learning performance."
        }
    },
    "ETKGuby0hcs": {
        "BHRdOoutSPE": {
            "0": "Strengths: \n- The proposed approach is novel to my knowledge.",
            "1": "- Strong empirical results across many datasets and models.",
            "2": "- The problem this paper trying to tackle is fundamental \n\nWeaknesses:\n- My major concern about this paper is that the claims made are not well supported by the experiments.",
            "3": "- In section 3.2.2, \"Recall our motivating goal: to discover latent knowledge in a language model even when its training objective causes the model to output false text.\"",
            "4": "I don't see how this claim is related to the experiments in this section.",
            "5": "The experiment is conducted in a zero-shot setting in which no training objectives are used.",
            "6": "What they really do is use a set of contrastive prompts to mislead the model and the experimental results show that **CCS can improve the robustness of the model**.",
            "7": "That's the takeaway I can conclude from the experiment.",
            "8": "- In section 3.3.1, \"CCS FINDS A TASK-AGNOSTIC REPRESENTATION OF TRUTH\".",
            "9": "I am not super convinced by this claim, as all of the models (without fine-tuning using the CCS objective) used for this experiment can already make zero-shot generalizations on those datasets to some extent.",
            "10": "It is unclear to me what is added by the CCS objective.",
            "11": "Does it just make the model more robust against domain shifts?",
            "12": "Or it captures something else?",
            "13": "Moreover, do you have a more formal definition of TRUTH here?",
            "14": "- In section 3.3.2 \"CCS CAN FIND INTERMEDIATE REPRESENTATIONS OF TRUTH\".",
            "15": "I don't quite get the logic behind this experiment.",
            "16": "How can we conclude by looking at the results that lower layers perform worse?",
            "17": "Can you elaborate on this a bit more?",
            "18": "- The baseline seems a bit weak to me.",
            "19": "How about you just fine-tune the models used in the paper using the original training objective on those datasets used for testing?",
            "20": "- The \"purely unsupervised\" setting seems to be a bit overclaiming.",
            "21": "In the experiments, they still need a non-trivial number of training examples to make the proposed approach work.",
            "22": "It would make the paper much stronger if they could use examples from a more \"wild\" setting, e.g., sentences from a random corpus, to train CCS and show it could still work."
        },
        "bq0oGA6O8h": {
            "0": "Strengths:\n- The paper targets an important issue with language models: verifying truthfulness of outputs and whether knowledge is learned within the model parameters.",
            "1": "- There is an interesting result in 3.2.2 for how CCS is robust to adversarial prompts.",
            "2": "I would have liked to see more discussion on why this particular design of \"misleading prefix\" was chosen, however.",
            "3": "- CCS is demonstrated to be usable with multiple models across a wide range of tasks.",
            "4": "- Good discussion of limitations and possible future challenges.",
            "5": "Weaknesses:\nI'm having a bit of a challenge reconciling the challenge of verifying truthfulness with the focus on results of how CCS out-performs zero shot approaches on accuracy - as mentioned in the paper, it *does* indicate that there is a disconnect between inferences made via one modality (ranking of activations) vs. direct model outputs, but it is difficult to see how that shows that one method is \"better\" than the other for probing knowledge."
        },
        "OncAEbHwGh": {
            "0": "Strengths:\n* very strong motivation\n* simple and effective idea\n* very valuable empirical results to the community\n* discusses relevant alternative hypotheses\n\nWeaknesses:\n* **update post rebuttal**: my biggest concerns have been addressed\n* statistical validity is unclear due to small test sets\n    * why are the datasets subsampled to include only 1000 examples, of which 400 are the test set?",
            "1": "* these are unneccessarily small test sets, causing greater uncertainty and therefore confidence in the results\n    * can you please justify why you believe that differences are unlikely to be due to randomness?",
            "2": "Note that stds in Table 1 are relatively large.",
            "3": "* evidence for disproving alternative hypotheses is weak in several cases:\n    * Section 3.2.2: CCS Is Robust To Misleading Prompts\n        * goal: \"discover latent knowledge in an LM even when its **training objective** causes the model to output false text\"\n        * method: change **test time** prompts and observe difference\n        * method is not well suited for the goal, because you don't touch the training objective of the model at all.",
            "4": "* result is found for only one out of 5 models.",
            "5": "Combined with the statistical uncertainty above, I am not convinced that this is sufficient evidence that this is a valid, general finding.",
            "6": "* Section 3.3.2: CCS Can Find Intermediate Representations of Truth\n        * motivation: output text might encode truth, and CCS may merely correlate with output text\n        * method: show that CCS applied to intermediate layers also works well.",
            "7": "* implicit assumption: lower layers don't correlate with the produced output text (as much?).",
            "8": "This needs evidence of some kind, e.g.",
            "9": "a reference.",
            "10": "* results: lower layers perform worse, but according to the paper, they still perform well enough.",
            "11": "It isn't clear what constitutes well enough.",
            "12": "* (their) conclusion: lower layers do well despite not correlating with the output text, so they have to encode truth qualitatively different from the output text.",
            "13": "* Lower performance at lower layers may be entirely explained by decreasing (but not vanishing) correlation with the output text.",
            "14": "Since there is no quantification of the latter, we cannot make the above conclusion.",
            "15": "Alternative method to prove that internal truth values are present independent of the input:\n* if truth values are encoded independent of textual output, you should be able to extract them by:\n    1. replacing positive and negative labels with completely uninformative, random text.",
            "16": "Since you aim to normalize out the effect of \"Yes\" and \"No\", the appended text shouldn't matter either way, or\n    2. don't alter x_i, but train the model with two different classification heads."
        },
        "N7mfjQpnOn3": {
            "0": "Strengths:\n- To the best of my knowledge, exploring the internal consistency of language models in an unsupervised way is a novel contribution.",
            "1": "The authors proposed an interesting method via optimizing the LM with a consistency and a confidence loss to figure out the more likely choice.",
            "2": "- The empirical results are significant across 4 out of 6 models, and across 10 tasks.",
            "3": "Weakness:\n- The proposed approach applies only to questions that can be converted with binary answers (i.e., the answer choices are fixed and are from a very limited set, otherwise the inference cost would increase substantially).",
            "4": "1) This largely constrains the applicability of this method to many tasks, e.g., math tasks that have numbers as answers, which would require generating an infinite number of binary-answer questions.",
            "5": "2) for some tasks the conversion might be non-trivial and requires additional human processing.",
            "6": "- Although the proposed method doesn't use any labels, it still uses input examples and requires a fairly large number of training examples to perform well (Figure 5) due to the optimization procedure.",
            "7": "This could pose a challenge compared to true zero-shot learning which doesn't require any examples at all.",
            "8": "For any new task, how to obtain a large number of training examples (even without labels)?",
            "9": "- Table 1 presents average performance.",
            "10": "Is there a more detailed breakdown of performance gains across different tasks?",
            "11": "Are there categories of tasks that benefit from the method more vs less?",
            "12": "- Relatedly, as the authors have stated, CCS relies on the assumption that true/false inputs can be separated reasonably well in the activation space.",
            "13": "Are there analysis regarding what are tasks that satisfy this property and what tasks are less easily separated?"
        }
    },
    "Pkb5FA5AjqP": {
        "h1bxsM_1V0J": {
            "0": "Strength\n- The safety issue of the large language models is an important topic nowadays.",
            "1": "The topic studied in this paper aligns with the topic.",
            "2": "- The proposed approach is also reasonable, given the difficulty of doing discrete space optimization.",
            "3": "The variant of first-order approximation also achieved good empirical results.",
            "4": "- Experiments are done with practical LLMs (though GPT-2 is not considered as that large).",
            "5": "Weakness\n- The practical usefulness of the paper needs further justification.",
            "6": "In practice if we can have a risk function \\phi(x, o), then one can simply reject the samples when the samples get high risks.",
            "7": "So relying on \\phi(x, o) to find the vulnerability of LLM may not be practical, as one can filter out these samples using the same \\phi(x, o).",
            "8": "We all know that the large language models are not safety guaranteed, and the proposed approach may not be super helpful in this context.",
            "9": "- Technically the coordinate-wise ascent may not be super efficient.",
            "10": "One can potentially improve this further, in terms of 1) the approximation, and 2) the scope of the optimization.",
            "11": "Regarding 1), the work named gibbs with gradient [1] might be helpful.",
            "12": "Regarding 2), one can think of approaches that can flip multiple sites at a time [2], or flipping them in parallel in a factorized way [3].",
            "13": "References:\n\n[1] Oops I Took A Gradient: Scalable Sampling for Discrete Distributions, Grathwohl et.al\n\n[2] Path Auxiliary Proposal for MCMC in Discrete Space, Sun et.al,\n\n[3] A Langevin-like Sampler for Discrete Distributions, Zhang et.al"
        },
        "kEBnALmzG2H": {
            "0": "Strengths:\n1.",
            "1": "The proposed algorithm and approximation seems novel to my knowledge.",
            "2": "2.",
            "3": "The problem of finding the prompt that causes certain behavior is interesting and important to study.",
            "4": "3.",
            "5": "Some of the prompts indeed works even for Codex, e.g., \"Barack Obama is a legalized unborn\", \"Florida governor\", which seem to prove the effectiveness of the method.",
            "6": "Weakness:\n1.",
            "7": "From Figure 1, the effectiveness of the method can fall significantly when output length is longer, which is a huge limitation.",
            "8": "2.",
            "9": "Most of the examples given in the paper look quite unnatural and difficult to understand, indicating it's difficult to expose undesirable behaviors in more natural interactions with the language models.",
            "10": "3.",
            "11": "The evaluations are limited to only GPT-2, despite most instances only take less than 1 minute to run."
        },
        "t-F5pr33aHp": {
            "0": "Strength\n\t• A simple and clear formulation to search for targeting properties of input-output behaviors via discrete optimization with relaxation.",
            "1": "•  A few effective insights in solving the formulated discrete optimization problem\n\t• The experimental results seem to demonstrate that the approach is promising\n\t\n\nWeakness\n        The writing of the key contribution --- decomposition and relaxation of the discrete optimization problem --- is not clear enough which might cause confusion for the readers."
        },
        "ocPaJNTWF5o": {
            "0": "Strength\nThis paper proposes a better way to solve the discrete optimization problem compared to prior works\n\nWeakness\nN/A"
        }
    },
    "XIIynqbMXgR": {
        "X2qpGvWL1D": {
            "0": "Strengths:\n- Potentially a very useful resource for discourse-aware evaluation across tasks.",
            "1": "- Very thorough description of the resources, including in-depth background in the appendix.",
            "2": "- Considerable experiment breadth.",
            "3": "- High-quality writeup.",
            "4": "Weaknesses:\n- The paper does not reflect thoroughly on the linguistic bias introduced by choosing Chinese and English as the focus languages.",
            "5": "There should be a Limitations section that addresses how the proposed approach would scale in low-resource scenarios or if extending the breadth of linguistic coverage in the datasets.",
            "6": "What would it take to introduce another language?",
            "7": "What if that language is low-resource?",
            "8": "How would that support the findings?",
            "9": "Can we simulate that with the existing data to an extent?",
            "10": "- Experiment breadth is not backed with experiment depth, at least in the main part of the paper, as the Main Results and Analysis are rather superficial.",
            "11": "This is a minor concern since the main focus of the paper is to provide the resource."
        },
        "kzkLSa4Mqv": {
            "0": "Strengths: data set construction is valuable, and the goals of the work seem worthwhile.",
            "1": "Weaknesses: first, there is no attempt to evaluate the quality of the resulting data, either through expert evaluations or inter-annotator consistency (I think the former is the only way to really check for this).",
            "2": "Second, many of the details of the paper are unclear.",
            "3": "Third, many claims are made without sufficent support."
        },
        "aeDDttvQZd": {
            "0": "Strengths:\n\n* The datasets are valuable for the document-level NLP research, which need to address the coherence and cohesion across clauses and sentences.",
            "1": "* The experiments provide baseline results for future research.",
            "2": "Weaknesses:\n* I have difficulties to fully understand the settings of the 9 tasks.",
            "3": "How to evaluate each task?",
            "4": "* SI: are the speakers always mentioned before the utterance of interest?",
            "5": "What are the expected outputs if there are multiple utterances with quotation marks?",
            "6": "* ZPR: What are Chinese-English movie subtitles?",
            "7": "Are they Chinese movies with English subtitles, English movies with Chinese subtitles, or both?",
            "8": "* NT: Is eclipsis not important for novel translation?",
            "9": "How about concept consistency in scientice fictions?",
            "10": "* CCT: do you mean traditional Chinese?",
            "11": "Novels written in traditional Chinese?",
            "12": "* PT: what's the target language?",
            "13": "English?",
            "14": "* How to evaluate the generation tasks if there are multiple plausible answers?",
            "15": "* What is the inter-annotator agreements for the tasks requiring human annotations?",
            "16": "* What are the inter-annotator agreements for the discourse-aware test suite?",
            "17": "How are the annotators instructed to construct adversarial examples or the noises are added by algorithms?",
            "18": "What kind of noises?",
            "19": "* Why coreference resolution models are not considered as part of or as baselines of applicable tasks?",
            "20": "* It is not clear to me what are the new challenges arising from the benchmark?"
        }
    },
    "yQdBtFfleh6": {
        "4J6TubtkV-": {
            "0": "Strength:\n\n[1] Interpret the skip connection with the help of the Markov chain is reasonable and innovative.",
            "1": "[2] When exploring the optimization of the Markov chain, the gradient to $z_l$ seems to add a simple penalization on the $z_l$, which is interesting and easy to use.",
            "2": "[3] This paper evaluated their method on both Natural Language Processing and Computer Vision.",
            "3": "Results show that their method improves the performance and the convergence of deep neural networks.",
            "4": "Weaknesses:\n\n[1] Can authors analyze why the proposed method can solve the model degradation problem?",
            "5": "Will the penal connection make the convolutional layer more sparsity, and can other regularization methods (i.e.",
            "6": "$L_1$ Norm) solve this problem?",
            "7": "[2] Experiments on more deeper networks (i.e.",
            "8": "ResNet101, ResNet152, ResNet110, ResNet1202) are needed to evaluate for demonstrating that the Markov chain can better solve the model degradation problem than the residual-like model.",
            "9": "[3] I have noticed ReLU is put before Linearly Layer in Figure 1 in the supplementary materials, so the model used in the main paper is whether ResNets or PreActResNets?"
        },
        "M1-Lqz9bJ60": {
            "0": "Pros\n\n- This paper formulated models with skip connections as a learnable Markov chain.",
            "1": "And introduced the ideal direction for improving the efficiency of the Markov chain.",
            "2": "- The proposed penal connection is a plug-in operation and the experiment evaluation the efficiency of this method.",
            "3": "Cons\n\n- Previous works [1,2] have already formulated the VGG-like models with the Markov chain, can you explain the advantage of ResNet over VGG under the Markov chain’s guide?",
            "4": "- The compared models’ performance in Table 2 is lower than their original paper, can you explain why, and can the proposed method promote their SOTA implementation?",
            "5": "[1] Opening the black box of Deep Neural Networks via Information \n\n[2] Markov Chain Neural Networks"
        },
        "PqcRFXQVM4": {
            "0": "Strengths:\nThis paper has a solid theoretical foundation and novel method.",
            "1": "Weaknesses:\n1、\tThe main contribution of this paper has not been summarized.",
            "2": "2、\tIn Fig.1, f_{\\theta_{l}} is a residual-like block.",
            "3": "Can you explain the difference between f_{\\theta_{l} and residual block?",
            "4": "3、\tHow to understander the definition of ideal direction?",
            "5": "The relationship between ℓ(a, c) ≥ ℓ(µa+ (1−µ)b, c) ≥ ℓ(b, c) and Eq.(1).",
            "6": "4、\tIn Fig.4, can you plot the curves about ℓ(xl − ηgxl , y) and  ℓ(xl , y)  to illustrate ℓ(xl − ηgxl , y) < ℓ(xl , y) always holds?"
        },
        "4HSDyC6XfN": {
            "0": "Strengths:\n* The Markov Chain perspective on skip connection type models is novel and interesting.",
            "1": "* The paper includes useful illustrations e.g.",
            "2": "Fig 2 and Fig 3, which make the paper clearer.",
            "3": "* The paper includes encouraging results on top-1 accuracy on ImageNet-1k across several state of the art models.",
            "4": "Weaknesses:\n* Central claims of the paper are not clear: Consider the “inefficient” Markov chain in Fig 2 (a).",
            "5": "Both the inefficient and efficient Markov chains successfully convert data from the source to the target domain.",
            "6": "In fact, for a classification type model there should be no difference in the finally test accuracies of both efficient and inefficient models.",
            "7": "If learning an efficient Markov chain is hard, it is not clear what is the advantage of an efficient Markov chain.",
            "8": "Perhaps the paper wants to claim that efficient Markov chains leads to better fit to the target distribution?",
            "9": "* In Proof 2.3, the paper derives only an c value for \\epsilon.",
            "10": "What is the quality of the approximation?",
            "11": "Are there any upper bounds to the absolute error?",
            "12": "This is important because the approximation has a direct impact on the quality of the proposed regularizer.",
            "13": "(The steps in Proof 2.3 should be numbered).",
            "14": "* It is not clear if a higher value of \\epsilon leads to a better model?",
            "15": "The paper should show better evidence for this.",
            "16": "In Fig 4 (b) the difference in \\epsilon between the two models is minimal.",
            "17": "In fact, the value of \\epsilon peaks early in training, but is not accompanied by peak accuracy?",
            "18": "* The paper should also consider including additional state of the art baselines for the machine translation task, as currently only the plain Transformer is considered."
        }
    },
    "O-G91-4cMdv": {
        "FLYixTi1fr3": {
            "0": "Reconstructing pairwise human similarity judgments across N objects is\nan interesting task, and the author's idea of gathering textual\ndescriptions is clever.",
            "1": "The performance of the stacked models (which\ndepend on domain-specific pretrained models and text-text\nsimilarities) and text-only models are surprisingly strong across a\nvariety of domains --- this finding has implications for the relative\nsurprising representational strength of text.",
            "2": "The annotation process\nthey describe for their tag corpus is interesting --- multiple rounds\nof annotations are undertaken with crowdworkers fixing each-other's\nerrors.",
            "3": "The authors consider a large number of models across many\ndomains --- the benchmark experiments are extensive, and the \"size\nvs. accuracy\" plots in the end are cool.",
            "4": "Figure 5 is amazing --- few\nworks offer such clear practical guidance.",
            "5": "Finally, I liked the\nhopeful message in the end --- that a combined multimodal approach\nseems to work best, so don't completely discard the domain-specific\nrepresentations.",
            "6": "It should be noted that the cited work where some of the data is from,\nMarjieh et al.",
            "7": "2022, is quite similar in the sense that it also\nproposes to estimate human similarity judgments.",
            "8": "This work appears to\nextend that work by exploring more types of models and their\ncombinations.",
            "9": "My main concerns are that this set of experiments suggests some clear\nnext setups that I don't nesc.",
            "10": "think are out of scope for this work.",
            "11": "Specifically:\n\n- If the goal in practice is to reconstruct human judgments --- I\n  would have liked the authors to compare against a supervised setup.",
            "12": "How much of the remaining misalignments can be fixed by gathering n\n  << N^2 additional pairwise judgments and then training a supervised\n  model ontop of the models?",
            "13": "- I would have liked to have seen more experiments with even less\n  supervision --- is it possible to gather n < N captions, and train a\n  model on those very few pairs to map to text, and then use the\n  resulting modality --> text model as input to the models shown here?",
            "14": "- I would have appreciated more discussion of tags vs. captions for\n  the images.",
            "15": "In figure 3A, I assume that the text only methods use\n  captions unless specified otherwise.",
            "16": "But --- because the tags were\n  not fed to, e.g., BERT/RoBERTa, I can't tell if the performance\n  gains are due to the full captions being used, or if the gains are\n  due to the more expressive models.",
            "17": "A trivial linearization of, e.g.,\n  \"A photo of a tag1, tag2, and tag3\" handed to a LLM would have been\n  a nice comparison to see.",
            "18": "- Finally, I would have been interested in a fully LLM setup where\n  instead of pairwise cosine similarities, both text pairs are fed to\n  a very large LLM (e.g., OPT or GPT3) and the model outputs a likert\n  rating as text."
        },
        "BnIPXCoBp_s": {
            "0": "Strengths: I think this is a well-motivated problem.",
            "1": "Learned representations are often used as features in the small-data regimen or sometimes directly for getting proximity scores in an AI setting.",
            "2": "This paper address the human interpretability of these representations by (i) confirming that human similarities and proximity scores from models can vary a lot, (ii) text-descriptions or tags can be leveraged and stacking these representations with the model-learned representations can help.",
            "3": "I also appreciate that the technique is scalable and in many cases not that much of an overhead to implement.",
            "4": "I appreciate the arguments in the related text that leverage cognitive science literature.",
            "5": "In addition, the paper is easy to follow.",
            "6": "Weaknesses: The paper doesn't have too many weaknesses.",
            "7": "I was wondering if we could get some numbers on if the stacked representations help in additional downstream tasks like say classification (i.e.",
            "8": "does the performance on imagenet improve if you use imagenet + text).",
            "9": "However, I understand that this can be significant undertaking and do not want to base my review on this experiment but it is a potential future direction."
        },
        "YNKRxEZYKke": {
            "0": "Strength:\n1.",
            "1": "The paper is overall well-written and easy to follow.",
            "2": "2.",
            "3": "Multiple datasets are evaluated for the proposed method.",
            "4": "3.",
            "5": "Multiple modalities are explored and evaluated on the proposed method.",
            "6": "Weakness:\n1.",
            "7": "The technical contribution of the proposed method is weak.",
            "8": "2.",
            "9": "No baselines are compared to the proposed method in the experiment section."
        },
        "yUP72x_OyqI": {
            "0": "[Strength]\nThe concept of the paper is nicely presented for the next AI abundant society where demand for human judgments is more increased.",
            "1": "They proposed the novel similarity approximation method with a smaller number of judgements.",
            "2": "They provide the evaluation data in the supplemental material, which is beneficial.",
            "3": "Overall, I believe what the authors done is quite systematic and very beneficial for the future refinement of the DNN model.",
            "4": "[Weakness]\n\n-\tRepresentational similarity\nFor beginners, the word of representation similarity is not easy to follow.",
            "5": "At least, authors should define the terminology in the introduction.",
            "6": "-\tThe title\nIn particular, the linkage between title and abstract seems not clear at the first glance.",
            "7": "Please consider to update the title and abstract so that readers can easily understand the topic theme.",
            "8": "-\tIs English best?",
            "9": "There are many languages.",
            "10": "In my opinion, I view that authors selected English language to represent the basis of all things in nature.",
            "11": "Why English(e.g., language system such as polysemous, grammar, dataset availability…)?",
            "12": "Justification of English employment would make the paper better.",
            "13": "Related to above topic, the paper report “N = 1,492 US participants for the new behavioral experiments reported in this paper.” Are they all Americans and share the same contexts?",
            "14": "(e.g., cultures…) \n\n-\tCrowd scouring\nHow long does it take to STEP-Tag?",
            "15": "It is good that measure actual time that participants consumed.",
            "16": "Comparing with that with the time used for writing captions may strengthen your claim.",
            "17": "-\tDiscussion\nI feel strange because the paper end with “Discussion”.",
            "18": "Please consider adding conclusion section or rename the last section as “Discussion and Conclusion”."
        }
    },
    "p0yrSRbN5Bu": {
        "6MFjlH-bp1": {
            "0": "Strengths:\n1.",
            "1": "A method developed based on well though through motivations.",
            "2": "2.",
            "3": "Empirical study shows better results.",
            "4": "Weaknesses:\n1.",
            "5": "To ensure this method work, the source models are expected to be robust.",
            "6": "In other words, some robust source models must be trained to be borrow.",
            "7": "But it may not be true that these source models are always available and comparable.",
            "8": "2.",
            "9": "Can the source models trained on top of other pre-trained models?"
        },
        "X1xxTwH_GcP": {
            "0": "Strengths\n========\n[+] The paper is clearly written and easy to understand\n\n[+] The proposed method outperforms the previous approaches and baselines considered on a variety of datasets\n\n[+] The authors empirically verify different design choices and baselines and perform interesting analyses (like the effect of using the top-k most similar source domains for each target task)\n\nWeaknesses\n===========\n[-] Some useful ablations / exploration of alternative design choices still missing (see below)\n\n[-] The proposed method requires several forward passes through the language model (one per source task, that uses a different prefix) in order to perform a single prediction, thus adding computational overhead at test time compared to other methods.",
            "1": "Would be good to add some discussion on this.",
            "2": "[-] While the paper is clearly written for the most part, I would have liked to see a detailed description of the tasks used, both as source tasks and the target tasks considered.",
            "3": "I couldn’t find details of them in the Appendix either, though please let me know if I missed it.",
            "4": "This is important as understanding the tasks considered is useful for interpreting the results."
        },
        "GhtlD8dK8A": {
            "0": "Strength:\n\n1.",
            "1": "The idea to use ensemble is straightforward while effective.",
            "2": "It makes the idea simple and easy to implement.",
            "3": "2.",
            "4": "The experiment results are good and improve the previous SOTA on most of the tasks considered in this paper.",
            "5": "3.",
            "6": "The paper is well written and easy to understand.",
            "7": "Weakness: I am not an expert in knowledge transfer and prompt tuning, thus I do not know the explicit weakness of this paper."
        },
        "ZDH1ym-hjCw": {
            "0": "The main strengths: \n1.",
            "1": "The paper is well-written and the idea is well-motivated.",
            "2": "2.",
            "3": "The experiments are quite comprehensive.",
            "4": "The empirical analysis section answers several interesting questions.",
            "5": "3.",
            "6": "The empirical study that compares the prediction ensemble with the prompt ensemble is quite interesting and can inspire many related fields.",
            "7": "The main weaknesses: \n1.",
            "8": "The idea that combining the output of several models using the attention strategy is not novel in deep learning.",
            "9": "2.",
            "10": "I can not understand why sample-specific rather than task-specific preference is important for prompt tuning.",
            "11": "What if a similar sample exists in a quite different source task?",
            "12": "Will the attention model pays more attention to this similar sample resulting in a negative impact on the target task performance since the source task and target task are quite different?"
        }
    },
    "HLQyRgRnoXo": {
        "_IA5vcDWl3": {
            "0": "Strength:\n1.",
            "1": "Firstly, the paper is generally well-written and easy to follow.",
            "2": "2.",
            "3": "The observation that transferring activation is faster than offloading weights in LLMs is interesting.",
            "4": "3.",
            "5": "The proposed method addressed an important question and allowed communities with lower-end GPUs to be able to serve and tune LLMs.",
            "6": "There could potentially be a new business model based on collective inference.",
            "7": "Weakness:\n1.",
            "8": "I am not very familiar with distributed system research.",
            "9": "But from my understanding, fault tolerance in a distributed system has already been well studied.",
            "10": "It seems the proposed method only applies the techniques to LLM inference and does not have a significant novelty.",
            "11": "2.",
            "12": "From my understanding, the method can only work when the model is large enough (as the authors mentioned, >100B).",
            "13": "Could you please show how it works for smaller LMs?",
            "14": "What model size is the turning point?",
            "15": "3.",
            "16": "When comparing the baseline of offloading, did you apply the same quantization technique to reduce bandwidth requirement?",
            "17": "4.",
            "18": "Did you implement pipeline parallelism to further improve the throughput?"
        },
        "gSXcpmH0i6": {
            "0": "Although, pre-trained LLMs are now freely available for download the hardware cost of inference and finetuning computation is still quite prohibitive and is a barrier to broad accessibility of AI advancements.",
            "1": "Thus, the paper is tackling an important problem.",
            "2": "The proposal of a community-approach that involves pooling consumer-grade resources together to inference and finetune LLMs is also reasonable and applicable to a broad class of users.",
            "3": "The presented algorithm and implementation details are useful in understanding some of the technical challenges.",
            "4": "My main concern is the evaluation, which I feel does not present a complete and fair assessment of PETALS.",
            "5": "Below are specific examples.",
            "6": "1.",
            "7": "Overhead of fault tolerance (4.1)\n    a) What are the runtime and memory costs of client and serving caching, and how they scale with increasing client and server counts?",
            "8": "b) When clients don't have GPUs, does this mean client-server communication involve GPU/CPU copying on the server?",
            "9": "c) Are the runtime and memory costs of fault tolerance reflected in the results in 4.2 and 4.3?",
            "10": "d) Table 1 only shows fault tolerance evaluation for inference.",
            "11": "Is the fault tolerance provided for fine tuning?",
            "12": "e) In Table 1, PETALS is the best option in only 2 of the 8 scenarios.",
            "13": "Caching with restarts wins 5 times, No caching wins once.",
            "14": "This is not very convincing for PETALs.",
            "15": "2.",
            "16": "Comparison to Offloading (4.2)\n   a) Using 1 A100 for Offloading and 3 A100 for PETALs does not seem like a fair comparison.",
            "17": "Can you elaborate?",
            "18": "b) The theoretical latency numbers of Offloading suggest that 16-bit weights are being used rather than 8-bit weights, is this correct?",
            "19": "c) Are the A100 GPUs connected by PCIe or NVLINK?",
            "20": "d) Depending on the response to the preceding 3 issues, a fair evaluation could mean scaling the Offloading performance by up to 18X: \n    3X for GPU count, 3X for parallelizing weight fetching from CPU, and 2X for 8-bit weight quantization.",
            "21": "e) Why are there no forward pass results for the multiple client section of Table 2?"
        },
        "VodjGdLCerf": {
            "0": "## Strength\n\n1.",
            "1": "The paper proposes a valid combination of multiple techniques for efficient inference and fine-tuning of LLMs, including pipeline parallelism, adapters, quantization and compression.",
            "2": "2.",
            "3": "The engineering behind the system is non-trivial and I appreciate the authors for open-sourcing their work.",
            "4": "I believe the work will be beneficial for researchers with access to geo-distributed machines.",
            "5": "## Weakness\n\n1.",
            "6": "Pipeline parallelism is a well-studied technique for large language models.",
            "7": "The way this paper applies pipeline parallelism is not new compare to previous works.",
            "8": "2.",
            "9": "The dynamic load balancing (i.e., schedule which layers to run on each GPU) are not evaluated in the experiments.",
            "10": "How does this algorithm adapts to different hardware configurations?",
            "11": "3.",
            "12": "Comparing the proposed setting with the offloading techniques is not a completely fair comparison: The offloading setting only has a single GPU, but the geo-distributed setting has many more GPUs and thus much higher total computational power.",
            "13": "4.",
            "14": "A more important comparison is to compare the efficiency of this method with the setting where the GPUs are within a single datacenter and the optimal performance in that case."
        },
        "OJS3AKKWV2f": {
            "0": "Strengths\n* Great problem, high impact, fun read \n* Technically interesting system architecture with a functional implementation  \n* Evaluation in the wide area, compelling numbers wrt an offloading baseline\n\nWeaknesses\n* The description of the fault-tolerant load-balancing algorithm is insufficient.",
            "1": "The stability of the N-player greedy approach needs to be addressed.",
            "2": "The performance model is not described nor its accuracy evaluated.",
            "3": "* It isn't clear how Petals initially groups layers to the servers or if layer groupings can change.",
            "4": "* The evaluation does not empirically explore actual server failures or network partitions (to the client, between servers).",
            "5": "I.e., there are no results bolstering the core contribution (I comment below on why Table 1 is a great microbenchmark but insufficient in this regard).",
            "6": "* Explores uniform network bandwidth and latency, but it's unclear what this is really testing in the Petals architecture.",
            "7": "* Compares to offloading but should compare to DeepSpeed in the wide area under conditions that illustrate Petals benefits."
        }
    },
    "8-2sjUPp_YD": {
        "yZ5xwc-8sy": {
            "0": "Pros:\n1.",
            "1": "Experiments are conducted on many pretrained variants and datasets, and clearly show gains over VL baselines.",
            "2": "This shows that the proposed method is effective.",
            "3": "2.",
            "4": "Ablation studies are performed and it is clear that each proposed component is beneficial.",
            "5": "3.",
            "6": "The paper is clear and easy to follow.",
            "7": "Cons:\n1.",
            "8": "The resulting student model is a large-scale VL pretrained checkpoint itself.",
            "9": "It will be more interesting if the method can get strong performance on non-pretrained or smaller-scale models.",
            "10": "As of now, it is hard to say the method brings 'efficiency' given everything is pretrained anyway.",
            "11": "2.",
            "12": "The method contains too many specialized components.",
            "13": "Although ablation does show the benefit of each, this still makes the method hard to use in practice.",
            "14": "In fact, I am a bit hesitant to call it a 'method' and feel it is more like a bag of 'methods'.",
            "15": "3.",
            "16": "Although some analysis is given, it is still hard to understand why the method is better.",
            "17": "Since it is not intuitive why such framework can/should improve visual attention, it seems a must to dig further to understand details such as which exact step brings this benefit and why.",
            "18": "4.",
            "19": "The proposed method is also designed for fusion-based VL models and not directly applicable for other trending architectures such as encoder-decoder."
        },
        "Tz6Y2xUCueC": {
            "0": "*Strength\n- The proposed ideas are good to achieve the research goal.",
            "1": "I think the proposed methods would be practically useful if they are generally applicable and the benefit is clear in most cases.",
            "2": "- The paper presents interesting findings on the performance improvements in the low-shot area.",
            "3": "- Various settings of experiments are performed and the results are consistent as the authors’ claims.",
            "4": "*Weaknesses\n- I'm concerned with that the significance of this work would be limited.",
            "5": "This method is not for building compact student models (in normal scenarios of knowledge distillation), but for improving the performance based on VL student models, unimodal teacher models for vision, and unimodal teacher models for language.",
            "6": "The generality of the performance improvement is not clearly validated yet, and the low-shot setting, the area that the benefit is significant, needs the criteria of how low is appropriate to apply this method.",
            "7": "- One of the main claims is that the proposed methods achieve new SOTA on the VCR tasks.",
            "8": "However, there are some problems on that paragraph.",
            "9": "I checked the two leaderboards (1: https://leaderboard.allenai.org/vcr/submissions/public, 2: https://visualcommonsense.com/leaderboard/ ).",
            "10": "Following the AI2 leaderboard, I realized that the numbers from the page 8 of the manuscript, “Q2A: 80.9%, QA2R:83.3%, Q2AR: 67.7%”, is the 1st one’s and it is for MERLOT, not for ADVL.",
            "11": "The ADVL’s is “80.4%, 82.3%, 66.2%”.",
            "12": "Following the VCR leaderboard, ADVL is the 18th runner and the score is “79.6, 82.9, 66.2”.",
            "13": "Considering the submission dates of the others and the ranking, I cannot accept the claim currently."
        },
        "3bp81zn4IQ": {
            "0": "**Strengths**:\n1.",
            "1": "The motivation is clear.",
            "2": "It is naturally expected that vision-language models can benefit from stronger unimodal encoders, for which the best strategies are not very well explored by the community.",
            "3": "2.",
            "4": "The idea is simple and easy to implement.",
            "5": "According to the evaluation, the proposed method shows its effectiveness especially when the finetuning data is limited.",
            "6": "3.",
            "7": "Although the presentation can be polished, the overall narrative and explanation is clear and easy to follow.",
            "8": "**Weakness**\n1.",
            "9": "**Flawed experiment setup**.",
            "10": "The motivation is to leverage unimodal data, which are assumed easier to obtain than image-text pairs.",
            "11": "However, the teacher networks used in the experiments are not always uni-modal.",
            "12": "For example, CLIP, SLIP are trained on a large amount of image-text pairs, meaning that their unimodal encoders are also aligned across modals.",
            "13": "This contradicts with the motivation.",
            "14": "2.",
            "15": "**Limited technical novelty and incremental empirical gains**.",
            "16": "The proposed distillation loss is standard and by itself is not technically new.",
            "17": "In addition, improvements on full-shot cases are mostly marginal.",
            "18": "Considering this is the combined benefit of multiple techniques, e.g.",
            "19": "distillation, text token selection, contrastive learning, I am not fully convinced by the empirical value of the proposed method.",
            "20": "3.",
            "21": "**Student networks** are too weak to prove the proposed techniques are useful for the more recent (and more powerful) models.",
            "22": "The selected student networks, VL-BERT, UNITER, VILLA, while they are great and highly reputable works in the community, their performance is not as competitive as for today.",
            "23": "Therefore, the obtained task performance is far from state-of-the-art.",
            "24": "For example, on VQA, more recent works (BEiT-3) achieve 84+, while the best reported result in the manuscript is ~76.",
            "25": "To make the method more convincing, authors may consider use more recent VL models as student works, and try to further push their limits.",
            "26": "For example, to use LLM such as GPT to improve the text representation of BEiT.",
            "27": "5.",
            "28": "**More recent VL-pretrained works are not well acknowledged**.",
            "29": "Although I understand the experiment setup, missing reference to more recent VL works prevent readers from getting a good research landscape in the multimodal pre-training.",
            "30": "For example, recent great VL works, ALIGN, ALBEF, OFA, Frozen, Flamingo, Florence.",
            "31": "BLIP, BEiT3.",
            "32": "Authors are suggested to better position their work among the more recent ones.",
            "33": "4.",
            "34": "It is not fully clarified what is the difference between the so-called \"ITM\" (image-text matching) and the contrastive losses used in other  VL pretrained models, such as ALIGN, ALBEF.",
            "35": "Conventionally the ITM loss is a binary prediction task, while the particular one used in this work is more often referred as contrastive learning loss.",
            "36": "This may create unnecessary confusions.",
            "37": "6.",
            "38": "Presentation can be improved.",
            "39": "Typos are not uncommon.",
            "40": "Experiment setups are not entirely clear.",
            "41": "For example, what is the experiment environment and training receipts."
        }
    },
    "dNyDCl2FsvM": {
        "Q8dNk0GftjX": {
            "0": "Strengths:\n- *Strong performance on split H*: The paper presents a model that show promise in improving performance on split H for GScan.",
            "1": "Improvements over recent baselines are promising.",
            "2": "- *Nice ablation study*: The ablation study and the analysis are interesting to understand the failures of the method.",
            "3": "I particularly appreciate when a particular problem is studied in detail and ablations are provided.",
            "4": "Weaknesses:\n- *Limited clarity*: The paper could be more self-contained: I found it hard to figure out what is going on without re-reading the relevant literature.",
            "5": "For example the GScan dataset and the original Meta-Seq2Seq model have not been introduced.",
            "6": "- *Limited scope*: In-depth analysis of a particular generalization failure in only one setting, GScan.",
            "7": "A more impactful paper would offer perspective on how the method can be fruitful to solve also other compositional generalization datasets (CFQ?",
            "8": "Natural Questions?)",
            "9": "- *Limited novelty*: An application of the Meta-Seq2Seq model from Lake et al.",
            "10": "2019 to GScan.",
            "11": "I cannot identify whether there exist an intrinsic modelling novelty brought forward by this work, apart from the design of the oracle function that generates support sets.",
            "12": "The oracle function resembles the methodology introduced by GECA.",
            "13": "- *Limited applicability*: Ablation offered the key insight that permutations are important to solve split H, but afaicu, permutations require knowing a lot about the structure of the problem (e.g.",
            "14": "that walk maps to I_WALK).",
            "15": "Is this realistic for other datasets?"
        },
        "gnAnv2BZ-c": {
            "0": "- The strength of this paper is that they obtained better performance than the previous models with “oracle templating function” in limited test splits, although there are following problems as written in weakness.",
            "1": "- The first problem is that the proposed model uses the periluminal knowledge of some testsets such as the different distributions of verbs and adverbs mentioned in Sec 3.2.",
            "2": "It is prohibited in the previous studies compared in Table 2.",
            "3": "The details of the contribution “oracle templating function” is written in Appendix, not in the main paper.",
            "4": "It still lacks details.",
            "5": "- The second problem is that the contribution / observation is limited.",
            "6": "In this paper, authors proved that tuning Meta-Sequence-to-Sequence learning approach on the limited testset of gSCAN is effective.",
            "7": "However, this is not so surprising because some testsets of gSCAN are designed for different test situations.",
            "8": "Therefore, we can tune our models for some specific test sets if we preliminary know the information of the testset, such as the different distributions of verbs and adverbs.",
            "9": "When we turn some models into the specific distribution, we obviously sacrifice the performance in other test sets with different distributions.",
            "10": "This is the observation of the main score Table 2 and is not a novel thing in the learning of the out-of-domain adaptation.",
            "11": "Hence the overall paper contribution looks not obscure.",
            "12": "In short, optimizing models just for a few good test sets is not a good contribution.",
            "13": "- The third problem is indeed the largest problem: the motivation to access the statistics/bias of gSCAN test set and taking advantage of the existing bias in tuning model is not discussed well in this paper.",
            "14": "I’d like to know concrete applications or explanations how the proposed models / approaches for the limited OOD test sets are useful in the following studies or real applications.",
            "15": "If the motivation in this paper relies on human compositional problem solving as written in the introduction, how the observations in the experiments, especially for the results of “oracle templating function,” have contributed to it?"
        },
        "qWdOzEI9EGz": {
            "0": "Strength \n\nThey study an important problem.",
            "1": "Using meta-learning for compositional generalization is reasonable.",
            "2": "The results on Split H are positive and they also conducted a range of ablation and error analysis.",
            "3": "Weakness \n\nThe paper is poorly organized and very hard to follow.",
            "4": "This is the key weakness, but this makes me find it really difficult to judge the overall technical quality and significance.",
            "5": "E.g., after reading the related sections a few times, I still do not understand how meta-seq2seq is applied in their setting and how the technical components handle the gSCAN environments.",
            "6": "It seems that many important introductions and remarks are missing.",
            "7": "So I suggest that the authors give a technical introduction of the framework and more precisely discuss how it can solve the problem of interest, possibly with visual illustrations.",
            "8": "Some important concepts are repeatedly used without a definition.",
            "9": "E.g., what is a \"support\"?",
            "10": "The paper has \"support set\" and \"support instructions\" at many places but it is unclear to me what it actually means.",
            "11": "I also read the original gSCAN paper but they didn't use this term at all.",
            "12": "Similarly, what is an \"oracle\"?",
            "13": "What is \"in-distribution\" instructions and how would an instruction from non-oracle look to an instruction from oracle?"
        },
        "3LDLC_SoDQ": {
            "0": "Strengths:\n- The paper addresses a highly relevant problem\n- The proposed method is elegant and might allow to model abstraction and generalization\n- The proposed method shows promising results\n\nWeaknesses:\n- The method is very closely related to the work \"Compositional generalization through meta\nsequence-to-sequence learning\" by Lake (2019), which it builds upon.",
            "1": "While adapting it to transformer architecture and a new task is not trivial, it does limit the conceptual novelty of the contribution.",
            "2": "- Empirical results, while promising, are confined to a relatively narrow domain.",
            "3": "This is especially unfortunate, since when novelty is relatively limited, the breadth and impact of empirical results becomes paramount."
        }
    },
    "C2ulri4duIs": {
        "6fm48ZRTxp6": {
            "0": "\nStrengths\n===\n\n* I really appreciate the motivation for this work.",
            "1": "Thinking about language acquisition from an evolutionary perspective seems important and the role of Theory of Mind in evolutionary language acquisition in AI has not been explored.",
            "2": "This has also been specifically identified as in need of further study in the cited work (Lazaridou et.",
            "3": "al.",
            "4": "2020).",
            "5": "* Futhermore, this particular computational relization of Theory of Mind seems new and the evidence points in the direction\n\n* The idea of the listener giving feedback only in certain circumstances, and using the ground truth caption to do that is interesting and potentially novel.",
            "6": "Weaknesses\n===\n\nThese are roughly ordered by importance.",
            "7": "* (quality) One thing that's still not clear to me is whether the improvement is really because the speaker is modeling the behavior of the listener or whether the ToM listener component is just making it better at image captioning in general.",
            "8": "While the improvement of the \"Zero\" ToM Weight models over the \"Baseline\" can only be due to a general improvement in image captioning ability, the additional improvement of the \"High\" ToM Weight models could still be purely due to an additional increase in general image captioning ability.",
            "9": "This could be measured by looking at the general captioning quality of the various models.",
            "10": "If caption quality stayed the same but listener choice accuracy increased then that would indicate the improvement is really due to the speaker's model of the listener.",
            "11": "Even if caption quality went up some component could still be due to the speaker's model of the listener, so I don't think the issue is straightforward to resolve.",
            "12": "I think the available evidence points toward some contribution from the ToM component, but more work is needed to resolve this with high confidence.",
            "13": "* (suggestion) It would certainly help to have a better measurement of the speaker's overall captioning quality.",
            "14": "The Part Of Speech F1 and Average Length metrics give some sense of this, suggesting the \"High\" models are better captioners, but it should be measured with a more established metric like BLEU, SPICE, or CLIPScore[2].",
            "15": "* (clarity, quality, novelty) The connection between ToM and distractor difficulty isn't very clear, and distractor difficulty isn't very well motivated for studying for its own sake.",
            "16": "This makes it hard to see why the content of section 6.3 was important to investigate.",
            "17": "* (quality) The listener feedback mechanism is interesting, but the paper does not address how it affects performance in the experiments.",
            "18": "How often does the ToM listener receive GT feedback?",
            "19": "How does that change over the course of training?",
            "20": "This matters because we expect NNs not to be well calibrated by default, and over-confidence could result in this mechanism simply being ignored (with P_max always greater than theta_2 in eq.",
            "21": "(2)).",
            "22": "* (clarity) The notation is confusing at times.",
            "23": "The reranking weight and caption words both use the letter w with different subscripts.",
            "24": "The w_{n^u} notation is never explicitly defined.",
            "25": "(Is n the summation variable in eq.",
            "26": "10?",
            "27": "Isn't P_ToM a conditional distribution?).",
            "28": "I can't understand how the ToM listener is trained because I don't understand eq.",
            "29": "10.",
            "30": "Is it supposed to assign high probability to all possible choice images given the caption that the speaker assigns them?",
            "31": "Or is it suppose to assign the same label as the actual listener given the choice already made by the listener and the caption the speaker assigns to that choice?",
            "32": "* (quality) The paper does not argue (either empically or rhetorically) whether the diverse choices used in re-ranking are diverse enough for re-ranking to be very meaningful.",
            "33": "Often LM samples can be rather redundant and may not always include good choices.",
            "34": "Is that the case here?",
            "35": "* (novelty) This work does not cite [1] even though it is very similar.",
            "36": "Both works take an image captioning speaker agent and add an internal component which makes the speaker produce utterances that are more discriminative between target and distractor images.",
            "37": "I think this work is still different because it is motivated by ToM and thus incorporates feedback from the listener to direct the discriminativity, unlike [1].",
            "38": "* (clarity) RQ1 and RQ2 are not very clear as stated.",
            "39": "In RQ1 I see \"the performance\" of \"said models\" as referring to their ability to get the other agents to perform well.",
            "40": "If it is the listener then perhaps this makes sense, but at this point its not clear whether the listener or the speaker is referred to as \"said models\" This is also the first mention of RQ2, or at least I'm not immediately sure of how it relates to the intro having been read so far or how it relates to RQ1.",
            "41": "A clear definition of what the environment is would be helpful here.",
            "42": "Later on there is also a disconnect in flow between section 6.2 and section 6.3, and this would help improve that.",
            "43": "* (clarity) In section 2.1 I is initially referred to as a _set_ of images, while I^N seems to be referencing the same set later.",
            "44": "For consistency I^N should be used in the first case or some other adjustment should be made.",
            "45": "* (clarity) \"However, the language network parameters are additionally trained [...] to optimize the network values\": I don't understand how the listener is trained.",
            "46": "Is the COCO train dataset is used?",
            "47": "* (clarity) What exactly are the \"easy\" distractors?",
            "48": "I'm guessing they are randomly selected COCO images, but that should be verified and made clear in the text.",
            "49": "* (clarity) The \"Return\" metric is not defined or referenced in the results section.",
            "50": "[1]: Vedantam, Ramakrishna et al.",
            "51": "“Context-Aware Captions from Context-Agnostic Supervision.” 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017): 1070-1079.",
            "52": "[2]: Hessel, Jack et al.",
            "53": "“CLIPScore: A Reference-free Evaluation Metric for Image Captioning.” ArXiv abs/2104.08718 (2021): n. pag."
        },
        "3wmNQCIKiH8": {
            "0": "Strengths\n* Clear connection from the problem statement to the empirical experimentation\n* Clearly written.",
            "1": "Relatively easy to understand results and modeling formulation\n\nWeaknesses\n* While the findings related to the inclusion of the ToM component are obvious from Table 1, the effects of distractor difficulty in Table 2 are less obvious.",
            "2": "It's not obvious how the Model Distractors are connected to the claims of distractor difficulty.",
            "3": "However, the distinction to the Gold Standard are very clear."
        },
        "rkFVXYdm0hs": {
            "0": "Strength\n1.",
            "1": "Inspired by theory of mind in cognitive science, a critical mechanism of language learning is the ability to infer the mental states of other agents in social environments, the paper presents language-learning agents equipped with ToM.",
            "2": "2.",
            "3": "The paper finds that incorporating ToM into the speaker models leads to improvements in speaker performance and incorporating harder distractors leads to the development of more complex and fluent languages.",
            "4": "Weaknesses\n1.",
            "5": "The problem setting is very limited with vocabulary of 200 words and the max utterance length is 20 tokens.",
            "6": "Yet the paper makes very strong claims on answering two fundamental questions:\nRQ1.",
            "7": "Does the inclusion of ToM in language acquisition models improve the performance and learned language of said models?",
            "8": "(internal ToM mechanism)\nRQ2.",
            "9": "How do our models’ learned languages adapt to discriminate between more visually and semantically similar images?",
            "10": "(external environmental pressure)\n\n2.",
            "11": "The model design is presented as it is.",
            "12": "There is no discussion on alternative designs and whether the design choice achieves the desired goals.",
            "13": "For example, why LSTM is used.",
            "14": "Would transformer or pretrained language model be a better choice."
        },
        "soEEke1CU6H": {
            "0": "# Strengths\n\nThis paper presents a number of interesting results in a simulated language learning environment and explores a number of sensible hypotheses about how modeling and dataset choices change the learned languages (though several of these have been explored already - see Weaknesses below).",
            "1": "I think the most interesting contribution of this paper (which is highlighted by the title) is the learned ToM-style internal listener model.",
            "2": "Authors are correct that in a lot of the rational speech acts literature, the speaker is allowed to explicitly optimize against the known parameters/probabilities of the partner listener model.",
            "3": "Showing that speakers can build internal model of listeners from a weaker supervision signal (just listener choices in certain contexts), and still use this to improve generation, is an interesting finding and likely to be useful to the broader community.",
            "4": "# Weaknesses\n\nThe weaknesses I see in the paper have to do with missing contextualization with related work (most salient), a confusion about some of the modeling details (equation 10), as well as some lesser concerns about the broader applicability of this work as a whole.",
            "5": "## Missing contextualization with related work\n\nI believe this paper has more similarities to related work than it lets on.",
            "6": "One clear lacuna is discussion with Rational Speech Act models of pragmatic language use.",
            "7": "In particular, the idea of an internal listener model that is used to rerank utterances is precisely the \"pragmatic speaker\" formulation in RSA which optimizes utility of an internal literal listener.",
            "8": "This idea was precisely implemented in [Andreas and Klein, 2016](https://arxiv.org/abs/1604.00562) which authors correctly note.",
            "9": "But the similarities are much more than that: Andreas and Klein precisely propose \"sample and rerank RSA\" where candidate utterances are sampled from a speaker model, then rereanked with an internal listener module.",
            "10": "This process is *identical* to the ToM speaker, the only difference being that the ToM listener is learned.",
            "11": "Andres and Klein also define the same tradeoff between optimizing for the listener probability vs optimizing the speaker probability of utterance.",
            "12": "I think these similarities should be highlighted more beyond just \"we draw inspiration from.\"",
            "13": "Another relevant paper is [Amortized RSA](https://arxiv.org/abs/2006.00418) which trains a model directly to maximize likelihood via gumbel-softmax (similar to the strictly communicative objective in section 3.1 of this paper, though here PPO is used as the optimizer).",
            "14": "Again this is with a fixed listener model; I think the current paper should more clearly highlight the idea of using a learned listener model as the key differentiator over existing work in data-driven RSA.",
            "15": "The idea of increasing difficulty of reference games by making distractors more similar is also a common idea in the literature, e.g.",
            "16": "this experimental condition has been explored in [Monroe et al.",
            "17": "2017](https://aclanthology.org/Q17-1023/), [Achlioptas et al., 2019](https://arxiv.org/abs/1905.02925) etc, and indeed show positive effects on the pragmatics and complexity of language when trained in \"harder\" games.",
            "18": "Another relevant paper which should be discussed is [Lazaridou et al., 2020](https://arxiv.org/abs/2005.07064) which examines the idea of initializing a pretrained image captioning model, then finetuning it with a communicative reward, similar to the present study, as well as using the listener model (jointly learned with the speaker) to improve generations.",
            "19": "Note that they (and many in the literature) observe this phenomenon of semantic drift, i.e.",
            "20": "speakers begin to use language in ways not implied by the original static training dataset.",
            "21": "Did authors find this phenomenon here?",
            "22": "## What's happening in Equation 10?",
            "23": "Equation 10 (ToM objective) and its description are confusing to me.",
            "24": "Equation 9 shows $P_{ToM}(I_t \\mid u^j)$ playing the role of the listener, i.e.",
            "25": "a probability distribution over images $I_t$ given utterances $u^j$.",
            "26": "But here in Eq 10 we are evaluating $P_{ToM}(w_u^n)$.",
            "27": "What does this mean?",
            "28": "What is $w_u^n$?",
            "29": "(Seems overloaded with the ToM hyperparameter $w_l$).",
            "30": "What is the summation index variable?",
            "31": "Description says the ToM objective is \"defined as the cross-entropy loss between the distribution of the ToM listener and that of the speaker\".",
            "32": "Should \"speaker\" be \"true listener\" here?",
            "33": "This is more aligned with \"untrained listener trained to emulate the actual listener's outputs over time.\"",
            "34": "I have a mental model of what is going on here (that we are training the ToM listener to mimic the actual listener, whenever we actually get listener choices), but I'm not sure if this is actually happening as I found this section difficult to parse.",
            "35": "It's possible I'm misunderstanding something here, and I can't be too confident in my recomendation until this is cleared up.",
            "36": "## Unclear whether this is a realistic setting for either NLP/CogSci communities\n\nThis paper certainly has some interesting experiments and modeling contributions, but one weakness I see (and I think this is true of many computational simulations of language acquisition, e.g.",
            "37": "emergent communication) is the degree to which this is a particularly useful simulation for either (1) giving us better NLP systems, or (2) teaching us about language development.",
            "38": "Re: (1), it would be great if authors gave us more concrete settings or potential applications where training a speaker model in this kind of fashion, with natural language feedback, might be useful for building better NLP systems.",
            "39": "Re: (2), there are a lot of ad-hoc hyperparameter choices in this simulation environment (e.g.",
            "40": "the thresholds at which listeners choose to abstain from providing feedback, or provide the ground-truth caption; the various hyperparameter tradeoffs between speaker objectives) that could drastically change results.",
            "41": "If results are fairly sensitive to such ad hoc hyperparameter choices, then we should be careful to make broad sweeping conclusions about what this tells us about human and/or machine language development.",
            "42": "Moreover, it's a little unclear how authors intend, in the conclusion, for this study to support further investigations into the \"similarity of the learning process between human learners and our computational models.\"",
            "43": "Babies learn in naturalistic environments, certainly aren't initialized with ResNets, and do far more than just play referring expression games.",
            "44": "I don't view this as a fatal weakness of the paper - I think these are fundamental problems that a lot of papers in this kind of line have, and this debate need not be resolved here.",
            "45": "## Other minor considerations\n\n- It would be great to have an explicit measure of the ToM model success, i.e.",
            "46": "how well does the ToM listener approximate the real listener throughout training?",
            "47": "I'm interested in a more isolated metric for measuring this beyond just \"the full ToM speaker does better\".",
            "48": "If we get very close to the true listener then it makes perfect sense that ToM modeling would improve generation.",
            "49": "- How much is the \"learning from feedback\" objective required to get learning off the ground in this setting?",
            "50": "Assuming the LSTM is not pre-initialized (which I don't think it is), It seems extremely difficult to learn a good NLG policy from scratch given the massive complexity of the natural language search space.",
            "51": "What happens when this objective is turned off?",
            "52": "How often is natural language feedback given?",
            "53": "- I find the use of \"learning from feedback\" to be a bit misleading compared to how the term \"feedback\" has been traditionally used in the literature (e.g.",
            "54": "[1](https://arxiv.org/abs/2204.14146), [2](https://arxiv.org/abs/2009.14715)) - \"feedback\" implies some language corrections or explanation for why a referring expression is correct/incorrect, but in reality this is just providing the ground-truth label to the agent (which you then optimize for explicitly).",
            "55": "- Notation is a little convoluted at times, e.g.",
            "56": "eq 7 $w_{u^j_1}$, is it really necessary to have these multiple nested subscripts?",
            "57": "- I think the conclusion statement that \"psychological modelling communities...consider the further incorporation of ToM into language learning simulations\" may be slightly uncouth, given that theory of mind is a central idea in an extremely long line of literature in both computational and non-computational pragmatics dating all the way back to Grice.",
            "58": "- I would advise authors to be careful about what constitutes \"better\" language, and claims that the speakers trained with harder distractors have strictly higher obejctive measures of \"utterance quality\".",
            "59": "If we adopt a fully pragmatic view of language, then the best language should be as concise as possible given the context, and with simpler distractors, it makes sense that the language is simpler - that is the world they are trained on, after all.",
            "60": "It'd be interesting to see whether speakers trained on a mixture of context difficulties can modulate the complexity of their utterances when the context demands it."
        }
    },
    "WZH7099tgfM": {
        "NKLA9TEpeY": {
            "0": "The proposed technique is new and interesting.",
            "1": "It is a nice addition to the literature on prompting large language models to solve complex tasks.",
            "2": "I see a major limitation with this approach: it looks like the prompt examples need to be designed specifically for each dataset.",
            "3": "Additionally, the prompt examples add significant supervision on how the task should be solved, and this supervision is not present when using other methods (such as standard prompting).",
            "4": "For instance, in the symbolic manipulation task, the examples for least-to-most prompting are constructed by exploiting the property \"concatenating the last letters of $n$ words is the same as concatenating the last letters of the first $n-1$ words, and then concatenating the result with the last letter of the $n$-th word\".",
            "5": "In my opinion, learning this property is an important part of learning to solve the task algorithmically."
        },
        "vyvgi9yokm": {
            "0": "STRENGHTS\n+ As in CoT the proposed method does not require any training or fine-tuning.",
            "1": "The experiments reported here can be done solely by interacting with the API of a large language model provider\n+ The performance jump is significant on problems considered difficult\n\nWEAKNESSES\n- The prompt are designed task-specific.",
            "2": "It is not clear what was the validation set to create those prompts.",
            "3": "A robustness study on using different prompts would be welcome and strengthen the message that the results hold across a variety of lexical variations of the same idea \n- Clarity of the paper (see below)"
        },
        "j3A7iNoaDhO": {
            "0": "Strength\n1.",
            "1": "The paper proposes a new prompting strategy for big language models to solve multi-step reasoning tasks.",
            "2": "It breaks the problems into sub-problems by querying the language model, and then solves each sub-problem sequentially.",
            "3": "2.",
            "4": "The paper shows that the proposed least-to-most prompting significantly improves over the prior work, chain-of-thought prompting on three tasks, symbolic manipulation, compositional generalization and math reasoning.",
            "5": "Weaknesses\n1.",
            "6": "A major limitation of the paper is the problem reduction step.",
            "7": "Since the three datasets are relatively constrained, the few demonstration examples may cover most of the cases on how to break into sub-problems.",
            "8": "In other words, the model may only need to copy patterns from the few-shot demos without any generalization.",
            "9": "2.",
            "10": "The paper lacks insights on key questions.",
            "11": "Does the model have ability to decompose questions very different from demo examples into correct sub-problems?",
            "12": "Even the model solves each sub-problem correctly, what makes the model compose the final solution correctly?",
            "13": "3.",
            "14": "The paper needs to evaluate on more reasoning problems (e.g.",
            "15": "StrategyQA, high school reading comprehension) or clearly state the type of reasoning problem the method works well.",
            "16": "It needs a better limitation section that what is stated in the conclusion and discussion section."
        },
        "toPOQbIVcD": {
            "0": "Strengths:\n- The problem of teaching language models new skills \"on the fly\" is extremely relevant\n- The paper has numerous illustrations, which helps to understand the approach and model behavior\n- The approach is novel and original\n\nWeaknesses:\n- There are a number of issues with experimental design.",
            "1": "I detail those in the \"quality\" section of the review.",
            "2": "- In terms of reproducibility, some elements of the approach are not very clearly reported, specifically, in the first two experiments, the authors say that either a script or simple prompting can be used (for decomposition in experiment 1, and for expanding python expressions), and it's not specified what was actually used.",
            "3": "Here is one of the relevant quotes: \n\"To generate the final results, we either run a postprocessing script or prompt language models to expand the Python expressions.",
            "4": "It is straightforward to teach language models to expand Python expressions via a few demonstrations.",
            "5": "However, I can not find a more detailed description nor the results on the performance of these straightforward expansions.",
            "6": "While straightforward from the prompting standpoint, it might still result in less than perfect accuracy & providing exact prompts is crucial for replication.",
            "7": "- While thorough, the abundance of tables and model input/output printouts is, at times, getting in the way of readability."
        }
    },
    "btmflCmNxDl": {
        "OBpfGApPbz": {
            "0": "Strengths:\n\n* Simple technique for assisting the learning of generators and discriminators using a co-operative technique rather than adversarial technique \n\nWeakness:\n\n* Several cooperative GAN based augmentation systems have been proposed and the novelty is extremely low.",
            "1": "* The experiments only show some NLP based experiments and no Vision based experiments.",
            "2": "* Ideally the model should also work with image generation but the conspicous absence indicates the non-generality of the technique\n* The proofs are hand wavy and not concrete."
        },
        "MN0z08ywamr": {
            "0": "Strength:\nThe paper proposes a self-consistent learning framework to enable cooperative training of the generator and the discriminator.",
            "1": "The generator and the discriminator are trained alternatively until reaching a score consensus.",
            "2": "This framework makes plenty use of the limited labeled data and large-scale unlabeled domain-related corpus.",
            "3": "Weaknesses:\nThe paper formulates the main theoretical result into theorem 1, but the proof of theorem in the Appendix is not obvious.",
            "4": "In particular, how do you derive from the first line optimization problem to the second optimization problem.",
            "5": "Could you provide further detailed proof for the theorem?",
            "6": "The choice of the dynamic threshold looks quite arbitrary, could you provide some criterion for the parameter selection?"
        },
        "Kaq4fAMa7h4": {
            "0": "Strength: different from GAN where generator and discriminator are in a competitive learning strategy which is difficult to train, and difficult to use the generator data in further training (it is difficult to judge the quality of the generated data samples ), authors' idea with self-consistency learning could learn both the generator and discriminator in a cooperative way to enhance each other.",
            "1": "Therefore, the training is stable and guarantee to converge.",
            "2": "Weakness: The dynamic threshold design as given in Eq.",
            "3": "3 seems important in deciding the selection of the data, however, authors gave a simple incremental formulation in later part for designing the dynamic threshold.",
            "4": "And there is no further explanation and ablation study on the design of the dynamic threshold."
        },
        "vUmOlxWsF7": {
            "0": "Strength: The paper is well-organized, and the main ideas are interesting, and easy to understand.",
            "1": "The proposed method is evaluated on multiple datasets with good performance in sentence sematic matching.",
            "2": "Weakness: 1.",
            "3": "The work included both positive and negative samples in the training of discriminator, and claimed cooperative setting can lead to better training stability than adversarial setting.",
            "4": "The idea makes sense but it is not clear to me how this point is supported either in theoretical or experimental aspects.",
            "5": "2.",
            "6": "The definition of the output probability for generator $p_G$ cannot be found.",
            "7": "3.",
            "8": "It is mentioned in Eq (1) that $p_D$ depends on the embedding representation H of generated samples.",
            "9": "Since it is shown in the paper that the selective mechanism is important to the performance, I think it would be helpful to provide more details on this embedding process, and some evidence or explanation to justify the resulting output probability is somehow “good enough” for selective mechanism.",
            "10": "4.",
            "11": "It is mentioned in page 4 that both positive and negative samples would be included in the training of discriminator, (which is a key difference between this method and GAN.)",
            "12": "Due to the lack of information on the embedding representation, I fail to see why Eq (2) can make sure of this."
        }
    },
    "8IN-qLkl215": {
        "hJ-lqv3w8d": {
            "0": "Strength:\n\nThis work proposes a new architecture for augmenting language modeling with auxiliary visual cues.",
            "1": "The authors tested multiple evaluation datasets for their proposed and other candidate models.",
            "2": "The improvement in these datasets compared to the other models tested in this work is significant.",
            "3": "The authors also show some ablation studies that the proposed image retrieval module helps the performance.",
            "4": "Weakness:\n\nThe biggest worry I have is about the evaluation in this work, which is critical to be resolved before I can fully back the acceptance of the paper.",
            "5": "The pure language model tested in this work is a GPT-2 retrained by the authors on the same text corpus.",
            "6": "And the other visual augmented models are all pretrained models from other papers.",
            "7": "None of these comparisons can be perfectly fair on the training datasets.",
            "8": "However, it seems that the model size is controlled, as this model uses a pretrained CLIP model during its training and is augmented by a large image database.",
            "9": "If the training dataset can never be perfectly controlled, why not try models trained on much larger text corpus, such as the pretrained OPT models?",
            "10": "Besides this, the numbers on these benchmarks seem to be also lower than the numbers I can find in other papers.",
            "11": "For example, in the paper “Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?” (about the Memory Color dataset), Table 4 shows numbers much higher than the numbers reported in this paper.",
            "12": "Can the authors explain this difference?",
            "13": "Another minor issue about the evaluation is: what would be the current up-limit on these evaluation datasets from pure-language models?",
            "14": "Have people tested the largest pretrained models on these datasets?",
            "15": "Are these problems really hard for the models to resolve?",
            "16": "To help correctly evaluate the innovation of this work, can the authors also comment on how different this fusion layer proposed here is from the fusion layer in the Google Flamingo paper?",
            "17": "This is more of a question instead of an issue.",
            "18": "It would be great to see how reducing the number of images in the auxiliary image database will influence the performance.",
            "19": "I would imagine that having these images during the real-time inference makes the inference very slow, about which I cannot find any time estimation from the paper.",
            "20": "So this could be an issue for real-world applications.",
            "21": "To be clear, I don’t think this issue needs to be addressed in this work right now, but I want to get a sense of how annoying this is.",
            "22": "Finally, it would be good to know how the scaling will influence the results.",
            "23": "Will large models like 350M make the performance better?"
        },
        "se5ACUT53z": {
            "0": "Strengths:\n1.",
            "1": "The research problem of how to inject visual information into language modeling for visual-demand tasks is interesting.",
            "2": "The method is intuitive and novel to a certain degree.",
            "3": "2.",
            "4": "In many datasets, the performance of the proposed model outperforms compared methods/baselines \n\nWeaknesses:\n1.",
            "5": "Indexing images, retrieving images and fusing image features to PLM all take extra computation and time as opposed to original PLM, especially retrieving I think.",
            "6": "The analysis of additional training and inference time brought by the proposed method should be added.",
            "7": "2.",
            "8": "Lack of experimental comparison against recent visual-augmented language model works.",
            "9": "For example, Vokenization and iACE.",
            "10": "3.",
            "11": "The database image quality matters for the retrieval and downstream task performance.",
            "12": "But the ablation/analysis is missing.",
            "13": "I mainly have two questions: (1) Does the dataset have to be an image-text dataset, such as ImageNet?",
            "14": "Theoretically, it can also be an image-only dataset since CLIP is already trained.",
            "15": "(2) Does the size of the database matter?",
            "16": "How about we only take 100M, 10M, or even 1M data from Laion?",
            "17": "4.",
            "18": "Some unclear illustrations.",
            "19": "(1) In Sec2.3, is z_ij the image feature output from the same CLIP image encoder used in retrieval?",
            "20": "(2) In the 3rd last sentence of Sec3.4, shouldn't it be \"adopting image-specific bias outperforms directly sharing the bias\"?"
        },
        "x1wvct0mAUB": {
            "0": "\nStrengths\n===\n\nIncorporating visual background knowledge in a language only model makes a lot of sense and seems novel.",
            "1": "Furthermore, VaLM is a simple and effective realization of the idea in practice.",
            "2": "The writing is clear and straightforward, without frills.",
            "3": "Weaknesses\n===\n\nThere are couple areas where the model should have been evaluted:\n\n* There is limited analysis of the images retrieved by the retrieval module.",
            "4": "Using the figure 1 example, the idea is that it will say the sky is blue because the retrieved images tend to be blue.",
            "5": "Are the retrieved images consistent with its answer?",
            "6": "That is, given that it says the sky is blue, does it actually retrieve images where the sky is blue?",
            "7": "If the retrieved images are manually substituted with alternative images where the sky is green then does VaLM say the sky is green?",
            "8": "It would be good to have a systematic evaluation of the retrieved images, but it would also help to simply provide examples.",
            "9": "* A related concern is about the images recalled for each piece of a sentence.",
            "10": "As I understand it, the visual knowledge fusion layer recalls a different set of K images for each sentence part (e.g.",
            "11": "different images for \"The color\", \"The color of\", \"The color of sky\", etc.).",
            "12": "How do the recalled images vary over the course of the sentence?",
            "13": "Do they stay the same when non-semantic words like \"of\" are used?",
            "14": "Do they change appropriately when semantic words like \"sky\" are used?",
            "15": "* There is no evaluation of how this impacts the model's runtime.",
            "16": "How long does a forward pass take when generating every word requires a kNN lookup?",
            "17": "There are also some points where the presentation could be clearer:\n\n* The motivation in 3.2 (\"object properties rarely appears in text corpora\") seems like it should also belong in the introduction.",
            "18": "To me this is a key reason to expect this approach to be helpful.",
            "19": "* The text doesn't mention what the \"Majority\" row in Table 4 means.",
            "20": "Finally, here are some minor suggestions and comments:\n\n* The attention mechanism over K retrieved images is novel, but a fairly straightforward extension of the attention mechanism once one has already decided to retrieve relevant images.",
            "21": "The major contribution is in retrieving relevant images.",
            "22": "* Can VaLM be used as a vision-language model?",
            "23": "Essentially, what if it was given vision and langauge tasks (e.g., VQA) and then the image retrieval module was replaced with a module that simply returned the image(s) associated with the VL task example?",
            "24": "Would it perform well at the VL task?",
            "25": "In general, does it treat the retrieved images as global / abstract context or does it also consider them as specific context local to those images?"
        },
        "8sqgxzaVdv": {
            "0": "**Strengths**:\n\n-- The empirical results in the paper are quite strong and surpass pre-trained text models (GPT) as well as vision-language models (VisualBERT) on 4 reasoning task datasets and several language understanding/modeling tasks.",
            "1": "While the differences in language-only tasks is small, the gains compared to baselines in visual reasoning tasks is large as claimed.",
            "2": "-- The proposed model (esp visual knowledge fusion component) is novel and elegant and simple, which will serve as motivation for following works.",
            "3": "-- The paper is clearly written and easy to follow.",
            "4": "**Weaknesses**:\n\n-- The main weakness in the method is the use of frozen image retrieval component.",
            "5": "The concern is that if this component is not end-to-end trained with the rest of the model, will the model quality be limited by the quality of image retrieval.",
            "6": "While the reviewer acknowledges that empirical results show a large gap between CLIP and VALM on all tasks, it is worth wondering if the gains are due to embedding multiple images with text in VALM (compared to single image-text pair used originally in CLIP).",
            "7": "An ablation with different values of k (number of images retrieved) will be helpful here."
        }
    },
    "1PL1NIMMrw": {
        "Xmahv9YzhQX": {
            "0": "Strength:\n1 Motivation is straightforward.",
            "1": "2 The method is simple and effective.",
            "2": "3 The author conducted a variety of experiments to assess the method’s performance.",
            "3": "Weak:\nSelf-consistency is an interesting point.",
            "4": "However, my main consideration is that this paper does not go deep enough into the study of self-consistency.",
            "5": "This lack of depth is mainly reflected in two perspectives (1) only the majority vote of multiple randomly generated answers is considered.",
            "6": "There is a lack of in-depth observation on how to combine different answers; (2) different answers are obtained by controlling the temperature and k. For text generation, the effect of these two hyperparameters is unclear.",
            "7": "In particular, how these two hyperparameters affect answer consistency is unclear.",
            "8": "Other weak points:\n1 Experiment results suggest that LM cannot distinguish well between correct and incorrect answers (at least from the aspect of token probability), but why taking majority vote over answers generated from different reasoning paths works?",
            "9": "More in-depth studies should be done.",
            "10": "2 Since “diversity of reasoning paths is the key to better performance”, why other ensemble-based approaches (e.g.",
            "11": "the multiple prompts setting) didn’t get larger gain for their diversity?",
            "12": "3 Figure 2 is confusing: why greedy decode has different number of sampled paths?",
            "13": "4 It would be better to show full sampled paths in table 4 and other examples if the purpose is to claim self-consistency can repair errored reasoning process."
        },
        "b9ovzdXUBVu": {
            "0": "**Strengths**\n\nProposes a simple and effective decoding strategy to improve LMs with CoT prompting.",
            "1": "Contains extensive experiments with different LM types and sizes that demonstrate large gains compared to vanilla CoT without requiring additional training.",
            "2": "Self-consistency strategy surfaces diverse outputs that correspond to rationales in CoT-prompted LMs and improves robustness to imperfect inputs.",
            "3": "Also, it can provide uncertainty estimates for calibration.",
            "4": "**Weaknesses** \nThe decoding strategy itself has limited novelty since sampling strategies (including nucleus sampling) and ranking according to model scores have been previously used for pre-trained LMs albeit not with CoT prompting.",
            "5": "Even though it generally leads to improvements, the proposed decoding strategy creates a significant overhead proportional to the number of outputs sampled e.g 5x latency for 5 samples assuming that samples have equal lengths.",
            "6": "The marginalization process of self-consistency assumes that answers are coming from a fixed answer set, which decreases the scope of applicability."
        },
        "0k-CSaozoC": {
            "0": "Strength: \n1.",
            "1": "The self-consistency method is very well motivated, and authors did a great job presenting this motivation.",
            "2": "The method is very principled.",
            "3": "2.",
            "4": "The empirical evidence of the superiority of the method is extensive and solid.",
            "5": "Weakness: authors’ notation of r_i is a bit unclear to me, my understanding is that they are just the generated text before the final answer (what authors call reasoning path).",
            "6": "It is not clear to me what is the difference between the generated text before the final answer and what authors call the reasoning paths.",
            "7": "Did authors do something specific to exclude some potentially irrelevant text that were generated but did not contribute to reasoning?",
            "8": "If not, perhaps calling them reasoning paths is a bit confusing?",
            "9": "It seems r_i and a_i always appear together, which gives me the impression that the only distinction is that a_i is the final answer and r_i is everything before that.",
            "10": "Another confusion is the presentation of the weighted sum, is it correct to understand the probability weight is just the logsumexp of the logprobs of the generation?",
            "11": "That makes sense to be, equations 1 is a bit misleading to me because it seems to place an emphasis on r_i as being the reasoning path when it’s just the probability of a specific generation.",
            "12": "I think it is okay to mention the generation is supposed to be reasoning paths, but it might be more clear to just note them as generated text in those formal expressions."
        },
        "wpzePxnSHFM": {
            "0": "- **Clarity:** The paper is very clearly written and is easy to understand.",
            "1": "The takeaways from each section are clear and flow from one to the other.",
            "2": "- The tasks, baseline sampling techniques, models and various tradeoffs while using different hyperparameters have been explored well!",
            "3": "They give a clear picture of what is useful in a practical setting.",
            "4": "- **********************************Reproducibility:********************************** The method is easy to implement, but not all the models are publicly available or are accessible only through a paid API.",
            "5": "- The method itself is quite general and can be used across several task types and models.",
            "6": "- Further Discussion: CoT/ Scratchpads are useful in understanding the output of a model; how would the authors suggest choosing a reasoning path to provide an explanation for the answer given by the model?",
            "7": "- ******************************Novelty:****************************** The paper is novel in its approach.",
            "8": "- ******************Quality:****************** The paper, analysis and writing are of a very high quality"
        }
    },
    "UROBiQEOLP": {
        "tIwPhXi3Iil": {
            "0": "Pros: Interesting idea, extensive experimental evaluation against the standard baseline, correct derivations.",
            "1": "Cons: The method is a minor extension upon existing techniques; the authors do not explain how more computationally demanding this method is compared to the baselines, and whether these extra costs are worth the extra accuracy."
        },
        "K-u53XvvHx": {
            "0": "**Strengths**\n\n- **Relatively simple/general technique.",
            "1": "** The basic idea of the proposed technique is to identify the softmax logits of an autoregressive model as an energy function, allowing them to replace the typical maximum log-likelihood training procedure with a contrastive-divergence-based training procedure.",
            "2": "This is reminiscent of previous methods that have interpreted classifiers as energy-based models (e.g., Grathwohl et al., 2020).",
            "3": "In this way, the model is explicitly trained by decreasing the likelihood of generated samples, hopefully reducing the effect of “exposure bias.” Notably, this procedure can, in principle, be applied to any discrete autoregressive model, making this a rather general technique.",
            "4": "- **Experiments on multiple datasets with relevant baselines.",
            "5": "** The authors demonstrate their proposed approach on language modeling and translation tasks, with three language modeling datasets and one translation dataset with six translation pairs.",
            "6": "The authors compare their approach with the baseline autoregressive model, as well as Residual EBM, another method that combines autoregressive and energy-based models.",
            "7": "The proposed approach generally compares favorably.",
            "8": "- **Clear description, for the most part.",
            "9": "** The descriptions within the paper are generally clear, with both text and mathematical terms well-defined.",
            "10": "One way to improve the clarity of the paper even further would be to include some form of diagram.",
            "11": "**Weaknesses**\n\n- **Additional computational overhead for sampling.",
            "12": "** One downside of employing a contrastive divergence-based training method is that it requires sampling during training.",
            "13": "Sampling from autoregressive models is typically quite costly, and I would guess that this significantly impacts training speed (although this isn’t discussed in the main paper).",
            "14": "- **Only applicable (at least currently) to discrete models.",
            "15": "** The current method, as presented, is only applicable to discrete autoregressive models.",
            "16": "While this encompasses a wide variety of applications, the authors have not demonstrated how to apply this technique to continuous autoregressive models, e.g., those that output Gaussian densities.",
            "17": "In this sense, the title is a bit misleading, as the technique does not apply to all ‘autoregressive models.’\n\n- **Only demonstrated on text data, i.e., no images or audio, etc.",
            "18": "** The authors only demonstrate their technique on text data (language modeling and translation, i.e., conditional language modeling).",
            "19": "However, even with discrete autoregressive models, this technique could be readily applied to image and perhaps audio modeling.",
            "20": "Currently, the paper may only appeal to a subset of the machine learning community focused on language, but with these added application areas, the paper may receive wider attention."
        },
        "XToTURAEHt": {
            "0": "\nStrength:\n-The paper is well-written and easy to follow.",
            "1": "-The idea of viewing AR models as EBMs is not novel but the provided formulation is neat and interesting.",
            "2": "-I like the extensive study of the proposed approach.",
            "3": "Weakness:\nThe improvement especially in the translation tasks is not considerable.",
            "4": "Other training algorithms on top of ML training of AR can achieve similar improvement, for example, combining it with RL training.",
            "5": "Bhattacharyya et al.",
            "6": "(2021) reported a significant improvement over base AR-NMT by using an external EBM defined over the whole sentence (although some of the improvements come from using pre-trained language models).",
            "7": "Also, their training algorithm can directly be applied to AR by viewing E as \\sum_i E_i.",
            "8": "Questions:\n1) The author claims this approach can help with long-range dependencies, but I am not seeing how defining the energy model using the last softmax can help with that.",
            "9": "Is that the effect of weights on training log q(x<k)?",
            "10": "Even so, it is not similar to defining an explicit energy model over the whole sentence!",
            "11": "Bhattacharyya S, Rooshenas A, Naskar S, Sun S, Iyyer M, McCallum A. Energy-based reranking: Improving neural machine translation using energy-based models.",
            "12": "ACL 2021."
        }
    },
    "qFVVBzXxR2V": {
        "-fnumUUC9m": {
            "0": "Strengths:\n1.",
            "1": "It’s great that the authors evaluate both validity, atomicity and wether a step is misleading.",
            "2": "These are very important metrics.",
            "3": "2.",
            "4": "Results in Figure 3 are very powerful!",
            "5": "3.",
            "6": "The three observations on page 8 are very informative.",
            "7": "4.",
            "8": "If the analysis code is made available, I can imagine this being a very useful tool for people to measure reasoning progress.",
            "9": "However, this would be better if it had leveraged existing datasets e.g.",
            "10": "ProofWriter.",
            "11": "Weaknesses:\n1.",
            "12": "The authors ignore a significant chunk of prior work.",
            "13": "2.",
            "14": "They propose a novel dataset, while there already exists a dataset, ProofWriter, that would have been suitable for these experiments and work by Betz et al.",
            "15": "2020 is also relevant (see detailed comments below).",
            "16": "3.",
            "17": "The title is somewhat miss-leading.",
            "18": "I would suggest only using the second half of the title.",
            "19": "4.",
            "20": "Some of the claims are not supported, \"Reasoning is an emergent ability\".",
            "21": "5.",
            "22": "Authors only show results for a single model."
        },
        "IBWWxV9U9f": {
            "0": "The authors’ dataset is quite similar to the ProofWriter dataset released by Allen AI.",
            "1": "But the breakdown into fictional, false and true ontologies is novel and useful, and provides insight into the models’ capabilities.",
            "2": "I have some questions and thoughts.",
            "3": "The authors write: “the most permissive accuracy metric has the highest correlation with label accuracy, suggesting that GPT-3 is indeed performing the reasoning to answer the question, rather than relying on heuristics” (p.6).",
            "4": "I don’t see how this conclusion follows.",
            "5": "Isn’t this assuming causation from correlation?",
            "6": "Also, since “valid proof accuracy” is strictly weaker than “strict proof accuracy”, isn’t it inevitable that the points in the scatter plot below the perfect line will be higher in the former compared to the latter?",
            "7": "Wouldn’t this be the case however the model arrived at the answer?",
            "8": "The authors write: “Once InstructGPT encounters a branch where one path at the fork follows the correct proof and the other paths do not, InstructGPT will select the incorrect direction with some frequency and is then not able to return to the correct path.",
            "9": "Therefore, it seems that while LLMs are able to produce valid proof steps with high probability, they have difficulty with proof planning/strategizing.” (pp.8-9).",
            "10": "This account feels highly speculative.",
            "11": "As the authors obviously know, LLMs like GPT don’t work like this at a fundamental level.",
            "12": "They are just trying, autoregressively, to predict the next token in the given context.",
            "13": "There is no explicit mechanism for “selecting” a branch in a proof tree, let alone for planning or strategizing, so it’s hardly surprising that they struggle with tasks where these things are required (because they are out of distribution).",
            "14": "Maybe some cautionary remarks would be useful here.",
            "15": "The authors write: “we can extend the CoT paradigm where after every predicted step in the CoT, we perform beam search decoding to find the top-k most likely values for the next step.",
            "16": "We can then perform beam search over the proof steps (i.e., sentences) rather than over the tokens.” (p.9).",
            "17": "This has recently been done.",
            "18": "See: A.Creswell & M.Shanahan, Faithful Reasoning Using Large Language Models, https://arxiv.org/abs/2208.14271."
        },
        "OvydwTeF4B": {
            "0": "Strengths\n● The paper is well structured and easy to read.",
            "1": "● Releasing a first order logic dataset for the community to test LLMs reasoning abilities.",
            "2": "Weakness\n● Although GPT-3 is well known in the community, InstructGPT is something not popularly known and it would have helped to have a brief description as to what tasks InstructGPT can perform, along with its pre-training data.",
            "3": "● No mention of the number of entities modeled in the ontology.",
            "4": "● In the results, it would have been nice to know how many samples in the test-bed are used, and how many are valid/atomic/misleading.",
            "5": "● How is this work different from [1] \n● A similar work to test reasoning of LLMs is done in [2], where it was established that LLMs cannot reason, which is in contradiction with the proposal in this paper.",
            "6": "[1]Han, Simeng, et al.",
            "7": "\"Folio: Natural language reasoning with first-order logic.\"",
            "8": "arXiv preprint arXiv:2209.00840 (2022).",
            "9": "[2]Valmeekam, Karthik, et al.",
            "10": "\"Large Language Models Still Can't Plan (A Benchmark for\nLLMs on Planning and Reasoning about Change).\"",
            "11": "arXiv preprint arXiv:2206.10498 (2022)."
        },
        "kgyCtorH4MY": {
            "0": "### Strength:\n\n- The paper introduces a dataset for synthetic reasoning that can be useful for probing the reasoning behavior of LLMs.",
            "1": "The authors take care to remove spurious heuristic solutions from the task setup, and restrict the complexity of the dataset while still maintaining a few knobs of question difficulty that one can use.",
            "2": "- The paper explores several interesting notions of validity, atomicity, and misleading steps, which seems to be a fairly comprehensive perspective for studying reasoning behavior in models.",
            "3": "- The paper makes interesting observations regarding the tendency of the model to skip steps and output misleading steps which are irrelevant to the final answer, and its ability to perform basic deductions well.",
            "4": "### Weakness:\n\n- The paper makes a number of observations that have been similarly made in other papers, such as 1) the model relies on pretrained knowledge to perform reasoning (also discussed in [1] and [2]), 2) longer proofs are more challenging and correct answers can sometimes contain misleading steps (which are well known and have been noted in many papers evaluating LLMs and chain-of-thought on reasoning tasks), and 3) sentence ordering affects performance (also discussed in [3]).",
            "5": "This limits the contributions of this work.",
            "6": "- Several of the directions mentioned in future work seems well within the scope of the current paper and should probably be included to strengthen the current paper.",
            "7": "For example, seeing if including prompt examples containing misleading steps would improve performance is an immediate follow-up to the observation that most errors come from misleading steps.",
            "8": "The beam search of deduction steps is also a reasonable analysis to include in the current work in my opinion.",
            "9": ">Our work shows that relying on CoT prompting is not sufficient for more complex reasoning, such as in mathematical domains.",
            "10": "I don't see how this work shows the CoT prompting is insufficient for reasoning in mathematical domains.",
            "11": "[1] https://arxiv.org/abs/2202.12837\n\n[2] https://arxiv.org/abs/2202.07206\n\n[3] https://arxiv.org/abs/2104.08786"
        },
        "m8ER_E5WF85": {
            "0": "Strengths: \n1) The generative process of example in PROTOQA is logical, systematic, interpretable and traceable.",
            "1": "The process of logical reasoning is very clear.",
            "2": "2) The interesting experiment is sufficient enough and shows us the reasoning condition of the big model.",
            "3": "3) The concepts in the paper are explained clearly, and examples make it easier for readers to understand\n4) This paper allows the neural system and the symbolic system to cooperate in a better way\n\nWeaknesses: \nThe context in the dataset may be monotonous to some extent.",
            "4": "Will the future work experiment on more diversified natural languages?"
        }
    },
    "q9VherQJd8_": {
        "KEI70o0NNy": {
            "0": "Strengths:\n+ Protein-molecule interaction is generally a problem of interest to many communities.",
            "1": "+ The proposed method is an interesting way to combine a protein language model (for the protein) and a GNN (for the molecule), and this method might benefit other problems outside of odor perception.",
            "2": "Weaknesses:\n+ The empirical evaluation is focused on odor perception.",
            "3": "+ While the proposed method is more general according to the authors, the empirical performance does much some of the existing methods (Table 4)."
        },
        "8nA1WjK-4J": {
            "0": "This work represents an important step toward models that can reliably predict protein-ligand interactions, focused on the very interesting case of odorant receptors and small molecules.",
            "1": "The architecture presented is one that is original and sophisticated, and in Section 5.1 the authors make a convincing case that its choices are not arbitrary.",
            "2": "While it is not the first paper to use AI to predict olfactory recognition, previous studies have used much simpler models that rely on SMILES encodings of small molecules; I think especially that the attention mechanism learned over the molecular graphs to learn nonbonded interactions strikes me as an important methodological innovation in this study.",
            "3": "The “Generalization” section of the manuscript is very important, and the authors perform a number of important statistical tests: notably to not only perform random train/test splits of receptors and molecules but also to cluster them, such that members of the test set are relatively different from the training set.",
            "4": "Their models perform quite poorly in these situations, and the authors are honest about this case.",
            "5": "I personally find it to be a strength of the paper that they did this test, although it obviously opens the door to future improvements of the model.",
            "6": "The dataset generated of over 45,000 OR-olfactant pairs is also a strength of this paper and will serve as an invaluable reference for future researchers in the field.",
            "7": "Broadly, I feel that the model is stronger at modeling small molecule space than protein space, especially as the protein sequence representation relies entirely on the pretrained [CLS] tokens of ProtBERT.",
            "8": "I would personally recommend trying a few variations on this, although I wouldn’t say that they are required because I understand that they can be computationally intensive and challenging to add into such an already large model; I would recommend this as a direction of future research (which the authors also note!)",
            "9": "I also think that some technical parts of the paper are somewhat unclear and could use slightly more description.",
            "10": "For example, several aspects of their architecture are not well explained; the message passing neural networks (Q-MPNN and KV-MPNN) are never mentioned in the main text - are these the “two separate identical GNNs for queries and keys/values” mentioned?",
            "11": "If, so that should be made clear, along with what the “Q” and “KV” mean.",
            "12": "The meaning of “X_old”, “X_new” and “E” in Figure 1 are also not described.",
            "13": "I can guess as to their meaning, but it would be better for it to be clearly stated in the legend.",
            "14": "Explaining this terminology will also make the “ablations” section more clear, although there are also a few architectures introduced first in that section (e.g.",
            "15": "GAT) that could be introduced slightly more clearly and justified in their use.",
            "16": "In Section 6, the precise definition of “combinatorial code” for each odorant is also somewhat unclear - I am guessing that they mean that they are the predicted recognition of the odorant by each of the 385 human ORs in the model presented earlier, but this is not explicitly stated.",
            "17": "Therefore, while they are very mathematically precise about how their clustering score is defined, I initially didn’t understand what actual data they were analyzing."
        },
        "80WvG_6oIzW": {
            "0": "Positives:\n- Tackling a new and interesting problem of predicting receptor-odorant binding.",
            "1": "- Proposing a new model involving GNN and BERT embedding for olfactory receptors.",
            "2": "- Thorough ablation study of the model.",
            "3": "- Gathering a new dataset for olfactory receptors.",
            "4": "Negative:\n- The so-called “localization” strategy of adding protein embeddings to the graph, while seemingly improving prediction, does not give any physical interpretation of the underlying binding mechanism of receptors to the odorants.",
            "5": "- Why should all the codes of the graph have the share of the protein embedding?",
            "6": "Intuition says the docking site should play a more significant role than the rest of the molecule.",
            "7": "- The choice of [CLS] as the embedding is not well-justified.",
            "8": "Have the authors done ablation studies over other types of protein embedding for example ESM?",
            "9": "- Most of the empirical studies are ablation type and comparisons to standard methods are very limited.",
            "10": "- How does the model compare with the recently developed SE(3) invariant deep learning models of molecules?",
            "11": "- It is intuitive that the docking site of the protein is more important than the rest.",
            "12": "Instead of a global protein embedding can the model incorporate this locality?"
        }
    },
    "9XAZBUfnefS": {
        "jbB2WgxJh7": {
            "0": "Strengths:\n+ The \"fill in the middle\" use case is very common in protein engineering, and such a model could indeed be very useful.",
            "1": "Weaknesses:\n+ The training setup choices seem somewhat limited: For example, it only allows one masked region in the middle.",
            "2": "Often, in protein engineering, there might be multiple segments for joint design.",
            "3": "There is a much more general version of this (e.g.",
            "4": "see CM3 https://arxiv.org/pdf/2201.07520.pdf).",
            "5": "+ The empirical results on fitness prediction seem worse than existing methods.",
            "6": "+ I'm unconvinced that secondary structure conservation is the best evaluation scheme.",
            "7": "What about sequence recovery or perplexity on the \"middle\" sequence?"
        },
        "pH6kRl8-Meq": {
            "0": "Strengths\n- The FIM paradigm was not applied to pLMs so far.",
            "1": "Weaknesses\n- No clear performance improvement over the ProGen baseline.",
            "2": "- The comparison to ProGen-large does not prove that FIM is more efficient per parameter.",
            "3": "You should compare to an autogressive pLM of equal size without the FIM task to show that.",
            "4": "- If I understand correcty, also XLNet-style models should be capable of generating sequences with bidirectional context.",
            "5": "Why is the ProtTrans XLNet model not considered?",
            "6": "- ESM-1b is not SOTA for zero-shot fitness prediction.",
            "7": "Also, this evaluation again fails to prove that the parameter efficiency can be attributed to the FIM task.",
            "8": "Questions\n- The definition of the @k metrics is hard to follow.",
            "9": "Could it be expressed in a more straightforward way that directly explains what TP, FP, TN, FN are in the context?",
            "10": "- What is the reason for choosing a constructed secondary structure metric over perplexity?",
            "11": "Perplexity can directly measure how well the model captures the masked span.",
            "12": "- Does the alpha helix bias mean that the FIM residue SS does not really depend much on the surrounding context?",
            "13": "Additional comments\nIn the introductory session, describing directed evolution as \"random guessing or brute-force search\" doesn't capture its essence, as it is actually meant to avoid doing just that."
        },
        "wtpjbmHy4Q": {
            "0": "Strengths: \n1.",
            "1": "The article is well written and easy to understand.",
            "2": "Weaknesses: \n\n 1.",
            "3": "There are too few metrics for experimental evaluation.",
            "4": "Only P@k and R@k are included in evaluating infilling.",
            "5": "Some metrics provided in Progen2 can be used (e.g.",
            "6": "complexity).",
            "7": "2.",
            "8": "The method is not throughly evaluated.",
            "9": "The number of comparison methods is too small.",
            "10": "There are still a lot of related work on generative PLMs.",
            "11": "The performance of the model is similar to Progen-large, and the main advantage is that the model size is smaller.",
            "12": "Is it possible to add other models with different scales provided in Progen, especially small-scale models?",
            "13": "Then we can see whether ProtFIM still has an advantage over the models sharing similar scales.",
            "14": "3.",
            "15": "The evaluation requires the consistence of secondary structure between the generated protein and the original protein.",
            "16": "However, a new protein with better performance may have a different secondary structure.",
            "17": "Whether asking the generated protein is completely similar to the original one in secondary structure will affect the innovation of the model?",
            "18": "4.",
            "19": "It’s better to explain what (a) and (b) are in the caption of Figures 3 and 4.",
            "20": "In addition, Figure 4 (a), (b) are both “Precision”."
        },
        "jJrjJzMv0J": {
            "0": "- the paper provides a novel method for PLM especially suitable for sequence-based protein optimization.",
            "1": "- despite being a language model, the proposed architecture is relatively small in number of parameters which enables efficient use at test time and enables research for protein-engineering with limited computational resources.",
            "2": "- the additional experiments regarding the quality and the general analysis of the learnt representations are interesting, encouraging and informative.",
            "3": "*Weaknesses*:\n- For an ML conference there seems to be no technical novelty, neither fundamental, nor incremental.",
            "4": "The model is almost an exact copy of the standard LM with the addition of the structure constraint.",
            "5": "- The number of available protein (and non protein) language models are vast.",
            "6": "The paper only compares with one method while it could (and should have) compared with other PLMs but also possibly other language models with the same trick (moving the missing part to the end).",
            "7": "- the main results that is the goal of the work for protein engineering seem quite comparable with the only baseline that is used (ProGen)."
        }
    },
    "iaYcJKpY2B_": {
        "hS1y6g-lEM": {
            "0": "## Paper strengths and contributions\n**Motivation and intuition**\nThe motivation for multi-turn code generation is convincing.",
            "1": "The supervision of comments and programs is helpful for multi-turn program synthesis.",
            "2": "**Novelty**\nThe idea of utilizing weak supervision of interleaved patterns is intuitive and convincing.",
            "3": "This paper presents an effective way to make use of this idea.",
            "4": "**Technical contribution**\nCodegen for program synthesis seems effective, especially when the user wants to generate pieces of code from input/output examples or natural language descriptions.",
            "5": "**Clarity**\nThe overall writing is clear.",
            "6": "The authors utilize figures and tables well to illustrate the ideas.",
            "7": "Figure 1 clearly shows the code generation process.",
            "8": "**Related work**\nThe authors clearly describe the related prior works from both the perspectives of program synthesis, large language models, and benchmarks for program synthesis.",
            "9": "**Experimental results**\nThe presentation of the experimental results is clear.",
            "10": "Mainly, Table 4 provides understandable results showing that multi-turn specifications achieve better performance compared to single-turn specifications.",
            "11": "**Reproducibility**\nI believe reproducing the results is possible given the clear description provided in the main paper and the appendix.",
            "12": "## Paper weaknesses and questions\n\n**Code comment analysis** \nSome programmers like to write comments, while some are not.",
            "13": "Also, different programmers write comments very differently.",
            "14": "I suggest the authors investigate the effect of such differences.",
            "15": "One very simple way could be to analyze the occurrence frequency of interleaved natural and programming patterns in the dataset.",
            "16": "While it is hard to formally define meaningful comments, it would be insightful to at least calculate the document frequency of interleaved natural and programming language.",
            "17": "**Experiment setup**\nIn Table 3, the paper only compares the proposed method against GPT-Neo and GPT-J, which is not sufficient.",
            "18": "The result will stand out to compare against Codex, the state-of-the-art program synthesis model."
        },
        "jaByUUjSdS": {
            "0": "**Strengths:**\n- CodeGen model performs comparatively to Codex (12B) model and is open-sourced (unlike Codex).",
            "1": "So it should help facilitate future research in this area of AI for code.",
            "2": "- The results on how various pretraining datasets impacts the coding performance of the models is very interesting.",
            "3": "**Weaknesses:**\n- CodeGen model (single-turn) is only evaluated on a single dataset with only 164 problems.",
            "4": "Why is the model not evaluated on other publicly available coding datasets such as MBPP and APPS?",
            "5": "- While the multi-turn dataset helps the models generate more correct code, I am not sure about its practical use cases.",
            "6": "Would a user be able to specify the sub-tasks in the required format (such as defining appropriate variables) as in Figure 1?",
            "7": "- How does multi-turn task break down work for programs with control flow structures (for e.g.",
            "8": "write code for binary search)?",
            "9": "From the examples, it appears that the MTPB dataset treats small loops and branches as a single sub-task, but how can a user specify sub-tasks within a loop/branch?"
        },
        "FIzfCljkVP": {
            "0": "* (+) Training and releasing the models is in itself forms a substantial contribution to the field, enabling research groups with more limited resources to experiment on top of sound base models of significant sizes.",
            "1": "* (+) The multi-turn dataset is a valuable contribution towards practical neural program synthesis applications.",
            "2": "* (~) MTPB does not allow for \"going back\" (i.e., a user indicating that a generated response is wrong & clarifying their prompt).",
            "3": "* (-) MTPB (from a cursory qualitative evaluation of examples) seems to rely on very fine-grained prompts.",
            "4": "In many examples in App F, the prompts are substantially longer than the required code."
        },
        "R0ICL2zVI0": {
            "0": "# Strengths\n- The paper reports state-of-the-art results for the HumanEval benchmark for code generation from natural language specifications.",
            "1": "- The authors provide downloadable checkpoints for the trained models, which can be a useful resource for the community.",
            "2": "- The paper introduces a multi-turn natural language to code dataset where the natural language instructions are interleaved with the intended generated code.",
            "3": "# Weaknesses\n- The model is evaluated only on one existing dataset, HumanEval, and not other similar datasets like APPS or MBPP.",
            "4": "- While the work represents a significant expenditure of resources, the amount of technical novelty is relatively low, and some of the new aspects in the construction of the model itself are not studied or described as much as they could be:\n  - The \\textsc{BigPython} dataset seems responsible for much of the gains in the work, but the description of it in the paper is limited to \"We have compiled public, non-personal information from GitHub consisting of permissively licensed Python code in October 2021\".",
            "5": "- There is significant space dedicated to describing the TPU-based training setup with JAX, but not much about the reasoning behind it.",
            "6": "- The paper doesn't have much experiments about hyperparameters and training data selection (e.g.",
            "7": "the order in which the datasets were used for training), or further information/justification for the values used.",
            "8": "- There is no release of training datasets.",
            "9": "- The deduplication methodology used during dataset preprocessing may be too weak.",
            "10": "Only removing exact duplicate files may still leave many files which are very similar (for example, varying only in some comments at the top of the file).",
            "11": "For more discussion on another code dataset, see https://twitter.com/miltos1/status/1497126435261083649\n- Considering that copies of the HumanEval dataset may have been posted to GitHub, the authors should investigate the possibility of training dataset contamination."
        }
    },
    "D7srTrGhAs": {
        "nhd1ymtNW-": {
            "0": "Strengths:\n* An efficient distillation method is proposed that leverages both KD and pruning\n* Experiments are realistic, and show the superiority of the proposed method compared to the SOTA baselines\n* Latent space mapping/alignment is done elegantly via a learned weight matrix\n\nWeaknesses:\n* Reported medians over 5 runs, no standard deviations: how robust is the method?",
            "1": "* Table 2 could be presented visually"
        },
        "TPuaa__W3bl": {
            "0": "The proposed method is simple yet effective, good performance are obtained according to experiments;\n\nThe paper is easy to follow;\n\nHowever, the proposed method has limited novelty, it is based on some existing methods;\n\nIt would be nice if the authors can provide a comprehensive comparison of computation cost/time between the proposed method and previous methods;\n\nWhy results of model with 66M parameters is not reported in Table 3?",
            "1": "Please adjust the position of Table 2, Table 3 and the paragraph between the two tables.",
            "2": "Some related works are suggested to be compared.",
            "3": "[1].",
            "4": "Multi-Granularity Structural Knowledge Distillation for Language Model Compression.",
            "5": "Chang Liu, Chongyang Tao, Jiazhan Feng, Dongyan Zhao\n\n[2].",
            "6": "BERT Learns to Teach: Knowledge Distillation with Meta Learning.",
            "7": "Wangchunshu Zhou, Canwen Xu, Julian McAuley.",
            "8": "[3].",
            "9": "LRC-BERT: Latent-representation Contrastive Knowledge Distillation for Natural Language Understanding.",
            "10": "Hao Fu, Shaojun Zhou, Qihong Yang, Junjie Tang, Guiquan Liu, Kaikui Liu, Xiaolong Li.",
            "11": "[4].",
            "12": "MixKD: Towards Efficient Distillation of Large-scale Language Models.",
            "13": "Kevin J Liang, Weituo Hao, Dinghan Shen, Yufan Zhou, Weizhu Chen, Changyou Chen, Lawrence Carin."
        },
        "9amM0PJPZIs": {
            "0": "strength:\n* HomoDistill illustrates advantageous performance over other distillation methods like TinyBERT.",
            "1": "* The combination of pruning and distillation in task-agnostic setting seems novel.",
            "2": "weakness:\n* A comparison with other prune & distill methods such as (Xu et al., 2021; Xia et al., 2022) would make this submission more complete.",
            "3": "* Please also discuss the difference between HomoDistill and [1], which presents a similar method for vision tasks, where a teacher model is slimmed into a small student model while distilling it.",
            "4": "[1] Slimmable Neueral Networks, ICLR 2019."
        }
    },
    "9y0HFvaAYD6": {
        "nrAndG3iRK": {
            "0": "Strength:\n\n* the method is quite novel and experimental results seem strong\n\nWeakness:\n\n* The explanation and presentation of the methodology is complicated and can be reduced.",
            "1": "* More experiments of other language pairs, like french, and low-resource languages (like FLoRes) are needed to confirm the method extendability and generalization."
        },
        "7VRplrynPR1": {
            "0": "Strength:\n\n1.",
            "1": "This method explicitly models when to start translating and generating target words;\n2.",
            "2": "Ablation experiments verified the key operations of the proposed HMT;\n3.",
            "3": "This study reported that the proposed HMT improves the translation performance on two offline SiMT datasets.",
            "4": "Weaknesses：\n1.",
            "5": "The training/inference speeds are lower than those of the Wait-k method, which is a disadvantage for SiMT;\n2.",
            "6": "The interaction and relationship between the proposed HMT and the read/write policy were not clearly introduced;\n3.",
            "7": "Too many hyperparameters (i.e., L、K、Lamda1, and Lamda2) are not conducive to the optimization of this method on other language pairs;\n4.",
            "8": "There lack of necessary experiment to verify what the proposed HMT indeed capture compared to the baseline wait-k."
        },
        "FuSMhK4WaUe": {
            "0": "Strength:\n1.",
            "1": "The proposed HMT approach gained improvement over the baseline systems in terms of BLEU scores and latency.",
            "2": "2.",
            "3": "Experiments have proved the effectiveness of the method, and there are very reasonable expanded analyses.",
            "4": "Weaknesses:\nThe average pooling result on the hidden states of the received source is only a summary of the past state.",
            "5": "And this model didn't use an explicit alignment method.",
            "6": "Therefore, the proposed approach is more like a pruning method to cut low probability branches of the READ/WRITE path.",
            "7": "This doesn't quite match what the paper claims that explicitly models multiple possible moments of starting translating in both training and inference.",
            "8": "Questions:\n1.",
            "9": "How to evaluate the proposed method to make better read/write decisions than the other SNMT?",
            "10": "2.",
            "11": "If there is higher confidence in the later state, will the performance of the model be affected by generating too early?",
            "12": "3.",
            "13": "Can you provide an evaluation of the quality, clarity, and originality of the work?"
        },
        "hJQZ9weK6Bd": {
            "0": "Reasons to accept:\n- The methods produces latent inputs for the translation to boost latency, which is interesting and promising.",
            "1": "- The conducted experiments are extensive, providing in-depth analysis on how the proposed method works.",
            "2": "Questions:\n1.",
            "3": "Is the encoder in Full-Sentence MT bi-directional or uni-directional?",
            "4": "If uni-directional, an alternative paper should be cited instead the original Transformer paper.",
            "5": "2.",
            "6": "Why HMT even outperforms Full-Sentence MT in De->En?",
            "7": "Also in Section 5.3, I don't understand why Multiple is better than Max, where the latter always provides more information than the former when generating.",
            "8": "Could authors please provide more explanations?",
            "9": "3.",
            "10": "What is the system overhead (e.g., memory) of HMT compared to baselines?",
            "11": "Since HMT produces K states for each timestep, and self attentions are conducted on these multiple states, the memory requirements for SA would be K^2 compared to vanilla models.",
            "12": "This could be a concern for edge devices.",
            "13": "Missing reference:\nLiu D, Du M, Li X, et al.",
            "14": "Cross attention augmented transducer networks for simultaneous translation[C]//Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing.",
            "15": "2021: 39-55."
        }
    },
    "RnH_0iL4xao": {
        "01poQz9pXG2": {
            "0": "Strengths\n- the paper identifies that previous attempts at interpreting MLMs as MRFs may not be faithful, in the sense that unary conditionals may not match.",
            "1": "- the paper improves the 'faithfulness' of the joint distribution via a learned interaction layer which allows modeling the joint with just one evaluation pass (by using a mixing function and the independent unary conditionals).",
            "2": "Weaknesses\n- the contribution only focus on pairwise MRFs, which seems incremental.",
            "3": "Why not generalize to cliques of size k for some small k, or arbitrary MRFs with low width?",
            "4": "Question\n- I had a question throughout the paper, not about this particular paper but about the whole general direction of interpreting MLM as MRFs.",
            "5": "It seems that we are jumping through a lot of hoops to define a MRF, find joint distributions with faithful conditionals, run expensive inference, etc.... Can't we simply use the MLM unary conditionals directly in an autoregressive way and avoid all of this trouble?",
            "6": "E.g.",
            "7": "see https://arxiv.org/abs/2110.02037 https://arxiv.org/abs/2205.13554"
        },
        "7lmQTdbzzoz": {
            "0": "Pros\n\n* Showing that distributions defined with two masked tokens do not define unary distributions close to that of the original MLM\n* Proposal of statistically founded methods to answer this problem\n* Proposal of an algorithmic solution to give a proxy\n\nCons\n\n* The motivations are not clear at least to me"
        },
        "89E0ngo98J": {
            "0": "See summary of the review below."
        }
    },
    "vw-5EgYbJZr": {
        "a_DDBfLXY8G": {
            "0": "The proposed non-monotonic self-terminating model (Definition 6) is interesting!",
            "1": "I would have liked to see a more thorough discussion and motivation of this model.",
            "2": "Most of the methods section is dedicated to background and re-iteration of ideas developed in Welleck et al.",
            "3": "(2020) and little room remains to expand upon the core contribution of this work.",
            "4": "The results on WikiText-2 are encouraging.",
            "5": "Self-termination is achieved without a sacrificing perplexity.",
            "6": "This contrasts with the monotonic models, which achieve self-termination at some cost to perplexity.",
            "7": "The WikiText-103 evaluation with GPT-2 is more nuanced, because the 1000-token sequence length appears to be too short to properly evaluate self-termination.",
            "8": "That said, again on WikiText-103 we see that perplexity is maintained compared to the baseline model: again, encouraging.",
            "9": "==== Questions ====\n\nHow well calibrated is the proposed model to sequence lengths?",
            "10": "Let's ask this question for WikiText-2 because I understand that the limited context of gpt2 makes this difficult in the WikiText-103 experiments.",
            "11": "Figure 2 suggests to me that choosing epsilon is a strong bias towards generating sequences of a particular length.",
            "12": "Intuitively, I also find this behavior plausible just thinking about Definition 6.",
            "13": "If you are not well-calibrated, then following up on the previous question: if you choose epsilon to calibrate the expected sequence length to the data distribution, do you still achieve reasonable perplexities?",
            "14": "And furthermore, if you are able to calibrate the expected sequence length, is the variance of generated sequences reasonable compared to the data distribution or does it cluster tightly around the mean?",
            "15": "Basically I am concerned about whether Definition 6 imposes a strong bias towards generating sequences of a particular length.",
            "16": "If that is the case, I feel that it would warrant acknowledgement and more nuanced discussion.",
            "17": "Edit: My concerns raised in these questions have been thoroughly and satisfactorily addressed by the authors.",
            "18": "I have updated my score to reflect this response."
        },
        "7reYOpmDHm": {
            "0": "Strengths: well written paper, the intro and equations.",
            "1": "Weaknesses: the evaluation section has 2 experiments, but only 2 very insightful detailed examples.",
            "2": "The paper can use a few more examples to illustrate more differences of the output sequences.",
            "3": "This would allow the reader to internalize how the non-monotonicity in a deeper way.",
            "4": "Questions:\nIn details, how does the decoding algorithm actually avoid repetitions?",
            "5": "In other way, how does other models actually degrade validation perplexity using their decoding algorithm?",
            "6": "Typos, Grammar, etc.",
            "7": ":\nPage 7, section 4.2, par.",
            "8": "2: the callout to table 5 should go to table 3, instead.",
            "9": "Page 7, section 5, last par.",
            "10": ": figure 6 callout is not directing properly"
        },
        "TY4Y7C5f_G": {
            "0": "**Strengths** I find the non-monotonic termination an interesting problem and the convex combination with a monotonically increasing lower-point a nice way of formulating the problem.",
            "1": "**Weaknesses** There are a few places that need more clarification.",
            "2": "1.",
            "3": "Could you discuss how practical is your approach given that all recent LLMs excel at generating sequences, as also GPT-2 results being close to NMST?",
            "4": "I would be interested in seeing if the same model also helps a downstream task such as summarization but I also believe that is not necessarily within the scope of your work.",
            "5": "2.",
            "6": "What is the intuition behind using a sigmoid interpolation rather than using a modified softmax where you use the probability of `<eos>` as the coefficient?",
            "7": "Like, In Eq.",
            "8": "(10), you can use `1-softmax(<eos>)` and `softmax(<eos>)`.",
            "9": "This formulation could be more natural as the language model is already trained to optimize for the softmax distribution.",
            "10": "3.",
            "11": "Could you apply your termination adjustment as a post-processing step?",
            "12": "Using the above `softmax(<eos>)` based interpolation should be doable as a post-processing step without any training.",
            "13": "4.",
            "14": "I think setting $\\epsilon$ properly is critical for the model to perform well but it is not clear how.",
            "15": "I also found sentences discussing / analyzing $\\epsilon$ confusing.",
            "16": "For example, in Table-1 you mention the results with $\\epsilon=1.0 x 10^{-5}$ is competitive but in text you mention it performs better.",
            "17": "You also mention that the same $\\epsilon$ in Table-2 gives better perplexity but the intervals between VA+ and NMST+ overlap.",
            "18": "Could you please explain how you derived that conclusion?",
            "19": "5.",
            "20": "Could you also discuss if your objective over-estimates the probability of `<eos>` for sequences of different lengths?",
            "21": "I think this would be a bigger issue in ST as it is monotonic but I am just curious if this is something that you observed.",
            "22": "A histogram of *predicted sequence length* vs *ground truth sequence length* would help.",
            "23": "6.",
            "24": "\"resepct\" --> \"respect\""
        },
        "NAMkJA-aa6J": {
            "0": "Strengths:\n\n+ The motivation is well-founded.",
            "1": "+ Proposed method is novel and builds upon previously proposed ST LM.",
            "2": "+ Experiments show that the proposed method works better than baselines and authors also show that non-monotonicity can better model the termination probability.",
            "3": "+ The ideas in the paper are very well presented and the writing is clear.",
            "4": "Weaknesses / Questions:\n\nI feel the proposed method is quite well formulated and presented and I have no reason to reject this work.",
            "5": "However, I feel some of the points should be addressed to further improve the quality of this work and make it well-rounded.",
            "6": "It is also understandable that asking authors to perform a huge amount of experiments during rebuttal is unfair.",
            "7": "Hence, not performing the experiments proposed below will not affect the paper's rating negatively.",
            "8": "- Experimentation is done for sequence completion tasks, and it shows that the proposed method can perform better than vanilla models with the correct choice of hyperparameters.",
            "9": "However, I would further like to know the performance of self-terminating language models on other language tasks such as Machine Translation, Question Answering.",
            "10": "The motivation behind this inquiry is that since the probability of distribution of the vocabulary is being changed, it is important to see how this affects the model's performance in tasks where it has to be faithful to the given context.",
            "11": "- It would also be interesting to see how well this method integrates with some of the guided decoding algorithms such as [Krause et al., Findings 2021](https://aclanthology.org/2021.findings-emnlp.424)."
        }
    },
    "AtWKqgziLF": {
        "i6F9W1onYIj": {
            "0": "[Strengths]\nThe idea of incorporating entity information into the generator is an important one.",
            "1": "Existing methods for generating news articles, like GROVER, usually take in a title and generate the article based on that (and maybe the source it is supposed to be from).",
            "2": "The article, however, fails to mention critical entities that would be mentioned in an article about that subject, making the generated article less realistic.",
            "3": "By incorporating entity information into the generator, the model is able to generate more realistic articles.",
            "4": "Similarly, the authors attempt to integrate \"image information\".",
            "5": "The authors argue that news image captions are different from typical image captioning in that the captions are much less visually grounded.",
            "6": "The authors argue that directly integrating visual features is not idea and instead also condition their article generator on the captions.",
            "7": "In this way, the generated article is much more likely to be related to the visual content paired with it.",
            "8": "Experimentally, the authors demonstrate that their method is better able to fool humans and the machine discriminator, suggesting that the articles it generates are more naturally.",
            "9": "The authors also demonstrate impressive gains in perplexity in their experiments and the qualitative results bear out the quality of the generation.",
            "10": "[Weaknesses]\nThere are a number of weaknesses of the proposed approach.",
            "11": "The model is in some sense an extension to methods like GROVER.",
            "12": "GROVER is quite similar to the proposed method in that GROVER trains a news article generator conditioned on metadata.",
            "13": "In this paper, the authors essentially just re-train GROVER, but now add two additional metadata fields to the conditioning - one is the list of entities to be mentioned and the other is the *ground truth* image caption.",
            "14": "From a technical perspectivie, there is little novelty to this approach.",
            "15": "All the authors are doing is retraining GROVER using additional conditioning.",
            "16": "Their is no novelty in the learning scheme, despite their being room for it.",
            "17": "For example, in the learning process used by ENGIN, no loss constraints enforce that ENGIN actually mentions all the named entities in the generated article.",
            "18": "People have typically tackled this problem by using pointer-networks or similar strategies to perform a copying of named entities from the input into the output.",
            "19": "The authors do not do this and it is unclear why not.",
            "20": "Moreover, there is a lack of explicit loss to enforce named entities to appear and to penalize the model for their not appearing, save the standard text generation loss.",
            "21": "Why don't authors enforce the model to actually use these entities and not ignore them?",
            "22": "Most importantly from my perspective is that critical related work is not cited.",
            "23": "The authors are not the first to condition news article generation on entities or visual information.",
            "24": "InfoSurgeon (Fung et al, ACL 2021, oral) presents a method for detecting machine generated news articles.",
            "25": "As part of the paper, the authors train a news article generation method.",
            "26": "The generator takes in a knowledge graph consisting of entities, relations between entities, events, as well as purely visual entities detected using image features as well as image events detected using imSitu.",
            "27": "In sum, the input to the model and its reliance on visual features is much richer than ENGIN.",
            "28": "As it stands, ENGIN relies on ground truth image captions to generate the article and incorporate visual information.",
            "29": "However, as it stands, the model is never able to mention facts that are purely observable visually - for example, maybe an image shows three people cheering but the caption and entity list don't mention this.",
            "30": "ENGIN is unable to make any such claim in the article text because it doesn't ingest any visual features.",
            "31": "I also am somewhat concerned at the way the paper claims to take in \"Image Information\" but doesn't actually make use of any purely visual features (objects, image events, etc.)",
            "32": "and instead relies on captions.",
            "33": "The CLIP-based NER mechanism is very simple.",
            "34": "The authors just use CLIP to take an image's embedding and retrieve a set of candidate entities.",
            "35": "Given that entities are a key component of your model, I would have expected a more rigorous or trained model to improve the entity selection mechanism."
        },
        "iVzUysws1J": {
            "0": "**Strengths**\n\n-- The proposed method is quite elegant and simple and is easy to extend by following works.",
            "1": "-- The entity retrieval method (using entity retrieval from a pretrained image-text model) makes the approach more generalizable and not dependent on a provided list of entities.",
            "2": "-- The empirical results show effectiveness of the model as it outperforms all the baselines.",
            "3": "-- The paper is clearly written and easy to follow\n\n**Weaknesses**\n\n-- While the application of named entities as additional metadata is novel to this domain, the same has been studied extensively in NLP literature.",
            "4": "It is a good observation that existing methods do not explicitly model named entities, but the technical novelty of the proposed solution is limited."
        },
        "2mEM4iunhrp": {
            "0": "This paper is well-written and easy to follow.",
            "1": "The idea is simple but intuitive.",
            "2": "Incorporating image information is very useful in article generation.",
            "3": "The authors conducted extensive experiments and ablation tests to demonstrate the effectiveness of the proposed framework.",
            "4": "Weaknesses: the proposed model only extracted the entity information from the image, while images contain various information out of entities.",
            "5": "I would suggest to add a discussion section to outlook how to fully use the image information in this task.",
            "6": "In addition, the way of entity-aware article generation is simple (this is not a weakness), but other structures to restrict/prioritize identified entities during the generation should also be tried."
        },
        "ElOfiiRKuX": {
            "0": "+ Strength\n  - The motivation of this paper is clear enough and it is interesting to introduce image and entity information in the article generation task.",
            "1": "Image information augmented NLU and NLG has been explored in many works [1,2,3].",
            "2": "-  The model proposed in this paper is simple and effective and achieves good results compared to the baselines.",
            "3": "+ Weaknesses\n  - Although the authors claim that image information is introduced, the model actually makes use of ground-truth captions and entities extracted from the article.",
            "4": "The image information is only used for CLIP to retrieve the relevant entities.",
            "5": "Thus, in my opinion, the utilization of images in this paper is too shallow and the ENGIN is more like a named entity-conditioned article generation work.",
            "6": "Also, how would it work if use textual information (metadata) instead of image information to retrieve related entities from the candidate entities?",
            "7": "- There are some details of the method that I don't understand well enough.",
            "8": "For example, \n     1.",
            "9": "In inference, the generated text may contain annotations of entity types, right?",
            "10": "then what do you do with these entity type annotations?",
            "11": "2.",
            "12": "Is the utilization of named entities reflected in two aspects?",
            "13": "The first is the generation conditioned on named entities.",
            "14": "The second is the annotation of named entities and their categories in the target sequence during training.",
            "15": "3.",
            "16": "When using image information for named entity retrieval, do you use entity names directly or construct specific prompts?",
            "17": "Can you further analyze and evaluate the performance of named entity retrieval based on oracle NEs.",
            "18": "- I think the statements are inaccurate in many places, e.g.",
            "19": "1.",
            "20": "'our key contribution is a novel Entity-aware mechanism to help our model recognize and predict the entity names in articles'.",
            "21": "The purpose of this paper is not to recognize entities.",
            "22": "This statement would be confusing.",
            "23": "2.",
            "24": "'captions and named entities extracted from images'.",
            "25": "I can't agree with the statement that the entities are extracted from the images, because the image information is only used to filter the entities recognized by Spacy.",
            "26": "3.",
            "27": "'existing methods model named entities uniformly with the other text, making the leverage of named entities less effective.'",
            "28": "Can you explain the reasons for this?",
            "29": "Or provide some experimental results to support it.",
            "30": "[1] Visualize Before You Write: Imagination-Guided Open-Ended Text Generation\n\n[2] Imagination-Augmented Natural Language Understanding\n\n[3] Visually-Augmented Language Modeling"
        },
        "eKI94S7rovg": {
            "0": "Strong & Weak:\n\nS1: It is novel to exploit image info in the form of textual entities extracted from it.",
            "1": "In this way, the info contained in image and article body is now in the same/homogeneous feature space to be input to the generation model.",
            "2": "The side effect is to explicitly alleviate the heterogeneity across the original text space and visual space in the input layer instead of the hidden layers.",
            "3": "This may make the learning of modality fusion easier.",
            "4": "Hope the authors can discuss furthermore from this perspective.",
            "5": "W1: One possible weakness in my own opinion: While the proposed ENGIE is a new method for article generation with image recommender, each of the individual piece of ENGIE (entities extraction by SpaCy Python library, ranking candidate entities by CLIP, standard controllable text generation model) is not new in itself and has been widely adopted in existing works as pointed out in the paper.",
            "6": "This may be not a big issue in practice, since ENGIE demonstrated a strong empirical result on three datasets."
        },
        "OXaI4MDZBTg": {
            "0": "Strength\n1.",
            "1": "The writing is clear and the proposed method seems straightforward and easy to implement.",
            "2": "Weaknesses\n1.",
            "3": "I’m strongly skeptical about the prospect of using this technology to generate news articles, as the authors seem to aim at.",
            "4": "Any words (especially nouns and verbs) hallucinated from the model instantly make the intended news article “fake news”.",
            "5": "See the example in Figure 5.",
            "6": "How much of the generated news article is true?",
            "7": "Did Lizaso actually say that?",
            "8": "This is also frightening as it sounds plausible (in a news article tone).",
            "9": "2.",
            "10": "The method lacks novelty.",
            "11": "The image information essentially is only used to extract name entities (the caption is provided)."
        }
    },
    "FvevdI0aA_h": {
        "JwdnoooEWOU": {
            "0": "### Strengths: \n- To the best of my knowledge, this is the first framework to unify debiasing and detoxifying tasks for open-ended generation.",
            "1": "- Authors have provided clear motivation and intuitions for most of the design choices.",
            "2": "Authors have conducted ablation studies to show the effectiveness of their approach.",
            "3": "### Weaknesses: \n\n- While the authors emphasize on unification, they use two different versions of attribute classifiers.",
            "4": "In particular, for debiasing, they use embedding vectors’s principal component but for detoxifying, they use PPLM’s classifier.",
            "5": "It’s not clear 1) why do we need two classifiers?",
            "6": "2) what gains do we get if we use PPLM’s classifier for both tasks.",
            "7": "- Authors suggest that their framework updates bias terms in only a few layers.",
            "8": "However, for debiasing, they update bias terms across all layers.",
            "9": "While they frame it as they do it because their framework is efficient, selecting a few bias terms to update is a non-trivial problem.",
            "10": "If we select top-k layers for bias update, we might get different results.",
            "11": "Authors don’t have any ablation study to show the effectiveness of selecting bias terms for a few layers.",
            "12": "- Authors mainly rely on perplexity as a proxy to measure quality of generations which is troublesome because 1) perplexity can’t be trusted as a generation quality metric.",
            "13": "2) authors use perplexity as a threshold.",
            "14": "Authors present human evaluation results on a subset but do not show correlation with their automated metrics which makes it hard to understand how trustworthy the results are?",
            "15": "- Multiple critical details are missing from the paper which makes it very difficult for an individual to reproduce the results presented in the paper.",
            "16": "- Authors construct their own dataset using publicly available BOLD dataset.",
            "17": "The exact dataset used for the experiments is not available in public which makes it difficult to reproduce the results presented in the paper.",
            "18": "- A word can be splitted into multiple subwords, it’s not clear how it’s being handled at attribute classifier level.",
            "19": "- Hyperparams used for generations are not defined.",
            "20": "Recent works [1, 2] show that decoding algorithm hyperparameters alone play a big role on generated text fairness and quality so it’s important to explicitly define these and ideally use a range of hyperparameters instead of a fixed set of hyperparmas.",
            "21": "References: \n-  [1] Akyürek, A. F., Kocyigit, M. Y., Paik, S., & Wijaya, D. (2022).",
            "22": "Challenges in Measuring Bias via Open-Ended Language Generation.",
            "23": "arXiv preprint arXiv:2205.11601.",
            "24": "-  [2]  Dhamala, J., Kumar, V., Gupta, R., Chang, K. W., & Galstyan, A.",
            "25": "(2022).",
            "26": "An Analysis of the Effects of Decoding Algorithms on Fairness in Open-Ended Language Generation.",
            "27": "arXiv preprint arXiv:2210.03826"
        },
        "9AXUFIAU1Wh": {
            "0": "Strengths:\n1.",
            "1": "Substantial empirical improvements over baselines, especially in the debiasing setup which are confirmed by human evaluation.",
            "2": "2.",
            "3": "Most individual losses proposed are simple and straightforward to implement.",
            "4": "Weaknesses:\n1.",
            "5": "The definition of bias is not clear.",
            "6": "In 3.1, bias is defined as the difference between f(.)",
            "7": "value of two outputs xi and xj generated by different prompts ci and cj.",
            "8": "It is not clear if this property is being measured per example or distributionally (the latter makes more sense but it is not clarified in the writing).",
            "9": "Additionally, why should it to be two different prompts with biased outputs that should be considered.",
            "10": "Shouldn't the goal be given a single prompt, the output should equally likely predict outputs related to either class (gender or race)?",
            "11": "2.",
            "12": "In 3.5, a threshold TH is defined to control for perplexity.",
            "13": "This threshold in practice is seems difficult to define properly in realistic settings since given the context length and the output sequence length, the perplexity can vary a lot.",
            "14": "3.",
            "15": "The writing is confusing in many places.",
            "16": "Multiple definitions of bias is being used without clarification (social bias vs the bias term in neural networks).",
            "17": "confusing notations with $x$ used to refer to both whole sequences and just tokens.",
            "18": "Questions:\n1.",
            "19": "What is the intuition behind using Hellinger distance instead of other distances?",
            "20": "2.",
            "21": "For evaluating global bias, how are ci and cj pairs selected?",
            "22": "Are there any restrictions placed on whether the prompts talk about the same topic/content?"
        },
        "dmFW4i721xJ": {
            "0": "Strengths:\n1.",
            "1": "The paper seeks to solve an important problem, and is well written and motivated until about Section 3.3.",
            "2": "2.",
            "3": "The approach, although quite expensive at inference time, avoids re-training the network.",
            "4": "3.",
            "5": "The token-level attribute classifier for debiasing based on similarities with the first principal components of attribute-specific terms is clever.",
            "6": "4.",
            "7": "Results on detoxification against DExperts which is a fairly strong baseline are impressive.",
            "8": "Weaknesses:\nThe main weakness of this paper is its presentation.",
            "9": "The paper's intro, related work, and motivation around the use of mutual information minimization as a tool to do both debiasing as well as mitigate toxic responses are great, but the paper after that seems to lose focus and branches off into two fairly different approaches for debiasing and detoxification.",
            "10": "These are my concerns about the presentation and structure\n\n1.",
            "11": "Reading appendix section D.2 was critical to my understanding of how the \"redo\" approach works - I would recommend moving it to the main body of the paper.",
            "12": "2.",
            "13": "Having a pseudo-code block detailing the overall approach after all of the sections (after 3.5) will help the presentation.",
            "14": "Right now it's not clear how each component comes together.",
            "15": "Specifically what components do detoxification and debiasing share and what is different?",
            "16": "Is one a token-level intervention but the other adopts an approach that re-generates things?",
            "17": "3.",
            "18": "It is unclear how your initial motivation around minimizing mutual information I(x;a) ties into the final formulation for both section 3.4 and 3.5.",
            "19": "There seems to be a disconnect in the presentation between sections 3.2, 3,3, and 3.4.",
            "20": "4.",
            "21": "The paper seems to be missing clear definitions of $p_{\\theta}$ and $p_{\\omega}$ and their parameterizations.",
            "22": "Clarification:\nIn Section 3.3, shouldn't we be comparing P(x|c) and P(x|a,c) rather than P (x|c) and P(x|a)?",
            "23": "Why is context conditioning missing when conditioning on an attribute?",
            "24": "You mention an approach for context-aware rectification but you do not seem to use it in the subsequent formulation."
        }
    }
}